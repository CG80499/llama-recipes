/mnt/cg-experimental/llama-recipes/llama_finetuning.py:11: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [06:19<12:39, 379.63s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [12:15<06:05, 365.94s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [16:03<00:00, 302.86s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [16:03<00:00, 321.31s/it]
/home/charlie/anaconda3/envs/llama_ft/lib/python3.10/site-packages/peft/utils/other.py:133: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
/home/charlie/anaconda3/envs/llama_ft/lib/python3.10/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
--> Model vicuna-13b-v1.5-verfier-v2-pretrain

--> vicuna-13b-v1.5-verfier-v2-pretrain has 328.09472 Million params

trainable params: 3,276,800 || all params: 13,019,141,120 || trainable%: 0.025169095025525
--> Training Set Length = 185
--> Validation Set Length = 50
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]/home/charlie/anaconda3/envs/llama_ft/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:45,  1.09it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:35,  1.34it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.49it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.57it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:27,  1.64it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:26,  1.64it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:26,  1.65it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:25,  1.65it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.63it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:24,  1.61it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.58it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.57it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.58it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.59it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.58it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.55it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.55it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.57it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.57it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.61it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:13<00:17,  1.62it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:16,  1.63it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:15,  1.64it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:15,  1.63it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:14,  1.64it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.63it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:13,  1.64it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:12,  1.63it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:18<00:12,  1.63it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:11,  1.62it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:10,  1.64it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:20<00:10,  1.61it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:09,  1.66it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:21<00:09,  1.64it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:22<00:08,  1.64it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:07,  1.65it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:23<00:07,  1.67it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:24<00:06,  1.65it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:24<00:06,  1.61it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:25<00:05,  1.59it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:05,  1.60it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:26<00:04,  1.60it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:27<00:03,  1.62it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.61it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:28<00:02,  1.63it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:29<00:01,  1.63it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:29<00:01,  1.64it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:30<00:00,  1.61it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.58it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.60it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6600)
Training Epoch0:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
Training Epoch0:   1%|[34m          [0m| 1/92 [00:03<05:35,  3.69s/it]Training Epoch0:   2%|[34mâ–         [0m| 2/92 [00:06<05:09,  3.44s/it]Training Epoch0:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:58,  3.35s/it]Training Epoch0:   4%|[34mâ–         [0m| 4/92 [00:13<04:49,  3.29s/it]Training Epoch0:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:43,  3.26s/it]Training Epoch0:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.26s/it]Training Epoch0:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:37,  3.27s/it]Training Epoch0:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:32,  3.25s/it]Training Epoch0:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:29,  3.24s/it]Training Epoch0:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:25,  3.24s/it]Training Epoch0:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:25,  3.28s/it]Training Epoch0:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.30s/it]Training Epoch0:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.29s/it]Training Epoch0:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:16,  3.29s/it]Training Epoch0:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:12,  3.27s/it]Training Epoch0:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:07,  3.25s/it]Training Epoch0:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:05,  3.28s/it]Training Epoch0:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.30s/it]Training Epoch0:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.28s/it]Training Epoch0:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.28s/it]Training Epoch0:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.30s/it]Training Epoch0:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.29s/it]Training Epoch0:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.29s/it]Training Epoch0:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:43,  3.29s/it]Training Epoch0:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:37,  3.25s/it]Training Epoch0:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:34,  3.26s/it]Training Epoch0:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:30,  3.24s/it]Training Epoch0:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:27,  3.23s/it]Training Epoch0:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:24,  3.24s/it]Training Epoch0:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:20,  3.24s/it]Training Epoch0:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:17,  3.24s/it]Training Epoch0:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:14,  3.24s/it]Training Epoch0:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:12,  3.27s/it]Training Epoch0:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:10,  3.28s/it]Training Epoch0:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:06,  3.28s/it]Training Epoch0:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:03,  3.27s/it]Training Epoch0:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:59,  3.27s/it]Training Epoch0:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:57,  3.28s/it]Training Epoch0:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:54,  3.28s/it]Training Epoch0:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:50,  3.27s/it]Training Epoch0:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:47,  3.29s/it]Training Epoch0:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:43,  3.28s/it]Training Epoch0:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:40,  3.29s/it]Training Epoch0:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:37,  3.28s/it]Training Epoch0:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.26s/it]Training Epoch0:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:30,  3.28s/it]Training Epoch0:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.30s/it]Training Epoch0:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:23,  3.26s/it]Training Epoch0:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:19,  3.24s/it]Training Epoch0:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:16,  3.25s/it]Training Epoch0:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:14,  3.28s/it]Training Epoch0:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:11,  3.28s/it]Training Epoch0:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:08,  3.29s/it]Training Epoch0:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:04,  3.28s/it]Training Epoch0:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:01,  3.29s/it]Training Epoch0:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:57,  3.28s/it]Training Epoch0:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:54,  3.26s/it]Training Epoch0:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:09<01:50,  3.25s/it]Training Epoch0:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:47,  3.25s/it]Training Epoch0:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:43,  3.23s/it]Training Epoch0:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:40,  3.25s/it]Training Epoch0:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:22<01:37,  3.27s/it]Training Epoch0:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:34,  3.26s/it]Training Epoch0:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:31,  3.28s/it]Training Epoch0:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:32<01:27,  3.25s/it]Training Epoch0:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.28s/it]Training Epoch0:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:21,  3.27s/it]Training Epoch0:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:18,  3.29s/it]Training Epoch0:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:45<01:15,  3.30s/it]Training Epoch0:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:12,  3.29s/it]Training Epoch0:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:09,  3.31s/it]Training Epoch0:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:55<01:06,  3.34s/it]Training Epoch0:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:03,  3.33s/it]Training Epoch0:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<01:00,  3.34s/it]Training Epoch0:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:05<00:56,  3.34s/it]Training Epoch0:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:53,  3.34s/it]Training Epoch0:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.32s/it]Training Epoch0:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:46,  3.30s/it]Training Epoch0:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:43,  3.33s/it]Training Epoch0:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:40,  3.34s/it]Training Epoch0:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:37,  3.37s/it]Training Epoch0:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:33,  3.37s/it]Training Epoch0:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.33s/it]Training Epoch0:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.32s/it]Training Epoch0:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.31s/it]Training Epoch0:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.31s/it]Training Epoch0:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.31s/it]Training Epoch0:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.32s/it]Training Epoch0:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.32s/it]Training Epoch0:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.33s/it]Training Epoch0:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.34s/it]Training Epoch0: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.34s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch0: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 0.5595178604125977

 step 1 is completed and loss is 1.4221864938735962

 step 2 is completed and loss is 0.18083126842975616

 step 3 is completed and loss is 1.5720305442810059

 step 4 is completed and loss is 1.6690700054168701

 step 5 is completed and loss is 0.4338095486164093

 step 6 is completed and loss is 1.610959768295288

 step 7 is completed and loss is 0.5237876772880554

 step 8 is completed and loss is 0.49641087651252747

 step 9 is completed and loss is 0.7918095588684082

 step 10 is completed and loss is 0.7544273138046265

 step 11 is completed and loss is 1.7186362743377686

 step 12 is completed and loss is 0.6905558705329895

 step 13 is completed and loss is 0.7043694853782654

 step 14 is completed and loss is 0.23934577405452728

 step 15 is completed and loss is 0.54547518491745

 step 16 is completed and loss is 0.37810376286506653

 step 17 is completed and loss is 0.5354334115982056

 step 18 is completed and loss is 0.5729042291641235

 step 19 is completed and loss is 0.12059365212917328

 step 20 is completed and loss is 0.7018446326255798

 step 21 is completed and loss is 0.2969471216201782

 step 22 is completed and loss is 0.7507295608520508

 step 23 is completed and loss is 0.7888420224189758

 step 24 is completed and loss is 0.12301699072122574

 step 25 is completed and loss is 0.5815065503120422

 step 26 is completed and loss is 0.25224146246910095

 step 27 is completed and loss is 0.34328556060791016

 step 28 is completed and loss is 0.21384932100772858

 step 29 is completed and loss is 0.25936415791511536

 step 30 is completed and loss is 0.7759418487548828

 step 31 is completed and loss is 0.5850973725318909

 step 32 is completed and loss is 0.4648166298866272

 step 33 is completed and loss is 0.4871620535850525

 step 34 is completed and loss is 0.9551944136619568

 step 35 is completed and loss is 0.7212685346603394

 step 36 is completed and loss is 0.6999504566192627

 step 37 is completed and loss is 0.17784267663955688

 step 38 is completed and loss is 0.6217879056930542

 step 39 is completed and loss is 0.5000470876693726

 step 40 is completed and loss is 0.12586992979049683

 step 41 is completed and loss is 0.4591911733150482

 step 42 is completed and loss is 0.20434460043907166

 step 43 is completed and loss is 0.5653718709945679

 step 44 is completed and loss is 0.13797472417354584

 step 45 is completed and loss is 0.13697783648967743

 step 46 is completed and loss is 0.7951779365539551

 step 47 is completed and loss is 1.244494080543518

 step 48 is completed and loss is 0.060126714408397675

 step 49 is completed and loss is 0.23241806030273438

 step 50 is completed and loss is 0.41340574622154236

 step 51 is completed and loss is 0.39463546872138977

 step 52 is completed and loss is 1.9062705039978027

 step 53 is completed and loss is 0.1604299545288086

 step 54 is completed and loss is 0.7251237630844116

 step 55 is completed and loss is 0.08381165564060211

 step 56 is completed and loss is 0.16305813193321228

 step 57 is completed and loss is 1.0130069255828857

 step 58 is completed and loss is 0.12555533647537231

 step 59 is completed and loss is 0.23834621906280518

 step 60 is completed and loss is 1.634890079498291

 step 61 is completed and loss is 0.5457164645195007

 step 62 is completed and loss is 2.6587319374084473

 step 63 is completed and loss is 0.45056217908859253

 step 64 is completed and loss is 1.5215038061141968

 step 65 is completed and loss is 0.8920208215713501

 step 66 is completed and loss is 0.48215699195861816

 step 67 is completed and loss is 0.8062954545021057

 step 68 is completed and loss is 0.5422661304473877

 step 69 is completed and loss is 0.7933857440948486

 step 70 is completed and loss is 0.7193936705589294

 step 71 is completed and loss is 0.8680043816566467

 step 72 is completed and loss is 0.23119477927684784

 step 73 is completed and loss is 0.20526248216629028

 step 74 is completed and loss is 0.08249644935131073

 step 75 is completed and loss is 0.46032965183258057

 step 76 is completed and loss is 0.2144191563129425

 step 77 is completed and loss is 0.05401226878166199

 step 78 is completed and loss is 0.03572440892457962

 step 79 is completed and loss is 1.225885033607483

 step 80 is completed and loss is 1.302988052368164

 step 81 is completed and loss is 0.4247584939002991

 step 82 is completed and loss is 1.780139446258545

 step 83 is completed and loss is 0.40375855565071106

 step 84 is completed and loss is 0.12244952470064163

 step 85 is completed and loss is 0.5110175609588623

 step 86 is completed and loss is 0.05040891841053963

 step 87 is completed and loss is 0.4098052978515625

 step 88 is completed and loss is 1.7931022644042969

 step 89 is completed and loss is 1.6579258441925049

 step 90 is completed and loss is 0.39127469062805176

 step 91 is completed and loss is 0.06812689453363419
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:32,  1.52it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.45it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.46it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.48it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.55it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.53it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.50it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.49it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:25,  1.52it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.49it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.49it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.47it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:20,  1.53it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.59it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.56it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.53it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.50it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.49it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.47it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.49it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.53it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.50it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.50it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.48it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.47it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.51it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.50it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.48it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.52it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.53it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.48it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.47it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.44it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.43it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.46it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.48it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.50it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
we are about to save the PEFT modules
PEFT modules are saved in FT-vicuna-13b-v1.5-verifier-v2 directory
best eval accuracy on epoch 0 is 0.6000000238418579
Epoch 1: train_perplexity=1.8855, train_epoch_loss=0.6342, epcoh time 302.896638014s
Training Epoch1:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch1:   1%|[34m          [0m| 1/92 [00:03<05:00,  3.30s/it]Training Epoch1:   2%|[34mâ–         [0m| 2/92 [00:06<04:52,  3.25s/it]Training Epoch1:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:48,  3.24s/it]Training Epoch1:   4%|[34mâ–         [0m| 4/92 [00:12<04:42,  3.21s/it]Training Epoch1:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:39,  3.22s/it]Training Epoch1:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:37,  3.23s/it]Training Epoch1:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:35,  3.24s/it]Training Epoch1:   9%|[34mâ–Š         [0m| 8/92 [00:25<04:32,  3.25s/it]Training Epoch1:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:28,  3.24s/it]Training Epoch1:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.27s/it]Training Epoch1:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:25,  3.28s/it]Training Epoch1:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.29s/it]Training Epoch1:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.30s/it]Training Epoch1:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.30s/it]Training Epoch1:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.31s/it]Training Epoch1:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:12,  3.32s/it]Training Epoch1:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:09,  3.33s/it]Training Epoch1:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.32s/it]Training Epoch1:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:01,  3.31s/it]Training Epoch1:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:57,  3.30s/it]Training Epoch1:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:56,  3.33s/it]Training Epoch1:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:53,  3.33s/it]Training Epoch1:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:49,  3.33s/it]Training Epoch1:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:48,  3.36s/it]Training Epoch1:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:45,  3.36s/it]Training Epoch1:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:39,  3.32s/it]Training Epoch1:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:35,  3.32s/it]Training Epoch1:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.31s/it]Training Epoch1:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:28,  3.30s/it]Training Epoch1:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:25,  3.32s/it]Training Epoch1:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.31s/it]Training Epoch1:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:17,  3.30s/it]Training Epoch1:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:15,  3.31s/it]Training Epoch1:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:09,  3.28s/it]Training Epoch1:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:07,  3.29s/it]Training Epoch1:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:05,  3.31s/it]Training Epoch1:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.31s/it]Training Epoch1:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.30s/it]Training Epoch1:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:52,  3.26s/it]Training Epoch1:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:50,  3.27s/it]Training Epoch1:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:46,  3.27s/it]Training Epoch1:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:44,  3.30s/it]Training Epoch1:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:42,  3.31s/it]Training Epoch1:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:38,  3.30s/it]Training Epoch1:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:34,  3.28s/it]Training Epoch1:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:31,  3.30s/it]Training Epoch1:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.31s/it]Training Epoch1:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.30s/it]Training Epoch1:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.31s/it]Training Epoch1:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:19,  3.33s/it]Training Epoch1:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:16,  3.32s/it]Training Epoch1:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:12,  3.30s/it]Training Epoch1:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.31s/it]Training Epoch1:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:04,  3.27s/it]Training Epoch1:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:00,  3.25s/it]Training Epoch1:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:57,  3.27s/it]Training Epoch1:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:54,  3.28s/it]Training Epoch1:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:51,  3.28s/it]Training Epoch1:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.32s/it]Training Epoch1:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:45,  3.29s/it]Training Epoch1:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.30s/it]Training Epoch1:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:38,  3.28s/it]Training Epoch1:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:35,  3.29s/it]Training Epoch1:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:32,  3.29s/it]Training Epoch1:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.29s/it]Training Epoch1:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.30s/it]Training Epoch1:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.32s/it]Training Epoch1:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.32s/it]Training Epoch1:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.35s/it]Training Epoch1:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:13,  3.36s/it]Training Epoch1:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:10,  3.35s/it]Training Epoch1:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.35s/it]Training Epoch1:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:03,  3.36s/it]Training Epoch1:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<01:00,  3.37s/it]Training Epoch1:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:57,  3.39s/it]Training Epoch1:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:54,  3.39s/it]Training Epoch1:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:50,  3.37s/it]Training Epoch1:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.35s/it]Training Epoch1:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.36s/it]Training Epoch1:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:40,  3.35s/it]Training Epoch1:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.32s/it]Training Epoch1:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.32s/it]Training Epoch1:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.32s/it]Training Epoch1:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.28s/it]Training Epoch1:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.33s/it]Training Epoch1:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.30s/it]Training Epoch1:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.35s/it]Training Epoch1:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.35s/it]Training Epoch1:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:10,  3.35s/it]Training Epoch1:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.35s/it]Training Epoch1:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.38s/it]Training Epoch1: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.36s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch1: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 1.3548991680145264

 step 1 is completed and loss is 0.9585604667663574

 step 2 is completed and loss is 0.7533938884735107

 step 3 is completed and loss is 0.9409323930740356

 step 4 is completed and loss is 0.8625229597091675

 step 5 is completed and loss is 0.9790037870407104

 step 6 is completed and loss is 0.707552433013916

 step 7 is completed and loss is 0.6410567760467529

 step 8 is completed and loss is 0.5131034851074219

 step 9 is completed and loss is 0.7824002504348755

 step 10 is completed and loss is 0.6226969361305237

 step 11 is completed and loss is 1.4066909551620483

 step 12 is completed and loss is 0.5051171183586121

 step 13 is completed and loss is 0.45310595631599426

 step 14 is completed and loss is 0.7519140243530273

 step 15 is completed and loss is 0.6652992367744446

 step 16 is completed and loss is 0.411235511302948

 step 17 is completed and loss is 0.5604822635650635

 step 18 is completed and loss is 0.5714859962463379

 step 19 is completed and loss is 0.4963722229003906

 step 20 is completed and loss is 0.4915741980075836

 step 21 is completed and loss is 0.36644384264945984

 step 22 is completed and loss is 0.5876461267471313

 step 23 is completed and loss is 0.5674592852592468

 step 24 is completed and loss is 0.21420016884803772

 step 25 is completed and loss is 0.5624884963035583

 step 26 is completed and loss is 0.37441158294677734

 step 27 is completed and loss is 0.5816479325294495

 step 28 is completed and loss is 0.2433260828256607

 step 29 is completed and loss is 0.19908377528190613

 step 30 is completed and loss is 0.45802921056747437

 step 31 is completed and loss is 0.6729006767272949

 step 32 is completed and loss is 0.34495246410369873

 step 33 is completed and loss is 0.13780567049980164

 step 34 is completed and loss is 0.49139806628227234

 step 35 is completed and loss is 0.17990842461585999

 step 36 is completed and loss is 0.3282279968261719

 step 37 is completed and loss is 0.1332138180732727

 step 38 is completed and loss is 0.30989477038383484

 step 39 is completed and loss is 0.20679941773414612

 step 40 is completed and loss is 0.036338966339826584

 step 41 is completed and loss is 0.17152158915996552

 step 42 is completed and loss is 0.06121240556240082

 step 43 is completed and loss is 0.17923186719417572

 step 44 is completed and loss is 0.02946876734495163

 step 45 is completed and loss is 0.014551316387951374

 step 46 is completed and loss is 0.10147211700677872

 step 47 is completed and loss is 1.2382477521896362

 step 48 is completed and loss is 0.011144056916236877

 step 49 is completed and loss is 0.017446625977754593

 step 50 is completed and loss is 0.03253331035375595

 step 51 is completed and loss is 0.06250148266553879

 step 52 is completed and loss is 2.843214511871338

 step 53 is completed and loss is 0.034213725477457047

 step 54 is completed and loss is 0.1255144476890564

 step 55 is completed and loss is 0.04049467667937279

 step 56 is completed and loss is 0.042561955749988556

 step 57 is completed and loss is 1.078656792640686

 step 58 is completed and loss is 0.056166812777519226

 step 59 is completed and loss is 0.26344019174575806

 step 60 is completed and loss is 1.6603820323944092

 step 61 is completed and loss is 0.1248076930642128

 step 62 is completed and loss is 1.1514644622802734

 step 63 is completed and loss is 0.14005151391029358

 step 64 is completed and loss is 0.875964343547821

 step 65 is completed and loss is 0.6224689483642578

 step 66 is completed and loss is 0.27565208077430725

 step 67 is completed and loss is 0.7117148041725159

 step 68 is completed and loss is 0.28661084175109863

 step 69 is completed and loss is 0.49536770582199097

 step 70 is completed and loss is 0.47994866967201233

 step 71 is completed and loss is 0.5947446823120117

 step 72 is completed and loss is 0.16928859055042267

 step 73 is completed and loss is 0.1771739423274994

 step 74 is completed and loss is 0.12817804515361786

 step 75 is completed and loss is 0.37817317247390747

 step 76 is completed and loss is 0.1885281503200531

 step 77 is completed and loss is 0.06609003245830536

 step 78 is completed and loss is 0.11294633150100708

 step 79 is completed and loss is 0.7381882071495056

 step 80 is completed and loss is 0.5664366483688354

 step 81 is completed and loss is 0.32252103090286255

 step 82 is completed and loss is 1.162672758102417

 step 83 is completed and loss is 0.14451755583286285

 step 84 is completed and loss is 0.19527305662631989

 step 85 is completed and loss is 0.07485304772853851

 step 86 is completed and loss is 0.017429634928703308

 step 87 is completed and loss is 0.226638063788414

 step 88 is completed and loss is 1.4879266023635864

 step 89 is completed and loss is 1.6076979637145996

 step 90 is completed and loss is 0.14174778759479523

 step 91 is completed and loss is 0.03395778685808182
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:37,  1.31it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.44it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.47it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.48it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.52it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.48it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.50it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.51it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.47it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.47it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.46it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:25,  1.40it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.41it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:24,  1.40it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:23,  1.42it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.45it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:21,  1.45it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.46it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.47it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:19,  1.44it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.45it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:18,  1.44it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.42it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.43it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.45it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:15,  1.46it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.48it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.48it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:12,  1.49it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.56it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:10,  1.60it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.57it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.50it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.47it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.55it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.53it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.51it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.48it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.51it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.57it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.63it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.62it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.59it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.62it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.57it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.54it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.7400)
we are about to save the PEFT modules
PEFT modules are saved in FT-vicuna-13b-v1.5-verifier-v2 directory
best eval accuracy on epoch 1 is 0.7400000095367432
Epoch 2: train_perplexity=1.6166, train_epoch_loss=0.4803, epcoh time 304.9335419040003s
Training Epoch2:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch2:   1%|[34m          [0m| 1/92 [00:03<05:01,  3.31s/it]Training Epoch2:   2%|[34mâ–         [0m| 2/92 [00:06<04:55,  3.28s/it]Training Epoch2:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:58,  3.35s/it]Training Epoch2:   4%|[34mâ–         [0m| 4/92 [00:13<04:57,  3.38s/it]Training Epoch2:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:52,  3.37s/it]Training Epoch2:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:48,  3.36s/it]Training Epoch2:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:46,  3.37s/it]Training Epoch2:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:43,  3.37s/it]Training Epoch2:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:38,  3.36s/it]Training Epoch2:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:34,  3.35s/it]Training Epoch2:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:32,  3.37s/it]Training Epoch2:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:27,  3.35s/it]Training Epoch2:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.33s/it]Training Epoch2:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.33s/it]Training Epoch2:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:50<04:15,  3.31s/it]Training Epoch2:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:11,  3.31s/it]Training Epoch2:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:06,  3.29s/it]Training Epoch2:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [01:00<04:05,  3.32s/it]Training Epoch2:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:02,  3.33s/it]Training Epoch2:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.31s/it]Training Epoch2:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:53,  3.29s/it]Training Epoch2:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:49,  3.28s/it]Training Epoch2:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:46,  3.28s/it]Training Epoch2:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:43,  3.29s/it]Training Epoch2:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:40,  3.30s/it]Training Epoch2:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:37,  3.30s/it]Training Epoch2:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.30s/it]Training Epoch2:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:32,  3.32s/it]Training Epoch2:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.33s/it]Training Epoch2:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:26,  3.33s/it]Training Epoch2:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:22,  3.32s/it]Training Epoch2:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:19,  3.32s/it]Training Epoch2:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:15,  3.31s/it]Training Epoch2:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.31s/it]Training Epoch2:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:08,  3.31s/it]Training Epoch2:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:06,  3.32s/it]Training Epoch2:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.32s/it]Training Epoch2:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<03:01,  3.37s/it]Training Epoch2:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:57,  3.35s/it]Training Epoch2:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:53,  3.34s/it]Training Epoch2:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:49,  3.33s/it]Training Epoch2:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:46,  3.34s/it]Training Epoch2:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:44,  3.35s/it]Training Epoch2:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:40,  3.35s/it]Training Epoch2:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.33s/it]Training Epoch2:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:32,  3.32s/it]Training Epoch2:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:29,  3.33s/it]Training Epoch2:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:26,  3.33s/it]Training Epoch2:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:24,  3.35s/it]Training Epoch2:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:20,  3.34s/it]Training Epoch2:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:16,  3.32s/it]Training Epoch2:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:13,  3.33s/it]Training Epoch2:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:09,  3.31s/it]Training Epoch2:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:05,  3.29s/it]Training Epoch2:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:01,  3.28s/it]Training Epoch2:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<01:59,  3.31s/it]Training Epoch2:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:55,  3.30s/it]Training Epoch2:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.30s/it]Training Epoch2:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:49,  3.32s/it]Training Epoch2:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:45,  3.31s/it]Training Epoch2:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:42,  3.29s/it]Training Epoch2:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:38,  3.28s/it]Training Epoch2:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:35,  3.29s/it]Training Epoch2:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:31,  3.28s/it]Training Epoch2:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:28,  3.28s/it]Training Epoch2:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:25,  3.30s/it]Training Epoch2:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:22,  3.31s/it]Training Epoch2:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:20,  3.34s/it]Training Epoch2:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:16,  3.34s/it]Training Epoch2:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:13,  3.36s/it]Training Epoch2:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:10,  3.34s/it]Training Epoch2:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.31s/it]Training Epoch2:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:03,  3.32s/it]Training Epoch2:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<01:00,  3.33s/it]Training Epoch2:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:57,  3.38s/it]Training Epoch2:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:54,  3.39s/it]Training Epoch2:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:16<00:50,  3.38s/it]Training Epoch2:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:47,  3.38s/it]Training Epoch2:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:43,  3.33s/it]Training Epoch2:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:26<00:39,  3.32s/it]Training Epoch2:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:29<00:36,  3.33s/it]Training Epoch2:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.34s/it]Training Epoch2:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:36<00:30,  3.38s/it]Training Epoch2:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:27,  3.42s/it]Training Epoch2:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:43<00:23,  3.38s/it]Training Epoch2:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:46<00:20,  3.35s/it]Training Epoch2:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.32s/it]Training Epoch2:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:52<00:13,  3.34s/it]Training Epoch2:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:56<00:10,  3.34s/it]Training Epoch2:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.32s/it]Training Epoch2:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.31s/it]Training Epoch2: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch2: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.33s/it]

 step 0 is completed and loss is 0.9480898380279541

 step 1 is completed and loss is 0.8025592565536499

 step 2 is completed and loss is 0.8943423628807068

 step 3 is completed and loss is 0.907907247543335

 step 4 is completed and loss is 0.42240089178085327

 step 5 is completed and loss is 0.8518651127815247

 step 6 is completed and loss is 1.0966145992279053

 step 7 is completed and loss is 0.5440833568572998

 step 8 is completed and loss is 0.36175161600112915

 step 9 is completed and loss is 0.6827067136764526

 step 10 is completed and loss is 0.6510974168777466

 step 11 is completed and loss is 1.698122501373291

 step 12 is completed and loss is 0.330233097076416

 step 13 is completed and loss is 0.20800641179084778

 step 14 is completed and loss is 0.5515660047531128

 step 15 is completed and loss is 0.5286135077476501

 step 16 is completed and loss is 0.21083828806877136

 step 17 is completed and loss is 0.4776233434677124

 step 18 is completed and loss is 0.4001147747039795

 step 19 is completed and loss is 0.2715134024620056

 step 20 is completed and loss is 0.41687819361686707

 step 21 is completed and loss is 0.14126276969909668

 step 22 is completed and loss is 0.5829746723175049

 step 23 is completed and loss is 0.4417901337146759

 step 24 is completed and loss is 0.10707448422908783

 step 25 is completed and loss is 0.3707665205001831

 step 26 is completed and loss is 0.16052290797233582

 step 27 is completed and loss is 0.5336471796035767

 step 28 is completed and loss is 0.07886920124292374

 step 29 is completed and loss is 0.11025728285312653

 step 30 is completed and loss is 0.4431074857711792

 step 31 is completed and loss is 0.4360300302505493

 step 32 is completed and loss is 0.4120607376098633

 step 33 is completed and loss is 0.064842090010643

 step 34 is completed and loss is 0.5778005719184875

 step 35 is completed and loss is 0.19627134501934052

 step 36 is completed and loss is 0.3040938377380371

 step 37 is completed and loss is 0.19513435661792755

 step 38 is completed and loss is 0.3970154821872711

 step 39 is completed and loss is 0.5023757219314575

 step 40 is completed and loss is 0.06562715023756027

 step 41 is completed and loss is 0.14231443405151367

 step 42 is completed and loss is 0.11006796360015869

 step 43 is completed and loss is 0.09830985218286514

 step 44 is completed and loss is 0.06971339881420135

 step 45 is completed and loss is 0.06517381966114044

 step 46 is completed and loss is 0.24484696984291077

 step 47 is completed and loss is 0.5606752634048462

 step 48 is completed and loss is 0.02797113172709942

 step 49 is completed and loss is 0.11015615612268448

 step 50 is completed and loss is 0.037767067551612854

 step 51 is completed and loss is 0.057466376572847366

 step 52 is completed and loss is 0.8358135223388672

 step 53 is completed and loss is 0.06378528475761414

 step 54 is completed and loss is 0.26269441843032837

 step 55 is completed and loss is 0.059857696294784546

 step 56 is completed and loss is 0.0714927613735199

 step 57 is completed and loss is 0.48840847611427307

 step 58 is completed and loss is 0.013826824724674225

 step 59 is completed and loss is 0.1435694545507431

 step 60 is completed and loss is 0.4982699751853943

 step 61 is completed and loss is 0.15462829172611237

 step 62 is completed and loss is 0.1500246524810791

 step 63 is completed and loss is 0.04099801182746887

 step 64 is completed and loss is 0.7276991605758667

 step 65 is completed and loss is 0.5937766432762146

 step 66 is completed and loss is 0.0252265315502882

 step 67 is completed and loss is 0.939616858959198

 step 68 is completed and loss is 0.04567454010248184

 step 69 is completed and loss is 0.08807245641946793

 step 70 is completed and loss is 0.32573720812797546

 step 71 is completed and loss is 0.1025754064321518

 step 72 is completed and loss is 0.05600287765264511

 step 73 is completed and loss is 0.004981312435120344

 step 74 is completed and loss is 0.004484471864998341

 step 75 is completed and loss is 0.13651064038276672

 step 76 is completed and loss is 0.027708806097507477

 step 77 is completed and loss is 0.0017968341708183289

 step 78 is completed and loss is 0.06239325553178787

 step 79 is completed and loss is 0.47215449810028076

 step 80 is completed and loss is 0.5092669129371643

 step 81 is completed and loss is 0.043999895453453064

 step 82 is completed and loss is 0.8887327909469604

 step 83 is completed and loss is 0.039946943521499634

 step 84 is completed and loss is 0.4854837954044342

 step 85 is completed and loss is 0.009377598762512207

 step 86 is completed and loss is 0.0011124381562694907

 step 87 is completed and loss is 0.09529762715101242

 step 88 is completed and loss is 1.1980348825454712

 step 89 is completed and loss is 0.3441846966743469

 step 90 is completed and loss is 0.033208247274160385

 step 91 is completed and loss is 0.02620757557451725
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.46it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.46it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.43it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.48it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.54it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.49it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.49it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.44it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.44it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:27,  1.42it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.45it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.48it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.51it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.52it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.52it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.50it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.49it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.52it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.57it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:16,  1.60it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.59it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.58it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.58it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.57it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.56it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.59it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.58it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:11,  1.60it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.60it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.61it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:09,  1.63it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.65it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.64it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.62it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.61it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.61it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.61it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.59it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.61it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.60it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.61it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.58it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.63it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.63it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.59it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.58it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.7400)
Epoch 3: train_perplexity=1.4003, train_epoch_loss=0.3367, epcoh time 306.374285461s
Training Epoch3:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch3:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.29s/it]Training Epoch3:   2%|[34mâ–         [0m| 2/92 [00:06<05:00,  3.34s/it]Training Epoch3:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:56,  3.33s/it]Training Epoch3:   4%|[34mâ–         [0m| 4/92 [00:13<04:52,  3.32s/it]Training Epoch3:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:48,  3.32s/it]Training Epoch3:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.31s/it]Training Epoch3:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.31s/it]Training Epoch3:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch3:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.31s/it]Training Epoch3:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.34s/it]Training Epoch3:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch3:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.32s/it]Training Epoch3:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:22,  3.32s/it]Training Epoch3:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.31s/it]Training Epoch3:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.30s/it]Training Epoch3:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.29s/it]Training Epoch3:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:06,  3.29s/it]Training Epoch3:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.31s/it]Training Epoch3:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:01,  3.31s/it]Training Epoch3:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.31s/it]Training Epoch3:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.30s/it]Training Epoch3:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.31s/it]Training Epoch3:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:48,  3.31s/it]Training Epoch3:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:44,  3.30s/it]Training Epoch3:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:41,  3.31s/it]Training Epoch3:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:36,  3.29s/it]Training Epoch3:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.30s/it]Training Epoch3:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.29s/it]Training Epoch3:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:27,  3.30s/it]Training Epoch3:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:24,  3.30s/it]Training Epoch3:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:20,  3.29s/it]Training Epoch3:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:17,  3.29s/it]Training Epoch3:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:15,  3.32s/it]Training Epoch3:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.31s/it]Training Epoch3:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.32s/it]Training Epoch3:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:06,  3.33s/it]Training Epoch3:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.31s/it]Training Epoch3:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:59,  3.33s/it]Training Epoch3:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:56,  3.33s/it]Training Epoch3:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:53,  3.33s/it]Training Epoch3:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.33s/it]Training Epoch3:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:46,  3.33s/it]Training Epoch3:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:42,  3.31s/it]Training Epoch3:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.31s/it]Training Epoch3:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:35,  3.31s/it]Training Epoch3:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:31,  3.30s/it]Training Epoch3:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.31s/it]Training Epoch3:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.31s/it]Training Epoch3:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:22,  3.32s/it]Training Epoch3:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.32s/it]Training Epoch3:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.32s/it]Training Epoch3:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:13,  3.33s/it]Training Epoch3:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:09,  3.33s/it]Training Epoch3:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.31s/it]Training Epoch3:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:02,  3.30s/it]Training Epoch3:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.32s/it]Training Epoch3:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.33s/it]Training Epoch3:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.32s/it]Training Epoch3:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.32s/it]Training Epoch3:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.30s/it]Training Epoch3:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.30s/it]Training Epoch3:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.31s/it]Training Epoch3:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.31s/it]Training Epoch3:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:33,  3.33s/it]Training Epoch3:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:30,  3.35s/it]Training Epoch3:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.32s/it]Training Epoch3:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:23,  3.34s/it]Training Epoch3:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:20,  3.35s/it]Training Epoch3:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.33s/it]Training Epoch3:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.31s/it]Training Epoch3:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.30s/it]Training Epoch3:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.30s/it]Training Epoch3:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.30s/it]Training Epoch3:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.32s/it]Training Epoch3:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.30s/it]Training Epoch3:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.31s/it]Training Epoch3:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.30s/it]Training Epoch3:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.33s/it]Training Epoch3:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.32s/it]Training Epoch3:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.30s/it]Training Epoch3:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.30s/it]Training Epoch3:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.31s/it]Training Epoch3:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:29,  3.32s/it]Training Epoch3:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.32s/it]Training Epoch3:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.33s/it]Training Epoch3:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.32s/it]Training Epoch3:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.31s/it]Training Epoch3:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.31s/it]Training Epoch3:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.33s/it]Training Epoch3:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.34s/it]Training Epoch3:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.35s/it]Training Epoch3: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.33s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch3: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 0.6294633150100708

 step 1 is completed and loss is 0.7172637581825256

 step 2 is completed and loss is 1.0603922605514526

 step 3 is completed and loss is 0.6083871126174927

 step 4 is completed and loss is 0.40588846802711487

 step 5 is completed and loss is 0.3964475095272064

 step 6 is completed and loss is 1.9057533740997314

 step 7 is completed and loss is 0.4695441424846649

 step 8 is completed and loss is 0.1207253634929657

 step 9 is completed and loss is 0.8529888391494751

 step 10 is completed and loss is 0.5165890455245972

 step 11 is completed and loss is 2.3819165229797363

 step 12 is completed and loss is 0.1918177604675293

 step 13 is completed and loss is 0.12512926757335663

 step 14 is completed and loss is 0.1641545444726944

 step 15 is completed and loss is 0.015356048010289669

 step 16 is completed and loss is 0.02159738354384899

 step 17 is completed and loss is 0.36434483528137207

 step 18 is completed and loss is 0.10937969386577606

 step 19 is completed and loss is 0.06458703428506851

 step 20 is completed and loss is 0.2552838623523712

 step 21 is completed and loss is 0.018967758864164352

 step 22 is completed and loss is 0.5333103537559509

 step 23 is completed and loss is 0.3101058900356293

 step 24 is completed and loss is 0.02436249703168869

 step 25 is completed and loss is 0.21226608753204346

 step 26 is completed and loss is 0.07440489530563354

 step 27 is completed and loss is 0.524344265460968

 step 28 is completed and loss is 0.019365176558494568

 step 29 is completed and loss is 0.04772081971168518

 step 30 is completed and loss is 0.14528493583202362

 step 31 is completed and loss is 0.12979257106781006

 step 32 is completed and loss is 0.17109882831573486

 step 33 is completed and loss is 0.02061939239501953

 step 34 is completed and loss is 0.19141730666160583

 step 35 is completed and loss is 0.09474737197160721

 step 36 is completed and loss is 0.08808349817991257

 step 37 is completed and loss is 0.12165716290473938

 step 38 is completed and loss is 0.25078245997428894

 step 39 is completed and loss is 0.9063942432403564

 step 40 is completed and loss is 0.03934261202812195

 step 41 is completed and loss is 0.05150666832923889

 step 42 is completed and loss is 0.24453875422477722

 step 43 is completed and loss is 0.33719921112060547

 step 44 is completed and loss is 0.021372124552726746

 step 45 is completed and loss is 0.05249081552028656

 step 46 is completed and loss is 0.1312548667192459

 step 47 is completed and loss is 0.1031273901462555

 step 48 is completed and loss is 0.01800825633108616

 step 49 is completed and loss is 0.07822589576244354

 step 50 is completed and loss is 0.015461215749382973

 step 51 is completed and loss is 0.11578512191772461

 step 52 is completed and loss is 1.8392751216888428

 step 53 is completed and loss is 0.08701271563768387

 step 54 is completed and loss is 0.11471394449472427

 step 55 is completed and loss is 0.08272114396095276

 step 56 is completed and loss is 0.07649099826812744

 step 57 is completed and loss is 0.3021562695503235

 step 58 is completed and loss is 0.05753225460648537

 step 59 is completed and loss is 0.1661244034767151

 step 60 is completed and loss is 0.40928521752357483

 step 61 is completed and loss is 0.05635674297809601

 step 62 is completed and loss is 0.1293913573026657

 step 63 is completed and loss is 0.045110564678907394

 step 64 is completed and loss is 0.3200645446777344

 step 65 is completed and loss is 0.40617573261260986

 step 66 is completed and loss is 0.052252281457185745

 step 67 is completed and loss is 0.5532486438751221

 step 68 is completed and loss is 0.03356441110372543

 step 69 is completed and loss is 0.13104599714279175

 step 70 is completed and loss is 0.14716240763664246

 step 71 is completed and loss is 0.0939846932888031

 step 72 is completed and loss is 0.022670036181807518

 step 73 is completed and loss is 0.0044420757330954075

 step 74 is completed and loss is 0.033063579350709915

 step 75 is completed and loss is 0.045073993504047394

 step 76 is completed and loss is 0.010514743626117706

 step 77 is completed and loss is 0.015189800411462784

 step 78 is completed and loss is 0.08590824902057648

 step 79 is completed and loss is 0.07061272114515305

 step 80 is completed and loss is 0.020526543259620667

 step 81 is completed and loss is 0.005370249506086111

 step 82 is completed and loss is 0.035596661269664764

 step 83 is completed and loss is 0.0023002061061561108

 step 84 is completed and loss is 0.004133278038352728

 step 85 is completed and loss is 0.0010557560017332435

 step 86 is completed and loss is 0.0002809368306770921

 step 87 is completed and loss is 0.00297390460036695

 step 88 is completed and loss is 0.09422770142555237

 step 89 is completed and loss is 0.02789398469030857

 step 90 is completed and loss is 0.006863007787615061

 step 91 is completed and loss is 0.0020255555864423513
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.38it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.42it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.46it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.43it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.44it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.44it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:30,  1.42it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.40it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:29,  1.40it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:28,  1.43it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.46it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.49it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.52it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.53it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.51it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.53it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.54it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.50it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.50it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.49it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.52it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:16,  1.56it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.59it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.58it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.58it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:13,  1.60it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.59it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.60it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:11,  1.61it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.63it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.63it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:09,  1.64it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.57it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.53it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.51it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.52it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.53it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.58it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.54it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.48it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.44it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.46it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.49it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.44it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.44it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.49it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.54it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.7800)
we are about to save the PEFT modules
PEFT modules are saved in FT-vicuna-13b-v1.5-verifier-v2 directory
best eval accuracy on epoch 3 is 0.7799999713897705
Epoch 4: train_perplexity=1.2710, train_epoch_loss=0.2398, epcoh time 305.31786244700015s
Training Epoch4:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch4:   1%|[34m          [0m| 1/92 [00:03<05:05,  3.35s/it]Training Epoch4:   2%|[34mâ–         [0m| 2/92 [00:06<04:59,  3.33s/it]Training Epoch4:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:54,  3.31s/it]Training Epoch4:   4%|[34mâ–         [0m| 4/92 [00:13<04:54,  3.35s/it]Training Epoch4:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:50,  3.34s/it]Training Epoch4:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:48,  3.35s/it]Training Epoch4:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:45,  3.36s/it]Training Epoch4:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.33s/it]Training Epoch4:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:37,  3.34s/it]Training Epoch4:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:34,  3.34s/it]Training Epoch4:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:30,  3.34s/it]Training Epoch4:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:27,  3.35s/it]Training Epoch4:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:24,  3.34s/it]Training Epoch4:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:19,  3.33s/it]Training Epoch4:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.30s/it]Training Epoch4:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:09,  3.29s/it]Training Epoch4:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:05,  3.28s/it]Training Epoch4:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:02,  3.28s/it]Training Epoch4:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:00,  3.29s/it]Training Epoch4:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:57,  3.30s/it]Training Epoch4:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.31s/it]Training Epoch4:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:51,  3.30s/it]Training Epoch4:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:58,  3.45s/it]Training Epoch4:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:20<03:53,  3.43s/it]Training Epoch4:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:47,  3.40s/it]Training Epoch4:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:42,  3.37s/it]Training Epoch4:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:38,  3.36s/it]Training Epoch4:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:33,  3.34s/it]Training Epoch4:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:30,  3.34s/it]Training Epoch4:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:40<03:26,  3.34s/it]Training Epoch4:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:23,  3.34s/it]Training Epoch4:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:18,  3.31s/it]Training Epoch4:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:14,  3.29s/it]Training Epoch4:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:11,  3.30s/it]Training Epoch4:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:06,  3.27s/it]Training Epoch4:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:02,  3.26s/it]Training Epoch4:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<02:59,  3.27s/it]Training Epoch4:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:58,  3.31s/it]Training Epoch4:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:56,  3.32s/it]Training Epoch4:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:53,  3.33s/it]Training Epoch4:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:49,  3.32s/it]Training Epoch4:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.31s/it]Training Epoch4:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:43,  3.33s/it]Training Epoch4:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:40,  3.34s/it]Training Epoch4:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.33s/it]Training Epoch4:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:33,  3.34s/it]Training Epoch4:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:29,  3.33s/it]Training Epoch4:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:26,  3.32s/it]Training Epoch4:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:22,  3.31s/it]Training Epoch4:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:18,  3.29s/it]Training Epoch4:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:15,  3.30s/it]Training Epoch4:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:11,  3.30s/it]Training Epoch4:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:08,  3.31s/it]Training Epoch4:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:06,  3.32s/it]Training Epoch4:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:03,  3.35s/it]Training Epoch4:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<02:00,  3.35s/it]Training Epoch4:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:56,  3.33s/it]Training Epoch4:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:53,  3.33s/it]Training Epoch4:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:49,  3.33s/it]Training Epoch4:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:46,  3.33s/it]Training Epoch4:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:43,  3.35s/it]Training Epoch4:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:40,  3.36s/it]Training Epoch4:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:37,  3.37s/it]Training Epoch4:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:33<01:33,  3.34s/it]Training Epoch4:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:29,  3.33s/it]Training Epoch4:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:26,  3.34s/it]Training Epoch4:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:43<01:23,  3.34s/it]Training Epoch4:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:20,  3.35s/it]Training Epoch4:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:17,  3.35s/it]Training Epoch4:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:53<01:14,  3.37s/it]Training Epoch4:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:56<01:10,  3.37s/it]Training Epoch4:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:07,  3.36s/it]Training Epoch4:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:03<01:03,  3.35s/it]Training Epoch4:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:06<01:00,  3.34s/it]Training Epoch4:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:56,  3.34s/it]Training Epoch4:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:13<00:53,  3.34s/it]Training Epoch4:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:16<00:50,  3.34s/it]Training Epoch4:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:46,  3.33s/it]Training Epoch4:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:23<00:43,  3.32s/it]Training Epoch4:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:26<00:39,  3.30s/it]Training Epoch4:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:29<00:36,  3.33s/it]Training Epoch4:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:33<00:33,  3.32s/it]Training Epoch4:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:36<00:29,  3.32s/it]Training Epoch4:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:26,  3.30s/it]Training Epoch4:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:43<00:23,  3.34s/it]Training Epoch4:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:46<00:20,  3.35s/it]Training Epoch4:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.35s/it]Training Epoch4:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:53<00:13,  3.35s/it]Training Epoch4:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:56<00:10,  3.35s/it]Training Epoch4:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.33s/it]Training Epoch4:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:03<00:03,  3.30s/it]Training Epoch4: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch4: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.33s/it]

 step 0 is completed and loss is 0.11837632954120636

 step 1 is completed and loss is 0.21241895854473114

 step 2 is completed and loss is 0.1251155287027359

 step 3 is completed and loss is 0.06167410686612129

 step 4 is completed and loss is 0.020157072693109512

 step 5 is completed and loss is 1.2756855487823486

 step 6 is completed and loss is 0.01780559867620468

 step 7 is completed and loss is 0.290364533662796

 step 8 is completed and loss is 0.17413689196109772

 step 9 is completed and loss is 0.03896649181842804

 step 10 is completed and loss is 0.055708061903715134

 step 11 is completed and loss is 2.3733158111572266

 step 12 is completed and loss is 0.01592053286731243

 step 13 is completed and loss is 0.007000346202403307

 step 14 is completed and loss is 0.5556069016456604

 step 15 is completed and loss is 0.204102024435997

 step 16 is completed and loss is 0.0016356422565877438

 step 17 is completed and loss is 0.327728271484375

 step 18 is completed and loss is 0.19654671847820282

 step 19 is completed and loss is 0.2738479673862457

 step 20 is completed and loss is 0.01540145929902792

 step 21 is completed and loss is 0.0009473176905885339

 step 22 is completed and loss is 0.08269640058279037

 step 23 is completed and loss is 0.5921372771263123

 step 24 is completed and loss is 0.005575939081609249

 step 25 is completed and loss is 0.02932201884686947

 step 26 is completed and loss is 0.0052374727092683315

 step 27 is completed and loss is 0.1926954984664917

 step 28 is completed and loss is 0.0014282966731116176

 step 29 is completed and loss is 0.003445917973294854

 step 30 is completed and loss is 0.03234099596738815

 step 31 is completed and loss is 0.008309938944876194

 step 32 is completed and loss is 0.09836358577013016

 step 33 is completed and loss is 0.0018845628947019577

 step 34 is completed and loss is 0.07061365991830826

 step 35 is completed and loss is 0.03804399445652962

 step 36 is completed and loss is 0.01001407764852047

 step 37 is completed and loss is 0.014972046948969364

 step 38 is completed and loss is 0.3888828158378601

 step 39 is completed and loss is 0.07185407727956772

 step 40 is completed and loss is 0.01143858302384615

 step 41 is completed and loss is 0.019366739317774773

 step 42 is completed and loss is 0.011757870204746723

 step 43 is completed and loss is 0.01918862573802471

 step 44 is completed and loss is 0.0014525200240314007

 step 45 is completed and loss is 0.024114128202199936

 step 46 is completed and loss is 0.008516449481248856

 step 47 is completed and loss is 0.037911441177129745

 step 48 is completed and loss is 0.009071076288819313

 step 49 is completed and loss is 0.10913646966218948

 step 50 is completed and loss is 0.03967985510826111

 step 51 is completed and loss is 0.04210871830582619

 step 52 is completed and loss is 0.396020770072937

 step 53 is completed and loss is 0.08774445950984955

 step 54 is completed and loss is 0.008146875537931919

 step 55 is completed and loss is 0.0724884495139122

 step 56 is completed and loss is 0.00482386676594615

 step 57 is completed and loss is 0.11313403397798538

 step 58 is completed and loss is 0.07119965553283691

 step 59 is completed and loss is 0.020555954426527023

 step 60 is completed and loss is 0.015505033545196056

 step 61 is completed and loss is 0.0029371557757258415

 step 62 is completed and loss is 0.06949980556964874

 step 63 is completed and loss is 0.03795144706964493

 step 64 is completed and loss is 0.07217840850353241

 step 65 is completed and loss is 0.06850963830947876

 step 66 is completed and loss is 0.007400002796202898

 step 67 is completed and loss is 0.16465623676776886

 step 68 is completed and loss is 1.0715466737747192

 step 69 is completed and loss is 0.10712880641222

 step 70 is completed and loss is 0.05683748424053192

 step 71 is completed and loss is 0.028974970802664757

 step 72 is completed and loss is 0.022282304242253304

 step 73 is completed and loss is 0.0007354739354923368

 step 74 is completed and loss is 0.0007834614370949566

 step 75 is completed and loss is 0.0136649701744318

 step 76 is completed and loss is 0.0013507417170330882

 step 77 is completed and loss is 0.000673085858579725

 step 78 is completed and loss is 0.00559911597520113

 step 79 is completed and loss is 0.03528129681944847

 step 80 is completed and loss is 0.0065971603617072105

 step 81 is completed and loss is 0.0008964018197730184

 step 82 is completed and loss is 0.02842612937092781

 step 83 is completed and loss is 0.0007367145735770464

 step 84 is completed and loss is 0.0008742315694689751

 step 85 is completed and loss is 0.0003137096355203539

 step 86 is completed and loss is 0.00010084597306558862

 step 87 is completed and loss is 0.0018163956701755524

 step 88 is completed and loss is 0.0144270658493042

 step 89 is completed and loss is 0.00851015467196703

 step 90 is completed and loss is 0.0015857740072533488

 step 91 is completed and loss is 0.001043821801431477
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.36it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.43it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.41it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.43it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.48it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:28,  1.56it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.51it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.51it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.51it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.50it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:24,  1.54it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.51it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.52it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.50it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.54it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.53it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.53it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.53it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.55it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.54it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.56it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.55it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.53it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.53it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.55it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.57it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.56it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.54it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.54it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.49it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.51it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.52it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.50it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.50it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.47it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.46it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.48it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.48it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.44it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.44it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.45it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.45it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.46it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.46it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.50it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.7600)
Epoch 5: train_perplexity=1.1266, train_epoch_loss=0.1192, epcoh time 306.6351065929998s
Training Epoch5:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch5:   1%|[34m          [0m| 1/92 [00:03<05:00,  3.30s/it]Training Epoch5:   2%|[34mâ–         [0m| 2/92 [00:06<04:59,  3.32s/it]Training Epoch5:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.27s/it]Training Epoch5:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.27s/it]Training Epoch5:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.28s/it]Training Epoch5:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.30s/it]Training Epoch5:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:39,  3.29s/it]Training Epoch5:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.28s/it]Training Epoch5:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.29s/it]Training Epoch5:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:30,  3.30s/it]Training Epoch5:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:27,  3.31s/it]Training Epoch5:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.31s/it]Training Epoch5:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:23,  3.33s/it]Training Epoch5:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.31s/it]Training Epoch5:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.30s/it]Training Epoch5:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.29s/it]Training Epoch5:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.32s/it]Training Epoch5:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.31s/it]Training Epoch5:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.32s/it]Training Epoch5:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.32s/it]Training Epoch5:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.31s/it]Training Epoch5:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.29s/it]Training Epoch5:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.29s/it]Training Epoch5:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:44,  3.30s/it]Training Epoch5:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.30s/it]Training Epoch5:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:39,  3.32s/it]Training Epoch5:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:35,  3.31s/it]Training Epoch5:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.30s/it]Training Epoch5:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:29,  3.32s/it]Training Epoch5:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:27,  3.35s/it]Training Epoch5:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:24,  3.34s/it]Training Epoch5:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:20,  3.35s/it]Training Epoch5:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:18,  3.36s/it]Training Epoch5:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:13,  3.34s/it]Training Epoch5:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:11,  3.36s/it]Training Epoch5:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:06,  3.33s/it]Training Epoch5:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.32s/it]Training Epoch5:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:56,  3.28s/it]Training Epoch5:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:55,  3.31s/it]Training Epoch5:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:50,  3.28s/it]Training Epoch5:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:47,  3.29s/it]Training Epoch5:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.31s/it]Training Epoch5:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:39,  3.27s/it]Training Epoch5:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:37,  3.28s/it]Training Epoch5:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:33,  3.26s/it]Training Epoch5:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:30,  3.28s/it]Training Epoch5:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:28,  3.29s/it]Training Epoch5:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:23,  3.27s/it]Training Epoch5:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:21,  3.28s/it]Training Epoch5:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.30s/it]Training Epoch5:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.30s/it]Training Epoch5:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:12,  3.32s/it]Training Epoch5:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:09,  3.32s/it]Training Epoch5:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:06,  3.33s/it]Training Epoch5:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.32s/it]Training Epoch5:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.33s/it]Training Epoch5:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.33s/it]Training Epoch5:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:53,  3.33s/it]Training Epoch5:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.33s/it]Training Epoch5:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:46,  3.34s/it]Training Epoch5:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:43,  3.33s/it]Training Epoch5:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.31s/it]Training Epoch5:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.31s/it]Training Epoch5:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.29s/it]Training Epoch5:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.27s/it]Training Epoch5:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:24,  3.26s/it]Training Epoch5:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.28s/it]Training Epoch5:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:18,  3.29s/it]Training Epoch5:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:15,  3.29s/it]Training Epoch5:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:11,  3.27s/it]Training Epoch5:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:08,  3.27s/it]Training Epoch5:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.29s/it]Training Epoch5:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.29s/it]Training Epoch5:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.31s/it]Training Epoch5:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.30s/it]Training Epoch5:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.31s/it]Training Epoch5:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.33s/it]Training Epoch5:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.32s/it]Training Epoch5:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.31s/it]Training Epoch5:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.33s/it]Training Epoch5:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.31s/it]Training Epoch5:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.33s/it]Training Epoch5:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.32s/it]Training Epoch5:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.34s/it]Training Epoch5:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.34s/it]Training Epoch5:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.33s/it]Training Epoch5:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.33s/it]Training Epoch5:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.34s/it]Training Epoch5:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:10,  3.35s/it]Training Epoch5:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.35s/it]Training Epoch5:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.34s/it]Training Epoch5: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch5: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.2943321466445923

 step 1 is completed and loss is 0.1775548905134201

 step 2 is completed and loss is 0.0035649838391691446

 step 3 is completed and loss is 0.6987864971160889

 step 4 is completed and loss is 0.8761281371116638

 step 5 is completed and loss is 0.04279869422316551

 step 6 is completed and loss is 0.013797917403280735

 step 7 is completed and loss is 0.004412450827658176

 step 8 is completed and loss is 0.3912080228328705

 step 9 is completed and loss is 0.003992178943008184

 step 10 is completed and loss is 0.12906424701213837

 step 11 is completed and loss is 0.5767505168914795

 step 12 is completed and loss is 0.1724463254213333

 step 13 is completed and loss is 0.01663387194275856

 step 14 is completed and loss is 0.00596826896071434

 step 15 is completed and loss is 0.0003800861886702478

 step 16 is completed and loss is 0.000974861322902143

 step 17 is completed and loss is 0.023063436150550842

 step 18 is completed and loss is 0.0011946631129831076

 step 19 is completed and loss is 0.03547535836696625

 step 20 is completed and loss is 0.003280762117356062

 step 21 is completed and loss is 0.00048652710393071175

 step 22 is completed and loss is 0.027734091505408287

 step 23 is completed and loss is 0.38742586970329285

 step 24 is completed and loss is 0.006606535520404577

 step 25 is completed and loss is 0.004459246061742306

 step 26 is completed and loss is 0.0006654211319983006

 step 27 is completed and loss is 0.11459638178348541

 step 28 is completed and loss is 0.0017353221774101257

 step 29 is completed and loss is 0.0038313651457428932

 step 30 is completed and loss is 0.0628860667347908

 step 31 is completed and loss is 0.0002620462328195572

 step 32 is completed and loss is 0.022022191435098648

 step 33 is completed and loss is 0.005133368540555239

 step 34 is completed and loss is 0.020322438329458237

 step 35 is completed and loss is 0.007297694217413664

 step 36 is completed and loss is 0.0002091297646984458

 step 37 is completed and loss is 0.017987344413995743

 step 38 is completed and loss is 1.2452753782272339

 step 39 is completed and loss is 0.035746052861213684

 step 40 is completed and loss is 0.0023126048035919666

 step 41 is completed and loss is 0.001556449569761753

 step 42 is completed and loss is 0.002537055406719446

 step 43 is completed and loss is 0.0026758029125630856

 step 44 is completed and loss is 0.0002208702644566074

 step 45 is completed and loss is 0.007410282269120216

 step 46 is completed and loss is 0.0017352382419630885

 step 47 is completed and loss is 0.0006340683321468532

 step 48 is completed and loss is 0.010488681495189667

 step 49 is completed and loss is 0.002039906568825245

 step 50 is completed and loss is 0.002460005460307002

 step 51 is completed and loss is 0.6971132755279541

 step 52 is completed and loss is 0.29367923736572266

 step 53 is completed and loss is 0.012381906621158123

 step 54 is completed and loss is 0.0022033907007426023

 step 55 is completed and loss is 0.05943388491868973

 step 56 is completed and loss is 0.003007255494594574

 step 57 is completed and loss is 0.02101253531873226

 step 58 is completed and loss is 0.005764021538197994

 step 59 is completed and loss is 0.016762295737862587

 step 60 is completed and loss is 0.01756446249783039

 step 61 is completed and loss is 0.001225421205163002

 step 62 is completed and loss is 0.006463661789894104

 step 63 is completed and loss is 0.05211515352129936

 step 64 is completed and loss is 0.012084688059985638

 step 65 is completed and loss is 0.4380819797515869

 step 66 is completed and loss is 0.015654481947422028

 step 67 is completed and loss is 0.075347401201725

 step 68 is completed and loss is 0.011355338618159294

 step 69 is completed and loss is 0.013480601832270622

 step 70 is completed and loss is 0.5184917449951172

 step 71 is completed and loss is 0.043124690651893616

 step 72 is completed and loss is 0.008768853731453419

 step 73 is completed and loss is 0.07669387012720108

 step 74 is completed and loss is 0.0038798737805336714

 step 75 is completed and loss is 0.01318019162863493

 step 76 is completed and loss is 0.008315504528582096

 step 77 is completed and loss is 0.0015472593950107694

 step 78 is completed and loss is 0.008367489092051983

 step 79 is completed and loss is 0.015567285008728504

 step 80 is completed and loss is 0.007057132665067911

 step 81 is completed and loss is 0.0013787990901619196

 step 82 is completed and loss is 0.017424611374735832

 step 83 is completed and loss is 0.0028612485621124506

 step 84 is completed and loss is 0.003209719667211175

 step 85 is completed and loss is 0.0001618731184862554

 step 86 is completed and loss is 0.00016640232934150845

 step 87 is completed and loss is 0.0016376550775021315

 step 88 is completed and loss is 0.023590408265590668

 step 89 is completed and loss is 0.016331706196069717

 step 90 is completed and loss is 0.004209252540022135

 step 91 is completed and loss is 0.004362543113529682
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.41it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.54it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.55it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.52it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.54it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.55it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.58it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.56it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.55it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.59it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.62it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.59it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.62it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:20,  1.67it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:20,  1.64it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:20,  1.63it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.58it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.55it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.55it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.57it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:13<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.52it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.50it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.49it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.50it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.51it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.48it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:14,  1.49it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.47it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.49it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:12,  1.46it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.47it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.50it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:10,  1.50it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.54it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.53it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.53it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.57it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.51it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.51it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:04,  1.49it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.54it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.51it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:02,  1.49it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.50it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.52it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.52it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.7800)
Epoch 6: train_perplexity=1.0909, train_epoch_loss=0.0870, epcoh time 304.69765060300006s
Training Epoch6:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch6:   1%|[34m          [0m| 1/92 [00:03<04:54,  3.24s/it]Training Epoch6:   2%|[34mâ–         [0m| 2/92 [00:06<04:53,  3.26s/it]Training Epoch6:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.27s/it]Training Epoch6:   4%|[34mâ–         [0m| 4/92 [00:13<04:49,  3.28s/it]Training Epoch6:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.30s/it]Training Epoch6:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.30s/it]Training Epoch6:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch6:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.31s/it]Training Epoch6:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.30s/it]Training Epoch6:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:30,  3.29s/it]Training Epoch6:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.29s/it]Training Epoch6:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch6:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.28s/it]Training Epoch6:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:15,  3.28s/it]Training Epoch6:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.30s/it]Training Epoch6:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:12,  3.32s/it]Training Epoch6:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.30s/it]Training Epoch6:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:02,  3.27s/it]Training Epoch6:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.28s/it]Training Epoch6:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:57,  3.29s/it]Training Epoch6:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.30s/it]Training Epoch6:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.30s/it]Training Epoch6:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.29s/it]Training Epoch6:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:44,  3.30s/it]Training Epoch6:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:41,  3.31s/it]Training Epoch6:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:39,  3.32s/it]Training Epoch6:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:36,  3.33s/it]Training Epoch6:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:32,  3.32s/it]Training Epoch6:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:29,  3.32s/it]Training Epoch6:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.32s/it]Training Epoch6:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.31s/it]Training Epoch6:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:18,  3.31s/it]Training Epoch6:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:13,  3.29s/it]Training Epoch6:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:10,  3.28s/it]Training Epoch6:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:05,  3.25s/it]Training Epoch6:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:02,  3.26s/it]Training Epoch6:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:59,  3.26s/it]Training Epoch6:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:56,  3.27s/it]Training Epoch6:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:52,  3.26s/it]Training Epoch6:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:48,  3.25s/it]Training Epoch6:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:46,  3.27s/it]Training Epoch6:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:42,  3.26s/it]Training Epoch6:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:39,  3.25s/it]Training Epoch6:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:36,  3.27s/it]Training Epoch6:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:35,  3.30s/it]Training Epoch6:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:32,  3.31s/it]Training Epoch6:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.30s/it]Training Epoch6:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:24,  3.29s/it]Training Epoch6:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.31s/it]Training Epoch6:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:18,  3.29s/it]Training Epoch6:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:14,  3.29s/it]Training Epoch6:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.29s/it]Training Epoch6:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.31s/it]Training Epoch6:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:05,  3.31s/it]Training Epoch6:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.32s/it]Training Epoch6:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<02:00,  3.33s/it]Training Epoch6:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:57,  3.35s/it]Training Epoch6:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:53,  3.33s/it]Training Epoch6:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.33s/it]Training Epoch6:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:46,  3.32s/it]Training Epoch6:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:43,  3.33s/it]Training Epoch6:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:40,  3.34s/it]Training Epoch6:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:36,  3.33s/it]Training Epoch6:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:32,  3.29s/it]Training Epoch6:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.28s/it]Training Epoch6:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.31s/it]Training Epoch6:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.30s/it]Training Epoch6:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.32s/it]Training Epoch6:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.31s/it]Training Epoch6:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.30s/it]Training Epoch6:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.26s/it]Training Epoch6:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.28s/it]Training Epoch6:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:02,  3.28s/it]Training Epoch6:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:59,  3.31s/it]Training Epoch6:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.32s/it]Training Epoch6:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:53,  3.33s/it]Training Epoch6:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:50,  3.33s/it]Training Epoch6:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.34s/it]Training Epoch6:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:43,  3.32s/it]Training Epoch6:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:40,  3.35s/it]Training Epoch6:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.33s/it]Training Epoch6:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.32s/it]Training Epoch6:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.33s/it]Training Epoch6:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.33s/it]Training Epoch6:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.34s/it]Training Epoch6:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.32s/it]Training Epoch6:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.32s/it]Training Epoch6:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.31s/it]Training Epoch6:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.30s/it]Training Epoch6:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.30s/it]Training Epoch6:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.28s/it]Training Epoch6: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.27s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch6: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.019549081102013588

 step 1 is completed and loss is 0.039676766842603683

 step 2 is completed and loss is 0.0037732773926109076

 step 3 is completed and loss is 0.0021265435498207808

 step 4 is completed and loss is 0.00047986782738007605

 step 5 is completed and loss is 0.010432382114231586

 step 6 is completed and loss is 0.0016476695891469717

 step 7 is completed and loss is 0.047070011496543884

 step 8 is completed and loss is 0.04445071145892143

 step 9 is completed and loss is 0.00010978441423503682

 step 10 is completed and loss is 0.0432715117931366

 step 11 is completed and loss is 0.008465620689094067

 step 12 is completed and loss is 0.11806150525808334

 step 13 is completed and loss is 0.1366518884897232

 step 14 is completed and loss is 0.0001547774882055819

 step 15 is completed and loss is 3.218599158572033e-05

 step 16 is completed and loss is 0.0008342974469996989

 step 17 is completed and loss is 0.09748152643442154

 step 18 is completed and loss is 0.00041374328429810703

 step 19 is completed and loss is 0.0005050435429438949

 step 20 is completed and loss is 0.00842328928411007

 step 21 is completed and loss is 0.00020876442431472242

 step 22 is completed and loss is 0.046424876898527145

 step 23 is completed and loss is 0.0007692368817515671

 step 24 is completed and loss is 0.00016115506878122687

 step 25 is completed and loss is 0.012390803545713425

 step 26 is completed and loss is 0.0009577010059729218

 step 27 is completed and loss is 0.049532704055309296

 step 28 is completed and loss is 0.0005092025967314839

 step 29 is completed and loss is 0.00019857769075315446

 step 30 is completed and loss is 0.002707351930439472

 step 31 is completed and loss is 0.000694644229952246

 step 32 is completed and loss is 0.0036386565770953894

 step 33 is completed and loss is 0.00023844695533625782

 step 34 is completed and loss is 0.0014332656282931566

 step 35 is completed and loss is 0.003238634206354618

 step 36 is completed and loss is 0.0004195872461423278

 step 37 is completed and loss is 0.0009935053531080484

 step 38 is completed and loss is 0.2851143777370453

 step 39 is completed and loss is 0.0003952549013774842

 step 40 is completed and loss is 0.0006572427810169756

 step 41 is completed and loss is 0.001083998940885067

 step 42 is completed and loss is 0.0004991439636796713

 step 43 is completed and loss is 0.0003983174101449549

 step 44 is completed and loss is 8.803101081866771e-05

 step 45 is completed and loss is 0.001548275351524353

 step 46 is completed and loss is 0.00025960078346543014

 step 47 is completed and loss is 0.002704436657950282

 step 48 is completed and loss is 0.0024061037693172693

 step 49 is completed and loss is 0.001069026766344905

 step 50 is completed and loss is 0.0005135913379490376

 step 51 is completed and loss is 0.0003364114963915199

 step 52 is completed and loss is 0.020105350762605667

 step 53 is completed and loss is 0.0012840346898883581

 step 54 is completed and loss is 0.0004040746425744146

 step 55 is completed and loss is 0.006978416349738836

 step 56 is completed and loss is 0.00030959819559939206

 step 57 is completed and loss is 0.008123090490698814

 step 58 is completed and loss is 0.0012825739104300737

 step 59 is completed and loss is 0.002758437069132924

 step 60 is completed and loss is 0.0016763174207881093

 step 61 is completed and loss is 0.0003136820741929114

 step 62 is completed and loss is 0.00089305080473423

 step 63 is completed and loss is 0.03576003760099411

 step 64 is completed and loss is 0.0017214446561411023

 step 65 is completed and loss is 0.0018241917714476585

 step 66 is completed and loss is 0.002389441477134824

 step 67 is completed and loss is 0.004481161013245583

 step 68 is completed and loss is 0.0011836985358968377

 step 69 is completed and loss is 0.0008928994066081941

 step 70 is completed and loss is 0.010502171702682972

 step 71 is completed and loss is 0.0009137231972999871

 step 72 is completed and loss is 0.001889440231025219

 step 73 is completed and loss is 0.0002482206327840686

 step 74 is completed and loss is 0.0007735788240097463

 step 75 is completed and loss is 0.0020082141272723675

 step 76 is completed and loss is 0.0017445811536163092

 step 77 is completed and loss is 0.0019819920416921377

 step 78 is completed and loss is 0.022265983745455742

 step 79 is completed and loss is 0.012044989503920078

 step 80 is completed and loss is 0.005354486871510744

 step 81 is completed and loss is 0.0032378225587308407

 step 82 is completed and loss is 0.0005930514889769256

 step 83 is completed and loss is 0.0103358319029212

 step 84 is completed and loss is 0.007109554950147867

 step 85 is completed and loss is 0.0003516055876389146

 step 86 is completed and loss is 0.0003860443539451808

 step 87 is completed and loss is 0.04552783817052841

 step 88 is completed and loss is 0.018479958176612854

 step 89 is completed and loss is 0.0011939959367737174

 step 90 is completed and loss is 0.008045620284974575

 step 91 is completed and loss is 0.028041109442710876
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.38it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.38it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.47it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:28,  1.54it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.50it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.49it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:26,  1.53it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.50it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.48it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.46it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.45it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.47it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.52it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.50it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.52it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:20,  1.55it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.55it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.55it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.55it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.51it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.50it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.50it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.49it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.53it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.54it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.53it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.51it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.54it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.55it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.54it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.57it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.58it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.57it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.56it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.51it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.51it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.50it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.48it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.49it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.49it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.50it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.49it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.47it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.44it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.5800)
Epoch 7: train_perplexity=1.0140, train_epoch_loss=0.0139, epcoh time 303.926142409s
Training Epoch7:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch7:   1%|[34m          [0m| 1/92 [00:03<05:02,  3.32s/it]Training Epoch7:   2%|[34mâ–         [0m| 2/92 [00:06<04:51,  3.24s/it]Training Epoch7:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:47,  3.23s/it]Training Epoch7:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.28s/it]Training Epoch7:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:43,  3.26s/it]Training Epoch7:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.26s/it]Training Epoch7:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.26s/it]Training Epoch7:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:33,  3.26s/it]Training Epoch7:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.27s/it]Training Epoch7:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.27s/it]Training Epoch7:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:23,  3.26s/it]Training Epoch7:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:20,  3.26s/it]Training Epoch7:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:17,  3.26s/it]Training Epoch7:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.30s/it]Training Epoch7:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.31s/it]Training Epoch7:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:12,  3.32s/it]Training Epoch7:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:10,  3.34s/it]Training Epoch7:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:07,  3.35s/it]Training Epoch7:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:04,  3.35s/it]Training Epoch7:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:59,  3.33s/it]Training Epoch7:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:56,  3.33s/it]Training Epoch7:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.31s/it]Training Epoch7:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:48,  3.31s/it]Training Epoch7:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:46,  3.33s/it]Training Epoch7:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:41,  3.30s/it]Training Epoch7:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:35,  3.27s/it]Training Epoch7:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:31,  3.25s/it]Training Epoch7:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:29,  3.28s/it]Training Epoch7:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:26,  3.28s/it]Training Epoch7:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:22,  3.27s/it]Training Epoch7:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:19,  3.27s/it]Training Epoch7:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:17,  3.30s/it]Training Epoch7:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:12,  3.27s/it]Training Epoch7:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:11,  3.31s/it]Training Epoch7:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.30s/it]Training Epoch7:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:04,  3.30s/it]Training Epoch7:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:59,  3.27s/it]Training Epoch7:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:55,  3.26s/it]Training Epoch7:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:53,  3.27s/it]Training Epoch7:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:51,  3.29s/it]Training Epoch7:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:49,  3.32s/it]Training Epoch7:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:45,  3.31s/it]Training Epoch7:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:41,  3.30s/it]Training Epoch7:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:37,  3.27s/it]Training Epoch7:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.27s/it]Training Epoch7:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:30,  3.28s/it]Training Epoch7:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.29s/it]Training Epoch7:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:24,  3.29s/it]Training Epoch7:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:21,  3.30s/it]Training Epoch7:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:19,  3.31s/it]Training Epoch7:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:16,  3.32s/it]Training Epoch7:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:12,  3.32s/it]Training Epoch7:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:07,  3.28s/it]Training Epoch7:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:05,  3.30s/it]Training Epoch7:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.30s/it]Training Epoch7:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:59,  3.33s/it]Training Epoch7:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:57,  3.34s/it]Training Epoch7:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:53,  3.34s/it]Training Epoch7:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:50,  3.34s/it]Training Epoch7:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:47,  3.36s/it]Training Epoch7:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:43,  3.34s/it]Training Epoch7:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.31s/it]Training Epoch7:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:35,  3.29s/it]Training Epoch7:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:31,  3.27s/it]Training Epoch7:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.27s/it]Training Epoch7:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:24,  3.25s/it]Training Epoch7:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:21,  3.27s/it]Training Epoch7:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:18,  3.28s/it]Training Epoch7:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.31s/it]Training Epoch7:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:13,  3.32s/it]Training Epoch7:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.28s/it]Training Epoch7:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.29s/it]Training Epoch7:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:04,  3.39s/it]Training Epoch7:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<01:00,  3.36s/it]Training Epoch7:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.34s/it]Training Epoch7:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:53,  3.35s/it]Training Epoch7:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:50,  3.34s/it]Training Epoch7:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.35s/it]Training Epoch7:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:43,  3.36s/it]Training Epoch7:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:40,  3.39s/it]Training Epoch7:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:37,  3.37s/it]Training Epoch7:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.35s/it]Training Epoch7:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:30,  3.33s/it]Training Epoch7:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.31s/it]Training Epoch7:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.31s/it]Training Epoch7:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.31s/it]Training Epoch7:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.31s/it]Training Epoch7:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.30s/it]Training Epoch7:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.33s/it]Training Epoch7:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.36s/it]Training Epoch7:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.40s/it]Training Epoch7: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.39s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch7: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.0008889449527487159

 step 1 is completed and loss is 0.0010891410056501627

 step 2 is completed and loss is 0.00015853572404012084

 step 3 is completed and loss is 0.0007864219369366765

 step 4 is completed and loss is 0.00015186029486358166

 step 5 is completed and loss is 0.00034052098635584116

 step 6 is completed and loss is 0.029489297419786453

 step 7 is completed and loss is 0.0005047921440564096

 step 8 is completed and loss is 0.0003797269018832594

 step 9 is completed and loss is 0.00011056048970203847

 step 10 is completed and loss is 0.03937350586056709

 step 11 is completed and loss is 0.0365673191845417

 step 12 is completed and loss is 0.0013531717704609036

 step 13 is completed and loss is 0.0004351382376626134

 step 14 is completed and loss is 0.00013678288087248802

 step 15 is completed and loss is 6.97350042173639e-05

 step 16 is completed and loss is 0.0007492199656553566

 step 17 is completed and loss is 0.001184680499136448

 step 18 is completed and loss is 0.00013785442570224404

 step 19 is completed and loss is 0.0004219793772790581

 step 20 is completed and loss is 0.0010342705063521862

 step 21 is completed and loss is 0.00017205975018441677

 step 22 is completed and loss is 0.013894609175622463

 step 23 is completed and loss is 0.00041070999577641487

 step 24 is completed and loss is 0.0001295716647291556

 step 25 is completed and loss is 0.0019629662856459618

 step 26 is completed and loss is 0.00026853231247514486

 step 27 is completed and loss is 0.0012133442796766758

 step 28 is completed and loss is 0.0006193023873493075

 step 29 is completed and loss is 0.0001450669951736927

 step 30 is completed and loss is 0.0016119852662086487

 step 31 is completed and loss is 8.481286931782961e-05

 step 32 is completed and loss is 0.0012430294882506132

 step 33 is completed and loss is 0.00020746205700561404

 step 34 is completed and loss is 0.0013917522737756371

 step 35 is completed and loss is 0.00207685143686831

 step 36 is completed and loss is 0.00015495852858293802

 step 37 is completed and loss is 0.000882875407114625

 step 38 is completed and loss is 0.0002561408618930727

 step 39 is completed and loss is 0.0002295051235705614

 step 40 is completed and loss is 0.0007968398276716471

 step 41 is completed and loss is 0.0006021378212608397

 step 42 is completed and loss is 0.0003387667238712311

 step 43 is completed and loss is 0.00018249268759973347

 step 44 is completed and loss is 6.031761586200446e-05

 step 45 is completed and loss is 0.0019508948316797614

 step 46 is completed and loss is 0.00013630581088364124

 step 47 is completed and loss is 0.0001683681912254542

 step 48 is completed and loss is 0.0035989307798445225

 step 49 is completed and loss is 0.0001288565108552575

 step 50 is completed and loss is 0.00016771296213846654

 step 51 is completed and loss is 0.00020316446898505092

 step 52 is completed and loss is 0.056393954902887344

 step 53 is completed and loss is 0.0027761412784457207

 step 54 is completed and loss is 0.00018332269974052906

 step 55 is completed and loss is 0.01610853150486946

 step 56 is completed and loss is 0.00032269072835333645

 step 57 is completed and loss is 0.0003577074676286429

 step 58 is completed and loss is 0.00014846352860331535

 step 59 is completed and loss is 0.018964335322380066

 step 60 is completed and loss is 0.0002470850886311382

 step 61 is completed and loss is 0.0002732856955844909

 step 62 is completed and loss is 0.00022003533376846462

 step 63 is completed and loss is 0.005020263139158487

 step 64 is completed and loss is 0.0016928621334955096

 step 65 is completed and loss is 0.00020918811787851155

 step 66 is completed and loss is 0.002003210363909602

 step 67 is completed and loss is 0.00018373427155893296

 step 68 is completed and loss is 0.00038282666355371475

 step 69 is completed and loss is 0.0009686948615126312

 step 70 is completed and loss is 0.0003437178675085306

 step 71 is completed and loss is 0.0016782536404207349

 step 72 is completed and loss is 0.0029745481442660093

 step 73 is completed and loss is 0.00012128809612477198

 step 74 is completed and loss is 0.0001616930530872196

 step 75 is completed and loss is 0.0007768250070512295

 step 76 is completed and loss is 0.00019959599012508988

 step 77 is completed and loss is 0.00014321962953545153

 step 78 is completed and loss is 0.0003489202354103327

 step 79 is completed and loss is 0.003631907282397151

 step 80 is completed and loss is 0.0009141623741015792

 step 81 is completed and loss is 0.0002827752323355526

 step 82 is completed and loss is 0.0008466342696920037

 step 83 is completed and loss is 0.0002722318167798221

 step 84 is completed and loss is 0.0003192840376868844

 step 85 is completed and loss is 0.00018880968855228275

 step 86 is completed and loss is 0.0001308832288486883

 step 87 is completed and loss is 0.00027925975155085325

 step 88 is completed and loss is 0.0012667858973145485

 step 89 is completed and loss is 0.00023993707145564258

 step 90 is completed and loss is 0.0034963355865329504

 step 91 is completed and loss is 0.00026554387295618653
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:32,  1.50it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:30,  1.56it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:29,  1.58it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.57it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.56it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.56it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.55it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.57it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.57it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.57it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.58it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.58it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.58it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.55it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.51it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.52it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.49it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.51it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.53it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.56it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.57it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.56it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.57it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.59it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.60it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:13,  1.60it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.61it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.61it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:11,  1.61it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.60it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.61it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:09,  1.62it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.60it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:22<00:08,  1.59it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.57it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.58it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:24<00:06,  1.58it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.57it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:05,  1.59it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.61it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:27<00:03,  1.59it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.60it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.61it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:29<00:01,  1.60it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.57it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.57it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.57it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 8: train_perplexity=1.0030, train_epoch_loss=0.0030, epcoh time 304.7169640130005s
Training Epoch8:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch8:   1%|[34m          [0m| 1/92 [00:03<05:03,  3.33s/it]Training Epoch8:   2%|[34mâ–         [0m| 2/92 [00:06<04:56,  3.29s/it]Training Epoch8:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:46,  3.22s/it]Training Epoch8:   4%|[34mâ–         [0m| 4/92 [00:12<04:44,  3.23s/it]Training Epoch8:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:43,  3.25s/it]Training Epoch8:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.27s/it]Training Epoch8:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:39,  3.29s/it]Training Epoch8:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.29s/it]Training Epoch8:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.31s/it]Training Epoch8:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:32,  3.32s/it]Training Epoch8:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch8:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.29s/it]Training Epoch8:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.28s/it]Training Epoch8:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:16,  3.29s/it]Training Epoch8:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:17,  3.34s/it]Training Epoch8:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:12,  3.32s/it]Training Epoch8:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:07,  3.30s/it]Training Epoch8:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.31s/it]Training Epoch8:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:58,  3.27s/it]Training Epoch8:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:54,  3.25s/it]Training Epoch8:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:50,  3.25s/it]Training Epoch8:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:47,  3.25s/it]Training Epoch8:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:44,  3.25s/it]Training Epoch8:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:42,  3.28s/it]Training Epoch8:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:39,  3.28s/it]Training Epoch8:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.28s/it]Training Epoch8:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.29s/it]Training Epoch8:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:29,  3.27s/it]Training Epoch8:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:26,  3.28s/it]Training Epoch8:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:23,  3.28s/it]Training Epoch8:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:20,  3.29s/it]Training Epoch8:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:16,  3.27s/it]Training Epoch8:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:12,  3.27s/it]Training Epoch8:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:12,  3.31s/it]Training Epoch8:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:08,  3.30s/it]Training Epoch8:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:03,  3.28s/it]Training Epoch8:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:58,  3.25s/it]Training Epoch8:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:55,  3.25s/it]Training Epoch8:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:50,  3.22s/it]Training Epoch8:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:47,  3.22s/it]Training Epoch8:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:45,  3.25s/it]Training Epoch8:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:43,  3.26s/it]Training Epoch8:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:39,  3.26s/it]Training Epoch8:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:36,  3.27s/it]Training Epoch8:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:34,  3.29s/it]Training Epoch8:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:31,  3.30s/it]Training Epoch8:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:29,  3.32s/it]Training Epoch8:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:25,  3.31s/it]Training Epoch8:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:22,  3.32s/it]Training Epoch8:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:19,  3.33s/it]Training Epoch8:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:15,  3.31s/it]Training Epoch8:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:12,  3.30s/it]Training Epoch8:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.29s/it]Training Epoch8:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:05,  3.31s/it]Training Epoch8:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:02,  3.30s/it]Training Epoch8:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:58,  3.28s/it]Training Epoch8:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:55,  3.29s/it]Training Epoch8:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:51,  3.29s/it]Training Epoch8:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:48,  3.30s/it]Training Epoch8:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:45,  3.31s/it]Training Epoch8:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:41,  3.29s/it]Training Epoch8:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:39,  3.31s/it]Training Epoch8:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:35,  3.30s/it]Training Epoch8:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:32,  3.30s/it]Training Epoch8:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:30,  3.33s/it]Training Epoch8:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:26,  3.33s/it]Training Epoch8:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.31s/it]Training Epoch8:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:19,  3.32s/it]Training Epoch8:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:17,  3.35s/it]Training Epoch8:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:13,  3.33s/it]Training Epoch8:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:09,  3.31s/it]Training Epoch8:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:06,  3.32s/it]Training Epoch8:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:02,  3.31s/it]Training Epoch8:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:59,  3.31s/it]Training Epoch8:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:56,  3.32s/it]Training Epoch8:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.30s/it]Training Epoch8:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:49,  3.27s/it]Training Epoch8:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:45,  3.24s/it]Training Epoch8:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:41,  3.19s/it]Training Epoch8:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:38,  3.21s/it]Training Epoch8:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:35,  3.22s/it]Training Epoch8:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:32,  3.22s/it]Training Epoch8:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.26s/it]Training Epoch8:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.28s/it]Training Epoch8:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.29s/it]Training Epoch8:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.29s/it]Training Epoch8:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.30s/it]Training Epoch8:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.29s/it]Training Epoch8:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.28s/it]Training Epoch8:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.27s/it]Training Epoch8:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:58<00:03,  3.26s/it]Training Epoch8: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch8: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 0.0006118773017078638

 step 1 is completed and loss is 0.0008149929344654083

 step 2 is completed and loss is 0.00010048836702480912

 step 3 is completed and loss is 0.00020214921096339822

 step 4 is completed and loss is 0.00014953322533983737

 step 5 is completed and loss is 0.00018552967230789363

 step 6 is completed and loss is 0.0022082377690821886

 step 7 is completed and loss is 0.0003169500268995762

 step 8 is completed and loss is 0.00032651860965415835

 step 9 is completed and loss is 0.00010239455150440335

 step 10 is completed and loss is 0.0028352155350148678

 step 11 is completed and loss is 0.020946882665157318

 step 12 is completed and loss is 0.0006865132017992437

 step 13 is completed and loss is 0.0002521554415579885

 step 14 is completed and loss is 9.130987746175379e-05

 step 15 is completed and loss is 8.987976616481319e-05

 step 16 is completed and loss is 0.0006393369403667748

 step 17 is completed and loss is 0.0006706512067466974

 step 18 is completed and loss is 9.810421033762395e-05

 step 19 is completed and loss is 0.0002638170262798667

 step 20 is completed and loss is 0.0002672704868018627

 step 21 is completed and loss is 0.00021645217202603817

 step 22 is completed and loss is 0.0017272756667807698

 step 23 is completed and loss is 0.00022563585662283003

 step 24 is completed and loss is 0.00014536496018990874

 step 25 is completed and loss is 0.0007665544981136918

 step 26 is completed and loss is 0.0001899396302178502

 step 27 is completed and loss is 0.0010467041283845901

 step 28 is completed and loss is 0.0003949274541810155

 step 29 is completed and loss is 0.00015466191689483821

 step 30 is completed and loss is 0.0005861309473402798

 step 31 is completed and loss is 4.833782440982759e-05

 step 32 is completed and loss is 0.0005896016955375671

 step 33 is completed and loss is 0.000175401073647663

 step 34 is completed and loss is 0.0002593519748188555

 step 35 is completed and loss is 0.0006608382682316005

 step 36 is completed and loss is 5.364263051887974e-05

 step 37 is completed and loss is 0.0002858684165403247

 step 38 is completed and loss is 0.00026948313461616635

 step 39 is completed and loss is 0.00011926174920517951

 step 40 is completed and loss is 0.0002695534494705498

 step 41 is completed and loss is 0.0002366468106629327

 step 42 is completed and loss is 0.0002047787857009098

 step 43 is completed and loss is 0.0001811218389775604

 step 44 is completed and loss is 5.036440052208491e-05

 step 45 is completed and loss is 0.0005811495939269662

 step 46 is completed and loss is 9.399167902301997e-05

 step 47 is completed and loss is 0.00015740343951620162

 step 48 is completed and loss is 0.0019904393702745438

 step 49 is completed and loss is 0.0001458419137634337

 step 50 is completed and loss is 0.00014369646669365466

 step 51 is completed and loss is 0.0001265920145669952

 step 52 is completed and loss is 0.009820228442549706

 step 53 is completed and loss is 0.0009485659538768232

 step 54 is completed and loss is 0.00012283666001167148

 step 55 is completed and loss is 0.011695712804794312

 step 56 is completed and loss is 0.00021836708765476942

 step 57 is completed and loss is 0.000729141291230917

 step 58 is completed and loss is 0.00012945068010594696

 step 59 is completed and loss is 0.0027021379210054874

 step 60 is completed and loss is 0.00019309920025989413

 step 61 is completed and loss is 0.00017491530161350965

 step 62 is completed and loss is 0.00017742296040523797

 step 63 is completed and loss is 0.0035140367690473795

 step 64 is completed and loss is 0.0010203879792243242

 step 65 is completed and loss is 0.00015448288468178362

 step 66 is completed and loss is 0.0017706610960885882

 step 67 is completed and loss is 0.00011026037100236863

 step 68 is completed and loss is 0.0003664403047878295

 step 69 is completed and loss is 0.0005027791485190392

 step 70 is completed and loss is 0.00030059105483815074

 step 71 is completed and loss is 0.0006636792095378041

 step 72 is completed and loss is 0.0021853791549801826

 step 73 is completed and loss is 0.00015311245806515217

 step 74 is completed and loss is 0.00017105060396716

 step 75 is completed and loss is 0.000962203775998205

 step 76 is completed and loss is 0.00022307518520392478

 step 77 is completed and loss is 0.00012665134272538126

 step 78 is completed and loss is 0.00036268524127081037

 step 79 is completed and loss is 0.002386660547927022

 step 80 is completed and loss is 0.0008899474050849676

 step 81 is completed and loss is 0.00032882543746382

 step 82 is completed and loss is 0.0006988844252191484

 step 83 is completed and loss is 0.00029725738568231463

 step 84 is completed and loss is 0.0003210097784176469

 step 85 is completed and loss is 0.00022742546570952982

 step 86 is completed and loss is 0.00013433984713628888

 step 87 is completed and loss is 0.0003015473484992981

 step 88 is completed and loss is 0.0004819500900339335

 step 89 is completed and loss is 0.00014095506048761308

 step 90 is completed and loss is 0.0039700474590063095

 step 91 is completed and loss is 0.0002622052270453423
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:39,  1.23it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:35,  1.34it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.43it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.45it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.44it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.48it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.47it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.47it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.45it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.46it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.48it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.50it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.47it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.46it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.45it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.47it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.46it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:21,  1.47it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.50it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.52it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:18,  1.49it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.49it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.46it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.45it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.49it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:14,  1.48it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.44it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:14,  1.41it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:12,  1.46it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.45it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.48it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.53it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.54it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.55it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.55it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.53it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:06,  1.58it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.56it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.57it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.60it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.56it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.54it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.58it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.59it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.55it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.50it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.48it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.48it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 9: train_perplexity=1.0010, train_epoch_loss=0.0010, epcoh time 302.56394803200055s
Training Epoch9:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch9:   1%|[34m          [0m| 1/92 [00:03<05:00,  3.30s/it]Training Epoch9:   2%|[34mâ–         [0m| 2/92 [00:06<04:55,  3.28s/it]Training Epoch9:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:50,  3.27s/it]Training Epoch9:   4%|[34mâ–         [0m| 4/92 [00:13<04:46,  3.26s/it]Training Epoch9:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:42,  3.25s/it]Training Epoch9:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.27s/it]Training Epoch9:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.31s/it]Training Epoch9:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.31s/it]Training Epoch9:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.31s/it]Training Epoch9:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:32,  3.32s/it]Training Epoch9:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.31s/it]Training Epoch9:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.32s/it]Training Epoch9:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:23,  3.33s/it]Training Epoch9:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.30s/it]Training Epoch9:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch9:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.29s/it]Training Epoch9:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:06,  3.29s/it]Training Epoch9:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:03,  3.30s/it]Training Epoch9:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:03,  3.34s/it]Training Epoch9:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:01,  3.36s/it]Training Epoch9:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.31s/it]Training Epoch9:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.31s/it]Training Epoch9:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:47,  3.30s/it]Training Epoch9:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.32s/it]Training Epoch9:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.29s/it]Training Epoch9:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:37,  3.30s/it]Training Epoch9:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.30s/it]Training Epoch9:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.29s/it]Training Epoch9:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:29,  3.33s/it]Training Epoch9:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.32s/it]Training Epoch9:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:23,  3.33s/it]Training Epoch9:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:19,  3.32s/it]Training Epoch9:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:15,  3.31s/it]Training Epoch9:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.31s/it]Training Epoch9:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:09,  3.33s/it]Training Epoch9:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:04,  3.30s/it]Training Epoch9:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:00,  3.28s/it]Training Epoch9:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.30s/it]Training Epoch9:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.29s/it]Training Epoch9:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:49,  3.27s/it]Training Epoch9:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:47,  3.28s/it]Training Epoch9:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:44,  3.30s/it]Training Epoch9:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:41,  3.29s/it]Training Epoch9:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.30s/it]Training Epoch9:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:34,  3.28s/it]Training Epoch9:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:31,  3.29s/it]Training Epoch9:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:28,  3.30s/it]Training Epoch9:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:24,  3.29s/it]Training Epoch9:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:20,  3.27s/it]Training Epoch9:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:16,  3.25s/it]Training Epoch9:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:13,  3.27s/it]Training Epoch9:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.28s/it]Training Epoch9:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.29s/it]Training Epoch9:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:04,  3.27s/it]Training Epoch9:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:00,  3.25s/it]Training Epoch9:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:57,  3.25s/it]Training Epoch9:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:54,  3.27s/it]Training Epoch9:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:51,  3.27s/it]Training Epoch9:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.31s/it]Training Epoch9:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:46,  3.32s/it]Training Epoch9:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.31s/it]Training Epoch9:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.33s/it]Training Epoch9:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:36,  3.32s/it]Training Epoch9:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.32s/it]Training Epoch9:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.31s/it]Training Epoch9:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.28s/it]Training Epoch9:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:21,  3.27s/it]Training Epoch9:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:18,  3.26s/it]Training Epoch9:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:15,  3.26s/it]Training Epoch9:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.27s/it]Training Epoch9:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.26s/it]Training Epoch9:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.25s/it]Training Epoch9:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:01,  3.26s/it]Training Epoch9:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:58,  3.27s/it]Training Epoch9:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:55,  3.28s/it]Training Epoch9:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.29s/it]Training Epoch9:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:49,  3.30s/it]Training Epoch9:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:45,  3.28s/it]Training Epoch9:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.29s/it]Training Epoch9:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:39,  3.29s/it]Training Epoch9:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:36,  3.28s/it]Training Epoch9:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:32,  3.30s/it]Training Epoch9:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.31s/it]Training Epoch9:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.30s/it]Training Epoch9:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.29s/it]Training Epoch9:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.28s/it]Training Epoch9:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.28s/it]Training Epoch9:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.29s/it]Training Epoch9:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.28s/it]Training Epoch9:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.29s/it]Training Epoch9:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.28s/it]Training Epoch9: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.27s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch9: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 0.0007270415080711246

 step 1 is completed and loss is 0.0004756208509206772

 step 2 is completed and loss is 7.646983431186527e-05

 step 3 is completed and loss is 0.00025076698511838913

 step 4 is completed and loss is 0.00012110552779631689

 step 5 is completed and loss is 0.0001489998830948025

 step 6 is completed and loss is 0.003160338383167982

 step 7 is completed and loss is 0.00024325652339030057

 step 8 is completed and loss is 0.0001816577569115907

 step 9 is completed and loss is 9.905738261295483e-05

 step 10 is completed and loss is 0.0016437459271401167

 step 11 is completed and loss is 0.004004999529570341

 step 12 is completed and loss is 0.0004311770899221301

 step 13 is completed and loss is 0.00021556664432864636

 step 14 is completed and loss is 8.624397742096335e-05

 step 15 is completed and loss is 7.283422019099817e-05

 step 16 is completed and loss is 0.00025005871430039406

 step 17 is completed and loss is 0.0005058447131887078

 step 18 is completed and loss is 8.403901301790029e-05

 step 19 is completed and loss is 0.0005901885451748967

 step 20 is completed and loss is 0.00022699596593156457

 step 21 is completed and loss is 0.0001628239988349378

 step 22 is completed and loss is 0.0015992606058716774

 step 23 is completed and loss is 0.00022909074323251843

 step 24 is completed and loss is 0.00012021533621009439

 step 25 is completed and loss is 0.001401027082465589

 step 26 is completed and loss is 0.00013076351024210453

 step 27 is completed and loss is 0.000636029988527298

 step 28 is completed and loss is 0.00025517615722492337

 step 29 is completed and loss is 0.00017218275752384216

 step 30 is completed and loss is 0.00036342977546155453

 step 31 is completed and loss is 4.041084321215749e-05

 step 32 is completed and loss is 0.0004368019290268421

 step 33 is completed and loss is 0.0001750429510138929

 step 34 is completed and loss is 0.0002088877954520285

 step 35 is completed and loss is 0.000534931430593133

 step 36 is completed and loss is 4.655007069231942e-05

 step 37 is completed and loss is 0.00014613947132602334

 step 38 is completed and loss is 0.00021126936189830303

 step 39 is completed and loss is 0.00011121600982733071

 step 40 is completed and loss is 0.00026061711832880974

 step 41 is completed and loss is 0.0001568008738104254

 step 42 is completed and loss is 0.0001563297410029918

 step 43 is completed and loss is 0.00010221558477496728

 step 44 is completed and loss is 5.382084418670274e-05

 step 45 is completed and loss is 0.0009861362632364035

 step 46 is completed and loss is 7.408532837871462e-05

 step 47 is completed and loss is 0.00015871426148805767

 step 48 is completed and loss is 0.0014942748239263892

 step 49 is completed and loss is 0.00012551946565508842

 step 50 is completed and loss is 0.00016699815751053393

 step 51 is completed and loss is 0.00010483901132829487

 step 52 is completed and loss is 0.007286825682967901

 step 53 is completed and loss is 0.0009678834467194974

 step 54 is completed and loss is 7.402620394714177e-05

 step 55 is completed and loss is 0.004978395998477936

 step 56 is completed and loss is 0.00013702167780138552

 step 57 is completed and loss is 0.0004316782287787646

 step 58 is completed and loss is 0.00011914021160919219

 step 59 is completed and loss is 0.001697104424238205

 step 60 is completed and loss is 0.00017474534979555756

 step 61 is completed and loss is 0.0001675266830716282

 step 62 is completed and loss is 0.00022688208264298737

 step 63 is completed and loss is 0.001979683991521597

 step 64 is completed and loss is 0.0011346910614520311

 step 65 is completed and loss is 0.000157284113811329

 step 66 is completed and loss is 0.0015179873444139957

 step 67 is completed and loss is 0.00014565781748387963

 step 68 is completed and loss is 0.00033718577469699085

 step 69 is completed and loss is 0.00036821377580054104

 step 70 is completed and loss is 0.00032311101676896214

 step 71 is completed and loss is 0.0005877724615857005

 step 72 is completed and loss is 0.0017414591275155544

 step 73 is completed and loss is 0.0001535892515676096

 step 74 is completed and loss is 0.00018487582565285265

 step 75 is completed and loss is 0.0005693135899491608

 step 76 is completed and loss is 0.0002203933836426586

 step 77 is completed and loss is 0.00011216939310543239

 step 78 is completed and loss is 0.00028933811699971557

 step 79 is completed and loss is 0.001966952346265316

 step 80 is completed and loss is 0.0007128069410100579

 step 81 is completed and loss is 0.00023427077394444495

 step 82 is completed and loss is 0.0005734984297305346

 step 83 is completed and loss is 0.00027359987143427134

 step 84 is completed and loss is 0.00023921072715893388

 step 85 is completed and loss is 0.00019095504831057042

 step 86 is completed and loss is 0.00015901254664640874

 step 87 is completed and loss is 0.00019780681759584695

 step 88 is completed and loss is 0.0007610043394379318

 step 89 is completed and loss is 0.0001460204366594553

 step 90 is completed and loss is 0.003426888259127736

 step 91 is completed and loss is 0.00048705836525186896
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:32,  1.53it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.53it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.52it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.49it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.46it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.44it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:30,  1.40it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.41it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.48it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.54it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.60it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.56it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.56it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.50it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.48it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.46it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:20,  1.53it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.53it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.49it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.50it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.50it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.50it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.49it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.51it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.50it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.48it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.45it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.47it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.46it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.47it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.49it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.51it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.54it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.50it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.52it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.51it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.50it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.50it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.57it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.57it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.57it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.54it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.51it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.51it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.52it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.52it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.50it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6600)
Epoch 10: train_perplexity=1.0007, train_epoch_loss=0.0007, epcoh time 303.2764677409996s
Training Epoch10:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch10:   1%|[34m          [0m| 1/92 [00:03<04:54,  3.23s/it]Training Epoch10:   2%|[34mâ–         [0m| 2/92 [00:06<04:51,  3.24s/it]Training Epoch10:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.25s/it]Training Epoch10:   4%|[34mâ–         [0m| 4/92 [00:13<04:49,  3.29s/it]Training Epoch10:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.28s/it]Training Epoch10:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.26s/it]Training Epoch10:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.26s/it]Training Epoch10:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.28s/it]Training Epoch10:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:32,  3.28s/it]Training Epoch10:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.27s/it]Training Epoch10:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:23,  3.25s/it]Training Epoch10:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.27s/it]Training Epoch10:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:21,  3.31s/it]Training Epoch10:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:22,  3.36s/it]Training Epoch10:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch10:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.31s/it]Training Epoch10:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:05,  3.28s/it]Training Epoch10:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:02,  3.28s/it]Training Epoch10:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:00,  3.29s/it]Training Epoch10:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.29s/it]Training Epoch10:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.31s/it]Training Epoch10:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch10:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:44,  3.26s/it]Training Epoch10:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:41,  3.26s/it]Training Epoch10:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:38,  3.26s/it]Training Epoch10:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.29s/it]Training Epoch10:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:32,  3.27s/it]Training Epoch10:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:29,  3.28s/it]Training Epoch10:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:27,  3.29s/it]Training Epoch10:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:25,  3.32s/it]Training Epoch10:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:23,  3.33s/it]Training Epoch10:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:17,  3.30s/it]Training Epoch10:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:12,  3.27s/it]Training Epoch10:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:08,  3.25s/it]Training Epoch10:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:05,  3.26s/it]Training Epoch10:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:02,  3.26s/it]Training Epoch10:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:59,  3.26s/it]Training Epoch10:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:57,  3.28s/it]Training Epoch10:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:52,  3.26s/it]Training Epoch10:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:49,  3.26s/it]Training Epoch10:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:46,  3.27s/it]Training Epoch10:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:44,  3.29s/it]Training Epoch10:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:41,  3.30s/it]Training Epoch10:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:38,  3.31s/it]Training Epoch10:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.26s/it]Training Epoch10:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:29,  3.26s/it]Training Epoch10:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:26,  3.26s/it]Training Epoch10:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:23,  3.26s/it]Training Epoch10:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:20,  3.27s/it]Training Epoch10:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:17,  3.27s/it]Training Epoch10:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:13,  3.27s/it]Training Epoch10:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:09,  3.25s/it]Training Epoch10:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:06,  3.25s/it]Training Epoch10:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:02,  3.24s/it]Training Epoch10:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:00,  3.27s/it]Training Epoch10:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:58,  3.28s/it]Training Epoch10:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:55,  3.30s/it]Training Epoch10:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:51,  3.28s/it]Training Epoch10:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:48,  3.28s/it]Training Epoch10:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:44,  3.28s/it]Training Epoch10:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:42,  3.29s/it]Training Epoch10:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:38,  3.29s/it]Training Epoch10:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:35,  3.29s/it]Training Epoch10:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:31,  3.28s/it]Training Epoch10:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:28,  3.28s/it]Training Epoch10:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:24,  3.27s/it]Training Epoch10:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:21,  3.26s/it]Training Epoch10:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:18,  3.25s/it]Training Epoch10:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:14,  3.25s/it]Training Epoch10:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:11,  3.25s/it]Training Epoch10:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:07,  3.24s/it]Training Epoch10:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:55<01:04,  3.23s/it]Training Epoch10:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:58<01:01,  3.24s/it]Training Epoch10:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:59,  3.28s/it]Training Epoch10:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:05<00:56,  3.31s/it]Training Epoch10:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:08<00:52,  3.26s/it]Training Epoch10:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:48,  3.27s/it]Training Epoch10:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:45,  3.27s/it]Training Epoch10:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:18<00:42,  3.25s/it]Training Epoch10:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:21<00:38,  3.24s/it]Training Epoch10:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:35,  3.26s/it]Training Epoch10:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:28<00:32,  3.25s/it]Training Epoch10:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:31<00:29,  3.24s/it]Training Epoch10:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:34<00:26,  3.26s/it]Training Epoch10:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:38<00:22,  3.25s/it]Training Epoch10:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:41<00:19,  3.23s/it]Training Epoch10:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:44<00:16,  3.24s/it]Training Epoch10:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:47<00:12,  3.25s/it]Training Epoch10:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:51<00:09,  3.27s/it]Training Epoch10:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:54<00:06,  3.26s/it]Training Epoch10:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:57<00:03,  3.29s/it]Training Epoch10: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch10: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.27s/it]

 step 0 is completed and loss is 0.0002741767093539238

 step 1 is completed and loss is 0.0004138536751270294

 step 2 is completed and loss is 7.545662083430216e-05

 step 3 is completed and loss is 0.000312242831569165

 step 4 is completed and loss is 0.0001552511239424348

 step 5 is completed and loss is 0.00011985642777290195

 step 6 is completed and loss is 0.0015818930696696043

 step 7 is completed and loss is 0.0002110224886564538

 step 8 is completed and loss is 0.00016634271014481783

 step 9 is completed and loss is 7.849582470953465e-05

 step 10 is completed and loss is 0.009267245419323444

 step 11 is completed and loss is 0.0037089260295033455

 step 12 is completed and loss is 0.00048572904779575765

 step 13 is completed and loss is 0.000170156781678088

 step 14 is completed and loss is 0.00010066713730338961

 step 15 is completed and loss is 7.390703103737906e-05

 step 16 is completed and loss is 0.0003499003651086241

 step 17 is completed and loss is 0.00048542555305175483

 step 18 is completed and loss is 8.73765820870176e-05

 step 19 is completed and loss is 0.00021579262102022767

 step 20 is completed and loss is 0.00010585144627839327

 step 21 is completed and loss is 0.00012081082968506962

 step 22 is completed and loss is 0.001205757143907249

 step 23 is completed and loss is 0.00022426337818615139

 step 24 is completed and loss is 0.0001323731557931751

 step 25 is completed and loss is 0.0007057777256704867

 step 26 is completed and loss is 0.00020042213145643473

 step 27 is completed and loss is 0.0007517954800277948

 step 28 is completed and loss is 0.00034828338539227843

 step 29 is completed and loss is 0.0001398819440510124

 step 30 is completed and loss is 0.0003817255492322147

 step 31 is completed and loss is 3.290117092547007e-05

 step 32 is completed and loss is 0.0002922342100646347

 step 33 is completed and loss is 0.00017015464254654944

 step 34 is completed and loss is 0.00018803185957949609

 step 35 is completed and loss is 0.0006823759758844972

 step 36 is completed and loss is 3.72521644749213e-05

 step 37 is completed and loss is 0.00020835152827203274

 step 38 is completed and loss is 0.00022521280334331095

 step 39 is completed and loss is 0.0001031702704494819

 step 40 is completed and loss is 0.000451086089015007

 step 41 is completed and loss is 0.0001332611864199862

 step 42 is completed and loss is 0.00020585002494044602

 step 43 is completed and loss is 0.0001373786071781069

 step 44 is completed and loss is 4.386761429486796e-05

 step 45 is completed and loss is 0.0006466669728979468

 step 46 is completed and loss is 6.711187597829849e-05

 step 47 is completed and loss is 0.00014667626237496734

 step 48 is completed and loss is 0.0009517093421891332

 step 49 is completed and loss is 0.00013356505951378495

 step 50 is completed and loss is 0.00014900004316587

 step 51 is completed and loss is 0.00010740179277490824

 step 52 is completed and loss is 0.006338999606668949

 step 53 is completed and loss is 0.000899215170647949

 step 54 is completed and loss is 9.345571743324399e-05

 step 55 is completed and loss is 0.003041674382984638

 step 56 is completed and loss is 0.0001298700663028285

 step 57 is completed and loss is 0.0006708157598040998

 step 58 is completed and loss is 0.00011252374679315835

 step 59 is completed and loss is 0.001581616117618978

 step 60 is completed and loss is 0.00015931014786474407

 step 61 is completed and loss is 0.00011109361366834491

 step 62 is completed and loss is 0.00015012850053608418

 step 63 is completed and loss is 0.0022738585248589516

 step 64 is completed and loss is 0.0006816844688728452

 step 65 is completed and loss is 0.00014923856360837817

 step 66 is completed and loss is 0.0008944026194512844

 step 67 is completed and loss is 0.00010871030099224299

 step 68 is completed and loss is 0.00029958708910271525

 step 69 is completed and loss is 0.0003243014507461339

 step 70 is completed and loss is 0.0002643092884682119

 step 71 is completed and loss is 0.0007468208204954863

 step 72 is completed and loss is 0.0013889053370803595

 step 73 is completed and loss is 0.00011926163278985769

 step 74 is completed and loss is 0.00015400572738144547

 step 75 is completed and loss is 0.0005337548209354281

 step 76 is completed and loss is 0.0002188438957091421

 step 77 is completed and loss is 0.00012140635953983292

 step 78 is completed and loss is 0.000271754979621619

 step 79 is completed and loss is 0.0017428759019821882

 step 80 is completed and loss is 0.0007729892968200147

 step 81 is completed and loss is 0.00021794496569782495

 step 82 is completed and loss is 0.0003987573436461389

 step 83 is completed and loss is 0.00023040433006826788

 step 84 is completed and loss is 0.0002203245967393741

 step 85 is completed and loss is 0.00019965562387369573

 step 86 is completed and loss is 0.00011860620725201443

 step 87 is completed and loss is 0.00024893638328649104

 step 88 is completed and loss is 0.0005360195063985884

 step 89 is completed and loss is 9.983271593227983e-05

 step 90 is completed and loss is 0.004308081232011318

 step 91 is completed and loss is 0.0002175208501284942
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.39it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.50it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.55it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.59it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.58it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.57it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.56it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.57it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.59it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.58it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:06<00:24,  1.62it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.64it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:22,  1.63it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.63it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.64it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:20,  1.64it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:19,  1.67it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:19,  1.65it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:11<00:19,  1.63it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:18,  1.62it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.58it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:13<00:18,  1.54it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.52it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:16,  1.52it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.54it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.58it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:13,  1.58it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.59it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:18<00:12,  1.61it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:11,  1.60it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.61it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:20<00:10,  1.60it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:09,  1.60it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:21<00:09,  1.62it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:22<00:08,  1.64it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.61it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:23<00:07,  1.59it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:24<00:06,  1.58it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:25<00:05,  1.59it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:04,  1.61it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:26<00:04,  1.62it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:27<00:03,  1.60it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.59it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:28<00:02,  1.60it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:29<00:01,  1.64it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.59it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:30<00:00,  1.60it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.61it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.59it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6600)
Epoch 11: train_perplexity=1.0006, train_epoch_loss=0.0006, epcoh time 301.402256974s
Training Epoch11:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch11:   1%|[34m          [0m| 1/92 [00:03<04:52,  3.22s/it]Training Epoch11:   2%|[34mâ–         [0m| 2/92 [00:06<04:46,  3.18s/it]Training Epoch11:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:41,  3.16s/it]Training Epoch11:   4%|[34mâ–         [0m| 4/92 [00:12<04:41,  3.20s/it]Training Epoch11:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:40,  3.22s/it]Training Epoch11:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:36,  3.22s/it]Training Epoch11:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:34,  3.23s/it]Training Epoch11:   9%|[34mâ–Š         [0m| 8/92 [00:25<04:31,  3.24s/it]Training Epoch11:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:29,  3.24s/it]Training Epoch11:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:25,  3.24s/it]Training Epoch11:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:23,  3.25s/it]Training Epoch11:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:38<04:19,  3.25s/it]Training Epoch11:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:41<04:16,  3.24s/it]Training Epoch11:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:13,  3.25s/it]Training Epoch11:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:48<04:09,  3.25s/it]Training Epoch11:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:51<04:07,  3.26s/it]Training Epoch11:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:04,  3.26s/it]Training Epoch11:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:02,  3.28s/it]Training Epoch11:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:01<04:00,  3.29s/it]Training Epoch11:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:04<03:56,  3.29s/it]Training Epoch11:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:51,  3.26s/it]Training Epoch11:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:48,  3.27s/it]Training Epoch11:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:14<03:45,  3.27s/it]Training Epoch11:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:44,  3.30s/it]Training Epoch11:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:40,  3.29s/it]Training Epoch11:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:36,  3.29s/it]Training Epoch11:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:27<03:32,  3.27s/it]Training Epoch11:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:29,  3.27s/it]Training Epoch11:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:26,  3.27s/it]Training Epoch11:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:22,  3.26s/it]Training Epoch11:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:40<03:17,  3.24s/it]Training Epoch11:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:13,  3.23s/it]Training Epoch11:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:11,  3.24s/it]Training Epoch11:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:06,  3.22s/it]Training Epoch11:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:53<03:02,  3.21s/it]Training Epoch11:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:56<02:59,  3.21s/it]Training Epoch11:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:00<02:57,  3.23s/it]Training Epoch11:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:03<02:54,  3.23s/it]Training Epoch11:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:06<02:50,  3.21s/it]Training Epoch11:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:09<02:47,  3.22s/it]Training Epoch11:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:44,  3.23s/it]Training Epoch11:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:16<02:41,  3.23s/it]Training Epoch11:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:19<02:38,  3.23s/it]Training Epoch11:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:22<02:36,  3.25s/it]Training Epoch11:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:25<02:31,  3.23s/it]Training Epoch11:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:29<02:28,  3.23s/it]Training Epoch11:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:32<02:25,  3.23s/it]Training Epoch11:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:35<02:22,  3.23s/it]Training Epoch11:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:38<02:19,  3.23s/it]Training Epoch11:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:42<02:16,  3.24s/it]Training Epoch11:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:45<02:13,  3.25s/it]Training Epoch11:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:48<02:11,  3.28s/it]Training Epoch11:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:52<02:08,  3.29s/it]Training Epoch11:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:55<02:04,  3.28s/it]Training Epoch11:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:58<02:01,  3.28s/it]Training Epoch11:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:01<01:58,  3.29s/it]Training Epoch11:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:05<01:55,  3.29s/it]Training Epoch11:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:08<01:52,  3.31s/it]Training Epoch11:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:11<01:49,  3.31s/it]Training Epoch11:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:15<01:46,  3.32s/it]Training Epoch11:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:18<01:43,  3.33s/it]Training Epoch11:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:21<01:38,  3.27s/it]Training Epoch11:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:24<01:33,  3.23s/it]Training Epoch11:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:28<01:30,  3.24s/it]Training Epoch11:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:31<01:27,  3.25s/it]Training Epoch11:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:34<01:24,  3.25s/it]Training Epoch11:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:37<01:21,  3.25s/it]Training Epoch11:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:41<01:18,  3.27s/it]Training Epoch11:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:44<01:15,  3.28s/it]Training Epoch11:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:47<01:11,  3.27s/it]Training Epoch11:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:51<01:08,  3.27s/it]Training Epoch11:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:54<01:05,  3.26s/it]Training Epoch11:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:57<01:01,  3.26s/it]Training Epoch11:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:00<00:58,  3.27s/it]Training Epoch11:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:04<00:55,  3.27s/it]Training Epoch11:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:07<00:52,  3.27s/it]Training Epoch11:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:10<00:49,  3.27s/it]Training Epoch11:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:13<00:45,  3.28s/it]Training Epoch11:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:17<00:42,  3.30s/it]Training Epoch11:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:20<00:39,  3.27s/it]Training Epoch11:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:23<00:35,  3.26s/it]Training Epoch11:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:26<00:32,  3.25s/it]Training Epoch11:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:30<00:29,  3.25s/it]Training Epoch11:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:33<00:26,  3.26s/it]Training Epoch11:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:36<00:22,  3.25s/it]Training Epoch11:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:39<00:19,  3.23s/it]Training Epoch11:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:43<00:16,  3.22s/it]Training Epoch11:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:46<00:13,  3.27s/it]Training Epoch11:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:49<00:09,  3.27s/it]Training Epoch11:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:52<00:06,  3.26s/it]Training Epoch11:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:56<00:03,  3.28s/it]Training Epoch11: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:59<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch11: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:59<00:00,  3.26s/it]

 step 0 is completed and loss is 0.00021394208306446671

 step 1 is completed and loss is 0.00035141606349498034

 step 2 is completed and loss is 6.878137355670333e-05

 step 3 is completed and loss is 0.00012605187657754868

 step 4 is completed and loss is 0.00013880337064620107

 step 5 is completed and loss is 0.00010686471068765968

 step 6 is completed and loss is 0.0017244938062503934

 step 7 is completed and loss is 0.00012736277130898088

 step 8 is completed and loss is 0.00013821352331433445

 step 9 is completed and loss is 6.68738575768657e-05

 step 10 is completed and loss is 0.0008568806224502623

 step 11 is completed and loss is 0.0024491797666996717

 step 12 is completed and loss is 0.00046050726086832583

 step 13 is completed and loss is 0.0001340413000434637

 step 14 is completed and loss is 9.530227544018999e-05

 step 15 is completed and loss is 7.676783570786938e-05

 step 16 is completed and loss is 0.0004579498781822622

 step 17 is completed and loss is 0.00032369373366236687

 step 18 is completed and loss is 8.505220466759056e-05

 step 19 is completed and loss is 0.00020513158233370632

 step 20 is completed and loss is 0.00013457635941449553

 step 21 is completed and loss is 0.00015805516159161925

 step 22 is completed and loss is 0.0011639780132099986

 step 23 is completed and loss is 0.00017194155952893198

 step 24 is completed and loss is 0.00011133527004858479

 step 25 is completed and loss is 0.0005345920217223465

 step 26 is completed and loss is 0.0001656238455325365

 step 27 is completed and loss is 0.00039566942723467946

 step 28 is completed and loss is 0.00029181584250181913

 step 29 is completed and loss is 0.0001564498379593715

 step 30 is completed and loss is 0.000331031100358814

 step 31 is completed and loss is 3.12322263198439e-05

 step 32 is completed and loss is 0.0002663203049451113

 step 33 is completed and loss is 0.00015400652773678303

 step 34 is completed and loss is 0.0001332657120656222

 step 35 is completed and loss is 0.0004866315284743905

 step 36 is completed and loss is 3.218591882614419e-05

 step 37 is completed and loss is 0.00011926111619686708

 step 38 is completed and loss is 0.00016622035764157772

 step 39 is completed and loss is 9.572047565598041e-05

 step 40 is completed and loss is 0.00023713853443041444

 step 41 is completed and loss is 9.691037848824635e-05

 step 42 is completed and loss is 0.00011777183681260794

 step 43 is completed and loss is 0.00010668504546629265

 step 44 is completed and loss is 4.321198503021151e-05

 step 45 is completed and loss is 0.0004108135763090104

 step 46 is completed and loss is 4.410626570461318e-05

 step 47 is completed and loss is 0.00012486393097788095

 step 48 is completed and loss is 0.0012068431824445724

 step 49 is completed and loss is 0.00013332668459042907

 step 50 is completed and loss is 0.0001428613904863596

 step 51 is completed and loss is 9.756801591720432e-05

 step 52 is completed and loss is 0.005579423625022173

 step 53 is completed and loss is 0.0006486964994110167

 step 54 is completed and loss is 7.65293079894036e-05

 step 55 is completed and loss is 0.0032219113782048225

 step 56 is completed and loss is 9.786603914108127e-05

 step 57 is completed and loss is 0.0004128575965296477

 step 58 is completed and loss is 9.726813004817814e-05

 step 59 is completed and loss is 0.00081141188275069

 step 60 is completed and loss is 0.00014339794870465994

 step 61 is completed and loss is 0.00015304653788916767

 step 62 is completed and loss is 0.00016311832587234676

 step 63 is completed and loss is 0.0009047602652572095

 step 64 is completed and loss is 0.0006746737635694444

 step 65 is completed and loss is 0.00013255146041046828

 step 66 is completed and loss is 0.0019142534583806992

 step 67 is completed and loss is 0.00011419280781410635

 step 68 is completed and loss is 0.00036006642039865255

 step 69 is completed and loss is 0.0002701449557207525

 step 70 is completed and loss is 0.0002772933803498745

 step 71 is completed and loss is 0.00038486981065943837

 step 72 is completed and loss is 0.002167124766856432

 step 73 is completed and loss is 0.00012486374180298299

 step 74 is completed and loss is 0.00016645988216623664

 step 75 is completed and loss is 0.0003482059692032635

 step 76 is completed and loss is 0.00023499327653553337

 step 77 is completed and loss is 0.00012194315058877692

 step 78 is completed and loss is 0.00028885770007036626

 step 79 is completed and loss is 0.0010995925404131413

 step 80 is completed and loss is 0.0004982054815627635

 step 81 is completed and loss is 0.0001842778583522886

 step 82 is completed and loss is 0.0003337044909130782

 step 83 is completed and loss is 0.000262400193605572

 step 84 is completed and loss is 0.00017217938147950917

 step 85 is completed and loss is 0.00020704510097857565

 step 86 is completed and loss is 0.0001387499796692282

 step 87 is completed and loss is 0.0002093671209877357

 step 88 is completed and loss is 0.000515892228577286

 step 89 is completed and loss is 9.274024341721088e-05

 step 90 is completed and loss is 0.0019093562150374055

 step 91 is completed and loss is 0.0007972161984071136
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.45it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.44it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.43it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.47it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.51it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.51it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.52it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.56it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.59it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.60it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.63it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:22,  1.63it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:22,  1.60it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.59it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.55it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.55it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.59it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.62it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:18,  1.65it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.58it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.57it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.56it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.53it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.55it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.54it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.51it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.52it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.55it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.54it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.53it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.50it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.51it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.51it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.53it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.56it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.56it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.61it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:04,  1.62it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.64it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.65it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.64it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.63it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.61it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.63it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.66it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.63it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.57it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 12: train_perplexity=1.0005, train_epoch_loss=0.0005, epcoh time 299.93850824200035s
Training Epoch12:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch12:   1%|[34m          [0m| 1/92 [00:03<04:54,  3.23s/it]Training Epoch12:   2%|[34mâ–         [0m| 2/92 [00:06<04:52,  3.25s/it]Training Epoch12:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:47,  3.23s/it]Training Epoch12:   4%|[34mâ–         [0m| 4/92 [00:12<04:43,  3.22s/it]Training Epoch12:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:40,  3.23s/it]Training Epoch12:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:37,  3.22s/it]Training Epoch12:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.27s/it]Training Epoch12:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.28s/it]Training Epoch12:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.29s/it]Training Epoch12:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:29,  3.29s/it]Training Epoch12:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:25,  3.28s/it]Training Epoch12:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.27s/it]Training Epoch12:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:16,  3.25s/it]Training Epoch12:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:12,  3.23s/it]Training Epoch12:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:48<04:06,  3.21s/it]Training Epoch12:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:51<04:02,  3.19s/it]Training Epoch12:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:00,  3.20s/it]Training Epoch12:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<03:59,  3.24s/it]Training Epoch12:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:01<03:55,  3.22s/it]Training Epoch12:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:04<03:52,  3.22s/it]Training Epoch12:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:48,  3.22s/it]Training Epoch12:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:45,  3.22s/it]Training Epoch12:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:14<03:41,  3.21s/it]Training Epoch12:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:17<03:40,  3.24s/it]Training Epoch12:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:20<03:36,  3.23s/it]Training Epoch12:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:33,  3.24s/it]Training Epoch12:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:27<03:29,  3.23s/it]Training Epoch12:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:30<03:26,  3.23s/it]Training Epoch12:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:33<03:24,  3.24s/it]Training Epoch12:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:20,  3.23s/it]Training Epoch12:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:40<03:17,  3.23s/it]Training Epoch12:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:43<03:14,  3.24s/it]Training Epoch12:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:46<03:10,  3.23s/it]Training Epoch12:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:08,  3.24s/it]Training Epoch12:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:53<03:04,  3.24s/it]Training Epoch12:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:56<03:00,  3.23s/it]Training Epoch12:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [01:59<02:56,  3.21s/it]Training Epoch12:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:02<02:54,  3.23s/it]Training Epoch12:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:06<02:52,  3.25s/it]Training Epoch12:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:09<02:48,  3.24s/it]Training Epoch12:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:12<02:44,  3.23s/it]Training Epoch12:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:15<02:41,  3.24s/it]Training Epoch12:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:19<02:37,  3.22s/it]Training Epoch12:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:22<02:34,  3.23s/it]Training Epoch12:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:25<02:32,  3.25s/it]Training Epoch12:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:28<02:28,  3.23s/it]Training Epoch12:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:31<02:24,  3.20s/it]Training Epoch12:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:35<02:20,  3.19s/it]Training Epoch12:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:38<02:17,  3.20s/it]Training Epoch12:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:41<02:14,  3.21s/it]Training Epoch12:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:44<02:11,  3.22s/it]Training Epoch12:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:48<02:09,  3.23s/it]Training Epoch12:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:51<02:06,  3.24s/it]Training Epoch12:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:54<02:02,  3.23s/it]Training Epoch12:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:57<01:58,  3.21s/it]Training Epoch12:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:00<01:55,  3.20s/it]Training Epoch12:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:04<01:52,  3.20s/it]Training Epoch12:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:07<01:49,  3.23s/it]Training Epoch12:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:10<01:46,  3.23s/it]Training Epoch12:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:13<01:42,  3.21s/it]Training Epoch12:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:16<01:38,  3.19s/it]Training Epoch12:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:20<01:36,  3.21s/it]Training Epoch12:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:23<01:34,  3.25s/it]Training Epoch12:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:26<01:31,  3.26s/it]Training Epoch12:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:30<01:28,  3.26s/it]Training Epoch12:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:33<01:24,  3.26s/it]Training Epoch12:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:36<01:21,  3.25s/it]Training Epoch12:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:39<01:18,  3.27s/it]Training Epoch12:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:43<01:14,  3.26s/it]Training Epoch12:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:46<01:11,  3.23s/it]Training Epoch12:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:49<01:07,  3.22s/it]Training Epoch12:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:52<01:04,  3.21s/it]Training Epoch12:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:55<01:01,  3.25s/it]Training Epoch12:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [03:59<00:58,  3.26s/it]Training Epoch12:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:02<00:55,  3.26s/it]Training Epoch12:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:05<00:51,  3.24s/it]Training Epoch12:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:08<00:48,  3.25s/it]Training Epoch12:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:12<00:45,  3.23s/it]Training Epoch12:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:15<00:42,  3.23s/it]Training Epoch12:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:18<00:38,  3.24s/it]Training Epoch12:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:21<00:35,  3.25s/it]Training Epoch12:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:25<00:32,  3.26s/it]Training Epoch12:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:28<00:29,  3.27s/it]Training Epoch12:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:31<00:26,  3.28s/it]Training Epoch12:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:35<00:23,  3.29s/it]Training Epoch12:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:38<00:19,  3.27s/it]Training Epoch12:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:41<00:16,  3.28s/it]Training Epoch12:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:44<00:13,  3.26s/it]Training Epoch12:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:48<00:09,  3.27s/it]Training Epoch12:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:51<00:06,  3.27s/it]Training Epoch12:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:54<00:03,  3.27s/it]Training Epoch12: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:57<00:00,  3.25s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch12: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:57<00:00,  3.24s/it]

 step 0 is completed and loss is 0.00034500291803851724

 step 1 is completed and loss is 0.0003251424350310117

 step 2 is completed and loss is 8.171462832251564e-05

 step 3 is completed and loss is 0.00016287916514556855

 step 4 is completed and loss is 0.00011502637062221766

 step 5 is completed and loss is 0.00013058305194135755

 step 6 is completed and loss is 0.0009002407896332443

 step 7 is completed and loss is 0.00013844722707290202

 step 8 is completed and loss is 0.0001423853391315788

 step 9 is completed and loss is 7.89129117038101e-05

 step 10 is completed and loss is 0.0011433333856984973

 step 11 is completed and loss is 0.0037326894234865904

 step 12 is completed and loss is 0.00035252771340310574

 step 13 is completed and loss is 0.00011538785474840552

 step 14 is completed and loss is 9.107166260946542e-05

 step 15 is completed and loss is 5.8530047681415454e-05

 step 16 is completed and loss is 0.0003643143572844565

 step 17 is completed and loss is 0.00022157514467835426

 step 18 is completed and loss is 7.098658534232527e-05

 step 19 is completed and loss is 0.00028710710466839373

 step 20 is completed and loss is 0.00010597028449410573

 step 21 is completed and loss is 0.00011884431296493858

 step 22 is completed and loss is 0.001102300127968192

 step 23 is completed and loss is 0.00016407569637522101

 step 24 is completed and loss is 0.00010644810390658677

 step 25 is completed and loss is 0.0003776562225539237

 step 26 is completed and loss is 8.564771269448102e-05

 step 27 is completed and loss is 0.0005851965397596359

 step 28 is completed and loss is 0.0001912440056912601

 step 29 is completed and loss is 0.0001315384724875912

 step 30 is completed and loss is 0.00027454912196844816

 step 31 is completed and loss is 2.8728880351991393e-05

 step 32 is completed and loss is 0.00023819624038878828

 step 33 is completed and loss is 0.00014822302910033613

 step 34 is completed and loss is 0.00020280687022022903

 step 35 is completed and loss is 0.0004139136290177703

 step 36 is completed and loss is 2.8371316147968173e-05

 step 37 is completed and loss is 0.00014590016508009285

 step 38 is completed and loss is 0.0001282604644075036

 step 39 is completed and loss is 9.673365275375545e-05

 step 40 is completed and loss is 0.00020013228640891612

 step 41 is completed and loss is 8.952014468377456e-05

 step 42 is completed and loss is 0.00011324240767862648

 step 43 is completed and loss is 0.00010078524064738303

 step 44 is completed and loss is 3.552344787749462e-05

 step 45 is completed and loss is 0.00039674490108154714

 step 46 is completed and loss is 4.130513116251677e-05

 step 47 is completed and loss is 0.00013112131273373961

 step 48 is completed and loss is 0.0008008292061276734

 step 49 is completed and loss is 0.00010948746785288677

 step 50 is completed and loss is 0.0001357699657091871

 step 51 is completed and loss is 0.00010912997095147148

 step 52 is completed and loss is 0.004914883524179459

 step 53 is completed and loss is 0.0006244604010134935

 step 54 is completed and loss is 6.937723082955927e-05

 step 55 is completed and loss is 0.0038265532348304987

 step 56 is completed and loss is 9.071393287740648e-05

 step 57 is completed and loss is 0.000417202158132568

 step 58 is completed and loss is 0.00012760197569150478

 step 59 is completed and loss is 0.0003846890467684716

 step 60 is completed and loss is 0.00017051372560672462

 step 61 is completed and loss is 0.00013844553905073553

 step 62 is completed and loss is 0.00014893582556396723

 step 63 is completed and loss is 0.0009869011119008064

 step 64 is completed and loss is 0.0007624576683156192

 step 65 is completed and loss is 0.00011961899872403592

 step 66 is completed and loss is 0.0008296070736832917

 step 67 is completed and loss is 8.356113539775833e-05

 step 68 is completed and loss is 0.00039235837175510824

 step 69 is completed and loss is 0.00031221535755321383

 step 70 is completed and loss is 0.00030964461620897055

 step 71 is completed and loss is 0.0002999262942466885

 step 72 is completed and loss is 0.0011869848240166903

 step 73 is completed and loss is 0.00014023979019839317

 step 74 is completed and loss is 0.00016455285367555916

 step 75 is completed and loss is 0.00048516259994357824

 step 76 is completed and loss is 0.00020549490000121295

 step 77 is completed and loss is 0.00011151366197736934

 step 78 is completed and loss is 0.00035850360291078687

 step 79 is completed and loss is 0.0015225677052512765

 step 80 is completed and loss is 0.0005756679456681013

 step 81 is completed and loss is 0.00011210946831852198

 step 82 is completed and loss is 0.00031338867847807705

 step 83 is completed and loss is 0.00023689755471423268

 step 84 is completed and loss is 0.00031451458926312625

 step 85 is completed and loss is 0.00019751029321923852

 step 86 is completed and loss is 0.00013815402053296566

 step 87 is completed and loss is 0.00023528940801043063

 step 88 is completed and loss is 0.00023355118173640221

 step 89 is completed and loss is 0.00011115635425085202

 step 90 is completed and loss is 0.0020019595976918936

 step 91 is completed and loss is 0.0002241325273644179
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.44it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.49it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.53it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.53it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.51it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.50it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.48it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.45it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.48it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.45it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.49it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.50it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.52it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.54it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.53it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.49it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.51it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:18,  1.53it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.53it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.56it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.59it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:14,  1.60it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.60it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.57it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.61it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.61it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:11,  1.59it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.58it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.58it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.59it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.60it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.58it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.57it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.57it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.58it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.61it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:04,  1.63it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.63it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.63it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:02,  1.69it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.72it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.69it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.69it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.64it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.63it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.56it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 13: train_perplexity=1.0004, train_epoch_loss=0.0004, epcoh time 298.1940036449996s
Training Epoch13:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch13:   1%|[34m          [0m| 1/92 [00:03<04:50,  3.19s/it]Training Epoch13:   2%|[34mâ–         [0m| 2/92 [00:06<04:47,  3.19s/it]Training Epoch13:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:45,  3.21s/it]Training Epoch13:   4%|[34mâ–         [0m| 4/92 [00:12<04:42,  3.21s/it]Training Epoch13:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:39,  3.21s/it]Training Epoch13:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.26s/it]Training Epoch13:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:39,  3.29s/it]Training Epoch13:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch13:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:32,  3.29s/it]Training Epoch13:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:30,  3.30s/it]Training Epoch13:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:30,  3.33s/it]Training Epoch13:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.30s/it]Training Epoch13:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.29s/it]Training Epoch13:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.30s/it]Training Epoch13:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch13:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.28s/it]Training Epoch13:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:06,  3.28s/it]Training Epoch13:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:07,  3.34s/it]Training Epoch13:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:03,  3.33s/it]Training Epoch13:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:58,  3.32s/it]Training Epoch13:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:53,  3.30s/it]Training Epoch13:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch13:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:46,  3.29s/it]Training Epoch13:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:43,  3.29s/it]Training Epoch13:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.29s/it]Training Epoch13:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:35,  3.27s/it]Training Epoch13:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:32,  3.26s/it]Training Epoch13:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.30s/it]Training Epoch13:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:27,  3.29s/it]Training Epoch13:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:24,  3.30s/it]Training Epoch13:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:20,  3.28s/it]Training Epoch13:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:16,  3.28s/it]Training Epoch13:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:12,  3.26s/it]Training Epoch13:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:10,  3.28s/it]Training Epoch13:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:06,  3.27s/it]Training Epoch13:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:01,  3.24s/it]Training Epoch13:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:58,  3.25s/it]Training Epoch13:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:55,  3.26s/it]Training Epoch13:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:52,  3.25s/it]Training Epoch13:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:48,  3.24s/it]Training Epoch13:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:45,  3.24s/it]Training Epoch13:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:42,  3.24s/it]Training Epoch13:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:39,  3.26s/it]Training Epoch13:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:36,  3.25s/it]Training Epoch13:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:31,  3.23s/it]Training Epoch13:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:28,  3.23s/it]Training Epoch13:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:24,  3.22s/it]Training Epoch13:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:36<02:22,  3.23s/it]Training Epoch13:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:19,  3.24s/it]Training Epoch13:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:15,  3.24s/it]Training Epoch13:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:46<02:13,  3.26s/it]Training Epoch13:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:10,  3.27s/it]Training Epoch13:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:08,  3.30s/it]Training Epoch13:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:04,  3.28s/it]Training Epoch13:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:59<02:00,  3.25s/it]Training Epoch13:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:57,  3.25s/it]Training Epoch13:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:53,  3.25s/it]Training Epoch13:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:09<01:50,  3.25s/it]Training Epoch13:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:12<01:48,  3.30s/it]Training Epoch13:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:44,  3.27s/it]Training Epoch13:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:41,  3.26s/it]Training Epoch13:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:22<01:37,  3.26s/it]Training Epoch13:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:35,  3.29s/it]Training Epoch13:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:32,  3.30s/it]Training Epoch13:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:32<01:28,  3.27s/it]Training Epoch13:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:35<01:25,  3.27s/it]Training Epoch13:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:22,  3.28s/it]Training Epoch13:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:19,  3.29s/it]Training Epoch13:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:45<01:15,  3.30s/it]Training Epoch13:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:12,  3.31s/it]Training Epoch13:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:09,  3.32s/it]Training Epoch13:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:55<01:06,  3.31s/it]Training Epoch13:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.30s/it]Training Epoch13:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:59,  3.31s/it]Training Epoch13:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:05<00:56,  3.34s/it]Training Epoch13:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:53,  3.31s/it]Training Epoch13:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:50,  3.34s/it]Training Epoch13:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:46,  3.35s/it]Training Epoch13:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.30s/it]Training Epoch13:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.31s/it]Training Epoch13:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.29s/it]Training Epoch13:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:28<00:32,  3.27s/it]Training Epoch13:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.26s/it]Training Epoch13:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.27s/it]Training Epoch13:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:38<00:22,  3.23s/it]Training Epoch13:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:41<00:19,  3.23s/it]Training Epoch13:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:44<00:16,  3.23s/it]Training Epoch13:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:48<00:12,  3.23s/it]Training Epoch13:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:51<00:09,  3.23s/it]Training Epoch13:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:54<00:06,  3.24s/it]Training Epoch13:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:57<00:03,  3.26s/it]Training Epoch13: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.24s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch13: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.27s/it]

 step 0 is completed and loss is 0.0002900227846112102

 step 1 is completed and loss is 0.00042617617873474956

 step 2 is completed and loss is 7.283419836312532e-05

 step 3 is completed and loss is 0.00016794310067780316

 step 4 is completed and loss is 0.00013635994400829077

 step 5 is completed and loss is 9.822301944950595e-05

 step 6 is completed and loss is 0.0011401897063478827

 step 7 is completed and loss is 0.00012360853725112975

 step 8 is completed and loss is 0.00013284986198414117

 step 9 is completed and loss is 6.97344949003309e-05

 step 10 is completed and loss is 0.0008416030323132873

 step 11 is completed and loss is 0.005414847284555435

 step 12 is completed and loss is 0.00040167069528251886

 step 13 is completed and loss is 0.00012242044613230973

 step 14 is completed and loss is 7.50986800994724e-05

 step 15 is completed and loss is 5.352353764465079e-05

 step 16 is completed and loss is 0.0004023732035420835

 step 17 is completed and loss is 0.00020859217329416424

 step 18 is completed and loss is 7.331097731366754e-05

 step 19 is completed and loss is 0.0002854988269973546

 step 20 is completed and loss is 0.00010114321048604324

 step 21 is completed and loss is 9.345552098238841e-05

 step 22 is completed and loss is 0.0006624810630455613

 step 23 is completed and loss is 0.00017009445582516491

 step 24 is completed and loss is 0.00011264610657235608

 step 25 is completed and loss is 0.00039624428609386086

 step 26 is completed and loss is 0.0001299271680181846

 step 27 is completed and loss is 0.0003724000125657767

 step 28 is completed and loss is 0.0002691732661332935

 step 29 is completed and loss is 0.00012110920215491205

 step 30 is completed and loss is 0.0002583423047326505

 step 31 is completed and loss is 2.5093144358834252e-05

 step 32 is completed and loss is 0.00040999907650984824

 step 33 is completed and loss is 0.00013183601549826562

 step 34 is completed and loss is 0.00015168059326242656

 step 35 is completed and loss is 0.0002988695923704654

 step 36 is completed and loss is 2.5987230401369743e-05

 step 37 is completed and loss is 0.0001317166752414778

 step 38 is completed and loss is 0.00012355214857961982

 step 39 is completed and loss is 0.00010579261288512498

 step 40 is completed and loss is 0.00019852316472679377

 step 41 is completed and loss is 7.777943392284214e-05

 step 42 is completed and loss is 9.887920168694109e-05

 step 43 is completed and loss is 0.00011318115139147267

 step 44 is completed and loss is 3.778822792810388e-05

 step 45 is completed and loss is 0.0004233189974911511

 step 46 is completed and loss is 3.820567508228123e-05

 step 47 is completed and loss is 0.00012784358114004135

 step 48 is completed and loss is 0.000945547129958868

 step 49 is completed and loss is 0.00012492328824009746

 step 50 is completed and loss is 0.00012158574827481061

 step 51 is completed and loss is 9.059491276275367e-05

 step 52 is completed and loss is 0.002134933602064848

 step 53 is completed and loss is 0.0005827076965942979

 step 54 is completed and loss is 6.770850450266153e-05

 step 55 is completed and loss is 0.002213440602645278

 step 56 is completed and loss is 7.497980550397187e-05

 step 57 is completed and loss is 0.00043918416486121714

 step 58 is completed and loss is 8.052161138039082e-05

 step 59 is completed and loss is 0.0014482593396678567

 step 60 is completed and loss is 0.00013714074157178402

 step 61 is completed and loss is 8.820909715723246e-05

 step 62 is completed and loss is 0.00012718519428744912

 step 63 is completed and loss is 0.0008060751133598387

 step 64 is completed and loss is 0.000692869012709707

 step 65 is completed and loss is 0.00012295562191866338

 step 66 is completed and loss is 0.0007042185170575976

 step 67 is completed and loss is 9.923465404426679e-05

 step 68 is completed and loss is 0.00034683855483308434

 step 69 is completed and loss is 0.00030512153171002865

 step 70 is completed and loss is 0.0002757466281764209

 step 71 is completed and loss is 0.00022723835718352348

 step 72 is completed and loss is 0.0009456406114622951

 step 73 is completed and loss is 0.0001341609749943018

 step 74 is completed and loss is 0.00016389765369240195

 step 75 is completed and loss is 0.0003217514022253454

 step 76 is completed and loss is 0.00018427999748382717

 step 77 is completed and loss is 0.00010126241249963641

 step 78 is completed and loss is 0.00024261957150883973

 step 79 is completed and loss is 0.0009380594128742814

 step 80 is completed and loss is 0.0004934592288918793

 step 81 is completed and loss is 0.000129034771816805

 step 82 is completed and loss is 0.0004533150349743664

 step 83 is completed and loss is 0.00018332488252781332

 step 84 is completed and loss is 0.0002488032914698124

 step 85 is completed and loss is 0.00017426878912374377

 step 86 is completed and loss is 0.00011586471373448148

 step 87 is completed and loss is 0.00020090462930966169

 step 88 is completed and loss is 0.0005060583353042603

 step 89 is completed and loss is 0.00011938040552195162

 step 90 is completed and loss is 0.0006737131043337286

 step 91 is completed and loss is 0.00012468182831071317
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.37it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.49it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.51it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.54it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.56it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.54it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.54it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.54it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.51it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.50it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.54it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.57it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.55it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.55it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.54it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.54it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.52it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.52it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.52it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.55it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.58it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.58it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.54it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.53it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.56it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:12,  1.62it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.56it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.56it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.57it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.58it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.58it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.57it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.57it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.58it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.51it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:06,  1.50it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.52it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.52it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.49it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:02,  1.47it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.48it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.48it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.50it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 14: train_perplexity=1.0004, train_epoch_loss=0.0004, epcoh time 301.4515629769994s
Training Epoch14:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch14:   1%|[34m          [0m| 1/92 [00:03<05:01,  3.32s/it]Training Epoch14:   2%|[34mâ–         [0m| 2/92 [00:06<04:55,  3.29s/it]Training Epoch14:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:50,  3.26s/it]Training Epoch14:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.28s/it]Training Epoch14:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch14:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.28s/it]Training Epoch14:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:38,  3.28s/it]Training Epoch14:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.30s/it]Training Epoch14:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.29s/it]Training Epoch14:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.27s/it]Training Epoch14:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:23,  3.25s/it]Training Epoch14:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.27s/it]Training Epoch14:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:17,  3.26s/it]Training Epoch14:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.30s/it]Training Epoch14:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.30s/it]Training Epoch14:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:08,  3.27s/it]Training Epoch14:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:02,  3.24s/it]Training Epoch14:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:00,  3.25s/it]Training Epoch14:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:57,  3.26s/it]Training Epoch14:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:52,  3.23s/it]Training Epoch14:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:50,  3.25s/it]Training Epoch14:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:48,  3.27s/it]Training Epoch14:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:46,  3.28s/it]Training Epoch14:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:43,  3.29s/it]Training Epoch14:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:41,  3.30s/it]Training Epoch14:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:39,  3.32s/it]Training Epoch14:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:35,  3.32s/it]Training Epoch14:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:32,  3.33s/it]Training Epoch14:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:30,  3.34s/it]Training Epoch14:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:27,  3.35s/it]Training Epoch14:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:22,  3.32s/it]Training Epoch14:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:19,  3.32s/it]Training Epoch14:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:15,  3.31s/it]Training Epoch14:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:12,  3.33s/it]Training Epoch14:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:10,  3.34s/it]Training Epoch14:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:05,  3.32s/it]Training Epoch14:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:01,  3.31s/it]Training Epoch14:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:59,  3.32s/it]Training Epoch14:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:56,  3.34s/it]Training Epoch14:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:51,  3.30s/it]Training Epoch14:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.32s/it]Training Epoch14:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:45,  3.31s/it]Training Epoch14:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:42,  3.32s/it]Training Epoch14:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.31s/it]Training Epoch14:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:35,  3.30s/it]Training Epoch14:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:32,  3.32s/it]Training Epoch14:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:29,  3.32s/it]Training Epoch14:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:26,  3.34s/it]Training Epoch14:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:24,  3.36s/it]Training Epoch14:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:21,  3.37s/it]Training Epoch14:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:18,  3.37s/it]Training Epoch14:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:14,  3.36s/it]Training Epoch14:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:09,  3.31s/it]Training Epoch14:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.31s/it]Training Epoch14:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.29s/it]Training Epoch14:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:58,  3.30s/it]Training Epoch14:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:55,  3.31s/it]Training Epoch14:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:53,  3.34s/it]Training Epoch14:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:50,  3.35s/it]Training Epoch14:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:46,  3.32s/it]Training Epoch14:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:43,  3.33s/it]Training Epoch14:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.32s/it]Training Epoch14:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:35,  3.29s/it]Training Epoch14:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.31s/it]Training Epoch14:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.31s/it]Training Epoch14:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:25,  3.29s/it]Training Epoch14:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.30s/it]Training Epoch14:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.31s/it]Training Epoch14:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.32s/it]Training Epoch14:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.31s/it]Training Epoch14:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.30s/it]Training Epoch14:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.29s/it]Training Epoch14:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.28s/it]Training Epoch14:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:58,  3.26s/it]Training Epoch14:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:55,  3.28s/it]Training Epoch14:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.27s/it]Training Epoch14:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.28s/it]Training Epoch14:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.29s/it]Training Epoch14:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.28s/it]Training Epoch14:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.29s/it]Training Epoch14:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.29s/it]Training Epoch14:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:32,  3.30s/it]Training Epoch14:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.32s/it]Training Epoch14:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.34s/it]Training Epoch14:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.35s/it]Training Epoch14:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.33s/it]Training Epoch14:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.33s/it]Training Epoch14:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.34s/it]Training Epoch14:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:10,  3.35s/it]Training Epoch14:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.35s/it]Training Epoch14:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.35s/it]Training Epoch14: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.33s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch14: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.00021388223103713244

 step 1 is completed and loss is 0.0003332387423142791

 step 2 is completed and loss is 5.733802026952617e-05

 step 3 is completed and loss is 0.00012569456885103136

 step 4 is completed and loss is 0.00013838615268468857

 step 5 is completed and loss is 8.350237476406619e-05

 step 6 is completed and loss is 0.001354541047476232

 step 7 is completed and loss is 0.00015703871031291783

 step 8 is completed and loss is 0.0001155667268903926

 step 9 is completed and loss is 4.96492903039325e-05

 step 10 is completed and loss is 0.0011100051924586296

 step 11 is completed and loss is 0.0031296880915760994

 step 12 is completed and loss is 0.00038695542025379837

 step 13 is completed and loss is 0.00012087062350474298

 step 14 is completed and loss is 5.6980115914484486e-05

 step 15 is completed and loss is 7.247662142617628e-05

 step 16 is completed and loss is 0.00024463344016112387

 step 17 is completed and loss is 0.00030385484569706023

 step 18 is completed and loss is 7.331102096941322e-05

 step 19 is completed and loss is 0.00016758855781517923

 step 20 is completed and loss is 0.00012069098011124879

 step 21 is completed and loss is 0.00013487391697708517

 step 22 is completed and loss is 0.0006322363042272627

 step 23 is completed and loss is 0.00013630648027174175

 step 24 is completed and loss is 9.458781278226525e-05

 step 25 is completed and loss is 0.00015102408360689878

 step 26 is completed and loss is 0.00010370601376052946

 step 27 is completed and loss is 0.0003965739451814443

 step 28 is completed and loss is 0.00018725043628364801

 step 29 is completed and loss is 0.00013052564463578165

 step 30 is completed and loss is 0.0001970308367162943

 step 31 is completed and loss is 2.0146118913544342e-05

 step 32 is completed and loss is 0.00018504902254790068

 step 33 is completed and loss is 9.577986202202737e-05

 step 34 is completed and loss is 0.00013445783406496048

 step 35 is completed and loss is 0.000286532478639856

 step 36 is completed and loss is 2.7417750970926136e-05

 step 37 is completed and loss is 8.761498611420393e-05

 step 38 is completed and loss is 0.00012724722910206765

 step 39 is completed and loss is 9.494541154708713e-05

 step 40 is completed and loss is 0.0001749839138938114

 step 41 is completed and loss is 9.959145245375112e-05

 step 42 is completed and loss is 0.0001394048158545047

 step 43 is completed and loss is 8.552842336939648e-05

 step 44 is completed and loss is 3.141092383884825e-05

 step 45 is completed and loss is 0.0003455784171819687

 step 46 is completed and loss is 3.8324982597259805e-05

 step 47 is completed and loss is 0.00011544738663360476

 step 48 is completed and loss is 0.0007834223797544837

 step 49 is completed and loss is 0.00010734215175034478

 step 50 is completed and loss is 0.00012462539598345757

 step 51 is completed and loss is 9.941559983417392e-05

 step 52 is completed and loss is 0.0022685970179736614

 step 53 is completed and loss is 0.0004052746808156371

 step 54 is completed and loss is 6.758904055459425e-05

 step 55 is completed and loss is 0.0017560092965140939

 step 56 is completed and loss is 6.836402462795377e-05

 step 57 is completed and loss is 0.0003643686941359192

 step 58 is completed and loss is 9.321499965153635e-05

 step 59 is completed and loss is 0.0005779419443570077

 step 60 is completed and loss is 0.00013696156383957714

 step 61 is completed and loss is 8.993725350592285e-05

 step 62 is completed and loss is 0.00011306173109915107

 step 63 is completed and loss is 0.0005519589758478105

 step 64 is completed and loss is 0.0005877918447367847

 step 65 is completed and loss is 0.00012009614147245884

 step 66 is completed and loss is 0.0007769156363792717

 step 67 is completed and loss is 7.134368206607178e-05

 step 68 is completed and loss is 0.000242857844568789

 step 69 is completed and loss is 0.0002447614388074726

 step 70 is completed and loss is 0.00031803938327357173

 step 71 is completed and loss is 0.0005086961318738759

 step 72 is completed and loss is 0.0009406344615854323

 step 73 is completed and loss is 0.00012087054346920922

 step 74 is completed and loss is 0.0001345774799119681

 step 75 is completed and loss is 0.00043667026329785585

 step 76 is completed and loss is 0.00017933413619175553

 step 77 is completed and loss is 0.00010495785681996495

 step 78 is completed and loss is 0.00030721473740413785

 step 79 is completed and loss is 0.0013315919786691666

 step 80 is completed and loss is 0.00041064294055104256

 step 81 is completed and loss is 0.00016300396237056702

 step 82 is completed and loss is 0.00016955981845967472

 step 83 is completed and loss is 0.0002939723781310022

 step 84 is completed and loss is 0.00015507650095969439

 step 85 is completed and loss is 0.00018094333063345402

 step 86 is completed and loss is 0.00010072677832795307

 step 87 is completed and loss is 0.00019083493680227548

 step 88 is completed and loss is 0.0001951759768417105

 step 89 is completed and loss is 0.00012927365605719388

 step 90 is completed and loss is 0.0014657694846391678

 step 91 is completed and loss is 0.00012664796668104827
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:37,  1.30it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.40it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.51it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.50it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.50it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.50it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.51it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.50it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.49it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.47it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.46it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.53it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.49it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.49it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.55it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.52it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.48it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.47it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.46it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:19,  1.46it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.47it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.46it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.49it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.54it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:14,  1.58it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:13,  1.61it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:12,  1.64it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.63it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.58it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.61it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.64it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:09,  1.66it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.58it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.56it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.55it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.48it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.53it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.53it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.50it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.51it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:04,  1.49it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.49it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.48it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:02,  1.49it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.52it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.50it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.52it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6600)
Epoch 15: train_perplexity=1.0003, train_epoch_loss=0.0003, epcoh time 304.4906017859994s
Training Epoch15:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch15:   1%|[34m          [0m| 1/92 [00:03<05:02,  3.33s/it]Training Epoch15:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.30s/it]Training Epoch15:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:56,  3.33s/it]Training Epoch15:   4%|[34mâ–         [0m| 4/92 [00:13<04:50,  3.30s/it]Training Epoch15:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch15:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.26s/it]Training Epoch15:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.27s/it]Training Epoch15:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:34,  3.27s/it]Training Epoch15:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.27s/it]Training Epoch15:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:26,  3.25s/it]Training Epoch15:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:23,  3.25s/it]Training Epoch15:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.27s/it]Training Epoch15:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:17,  3.26s/it]Training Epoch15:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:15,  3.27s/it]Training Epoch15:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:10,  3.26s/it]Training Epoch15:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:07,  3.26s/it]Training Epoch15:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:03,  3.25s/it]Training Epoch15:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:01,  3.27s/it]Training Epoch15:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:00,  3.29s/it]Training Epoch15:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:57,  3.30s/it]Training Epoch15:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:53,  3.29s/it]Training Epoch15:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.29s/it]Training Epoch15:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.30s/it]Training Epoch15:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:44,  3.31s/it]Training Epoch15:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:39,  3.27s/it]Training Epoch15:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.29s/it]Training Epoch15:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:33,  3.28s/it]Training Epoch15:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:28,  3.26s/it]Training Epoch15:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:26,  3.28s/it]Training Epoch15:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:23,  3.29s/it]Training Epoch15:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:20,  3.28s/it]Training Epoch15:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:16,  3.27s/it]Training Epoch15:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:13,  3.27s/it]Training Epoch15:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:09,  3.28s/it]Training Epoch15:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:07,  3.29s/it]Training Epoch15:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:04,  3.29s/it]Training Epoch15:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:01,  3.30s/it]Training Epoch15:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:57,  3.29s/it]Training Epoch15:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:56,  3.33s/it]Training Epoch15:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:51,  3.30s/it]Training Epoch15:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:48,  3.30s/it]Training Epoch15:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:45,  3.30s/it]Training Epoch15:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:43,  3.34s/it]Training Epoch15:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:42,  3.39s/it]Training Epoch15:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:39,  3.39s/it]Training Epoch15:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:33,  3.34s/it]Training Epoch15:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:30,  3.34s/it]Training Epoch15:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:26,  3.33s/it]Training Epoch15:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.31s/it]Training Epoch15:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:19,  3.31s/it]Training Epoch15:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:15,  3.31s/it]Training Epoch15:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:12,  3.30s/it]Training Epoch15:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.30s/it]Training Epoch15:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:04,  3.28s/it]Training Epoch15:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:00,  3.25s/it]Training Epoch15:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:55,  3.22s/it]Training Epoch15:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:52,  3.20s/it]Training Epoch15:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:49,  3.22s/it]Training Epoch15:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:47,  3.25s/it]Training Epoch15:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:44,  3.27s/it]Training Epoch15:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:41,  3.27s/it]Training Epoch15:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:37,  3.25s/it]Training Epoch15:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:34,  3.26s/it]Training Epoch15:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:31,  3.26s/it]Training Epoch15:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:28,  3.27s/it]Training Epoch15:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:26,  3.33s/it]Training Epoch15:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.29s/it]Training Epoch15:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:20,  3.34s/it]Training Epoch15:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:16,  3.33s/it]Training Epoch15:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.30s/it]Training Epoch15:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.28s/it]Training Epoch15:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:05,  3.27s/it]Training Epoch15:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.27s/it]Training Epoch15:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:59,  3.28s/it]Training Epoch15:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:55,  3.28s/it]Training Epoch15:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:52,  3.28s/it]Training Epoch15:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.27s/it]Training Epoch15:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:45,  3.26s/it]Training Epoch15:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.28s/it]Training Epoch15:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.28s/it]Training Epoch15:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:36,  3.31s/it]Training Epoch15:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:33,  3.31s/it]Training Epoch15:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.32s/it]Training Epoch15:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.31s/it]Training Epoch15:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.32s/it]Training Epoch15:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.32s/it]Training Epoch15:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.31s/it]Training Epoch15:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.31s/it]Training Epoch15:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.31s/it]Training Epoch15:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.32s/it]Training Epoch15:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.29s/it]Training Epoch15: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch15: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 0.00013653913629241288

 step 1 is completed and loss is 0.00036290750722400844

 step 2 is completed and loss is 4.857650492340326e-05

 step 3 is completed and loss is 0.00011878104123752564

 step 4 is completed and loss is 0.0001069809150067158

 step 5 is completed and loss is 8.916357182897627e-05

 step 6 is completed and loss is 0.0010522004449740052

 step 7 is completed and loss is 8.040267857722938e-05

 step 8 is completed and loss is 0.00011830820585601032

 step 9 is completed and loss is 6.550295074703172e-05

 step 10 is completed and loss is 0.0012476484989747405

 step 11 is completed and loss is 0.0013322432059794664

 step 12 is completed and loss is 0.00034847488859668374

 step 13 is completed and loss is 0.00013302871957421303

 step 14 is completed and loss is 6.824498996138573e-05

 step 15 is completed and loss is 7.283422019099817e-05

 step 16 is completed and loss is 0.00021627318346872926

 step 17 is completed and loss is 0.00015912970411591232

 step 18 is completed and loss is 6.46093103569001e-05

 step 19 is completed and loss is 0.00017098210810218006

 step 20 is completed and loss is 6.30001159152016e-05

 step 21 is completed and loss is 0.00010454057337483391

 step 22 is completed and loss is 0.0007446222007274628

 step 23 is completed and loss is 0.00021294275938998908

 step 24 is completed and loss is 7.891339191701263e-05

 step 25 is completed and loss is 0.0003468593640718609

 step 26 is completed and loss is 0.0001319545553997159

 step 27 is completed and loss is 0.0003151910495944321

 step 28 is completed and loss is 0.00018885871395468712

 step 29 is completed and loss is 0.0001286179176531732

 step 30 is completed and loss is 0.0002355228061787784

 step 31 is completed and loss is 3.111297337454744e-05

 step 32 is completed and loss is 0.00019112424342893064

 step 33 is completed and loss is 0.00012069173681084067

 step 34 is completed and loss is 0.00013838941231369972

 step 35 is completed and loss is 0.00023665977641940117

 step 36 is completed and loss is 2.127859443135094e-05

 step 37 is completed and loss is 0.0001410739350831136

 step 38 is completed and loss is 0.00017777951143216342

 step 39 is completed and loss is 7.140368688851595e-05

 step 40 is completed and loss is 0.00014810595894232392

 step 41 is completed and loss is 9.178473555948585e-05

 step 42 is completed and loss is 0.00011973855725955218

 step 43 is completed and loss is 8.809039718471467e-05

 step 44 is completed and loss is 3.492740142974071e-05

 step 45 is completed and loss is 0.0004124030820094049

 step 46 is completed and loss is 3.433164602029137e-05

 step 47 is completed and loss is 0.00012164531653979793

 step 48 is completed and loss is 0.0009156689047813416

 step 49 is completed and loss is 0.00011056041694246233

 step 50 is completed and loss is 0.00013356463750824332

 step 51 is completed and loss is 8.004583651199937e-05

 step 52 is completed and loss is 0.005787747912108898

 step 53 is completed and loss is 0.0004945719847455621

 step 54 is completed and loss is 6.562250928254798e-05

 step 55 is completed and loss is 0.0020957328379154205

 step 56 is completed and loss is 5.87088470638264e-05

 step 57 is completed and loss is 0.0002346205001231283

 step 58 is completed and loss is 8.004409755812958e-05

 step 59 is completed and loss is 0.0009333369671367109

 step 60 is completed and loss is 0.00012516173592302948

 step 61 is completed and loss is 8.910278120310977e-05

 step 62 is completed and loss is 0.00012342992704361677

 step 63 is completed and loss is 0.0006361101986840367

 step 64 is completed and loss is 0.0005055026849731803

 step 65 is completed and loss is 0.00010716337419580668

 step 66 is completed and loss is 0.0009024694445542991

 step 67 is completed and loss is 0.00010304873285349458

 step 68 is completed and loss is 0.00023213292297441512

 step 69 is completed and loss is 0.00019172916654497385

 step 70 is completed and loss is 0.00030797102954238653

 step 71 is completed and loss is 0.00038617991958744824

 step 72 is completed and loss is 0.0006003089365549386

 step 73 is completed and loss is 0.00010191866022069007

 step 74 is completed and loss is 0.000132848639623262

 step 75 is completed and loss is 0.0003067369107156992

 step 76 is completed and loss is 0.00016169401351362467

 step 77 is completed and loss is 0.00010311028745491058

 step 78 is completed and loss is 0.0002932694333139807

 step 79 is completed and loss is 0.001122094108723104

 step 80 is completed and loss is 0.0003330737818032503

 step 81 is completed and loss is 0.00014250200183596462

 step 82 is completed and loss is 0.0002508359029889107

 step 83 is completed and loss is 0.00020036977366544306

 step 84 is completed and loss is 0.0002508274046704173

 step 85 is completed and loss is 0.00015364897262770683

 step 86 is completed and loss is 0.00011359999916749075

 step 87 is completed and loss is 0.00019530393183231354

 step 88 is completed and loss is 0.00023885075643192977

 step 89 is completed and loss is 6.92580288159661e-05

 step 90 is completed and loss is 0.0016637117369100451

 step 91 is completed and loss is 0.00042887305608019233
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.37it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.50it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:30,  1.52it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.51it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.54it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.55it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:26,  1.60it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.59it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.56it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.52it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.51it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:25,  1.52it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.56it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.54it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:23,  1.52it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.57it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.55it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.55it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.56it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.60it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.53it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.51it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.51it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.51it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.56it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.56it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.56it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:12,  1.50it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.49it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.53it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.51it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.57it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:07,  1.64it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.65it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.60it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.58it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.57it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.54it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.50it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.50it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.57it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.55it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.58it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.57it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 16: train_perplexity=1.0004, train_epoch_loss=0.0004, epcoh time 302.85597416900055s
Training Epoch16:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch16:   1%|[34m          [0m| 1/92 [00:03<05:07,  3.38s/it]Training Epoch16:   2%|[34mâ–         [0m| 2/92 [00:06<05:01,  3.35s/it]Training Epoch16:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:58,  3.35s/it]Training Epoch16:   4%|[34mâ–         [0m| 4/92 [00:13<04:51,  3.31s/it]Training Epoch16:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.28s/it]Training Epoch16:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:39,  3.25s/it]Training Epoch16:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:38,  3.28s/it]Training Epoch16:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.30s/it]Training Epoch16:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.30s/it]Training Epoch16:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:31,  3.31s/it]Training Epoch16:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.29s/it]Training Epoch16:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.29s/it]Training Epoch16:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.29s/it]Training Epoch16:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:15,  3.28s/it]Training Epoch16:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:11,  3.27s/it]Training Epoch16:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:08,  3.28s/it]Training Epoch16:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:05,  3.27s/it]Training Epoch16:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:02,  3.28s/it]Training Epoch16:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:00,  3.30s/it]Training Epoch16:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:57,  3.30s/it]Training Epoch16:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:52,  3.27s/it]Training Epoch16:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:48,  3.26s/it]Training Epoch16:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.26s/it]Training Epoch16:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:42,  3.27s/it]Training Epoch16:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:37,  3.25s/it]Training Epoch16:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.28s/it]Training Epoch16:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.30s/it]Training Epoch16:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.28s/it]Training Epoch16:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:27,  3.30s/it]Training Epoch16:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:23,  3.28s/it]Training Epoch16:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:20,  3.29s/it]Training Epoch16:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:19,  3.32s/it]Training Epoch16:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:15,  3.31s/it]Training Epoch16:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:13,  3.33s/it]Training Epoch16:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:09,  3.32s/it]Training Epoch16:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:04,  3.30s/it]Training Epoch16:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:00,  3.29s/it]Training Epoch16:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.30s/it]Training Epoch16:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:55,  3.31s/it]Training Epoch16:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:51,  3.31s/it]Training Epoch16:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.32s/it]Training Epoch16:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:47,  3.34s/it]Training Epoch16:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:42,  3.32s/it]Training Epoch16:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:39,  3.33s/it]Training Epoch16:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:36,  3.33s/it]Training Epoch16:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:33,  3.33s/it]Training Epoch16:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.33s/it]Training Epoch16:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:27,  3.34s/it]Training Epoch16:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:23,  3.33s/it]Training Epoch16:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:21,  3.36s/it]Training Epoch16:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:18,  3.37s/it]Training Epoch16:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:13,  3.33s/it]Training Epoch16:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:09,  3.33s/it]Training Epoch16:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.31s/it]Training Epoch16:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.30s/it]Training Epoch16:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:58,  3.30s/it]Training Epoch16:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.32s/it]Training Epoch16:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.32s/it]Training Epoch16:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.32s/it]Training Epoch16:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.30s/it]Training Epoch16:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.29s/it]Training Epoch16:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:38,  3.27s/it]Training Epoch16:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:34,  3.27s/it]Training Epoch16:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:31,  3.26s/it]Training Epoch16:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:27,  3.26s/it]Training Epoch16:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:24,  3.25s/it]Training Epoch16:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:21,  3.26s/it]Training Epoch16:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:18,  3.27s/it]Training Epoch16:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:15,  3.30s/it]Training Epoch16:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:13,  3.33s/it]Training Epoch16:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.31s/it]Training Epoch16:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.31s/it]Training Epoch16:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:02,  3.31s/it]Training Epoch16:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.33s/it]Training Epoch16:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.33s/it]Training Epoch16:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:53,  3.32s/it]Training Epoch16:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:50,  3.33s/it]Training Epoch16:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.31s/it]Training Epoch16:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.29s/it]Training Epoch16:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.30s/it]Training Epoch16:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.31s/it]Training Epoch16:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.32s/it]Training Epoch16:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.32s/it]Training Epoch16:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.34s/it]Training Epoch16:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.31s/it]Training Epoch16:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.30s/it]Training Epoch16:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.29s/it]Training Epoch16:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.28s/it]Training Epoch16:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.27s/it]Training Epoch16:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.28s/it]Training Epoch16:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.30s/it]Training Epoch16: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.32s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch16: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.00017175733228214085

 step 1 is completed and loss is 0.0002837914216797799

 step 2 is completed and loss is 5.7218676374759525e-05

 step 3 is completed and loss is 0.00010155900963582098

 step 4 is completed and loss is 0.00010829197708517313

 step 5 is completed and loss is 9.631566354073584e-05

 step 6 is completed and loss is 0.0008662701002322137

 step 7 is completed and loss is 7.962759991642088e-05

 step 8 is completed and loss is 0.00011556668323464692

 step 9 is completed and loss is 7.18205701559782e-05

 step 10 is completed and loss is 0.000870675197802484

 step 11 is completed and loss is 0.0028542173095047474

 step 12 is completed and loss is 0.00041696723201312125

 step 13 is completed and loss is 0.00010019030014518648

 step 14 is completed and loss is 6.764881254639477e-05

 step 15 is completed and loss is 6.639736966462806e-05

 step 16 is completed and loss is 0.00023980707919690758

 step 17 is completed and loss is 0.00018904282478615642

 step 18 is completed and loss is 7.08077204762958e-05

 step 19 is completed and loss is 0.00012670761498156935

 step 20 is completed and loss is 8.03437433205545e-05

 step 21 is completed and loss is 8.385969704249874e-05

 step 22 is completed and loss is 0.0005361486109904945

 step 23 is completed and loss is 0.00016955836326815188

 step 24 is completed and loss is 7.754252874292433e-05

 step 25 is completed and loss is 0.000346319138770923

 step 26 is completed and loss is 0.00011985639139311388

 step 27 is completed and loss is 0.0002480410330463201

 step 28 is completed and loss is 0.00016567982675042003

 step 29 is completed and loss is 0.00011252719559706748

 step 30 is completed and loss is 0.00012742566468659788

 step 31 is completed and loss is 2.3841501388233155e-05

 step 32 is completed and loss is 0.00018939602887257934

 step 33 is completed and loss is 0.00010692426440073177

 step 34 is completed and loss is 9.125014184974134e-05

 step 35 is completed and loss is 0.0002747339312918484

 step 36 is completed and loss is 2.199385744461324e-05

 step 37 is completed and loss is 0.00010191866022069007

 step 38 is completed and loss is 0.00014804399688728154

 step 39 is completed and loss is 8.386014815187082e-05

 step 40 is completed and loss is 0.00015054992400109768

 step 41 is completed and loss is 5.5489792430307716e-05

 step 42 is completed and loss is 9.297892393078655e-05

 step 43 is completed and loss is 9.029584180098027e-05

 step 44 is completed and loss is 2.7000438421964645e-05

 step 45 is completed and loss is 0.00035909644793719053

 step 46 is completed and loss is 3.123230635537766e-05

 step 47 is completed and loss is 8.856850035954267e-05

 step 48 is completed and loss is 0.0008348049595952034

 step 49 is completed and loss is 0.000120572789455764

 step 50 is completed and loss is 0.00010817627480719239

 step 51 is completed and loss is 8.320453343912959e-05

 step 52 is completed and loss is 0.0025675243232399225

 step 53 is completed and loss is 0.00042833591578528285

 step 54 is completed and loss is 6.586061499547213e-05

 step 55 is completed and loss is 0.0024346348363906145

 step 56 is completed and loss is 5.817211058456451e-05

 step 57 is completed and loss is 0.00023843688541091979

 step 58 is completed and loss is 7.551479211542755e-05

 step 59 is completed and loss is 0.00073993083788082

 step 60 is completed and loss is 0.00014673516852781177

 step 61 is completed and loss is 0.00010906661191256717

 step 62 is completed and loss is 0.00010322788875782862

 step 63 is completed and loss is 0.0005085963639430702

 step 64 is completed and loss is 0.0006103042396716774

 step 65 is completed and loss is 0.00010984499385813251

 step 66 is completed and loss is 0.000684753991663456

 step 67 is completed and loss is 6.723086698912084e-05

 step 68 is completed and loss is 0.00024059490533545613

 step 69 is completed and loss is 0.0002074610674753785

 step 70 is completed and loss is 0.0001894026790978387

 step 71 is completed and loss is 0.0002783013042062521

 step 72 is completed and loss is 0.0006253191968426108

 step 73 is completed and loss is 0.0001178910315502435

 step 74 is completed and loss is 0.0001347552315564826

 step 75 is completed and loss is 0.0004341683816164732

 step 76 is completed and loss is 0.0001497752673458308

 step 77 is completed and loss is 9.989182581193745e-05

 step 78 is completed and loss is 0.00024655036395415664

 step 79 is completed and loss is 0.0010194284841418266

 step 80 is completed and loss is 0.0004134463961236179

 step 81 is completed and loss is 0.00012760415847878903

 step 82 is completed and loss is 0.00021943160390947014

 step 83 is completed and loss is 0.00019965470710303634

 step 84 is completed and loss is 0.0001789111556718126

 step 85 is completed and loss is 0.0002060916303889826

 step 86 is completed and loss is 0.0001436368766007945

 step 87 is completed and loss is 0.0002044212305918336

 step 88 is completed and loss is 0.0003954629646614194

 step 89 is completed and loss is 9.82229394139722e-05

 step 90 is completed and loss is 0.0012054051039740443

 step 91 is completed and loss is 0.00020143348956480622
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:30,  1.63it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.54it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:29,  1.61it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.49it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.43it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.44it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:30,  1.43it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.48it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.48it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.49it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:27,  1.40it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.43it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.50it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:22,  1.57it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.61it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:20,  1.64it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:19,  1.60it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.57it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.54it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.49it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.52it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.56it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.51it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.51it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.53it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.49it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.52it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.50it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.49it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.50it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.49it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.48it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.49it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.54it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.50it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.50it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.50it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.53it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.51it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.49it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.50it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.46it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.43it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.43it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.43it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.43it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.44it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.50it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 17: train_perplexity=1.0003, train_epoch_loss=0.0003, epcoh time 304.14404586899946s
Training Epoch17:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch17:   1%|[34m          [0m| 1/92 [00:03<05:07,  3.38s/it]Training Epoch17:   2%|[34mâ–         [0m| 2/92 [00:06<04:58,  3.31s/it]Training Epoch17:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:52,  3.28s/it]Training Epoch17:   4%|[34mâ–         [0m| 4/92 [00:13<04:46,  3.26s/it]Training Epoch17:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.29s/it]Training Epoch17:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.30s/it]Training Epoch17:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:38,  3.27s/it]Training Epoch17:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.29s/it]Training Epoch17:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.31s/it]Training Epoch17:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.33s/it]Training Epoch17:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:33,  3.38s/it]Training Epoch17:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:29,  3.37s/it]Training Epoch17:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:24,  3.34s/it]Training Epoch17:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.34s/it]Training Epoch17:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch17:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:12,  3.32s/it]Training Epoch17:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:11,  3.36s/it]Training Epoch17:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:07,  3.34s/it]Training Epoch17:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:03,  3.34s/it]Training Epoch17:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:01,  3.35s/it]Training Epoch17:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:59,  3.37s/it]Training Epoch17:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:55,  3.36s/it]Training Epoch17:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:50,  3.34s/it]Training Epoch17:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:47,  3.34s/it]Training Epoch17:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:44,  3.35s/it]Training Epoch17:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:41,  3.35s/it]Training Epoch17:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:38,  3.36s/it]Training Epoch17:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:34,  3.36s/it]Training Epoch17:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:30,  3.34s/it]Training Epoch17:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.31s/it]Training Epoch17:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:23,  3.34s/it]Training Epoch17:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:20,  3.34s/it]Training Epoch17:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:15,  3.31s/it]Training Epoch17:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:12,  3.32s/it]Training Epoch17:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:08,  3.30s/it]Training Epoch17:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:05,  3.32s/it]Training Epoch17:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:04,  3.36s/it]Training Epoch17:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:59,  3.33s/it]Training Epoch17:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:56,  3.34s/it]Training Epoch17:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:53,  3.33s/it]Training Epoch17:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:49,  3.33s/it]Training Epoch17:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.31s/it]Training Epoch17:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:41,  3.30s/it]Training Epoch17:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:38,  3.31s/it]Training Epoch17:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:35,  3.31s/it]Training Epoch17:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:32,  3.32s/it]Training Epoch17:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:30,  3.35s/it]Training Epoch17:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:26,  3.33s/it]Training Epoch17:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:22,  3.33s/it]Training Epoch17:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:19,  3.31s/it]Training Epoch17:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:16,  3.32s/it]Training Epoch17:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:13,  3.33s/it]Training Epoch17:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:10,  3.35s/it]Training Epoch17:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:06,  3.33s/it]Training Epoch17:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:03<02:03,  3.33s/it]Training Epoch17:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<02:00,  3.36s/it]Training Epoch17:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:10<01:59,  3.43s/it]Training Epoch17:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:13<01:54,  3.37s/it]Training Epoch17:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:51,  3.38s/it]Training Epoch17:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:20<01:47,  3.35s/it]Training Epoch17:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:43,  3.34s/it]Training Epoch17:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:39,  3.33s/it]Training Epoch17:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:30<01:36,  3.33s/it]Training Epoch17:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:33<01:33,  3.34s/it]Training Epoch17:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:30,  3.34s/it]Training Epoch17:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:40<01:27,  3.35s/it]Training Epoch17:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:43<01:23,  3.34s/it]Training Epoch17:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:19,  3.32s/it]Training Epoch17:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:50<01:16,  3.33s/it]Training Epoch17:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:53<01:13,  3.35s/it]Training Epoch17:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:56<01:10,  3.34s/it]Training Epoch17:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [04:00<01:06,  3.33s/it]Training Epoch17:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:03<01:03,  3.32s/it]Training Epoch17:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:06<00:59,  3.33s/it]Training Epoch17:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:10<00:56,  3.32s/it]Training Epoch17:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:13<00:53,  3.34s/it]Training Epoch17:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:16<00:50,  3.37s/it]Training Epoch17:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:20<00:46,  3.32s/it]Training Epoch17:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:23<00:42,  3.31s/it]Training Epoch17:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:26<00:39,  3.32s/it]Training Epoch17:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:30<00:36,  3.34s/it]Training Epoch17:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:33<00:33,  3.32s/it]Training Epoch17:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:36<00:29,  3.32s/it]Training Epoch17:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:26,  3.32s/it]Training Epoch17:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:43<00:22,  3.28s/it]Training Epoch17:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:46<00:19,  3.30s/it]Training Epoch17:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.30s/it]Training Epoch17:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:53<00:13,  3.31s/it]Training Epoch17:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:56<00:10,  3.34s/it]Training Epoch17:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.37s/it]Training Epoch17:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:03<00:03,  3.37s/it]Training Epoch17: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.38s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch17: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.33s/it]

 step 0 is completed and loss is 0.00016055448213592172

 step 1 is completed and loss is 0.0002672893460839987

 step 2 is completed and loss is 6.127168308012187e-05

 step 3 is completed and loss is 0.00014905321586411446

 step 4 is completed and loss is 8.534813241567463e-05

 step 5 is completed and loss is 7.980665395734832e-05

 step 6 is completed and loss is 0.0006462255259975791

 step 7 is completed and loss is 8.475309005007148e-05

 step 8 is completed and loss is 0.00010352789831813425

 step 9 is completed and loss is 6.639726052526385e-05

 step 10 is completed and loss is 0.0006040096050128341

 step 11 is completed and loss is 0.0016496086027473211

 step 12 is completed and loss is 0.00040415662806481123

 step 13 is completed and loss is 8.159541175700724e-05

 step 14 is completed and loss is 6.133112765382975e-05

 step 15 is completed and loss is 6.270212179515511e-05

 step 16 is completed and loss is 0.00024445244343951344

 step 17 is completed and loss is 0.00019381007587071508

 step 18 is completed and loss is 8.034383063204587e-05

 step 19 is completed and loss is 0.00018325909331906587

 step 20 is completed and loss is 7.956898480188102e-05

 step 21 is completed and loss is 0.00010924783418886364

 step 22 is completed and loss is 0.0007213664939627051

 step 23 is completed and loss is 0.00012611408601514995

 step 24 is completed and loss is 7.813857519067824e-05

 step 25 is completed and loss is 0.0004503777017816901

 step 26 is completed and loss is 9.440843132324517e-05

 step 27 is completed and loss is 0.00021508996724151075

 step 28 is completed and loss is 0.00014065175491850823

 step 29 is completed and loss is 0.00011121608258690685

 step 30 is completed and loss is 0.0001762913161655888

 step 31 is completed and loss is 2.0205730834277347e-05

 step 32 is completed and loss is 0.00013052152644377202

 step 33 is completed and loss is 0.000145601574331522

 step 34 is completed and loss is 9.369388862978667e-05

 step 35 is completed and loss is 0.0002264110662508756

 step 36 is completed and loss is 2.4795215722406283e-05

 step 37 is completed and loss is 8.523091673851013e-05

 step 38 is completed and loss is 0.00014321712660603225

 step 39 is completed and loss is 7.12249384378083e-05

 step 40 is completed and loss is 0.00014000150258652866

 step 41 is completed and loss is 4.750335938297212e-05

 step 42 is completed and loss is 0.00010394483979325742

 step 43 is completed and loss is 8.505122241331264e-05

 step 44 is completed and loss is 3.2245428883470595e-05

 step 45 is completed and loss is 0.0002870069583877921

 step 46 is completed and loss is 2.7477308321977034e-05

 step 47 is completed and loss is 8.946251182351261e-05

 step 48 is completed and loss is 0.0006821802235208452

 step 49 is completed and loss is 9.804482397157699e-05

 step 50 is completed and loss is 0.00010245510202366859

 step 51 is completed and loss is 7.22381955711171e-05

 step 52 is completed and loss is 0.0023481622338294983

 step 53 is completed and loss is 0.0003461204469203949

 step 54 is completed and loss is 5.227155997999944e-05

 step 55 is completed and loss is 0.0011639122385531664

 step 56 is completed and loss is 6.395371747203171e-05

 step 57 is completed and loss is 0.00030599546153098345

 step 58 is completed and loss is 8.260690083261579e-05

 step 59 is completed and loss is 0.0004691492940764874

 step 60 is completed and loss is 0.00011908287706319243

 step 61 is completed and loss is 8.558657282264903e-05

 step 62 is completed and loss is 0.00010531315638218075

 step 63 is completed and loss is 0.0006257234490476549

 step 64 is completed and loss is 0.0004348192014731467

 step 65 is completed and loss is 0.00010436226148158312

 step 66 is completed and loss is 0.0009465148905292153

 step 67 is completed and loss is 0.00010334669059375301

 step 68 is completed and loss is 0.0002557307598181069

 step 69 is completed and loss is 0.00018207535322289914

 step 70 is completed and loss is 0.00021413320791907609

 step 71 is completed and loss is 0.0002286667877342552

 step 72 is completed and loss is 0.000883519125636667

 step 73 is completed and loss is 0.0001222416467498988

 step 74 is completed and loss is 0.0001492978335591033

 step 75 is completed and loss is 0.00023880667868070304

 step 76 is completed and loss is 0.0001718247658573091

 step 77 is completed and loss is 9.947419312084094e-05

 step 78 is completed and loss is 0.00026436796179041266

 step 79 is completed and loss is 0.001205566106364131

 step 80 is completed and loss is 0.00043762719724327326

 step 81 is completed and loss is 0.0001348753139609471

 step 82 is completed and loss is 0.00028139346977695823

 step 83 is completed and loss is 0.00019011941913049668

 step 84 is completed and loss is 0.00011222832108614966

 step 85 is completed and loss is 0.00015555603022221476

 step 86 is completed and loss is 0.00010227633902104571

 step 87 is completed and loss is 0.0001623494317755103

 step 88 is completed and loss is 0.00043108101817779243

 step 89 is completed and loss is 8.17741674836725e-05

 step 90 is completed and loss is 0.0008871859172359109

 step 91 is completed and loss is 0.0001236093376064673
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:37,  1.31it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.40it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.43it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.45it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.51it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.48it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.45it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.44it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.48it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.47it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.52it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:22,  1.57it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:22,  1.58it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.55it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.55it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.57it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.59it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.62it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.56it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.56it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.56it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.59it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.55it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.55it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.55it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.58it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.55it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.52it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.53it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.57it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.59it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.55it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.58it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:07,  1.63it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.61it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.58it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.58it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:04,  1.61it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.59it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.58it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.58it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.58it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.59it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.58it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.61it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.61it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 18: train_perplexity=1.0003, train_epoch_loss=0.0003, epcoh time 307.0414187409997s
Training Epoch18:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch18:   1%|[34m          [0m| 1/92 [00:03<05:09,  3.40s/it]Training Epoch18:   2%|[34mâ–         [0m| 2/92 [00:06<05:01,  3.35s/it]Training Epoch18:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:57,  3.35s/it]Training Epoch18:   4%|[34mâ–         [0m| 4/92 [00:13<04:50,  3.30s/it]Training Epoch18:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:48,  3.31s/it]Training Epoch18:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:42,  3.29s/it]Training Epoch18:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch18:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.27s/it]Training Epoch18:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.32s/it]Training Epoch18:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:31,  3.31s/it]Training Epoch18:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.31s/it]Training Epoch18:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.32s/it]Training Epoch18:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:22,  3.32s/it]Training Epoch18:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.30s/it]Training Epoch18:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.29s/it]Training Epoch18:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.29s/it]Training Epoch18:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:09,  3.33s/it]Training Epoch18:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:07,  3.34s/it]Training Epoch18:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:04,  3.35s/it]Training Epoch18:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:01,  3.35s/it]Training Epoch18:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:57,  3.35s/it]Training Epoch18:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:53,  3.33s/it]Training Epoch18:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:50,  3.34s/it]Training Epoch18:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:46,  3.33s/it]Training Epoch18:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.29s/it]Training Epoch18:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:37,  3.30s/it]Training Epoch18:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.30s/it]Training Epoch18:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:32,  3.32s/it]Training Epoch18:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:30,  3.34s/it]Training Epoch18:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:27,  3.35s/it]Training Epoch18:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:24,  3.35s/it]Training Epoch18:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:21,  3.35s/it]Training Epoch18:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:16,  3.33s/it]Training Epoch18:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:13,  3.34s/it]Training Epoch18:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:08,  3.30s/it]Training Epoch18:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:04,  3.29s/it]Training Epoch18:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.31s/it]Training Epoch18:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:58,  3.31s/it]Training Epoch18:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:55,  3.31s/it]Training Epoch18:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.29s/it]Training Epoch18:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:47,  3.29s/it]Training Epoch18:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.30s/it]Training Epoch18:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:42,  3.31s/it]Training Epoch18:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.30s/it]Training Epoch18:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:34,  3.30s/it]Training Epoch18:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:31,  3.29s/it]Training Epoch18:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.31s/it]Training Epoch18:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:25,  3.31s/it]Training Epoch18:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:21,  3.30s/it]Training Epoch18:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.31s/it]Training Epoch18:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:14,  3.29s/it]Training Epoch18:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:11,  3.28s/it]Training Epoch18:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:08,  3.30s/it]Training Epoch18:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.30s/it]Training Epoch18:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:01,  3.30s/it]Training Epoch18:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:58,  3.30s/it]Training Epoch18:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.32s/it]Training Epoch18:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.31s/it]Training Epoch18:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:50,  3.34s/it]Training Epoch18:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:47,  3.36s/it]Training Epoch18:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:42,  3.32s/it]Training Epoch18:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.32s/it]Training Epoch18:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.32s/it]Training Epoch18:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:32,  3.30s/it]Training Epoch18:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.30s/it]Training Epoch18:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:25,  3.30s/it]Training Epoch18:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.29s/it]Training Epoch18:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.33s/it]Training Epoch18:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:17,  3.35s/it]Training Epoch18:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:13,  3.35s/it]Training Epoch18:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:10,  3.35s/it]Training Epoch18:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.31s/it]Training Epoch18:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.31s/it]Training Epoch18:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.30s/it]Training Epoch18:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.31s/it]Training Epoch18:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.29s/it]Training Epoch18:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:48,  3.27s/it]Training Epoch18:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:45,  3.28s/it]Training Epoch18:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:42,  3.25s/it]Training Epoch18:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.27s/it]Training Epoch18:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.30s/it]Training Epoch18:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.32s/it]Training Epoch18:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.33s/it]Training Epoch18:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.31s/it]Training Epoch18:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.31s/it]Training Epoch18:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.30s/it]Training Epoch18:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.29s/it]Training Epoch18:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.31s/it]Training Epoch18:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.29s/it]Training Epoch18:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.28s/it]Training Epoch18:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.30s/it]Training Epoch18: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch18: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.00014392760931514204

 step 1 is completed and loss is 0.00027247026446275413

 step 2 is completed and loss is 5.0603062845766544e-05

 step 3 is completed and loss is 0.00014488198212347925

 step 4 is completed and loss is 8.558625995647162e-05

 step 5 is completed and loss is 6.365559238474816e-05

 step 6 is completed and loss is 0.0005107794422656298

 step 7 is completed and loss is 7.74820800870657e-05

 step 8 is completed and loss is 9.804483852349222e-05

 step 9 is completed and loss is 6.842330913059413e-05

 step 10 is completed and loss is 0.0005906102014705539

 step 11 is completed and loss is 0.0020306408405303955

 step 12 is completed and loss is 0.00026339685427956283

 step 13 is completed and loss is 8.153582894010469e-05

 step 14 is completed and loss is 4.6728946472285315e-05

 step 15 is completed and loss is 4.6132929128361866e-05

 step 16 is completed and loss is 0.00019839299784507602

 step 17 is completed and loss is 0.00019916972087230533

 step 18 is completed and loss is 6.46092594251968e-05

 step 19 is completed and loss is 0.00015334512863773853

 step 20 is completed and loss is 5.554997187573463e-05

 step 21 is completed and loss is 8.570771024096757e-05

 step 22 is completed and loss is 0.000504699710290879

 step 23 is completed and loss is 0.0001164003333542496

 step 24 is completed and loss is 0.00010120306978933513

 step 25 is completed and loss is 0.0002605383924674243

 step 26 is completed and loss is 9.780557593330741e-05

 step 27 is completed and loss is 0.0003941330360248685

 step 28 is completed and loss is 0.00021519498841371387

 step 29 is completed and loss is 0.00010692501382436603

 step 30 is completed and loss is 0.00015668419655412436

 step 31 is completed and loss is 2.115936513291672e-05

 step 32 is completed and loss is 0.00017628735804464668

 step 33 is completed and loss is 0.00011508952593430877

 step 34 is completed and loss is 0.00011365847603883594

 step 35 is completed and loss is 0.00020865154510829598

 step 36 is completed and loss is 1.776201679604128e-05

 step 37 is completed and loss is 0.0001204532163683325

 step 38 is completed and loss is 9.56608128035441e-05

 step 39 is completed and loss is 6.413253140635788e-05

 step 40 is completed and loss is 0.00012116876314394176

 step 41 is completed and loss is 6.282045796979219e-05

 step 42 is completed and loss is 0.0001026338868541643

 step 43 is completed and loss is 8.099869592115283e-05

 step 44 is completed and loss is 2.962292819574941e-05

 step 45 is completed and loss is 0.0002880766987800598

 step 46 is completed and loss is 3.4152762964367867e-05

 step 47 is completed and loss is 0.00010829569509951398

 step 48 is completed and loss is 0.0007230257615447044

 step 49 is completed and loss is 0.00011997691763099283

 step 50 is completed and loss is 0.00010168021253775805

 step 51 is completed and loss is 8.689974492881447e-05

 step 52 is completed and loss is 0.003016772447153926

 step 53 is completed and loss is 0.00039479005499742925

 step 54 is completed and loss is 5.5490119848400354e-05

 step 55 is completed and loss is 0.0024784717243164778

 step 56 is completed and loss is 4.243759758537635e-05

 step 57 is completed and loss is 0.00038533832412213087

 step 58 is completed and loss is 6.514483538921922e-05

 step 59 is completed and loss is 0.00032589331385679543

 step 60 is completed and loss is 0.0001085340918507427

 step 61 is completed and loss is 9.005617903312668e-05

 step 62 is completed and loss is 0.00010352600656915456

 step 63 is completed and loss is 0.0005483211716637015

 step 64 is completed and loss is 0.00036203916533850133

 step 65 is completed and loss is 0.00011634140537353233

 step 66 is completed and loss is 0.0006814753287471831

 step 67 is completed and loss is 9.381121344631538e-05

 step 68 is completed and loss is 0.0003368849866092205

 step 69 is completed and loss is 0.0002093074726872146

 step 70 is completed and loss is 0.0002427920699119568

 step 71 is completed and loss is 0.00022866911604069173

 step 72 is completed and loss is 0.0011344340164214373

 step 73 is completed and loss is 9.840234997682273e-05

 step 74 is completed and loss is 0.000131061184220016

 step 75 is completed and loss is 0.0003572591522242874

 step 76 is completed and loss is 0.00016181307728402317

 step 77 is completed and loss is 8.636293205199763e-05

 step 78 is completed and loss is 0.00031430204398930073

 step 79 is completed and loss is 0.000972994021140039

 step 80 is completed and loss is 0.0003311646287329495

 step 81 is completed and loss is 0.00012617403990589082

 step 82 is completed and loss is 0.00017629051581025124

 step 83 is completed and loss is 0.0002249803947051987

 step 84 is completed and loss is 0.0001562065735924989

 step 85 is completed and loss is 0.00017832119192462415

 step 86 is completed and loss is 0.0001225396408699453

 step 87 is completed and loss is 0.0001688444463070482

 step 88 is completed and loss is 0.00018617833848111331

 step 89 is completed and loss is 8.302582136821002e-05

 step 90 is completed and loss is 0.0008404272957704961

 step 91 is completed and loss is 0.0004308959760237485
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.44it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.48it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.51it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.53it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.50it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.51it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.56it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.58it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.57it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.51it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.53it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.55it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:22,  1.60it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.65it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:20,  1.62it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.57it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.55it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.55it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.52it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.53it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.52it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:16,  1.50it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.48it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.51it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.53it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.56it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.56it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.56it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.54it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.54it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.57it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.62it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.58it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.55it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.54it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.56it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.57it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.55it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.57it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.53it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.55it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.55it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.57it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.57it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 19: train_perplexity=1.0003, train_epoch_loss=0.0003, epcoh time 304.8198143109985s
Training Epoch19:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch19:   1%|[34m          [0m| 1/92 [00:03<04:50,  3.20s/it]Training Epoch19:   2%|[34mâ–         [0m| 2/92 [00:06<04:49,  3.21s/it]Training Epoch19:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.26s/it]Training Epoch19:   4%|[34mâ–         [0m| 4/92 [00:12<04:44,  3.24s/it]Training Epoch19:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:42,  3.24s/it]Training Epoch19:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:39,  3.25s/it]Training Epoch19:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:39,  3.29s/it]Training Epoch19:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.28s/it]Training Epoch19:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.30s/it]Training Epoch19:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:29,  3.29s/it]Training Epoch19:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:25,  3.28s/it]Training Epoch19:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch19:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:21,  3.31s/it]Training Epoch19:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.31s/it]Training Epoch19:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.31s/it]Training Epoch19:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.29s/it]Training Epoch19:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:07,  3.30s/it]Training Epoch19:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:07,  3.34s/it]Training Epoch19:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.33s/it]Training Epoch19:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:58,  3.32s/it]Training Epoch19:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:53,  3.29s/it]Training Epoch19:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.30s/it]Training Epoch19:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:44,  3.26s/it]Training Epoch19:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:42,  3.27s/it]Training Epoch19:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:37,  3.25s/it]Training Epoch19:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:33,  3.24s/it]Training Epoch19:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:29,  3.23s/it]Training Epoch19:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:25,  3.22s/it]Training Epoch19:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:23,  3.23s/it]Training Epoch19:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:21,  3.24s/it]Training Epoch19:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:18,  3.25s/it]Training Epoch19:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:16,  3.27s/it]Training Epoch19:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:11,  3.25s/it]Training Epoch19:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:07,  3.24s/it]Training Epoch19:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:05,  3.26s/it]Training Epoch19:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:02,  3.26s/it]Training Epoch19:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:00,  3.28s/it]Training Epoch19:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:58,  3.30s/it]Training Epoch19:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:53,  3.27s/it]Training Epoch19:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:10<02:50,  3.27s/it]Training Epoch19:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:47,  3.28s/it]Training Epoch19:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:43,  3.28s/it]Training Epoch19:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:40,  3.27s/it]Training Epoch19:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:37,  3.27s/it]Training Epoch19:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.26s/it]Training Epoch19:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:30,  3.28s/it]Training Epoch19:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:27,  3.27s/it]Training Epoch19:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:24,  3.28s/it]Training Epoch19:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:21,  3.28s/it]Training Epoch19:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:17,  3.29s/it]Training Epoch19:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:15,  3.30s/it]Training Epoch19:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:12,  3.32s/it]Training Epoch19:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:09,  3.33s/it]Training Epoch19:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:05,  3.30s/it]Training Epoch19:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:02,  3.30s/it]Training Epoch19:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:59,  3.32s/it]Training Epoch19:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:56,  3.32s/it]Training Epoch19:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:52,  3.32s/it]Training Epoch19:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:49,  3.31s/it]Training Epoch19:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:46,  3.32s/it]Training Epoch19:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:42,  3.32s/it]Training Epoch19:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:39,  3.31s/it]Training Epoch19:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:36,  3.31s/it]Training Epoch19:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:32,  3.32s/it]Training Epoch19:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:29,  3.32s/it]Training Epoch19:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.30s/it]Training Epoch19:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:21,  3.25s/it]Training Epoch19:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:18,  3.27s/it]Training Epoch19:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:15,  3.27s/it]Training Epoch19:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:12,  3.31s/it]Training Epoch19:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:09,  3.30s/it]Training Epoch19:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:05,  3.28s/it]Training Epoch19:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.28s/it]Training Epoch19:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:58,  3.26s/it]Training Epoch19:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:55,  3.25s/it]Training Epoch19:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:52,  3.25s/it]Training Epoch19:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:48,  3.27s/it]Training Epoch19:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:45,  3.26s/it]Training Epoch19:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.27s/it]Training Epoch19:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:40,  3.35s/it]Training Epoch19:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:37,  3.37s/it]Training Epoch19:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:33,  3.38s/it]Training Epoch19:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:30,  3.37s/it]Training Epoch19:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:27,  3.38s/it]Training Epoch19:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.40s/it]Training Epoch19:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:20,  3.41s/it]Training Epoch19:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:17,  3.42s/it]Training Epoch19:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.41s/it]Training Epoch19:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:10,  3.37s/it]Training Epoch19:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.38s/it]Training Epoch19:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.34s/it]Training Epoch19: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.35s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch19: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.00019433746638242155

 step 1 is completed and loss is 0.0002947499742731452

 step 2 is completed and loss is 5.340432107914239e-05

 step 3 is completed and loss is 0.00021006623865105212

 step 4 is completed and loss is 9.023477468872443e-05

 step 5 is completed and loss is 6.174828740768135e-05

 step 6 is completed and loss is 0.0006719449302181602

 step 7 is completed and loss is 4.887449540547095e-05

 step 8 is completed and loss is 8.499254181515425e-05

 step 9 is completed and loss is 5.7039658713620156e-05

 step 10 is completed and loss is 0.0006008093478158116

 step 11 is completed and loss is 0.0018182536587119102

 step 12 is completed and loss is 0.0002971123903989792

 step 13 is completed and loss is 8.43370144139044e-05

 step 14 is completed and loss is 5.793391028419137e-05

 step 15 is completed and loss is 6.305972783593461e-05

 step 16 is completed and loss is 0.00029151421040296555

 step 17 is completed and loss is 0.00016753259114921093

 step 18 is completed and loss is 6.949660019017756e-05

 step 19 is completed and loss is 0.0002495720109436661

 step 20 is completed and loss is 6.985377694945782e-05

 step 21 is completed and loss is 8.737628377275541e-05

 step 22 is completed and loss is 0.00046129035763442516

 step 23 is completed and loss is 0.00014339688641484827

 step 24 is completed and loss is 8.248923404607922e-05

 step 25 is completed and loss is 0.00021621177438646555

 step 26 is completed and loss is 8.207201608456671e-05

 step 27 is completed and loss is 0.00048618842265568674

 step 28 is completed and loss is 0.00017908687004819512

 step 29 is completed and loss is 0.00010990489681717008

 step 30 is completed and loss is 0.00017116684466600418

 step 31 is completed and loss is 2.026533184107393e-05

 step 32 is completed and loss is 0.0001187228481285274

 step 33 is completed and loss is 0.00010930887219728902

 step 34 is completed and loss is 0.00010167969594476745

 step 35 is completed and loss is 0.00020001195662189275

 step 36 is completed and loss is 2.0086561562493443e-05

 step 37 is completed and loss is 0.0001336833811365068

 step 38 is completed and loss is 9.685189434094355e-05

 step 39 is completed and loss is 7.253611693158746e-05

 step 40 is completed and loss is 0.00012307584984228015

 step 41 is completed and loss is 4.047044785693288e-05

 step 42 is completed and loss is 9.917721035890281e-05

 step 43 is completed and loss is 7.0389942266047e-05

 step 44 is completed and loss is 2.5093131625908427e-05

 step 45 is completed and loss is 0.0002962370926979929

 step 46 is completed and loss is 2.5450801331317052e-05

 step 47 is completed and loss is 9.428993507754058e-05

 step 48 is completed and loss is 0.0007045717211440206

 step 49 is completed and loss is 7.641022966708988e-05

 step 50 is completed and loss is 0.00011538776743691415

 step 51 is completed and loss is 6.979460158618167e-05

 step 52 is completed and loss is 0.002471592742949724

 step 53 is completed and loss is 0.00029797537717968225

 step 54 is completed and loss is 4.9887585191754624e-05

 step 55 is completed and loss is 0.001195836695842445

 step 56 is completed and loss is 6.776791269658133e-05

 step 57 is completed and loss is 0.0002898486563935876

 step 58 is completed and loss is 7.098536298144609e-05

 step 59 is completed and loss is 0.0002582199522294104

 step 60 is completed and loss is 0.00011145431199111044

 step 61 is completed and loss is 0.00010221362754236907

 step 62 is completed and loss is 0.000118304968054872

 step 63 is completed and loss is 0.0007890165434218943

 step 64 is completed and loss is 0.0003138473257422447

 step 65 is completed and loss is 0.0001289154461119324

 step 66 is completed and loss is 0.0006540807080455124

 step 67 is completed and loss is 6.937669240869582e-05

 step 68 is completed and loss is 0.00028010166715830564

 step 69 is completed and loss is 0.00012087085633538663

 step 70 is completed and loss is 0.0002774070017039776

 step 71 is completed and loss is 0.00029265802004374564

 step 72 is completed and loss is 0.0006986588123254478

 step 73 is completed and loss is 0.00010764018225017935

 step 74 is completed and loss is 0.0001420858025085181

 step 75 is completed and loss is 0.00022092995641287416

 step 76 is completed and loss is 0.00014423264656215906

 step 77 is completed and loss is 8.087977766990662e-05

 step 78 is completed and loss is 0.00028480630135163665

 step 79 is completed and loss is 0.0012347397860139608

 step 80 is completed and loss is 0.00033527458435855806

 step 81 is completed and loss is 0.00012230037827976048

 step 82 is completed and loss is 0.00016723269072826952

 step 83 is completed and loss is 0.00022480051848106086

 step 84 is completed and loss is 0.00034256745129823685

 step 85 is completed and loss is 0.00016890530241653323

 step 86 is completed and loss is 0.00010835537250386551

 step 87 is completed and loss is 0.00013958418276160955

 step 88 is completed and loss is 0.0002766852267086506

 step 89 is completed and loss is 7.468127296306193e-05

 step 90 is completed and loss is 0.0007108442950993776

 step 91 is completed and loss is 0.00014899545931257308
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:40,  1.22it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:35,  1.35it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.39it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.45it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.50it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.44it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.53it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:25,  1.60it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:24,  1.60it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.58it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.55it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.52it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.49it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.54it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.54it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.58it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.61it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.62it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.59it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.61it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.53it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.54it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.54it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:15,  1.45it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.44it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:14,  1.42it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.37it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.45it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.43it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:11,  1.44it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.55it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.55it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.60it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.59it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:04,  1.63it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.64it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.58it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.61it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.64it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.64it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.63it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.64it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.66it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 20: train_perplexity=1.0003, train_epoch_loss=0.0003, epcoh time 303.59572729699903s
Training Epoch20:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch20:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.26s/it]Training Epoch20:   2%|[34mâ–         [0m| 2/92 [00:06<04:53,  3.27s/it]Training Epoch20:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:50,  3.27s/it]Training Epoch20:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.27s/it]Training Epoch20:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch20:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:39,  3.25s/it]Training Epoch20:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:36,  3.25s/it]Training Epoch20:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:32,  3.24s/it]Training Epoch20:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.27s/it]Training Epoch20:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.28s/it]Training Epoch20:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:27,  3.30s/it]Training Epoch20:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.29s/it]Training Epoch20:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.28s/it]Training Epoch20:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:18,  3.31s/it]Training Epoch20:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.31s/it]Training Epoch20:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:13,  3.33s/it]Training Epoch20:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:09,  3.33s/it]Training Epoch20:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.31s/it]Training Epoch20:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.32s/it]Training Epoch20:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:59,  3.32s/it]Training Epoch20:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.32s/it]Training Epoch20:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.29s/it]Training Epoch20:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.29s/it]Training Epoch20:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:46,  3.32s/it]Training Epoch20:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.30s/it]Training Epoch20:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:38,  3.31s/it]Training Epoch20:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.31s/it]Training Epoch20:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.30s/it]Training Epoch20:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:28,  3.31s/it]Training Epoch20:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:25,  3.31s/it]Training Epoch20:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.30s/it]Training Epoch20:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:19,  3.32s/it]Training Epoch20:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:15,  3.31s/it]Training Epoch20:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.30s/it]Training Epoch20:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.30s/it]Training Epoch20:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:04,  3.30s/it]Training Epoch20:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.31s/it]Training Epoch20:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.31s/it]Training Epoch20:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:56,  3.33s/it]Training Epoch20:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.33s/it]Training Epoch20:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:50,  3.35s/it]Training Epoch20:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:46,  3.32s/it]Training Epoch20:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:44,  3.35s/it]Training Epoch20:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:40,  3.35s/it]Training Epoch20:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:37,  3.34s/it]Training Epoch20:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.33s/it]Training Epoch20:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.33s/it]Training Epoch20:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:26,  3.33s/it]Training Epoch20:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.32s/it]Training Epoch20:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.30s/it]Training Epoch20:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:14,  3.28s/it]Training Epoch20:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:10,  3.27s/it]Training Epoch20:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:07,  3.26s/it]Training Epoch20:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:03,  3.26s/it]Training Epoch20:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.27s/it]Training Epoch20:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:59,  3.32s/it]Training Epoch20:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.32s/it]Training Epoch20:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.31s/it]Training Epoch20:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:48,  3.29s/it]Training Epoch20:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:44,  3.28s/it]Training Epoch20:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:41,  3.27s/it]Training Epoch20:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:37,  3.26s/it]Training Epoch20:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:34,  3.26s/it]Training Epoch20:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:31,  3.25s/it]Training Epoch20:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.27s/it]Training Epoch20:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.29s/it]Training Epoch20:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.30s/it]Training Epoch20:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.29s/it]Training Epoch20:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.32s/it]Training Epoch20:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.32s/it]Training Epoch20:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.32s/it]Training Epoch20:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.33s/it]Training Epoch20:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:03,  3.33s/it]Training Epoch20:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.31s/it]Training Epoch20:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.30s/it]Training Epoch20:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.27s/it]Training Epoch20:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.27s/it]Training Epoch20:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:45,  3.27s/it]Training Epoch20:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.29s/it]Training Epoch20:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:39,  3.30s/it]Training Epoch20:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.36s/it]Training Epoch20:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.37s/it]Training Epoch20:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:30,  3.37s/it]Training Epoch20:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.35s/it]Training Epoch20:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.35s/it]Training Epoch20:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.32s/it]Training Epoch20:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.31s/it]Training Epoch20:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.28s/it]Training Epoch20:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.31s/it]Training Epoch20:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.31s/it]Training Epoch20:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.31s/it]Training Epoch20: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.32s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch20: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.00012426276225596666

 step 1 is completed and loss is 0.00025507257669232786

 step 2 is completed and loss is 5.2987103117629886e-05

 step 3 is completed and loss is 9.059305739356205e-05

 step 4 is completed and loss is 9.142678754869848e-05

 step 5 is completed and loss is 6.180800119182095e-05

 step 6 is completed and loss is 0.0007893182337284088

 step 7 is completed and loss is 7.301216828636825e-05

 step 8 is completed and loss is 0.00013851110998075455

 step 9 is completed and loss is 4.804004856850952e-05

 step 10 is completed and loss is 0.0003191595897078514

 step 11 is completed and loss is 0.0018605806399136782

 step 12 is completed and loss is 0.0003029528015758842

 step 13 is completed and loss is 9.625677193980664e-05

 step 14 is completed and loss is 6.395373202394694e-05

 step 15 is completed and loss is 4.935142715112306e-05

 step 16 is completed and loss is 0.00022895737492945045

 step 17 is completed and loss is 0.00020590404164977372

 step 18 is completed and loss is 5.6861092161852866e-05

 step 19 is completed and loss is 0.00020172845688648522

 step 20 is completed and loss is 4.5596505515277386e-05

 step 21 is completed and loss is 6.252330786082894e-05

 step 22 is completed and loss is 0.0006781897973269224

 step 23 is completed and loss is 0.00010609044693410397

 step 24 is completed and loss is 8.225084457080811e-05

 step 25 is completed and loss is 0.0004441850178409368

 step 26 is completed and loss is 0.00011383638775441796

 step 27 is completed and loss is 0.00027700350619852543

 step 28 is completed and loss is 0.00016311713261529803

 step 29 is completed and loss is 0.00010036904131993651

 step 30 is completed and loss is 0.00013159752415958792

 step 31 is completed and loss is 1.7821583242039196e-05

 step 32 is completed and loss is 0.0001131810640799813

 step 33 is completed and loss is 0.00012498298019636422

 step 34 is completed and loss is 0.00010465960076544434

 step 35 is completed and loss is 0.00022956726024858654

 step 36 is completed and loss is 2.0503757696133107e-05

 step 37 is completed and loss is 8.73167664394714e-05

 step 38 is completed and loss is 8.767451799940318e-05

 step 39 is completed and loss is 7.503936649300158e-05

 step 40 is completed and loss is 0.00012164567306172103

 step 41 is completed and loss is 5.203296313993633e-05

 step 42 is completed and loss is 7.658902904950082e-05

 step 43 is completed and loss is 6.776746158720925e-05

 step 44 is completed and loss is 2.7536789275472984e-05

 step 45 is completed and loss is 0.0004417111922521144

 step 46 is completed and loss is 3.069580270675942e-05

 step 47 is completed and loss is 7.497983460780233e-05

 step 48 is completed and loss is 0.0009248884744010866

 step 49 is completed and loss is 0.00010048833792097867

 step 50 is completed and loss is 0.00011508964962558821

 step 51 is completed and loss is 8.546937897335738e-05

 step 52 is completed and loss is 0.003171795280650258

 step 53 is completed and loss is 0.000383775302907452

 step 54 is completed and loss is 5.40000619366765e-05

 step 55 is completed and loss is 0.002694755094125867

 step 56 is completed and loss is 4.5000451791565865e-05

 step 57 is completed and loss is 0.0005713154678232968

 step 58 is completed and loss is 5.900613541598432e-05

 step 59 is completed and loss is 0.00043632680899463594

 step 60 is completed and loss is 0.00011079871183028445

 step 61 is completed and loss is 7.748165080556646e-05

 step 62 is completed and loss is 9.661231888458133e-05

 step 63 is completed and loss is 0.00035152421332895756

 step 64 is completed and loss is 0.00025558361085131764

 step 65 is completed and loss is 0.00010102443775394931

 step 66 is completed and loss is 0.0009651703294366598

 step 67 is completed and loss is 6.031749217072502e-05

 step 68 is completed and loss is 0.00023588736075907946

 step 69 is completed and loss is 0.00014327908866107464

 step 70 is completed and loss is 0.00017093002679757774

 step 71 is completed and loss is 0.00023992499336600304

 step 72 is completed and loss is 0.0006407919572666287

 step 73 is completed and loss is 0.00010418307647341862

 step 74 is completed and loss is 0.00010376566933700815

 step 75 is completed and loss is 0.000388173182727769

 step 76 is completed and loss is 0.00015442344010807574

 step 77 is completed and loss is 8.850853919284418e-05

 step 78 is completed and loss is 0.00024911120999604464

 step 79 is completed and loss is 0.000818003376480192

 step 80 is completed and loss is 0.00038324150955304503

 step 81 is completed and loss is 0.00014756762539036572

 step 82 is completed and loss is 0.00015656791219953448

 step 83 is completed and loss is 0.00018904663738794625

 step 84 is completed and loss is 0.0001560275413794443

 step 85 is completed and loss is 0.00016926287207752466

 step 86 is completed and loss is 0.0001267114421352744

 step 87 is completed and loss is 0.00015746198187116534

 step 88 is completed and loss is 0.00027018654509447515

 step 89 is completed and loss is 7.617172377649695e-05

 step 90 is completed and loss is 0.0007447722600772977

 step 91 is completed and loss is 0.00010275132081005722
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.37it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.45it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.50it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.51it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.53it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:27,  1.60it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.58it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.57it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.57it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.53it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.53it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.53it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.53it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.54it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.53it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.52it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.53it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.53it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.53it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.54it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.54it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.53it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.52it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.51it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.50it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.49it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.55it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.56it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.58it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.58it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.57it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.55it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.53it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.56it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.56it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.54it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.50it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.51it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.51it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.51it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.51it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.53it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.57it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.58it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.58it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 21: train_perplexity=1.0003, train_epoch_loss=0.0003, epcoh time 304.21005883200087s
Training Epoch21:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch21:   1%|[34m          [0m| 1/92 [00:03<05:01,  3.31s/it]Training Epoch21:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.31s/it]Training Epoch21:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:54,  3.31s/it]Training Epoch21:   4%|[34mâ–         [0m| 4/92 [00:13<04:52,  3.32s/it]Training Epoch21:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.30s/it]Training Epoch21:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:42,  3.28s/it]Training Epoch21:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.31s/it]Training Epoch21:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.31s/it]Training Epoch21:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.32s/it]Training Epoch21:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.33s/it]Training Epoch21:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.32s/it]Training Epoch21:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.28s/it]Training Epoch21:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.29s/it]Training Epoch21:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:16,  3.29s/it]Training Epoch21:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.30s/it]Training Epoch21:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.30s/it]Training Epoch21:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.32s/it]Training Epoch21:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:06,  3.33s/it]Training Epoch21:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.33s/it]Training Epoch21:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.32s/it]Training Epoch21:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:56,  3.34s/it]Training Epoch21:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:53,  3.33s/it]Training Epoch21:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:50,  3.34s/it]Training Epoch21:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:47,  3.35s/it]Training Epoch21:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.34s/it]Training Epoch21:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:40,  3.34s/it]Training Epoch21:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:38,  3.36s/it]Training Epoch21:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:33,  3.34s/it]Training Epoch21:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.32s/it]Training Epoch21:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:24,  3.31s/it]Training Epoch21:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:20,  3.29s/it]Training Epoch21:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:15,  3.25s/it]Training Epoch21:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:11,  3.25s/it]Training Epoch21:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:08,  3.24s/it]Training Epoch21:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:05,  3.26s/it]Training Epoch21:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:04,  3.29s/it]Training Epoch21:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:01,  3.30s/it]Training Epoch21:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.31s/it]Training Epoch21:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:55,  3.31s/it]Training Epoch21:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.29s/it]Training Epoch21:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.32s/it]Training Epoch21:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:46,  3.33s/it]Training Epoch21:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:41,  3.30s/it]Training Epoch21:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.29s/it]Training Epoch21:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:35,  3.31s/it]Training Epoch21:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:32,  3.31s/it]Training Epoch21:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:28,  3.30s/it]Training Epoch21:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.30s/it]Training Epoch21:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:21,  3.28s/it]Training Epoch21:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:17,  3.27s/it]Training Epoch21:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:13,  3.26s/it]Training Epoch21:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:10,  3.26s/it]Training Epoch21:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:08,  3.29s/it]Training Epoch21:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:04,  3.28s/it]Training Epoch21:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.27s/it]Training Epoch21:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:58,  3.29s/it]Training Epoch21:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.33s/it]Training Epoch21:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:53,  3.34s/it]Training Epoch21:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:50,  3.33s/it]Training Epoch21:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:46,  3.33s/it]Training Epoch21:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:43,  3.33s/it]Training Epoch21:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:40,  3.34s/it]Training Epoch21:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:37,  3.34s/it]Training Epoch21:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:33,  3.35s/it]Training Epoch21:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.31s/it]Training Epoch21:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:25,  3.29s/it]Training Epoch21:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:23,  3.32s/it]Training Epoch21:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:20,  3.34s/it]Training Epoch21:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.33s/it]Training Epoch21:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:13,  3.33s/it]Training Epoch21:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.33s/it]Training Epoch21:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.32s/it]Training Epoch21:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.30s/it]Training Epoch21:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.32s/it]Training Epoch21:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.30s/it]Training Epoch21:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:53,  3.32s/it]Training Epoch21:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:50,  3.34s/it]Training Epoch21:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.33s/it]Training Epoch21:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.34s/it]Training Epoch21:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:40,  3.34s/it]Training Epoch21:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.36s/it]Training Epoch21:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.33s/it]Training Epoch21:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:30,  3.36s/it]Training Epoch21:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.34s/it]Training Epoch21:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.34s/it]Training Epoch21:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:19,  3.33s/it]Training Epoch21:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.33s/it]Training Epoch21:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.33s/it]Training Epoch21:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.33s/it]Training Epoch21:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.32s/it]Training Epoch21:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.32s/it]Training Epoch21: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.32s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch21: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.00016716792015358806

 step 1 is completed and loss is 0.00024911481887102127

 step 2 is completed and loss is 4.464286757865921e-05

 step 3 is completed and loss is 0.0001591825857758522

 step 4 is completed and loss is 7.53952917875722e-05

 step 5 is completed and loss is 7.31318723410368e-05

 step 6 is completed and loss is 0.0005355397588573396

 step 7 is completed and loss is 6.0019858210580423e-05

 step 8 is completed and loss is 9.160804620478302e-05

 step 9 is completed and loss is 5.1139224524376914e-05

 step 10 is completed and loss is 0.001390047837048769

 step 11 is completed and loss is 0.0010544146643951535

 step 12 is completed and loss is 0.0002448666491545737

 step 13 is completed and loss is 7.062897202558815e-05

 step 14 is completed and loss is 6.10332572250627e-05

 step 15 is completed and loss is 5.638440416078083e-05

 step 16 is completed and loss is 0.00016955471073742956

 step 17 is completed and loss is 0.0001050767459673807

 step 18 is completed and loss is 6.222525553312153e-05

 step 19 is completed and loss is 0.0002540985296946019

 step 20 is completed and loss is 6.502645555883646e-05

 step 21 is completed and loss is 9.345504804514349e-05

 step 22 is completed and loss is 0.0006374816293828189

 step 23 is completed and loss is 0.0001389272656524554

 step 24 is completed and loss is 8.22508372948505e-05

 step 25 is completed and loss is 0.00032720755552873015

 step 26 is completed and loss is 8.105879533104599e-05

 step 27 is completed and loss is 0.00034998488263227046

 step 28 is completed and loss is 0.00016144891560543329

 step 29 is completed and loss is 9.196566679747775e-05

 step 30 is completed and loss is 0.00016276394308079034

 step 31 is completed and loss is 1.8238826669403352e-05

 step 32 is completed and loss is 0.0001402947527822107

 step 33 is completed and loss is 0.00010787843348225579

 step 34 is completed and loss is 0.0001484016393078491

 step 35 is completed and loss is 0.00023081808467395604

 step 36 is completed and loss is 1.9013677956536412e-05

 step 37 is completed and loss is 6.800658593419939e-05

 step 38 is completed and loss is 0.0001038256668834947

 step 39 is completed and loss is 6.520517490571365e-05

 step 40 is completed and loss is 0.00012063246686011553

 step 41 is completed and loss is 6.347591988742352e-05

 step 42 is completed and loss is 9.583962673787028e-05

 step 43 is completed and loss is 7.21187680028379e-05

 step 44 is completed and loss is 3.236452175769955e-05

 step 45 is completed and loss is 0.0003137541061732918

 step 46 is completed and loss is 2.8788563213311136e-05

 step 47 is completed and loss is 9.32172843022272e-05

 step 48 is completed and loss is 0.0005271821282804012

 step 49 is completed and loss is 8.213178080040962e-05

 step 50 is completed and loss is 9.494565892964602e-05

 step 51 is completed and loss is 7.581416139146313e-05

 step 52 is completed and loss is 0.0017125222366303205

 step 53 is completed and loss is 0.00036137059214524925

 step 54 is completed and loss is 5.0364425987936556e-05

 step 55 is completed and loss is 0.0013314400566741824

 step 56 is completed and loss is 4.178192466497421e-05

 step 57 is completed and loss is 0.00047371539403684437

 step 58 is completed and loss is 7.795885903760791e-05

 step 59 is completed and loss is 0.00023420694924425334

 step 60 is completed and loss is 0.00010781895252875984

 step 61 is completed and loss is 9.160571062238887e-05

 step 62 is completed and loss is 0.00011186880146851763

 step 63 is completed and loss is 0.0007193526835180819

 step 64 is completed and loss is 0.00046512740664184093

 step 65 is completed and loss is 0.00014053711493033916

 step 66 is completed and loss is 0.0010102946544066072

 step 67 is completed and loss is 6.770807522116229e-05

 step 68 is completed and loss is 0.0001730164949549362

 step 69 is completed and loss is 0.00015883363084867597

 step 70 is completed and loss is 0.00018433750665280968

 step 71 is completed and loss is 0.0002367097040405497

 step 72 is completed and loss is 0.0005077244713902473

 step 73 is completed and loss is 0.00010471971472725272

 step 74 is completed and loss is 0.0001273064553970471

 step 75 is completed and loss is 0.0005387348355725408

 step 76 is completed and loss is 0.00015984682249836624

 step 77 is completed and loss is 0.00010072614531964064

 step 78 is completed and loss is 0.0002539958222769201

 step 79 is completed and loss is 0.0006935956771485507

 step 80 is completed and loss is 0.000325207831338048

 step 81 is completed and loss is 0.00012247941049281508

 step 82 is completed and loss is 0.00016705515736248344

 step 83 is completed and loss is 0.000150132313137874

 step 84 is completed and loss is 0.00013272726209834218

 step 85 is completed and loss is 0.00015841660206206143

 step 86 is completed and loss is 0.00011181206355104223

 step 87 is completed and loss is 0.00016091798897832632

 step 88 is completed and loss is 0.00020423423848114908

 step 89 is completed and loss is 7.611211913172156e-05

 step 90 is completed and loss is 0.00037486583460122347

 step 91 is completed and loss is 0.0001835554139688611
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:37,  1.32it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:35,  1.34it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:34,  1.36it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.40it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:33,  1.35it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:31,  1.41it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:05<00:30,  1.43it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.40it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:29,  1.41it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:28,  1.41it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:27,  1.43it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.44it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:25,  1.44it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:25,  1.43it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.42it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.43it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:12<00:23,  1.42it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.42it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:21,  1.44it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:14<00:20,  1.46it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.47it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:18,  1.52it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:16<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.49it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:16,  1.48it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:18<00:16,  1.49it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.48it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:14,  1.47it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:20<00:13,  1.52it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.49it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:12,  1.47it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:12,  1.47it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.47it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:11,  1.40it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:10,  1.42it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.51it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.50it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:08,  1.48it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.49it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:07,  1.42it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:06,  1.43it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:29<00:05,  1.45it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.42it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:04,  1.39it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:31<00:03,  1.39it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.42it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:32<00:02,  1.43it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:33<00:01,  1.42it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:34<00:00,  1.41it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.36it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.43it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 22: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.2541751099998s
Training Epoch22:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch22:   1%|[34m          [0m| 1/92 [00:03<05:06,  3.37s/it]Training Epoch22:   2%|[34mâ–         [0m| 2/92 [00:06<05:05,  3.40s/it]Training Epoch22:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:54,  3.31s/it]Training Epoch22:   4%|[34mâ–         [0m| 4/92 [00:13<04:51,  3.31s/it]Training Epoch22:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.30s/it]Training Epoch22:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.30s/it]Training Epoch22:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.33s/it]Training Epoch22:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:40,  3.34s/it]Training Epoch22:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.32s/it]Training Epoch22:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.33s/it]Training Epoch22:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:33,  3.38s/it]Training Epoch22:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:32,  3.40s/it]Training Epoch22:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:27,  3.39s/it]Training Epoch22:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:22,  3.37s/it]Training Epoch22:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:50<04:17,  3.34s/it]Training Epoch22:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:10,  3.30s/it]Training Epoch22:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:09,  3.32s/it]Training Epoch22:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [01:00<04:06,  3.34s/it]Training Epoch22:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:02,  3.33s/it]Training Epoch22:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:00,  3.34s/it]Training Epoch22:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:10<03:57,  3.34s/it]Training Epoch22:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:55,  3.37s/it]Training Epoch22:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:51,  3.35s/it]Training Epoch22:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:20<03:48,  3.36s/it]Training Epoch22:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:44,  3.35s/it]Training Epoch22:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:41,  3.36s/it]Training Epoch22:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:37,  3.35s/it]Training Epoch22:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:34,  3.35s/it]Training Epoch22:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:31,  3.35s/it]Training Epoch22:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:40<03:27,  3.34s/it]Training Epoch22:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:23,  3.34s/it]Training Epoch22:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:47<03:21,  3.35s/it]Training Epoch22:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:50<03:17,  3.34s/it]Training Epoch22:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:14,  3.35s/it]Training Epoch22:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:57<03:10,  3.34s/it]Training Epoch22:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [02:00<03:08,  3.37s/it]Training Epoch22:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:05,  3.37s/it]Training Epoch22:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:07<03:00,  3.35s/it]Training Epoch22:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:10<02:58,  3.36s/it]Training Epoch22:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:52,  3.32s/it]Training Epoch22:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:17<02:48,  3.30s/it]Training Epoch22:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:20<02:45,  3.30s/it]Training Epoch22:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:41,  3.29s/it]Training Epoch22:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:38,  3.31s/it]Training Epoch22:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:30<02:34,  3.29s/it]Training Epoch22:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:32,  3.32s/it]Training Epoch22:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:29,  3.32s/it]Training Epoch22:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:40<02:25,  3.31s/it]Training Epoch22:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:22,  3.32s/it]Training Epoch22:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:19,  3.33s/it]Training Epoch22:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:50<02:17,  3.34s/it]Training Epoch22:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:13,  3.34s/it]Training Epoch22:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:09,  3.33s/it]Training Epoch22:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [03:00<02:06,  3.32s/it]Training Epoch22:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:03<02:02,  3.30s/it]Training Epoch22:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<01:59,  3.33s/it]Training Epoch22:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:10<01:56,  3.34s/it]Training Epoch22:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:13<01:52,  3.31s/it]Training Epoch22:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:50,  3.35s/it]Training Epoch22:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:20<01:47,  3.35s/it]Training Epoch22:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:43,  3.34s/it]Training Epoch22:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:39,  3.31s/it]Training Epoch22:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:30<01:36,  3.32s/it]Training Epoch22:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:33<01:32,  3.32s/it]Training Epoch22:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:29,  3.33s/it]Training Epoch22:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:40<01:26,  3.32s/it]Training Epoch22:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:43<01:23,  3.33s/it]Training Epoch22:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:20,  3.33s/it]Training Epoch22:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:50<01:17,  3.35s/it]Training Epoch22:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:53<01:13,  3.36s/it]Training Epoch22:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:56<01:10,  3.34s/it]Training Epoch22:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [04:00<01:07,  3.36s/it]Training Epoch22:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:03<01:03,  3.34s/it]Training Epoch22:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:06<01:00,  3.36s/it]Training Epoch22:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:10<00:57,  3.36s/it]Training Epoch22:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:13<00:53,  3.34s/it]Training Epoch22:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:17<00:50,  3.37s/it]Training Epoch22:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:20<00:47,  3.37s/it]Training Epoch22:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:23<00:43,  3.35s/it]Training Epoch22:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:27<00:40,  3.35s/it]Training Epoch22:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:30<00:36,  3.33s/it]Training Epoch22:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:33<00:33,  3.31s/it]Training Epoch22:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:36<00:29,  3.32s/it]Training Epoch22:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:40<00:26,  3.32s/it]Training Epoch22:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:43<00:23,  3.31s/it]Training Epoch22:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:46<00:19,  3.32s/it]Training Epoch22:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:50<00:16,  3.35s/it]Training Epoch22:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:53<00:13,  3.36s/it]Training Epoch22:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:57<00:10,  3.36s/it]Training Epoch22:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [05:00<00:06,  3.35s/it]Training Epoch22:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:03<00:03,  3.34s/it]Training Epoch22: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:07<00:00,  3.32s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch22: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:07<00:00,  3.34s/it]

 step 0 is completed and loss is 0.00011633784743025899

 step 1 is completed and loss is 0.00018767695291899145

 step 2 is completed and loss is 4.31528314948082e-05

 step 3 is completed and loss is 0.0001510193251306191

 step 4 is completed and loss is 7.855387957533821e-05

 step 5 is completed and loss is 6.419180135708302e-05

 step 6 is completed and loss is 0.0006463503232225776

 step 7 is completed and loss is 5.9006350056733936e-05

 step 8 is completed and loss is 9.595852316124365e-05

 step 9 is completed and loss is 4.535794505500235e-05

 step 10 is completed and loss is 0.0003797965182457119

 step 11 is completed and loss is 0.004144961480051279

 step 12 is completed and loss is 0.00030200256151147187

 step 13 is completed and loss is 9.417085675522685e-05

 step 14 is completed and loss is 5.441737448563799e-05

 step 15 is completed and loss is 4.9470632802695036e-05

 step 16 is completed and loss is 0.00017509580357000232

 step 17 is completed and loss is 0.00019190323655493557

 step 18 is completed and loss is 5.286791565595195e-05

 step 19 is completed and loss is 0.00021704139362554997

 step 20 is completed and loss is 6.073528857086785e-05

 step 21 is completed and loss is 7.587378786411136e-05

 step 22 is completed and loss is 0.0003527555672917515

 step 23 is completed and loss is 0.00012152612180216238

 step 24 is completed and loss is 8.421754318987951e-05

 step 25 is completed and loss is 0.00046913843834772706

 step 26 is completed and loss is 0.00011568472837097943

 step 27 is completed and loss is 0.00020317145390436053

 step 28 is completed and loss is 0.00014536044909618795

 step 29 is completed and loss is 0.0001099645160138607

 step 30 is completed and loss is 0.0001121692403103225

 step 31 is completed and loss is 1.9252067431807518e-05

 step 32 is completed and loss is 0.0001375529682263732

 step 33 is completed and loss is 0.00011103654105681926

 step 34 is completed and loss is 6.705296254949644e-05

 step 35 is completed and loss is 0.0002579882857389748

 step 36 is completed and loss is 1.9132872694171965e-05

 step 37 is completed and loss is 0.00010710333299357444

 step 38 is completed and loss is 7.825760258128867e-05

 step 39 is completed and loss is 7.581423415103927e-05

 step 40 is completed and loss is 0.00014321968774311244

 step 41 is completed and loss is 0.00010108092101290822

 step 42 is completed and loss is 9.667394624557346e-05

 step 43 is completed and loss is 6.413205119315535e-05

 step 44 is completed and loss is 2.3662678358959965e-05

 step 45 is completed and loss is 0.0002734207082539797

 step 46 is completed and loss is 2.759651397354901e-05

 step 47 is completed and loss is 9.91174892988056e-05

 step 48 is completed and loss is 0.00045588385546579957

 step 49 is completed and loss is 8.66017653606832e-05

 step 50 is completed and loss is 9.5422423328273e-05

 step 51 is completed and loss is 7.450302655342966e-05

 step 52 is completed and loss is 0.0016078371554613113

 step 53 is completed and loss is 0.00027682355721481144

 step 54 is completed and loss is 4.583463305607438e-05

 step 55 is completed and loss is 0.0012566463556140661

 step 56 is completed and loss is 6.627802940784022e-05

 step 57 is completed and loss is 0.0002437371585983783

 step 58 is completed and loss is 6.103244231780991e-05

 step 59 is completed and loss is 0.0003205295361112803

 step 60 is completed and loss is 0.00010561335511738434

 step 61 is completed and loss is 8.630131924292073e-05

 step 62 is completed and loss is 0.00010191623732680455

 step 63 is completed and loss is 0.00030130904633551836

 step 64 is completed and loss is 0.0003632281150203198

 step 65 is completed and loss is 0.00010567286517471075

 step 66 is completed and loss is 0.001117265084758401

 step 67 is completed and loss is 6.204601231729612e-05

 step 68 is completed and loss is 0.0002057340752799064

 step 69 is completed and loss is 0.000177128822542727

 step 70 is completed and loss is 0.0002268229000037536

 step 71 is completed and loss is 0.0002962881699204445

 step 72 is completed and loss is 0.0006509145023301244

 step 73 is completed and loss is 9.98923642328009e-05

 step 74 is completed and loss is 0.00012730674643535167

 step 75 is completed and loss is 0.00024369184393435717

 step 76 is completed and loss is 0.00015066844935063273

 step 77 is completed and loss is 7.933042070362717e-05

 step 78 is completed and loss is 0.0002121653378708288

 step 79 is completed and loss is 0.0007736703264527023

 step 80 is completed and loss is 0.00026449025608599186

 step 81 is completed and loss is 0.00013135811605025083

 step 82 is completed and loss is 0.00024749257136136293

 step 83 is completed and loss is 0.00017271863180212677

 step 84 is completed and loss is 0.00011830648145405576

 step 85 is completed and loss is 0.00018785618885885924

 step 86 is completed and loss is 0.00013159839727450162

 step 87 is completed and loss is 0.0001866003731265664

 step 88 is completed and loss is 0.00024337973445653915

 step 89 is completed and loss is 7.611208275193349e-05

 step 90 is completed and loss is 0.0010324605973437428

 step 91 is completed and loss is 0.0003039626753889024
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:38,  1.28it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:36,  1.32it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:34,  1.35it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:33,  1.36it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:32,  1.40it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.42it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:05<00:30,  1.41it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.46it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.51it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.49it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.47it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.51it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.46it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.43it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.47it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.45it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:21,  1.44it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:21,  1.42it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:20,  1.41it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:19,  1.43it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:16<00:19,  1.37it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:18,  1.38it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.41it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:18<00:16,  1.43it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:15,  1.46it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:20<00:14,  1.43it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:14,  1.42it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:13,  1.41it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:12,  1.39it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:23<00:12,  1.32it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:24<00:12,  1.33it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:11,  1.36it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:25<00:09,  1.40it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:26<00:09,  1.43it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:08,  1.43it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:27<00:07,  1.47it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:28<00:06,  1.48it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:06,  1.50it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:29<00:05,  1.48it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.54it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:03,  1.51it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:31<00:03,  1.55it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.52it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:32<00:02,  1.49it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:33<00:01,  1.49it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:34<00:00,  1.44it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.44it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.44it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 23: train_perplexity=1.0003, train_epoch_loss=0.0003, epcoh time 307.30300473900024s
Training Epoch23:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch23:   1%|[34m          [0m| 1/92 [00:03<05:03,  3.34s/it]Training Epoch23:   2%|[34mâ–         [0m| 2/92 [00:06<05:00,  3.34s/it]Training Epoch23:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:56,  3.33s/it]Training Epoch23:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.28s/it]Training Epoch23:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.30s/it]Training Epoch23:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.31s/it]Training Epoch23:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.32s/it]Training Epoch23:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.33s/it]Training Epoch23:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:36,  3.33s/it]Training Epoch23:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:32,  3.32s/it]Training Epoch23:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:30,  3.34s/it]Training Epoch23:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:26,  3.33s/it]Training Epoch23:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:22,  3.32s/it]Training Epoch23:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.33s/it]Training Epoch23:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:17,  3.34s/it]Training Epoch23:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:14,  3.35s/it]Training Epoch23:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:10,  3.34s/it]Training Epoch23:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [01:00<04:09,  3.37s/it]Training Epoch23:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:04,  3.35s/it]Training Epoch23:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:00,  3.35s/it]Training Epoch23:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:10<03:57,  3.35s/it]Training Epoch23:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:54,  3.35s/it]Training Epoch23:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:48,  3.32s/it]Training Epoch23:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:43,  3.29s/it]Training Epoch23:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:39,  3.27s/it]Training Epoch23:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:37,  3.29s/it]Training Epoch23:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:32,  3.27s/it]Training Epoch23:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:28,  3.27s/it]Training Epoch23:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:26,  3.28s/it]Training Epoch23:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:26,  3.32s/it]Training Epoch23:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:20,  3.29s/it]Training Epoch23:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:18,  3.31s/it]Training Epoch23:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:16,  3.33s/it]Training Epoch23:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:10,  3.29s/it]Training Epoch23:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:07,  3.29s/it]Training Epoch23:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:04,  3.29s/it]Training Epoch23:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:01,  3.30s/it]Training Epoch23:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<03:00,  3.34s/it]Training Epoch23:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:55,  3.31s/it]Training Epoch23:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.31s/it]Training Epoch23:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.32s/it]Training Epoch23:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.31s/it]Training Epoch23:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:41,  3.30s/it]Training Epoch23:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.30s/it]Training Epoch23:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.32s/it]Training Epoch23:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.33s/it]Training Epoch23:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:30,  3.34s/it]Training Epoch23:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:25,  3.31s/it]Training Epoch23:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:23,  3.33s/it]Training Epoch23:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.30s/it]Training Epoch23:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:14,  3.28s/it]Training Epoch23:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:12,  3.31s/it]Training Epoch23:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:10,  3.34s/it]Training Epoch23:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:06,  3.33s/it]Training Epoch23:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:02,  3.31s/it]Training Epoch23:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.32s/it]Training Epoch23:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:56,  3.32s/it]Training Epoch23:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:51,  3.29s/it]Training Epoch23:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:48,  3.28s/it]Training Epoch23:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.29s/it]Training Epoch23:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:42,  3.30s/it]Training Epoch23:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.31s/it]Training Epoch23:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:35,  3.31s/it]Training Epoch23:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:32,  3.31s/it]Training Epoch23:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.31s/it]Training Epoch23:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.31s/it]Training Epoch23:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:22,  3.31s/it]Training Epoch23:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.33s/it]Training Epoch23:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.32s/it]Training Epoch23:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:12,  3.32s/it]Training Epoch23:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.32s/it]Training Epoch23:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.32s/it]Training Epoch23:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:03,  3.33s/it]Training Epoch23:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<01:00,  3.34s/it]Training Epoch23:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.33s/it]Training Epoch23:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:53,  3.34s/it]Training Epoch23:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.33s/it]Training Epoch23:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.35s/it]Training Epoch23:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:43,  3.34s/it]Training Epoch23:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.30s/it]Training Epoch23:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.28s/it]Training Epoch23:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:32,  3.28s/it]Training Epoch23:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:29,  3.31s/it]Training Epoch23:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.34s/it]Training Epoch23:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.34s/it]Training Epoch23:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:20,  3.33s/it]Training Epoch23:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.32s/it]Training Epoch23:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.36s/it]Training Epoch23:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:10,  3.36s/it]Training Epoch23:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.37s/it]Training Epoch23:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.35s/it]Training Epoch23: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.34s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch23: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 0.00012325083662290126

 step 1 is completed and loss is 0.0001910715945996344

 step 2 is completed and loss is 4.559642911772244e-05

 step 3 is completed and loss is 0.00011836306657642126

 step 4 is completed and loss is 7.646818266948685e-05

 step 5 is completed and loss is 5.495387813425623e-05

 step 6 is completed and loss is 0.0009668171987868845

 step 7 is completed and loss is 6.723112164763734e-05

 step 8 is completed and loss is 9.12505347514525e-05

 step 9 is completed and loss is 4.48811988462694e-05

 step 10 is completed and loss is 0.0009125483338721097

 step 11 is completed and loss is 0.0016818343428894877

 step 12 is completed and loss is 0.00036443001590669155

 step 13 is completed and loss is 8.391981828026474e-05

 step 14 is completed and loss is 4.9768634198699147e-05

 step 15 is completed and loss is 4.5060096454108134e-05

 step 16 is completed and loss is 0.00013701748684979975

 step 17 is completed and loss is 0.00011681685282383114

 step 18 is completed and loss is 5.453676203615032e-05

 step 19 is completed and loss is 0.00022448660456575453

 step 20 is completed and loss is 4.59541188320145e-05

 step 21 is completed and loss is 8.487270679324865e-05

 step 22 is completed and loss is 0.0005186944035813212

 step 23 is completed and loss is 0.00011610292131081223

 step 24 is completed and loss is 8.439632074441761e-05

 step 25 is completed and loss is 0.0003493034455459565

 step 26 is completed and loss is 7.295310206245631e-05

 step 27 is completed and loss is 0.0002102034486597404

 step 28 is completed and loss is 0.00024879659758880734

 step 29 is completed and loss is 9.113104169955477e-05

 step 30 is completed and loss is 0.00012504176993388683

 step 31 is completed and loss is 2.264941213070415e-05

 step 32 is completed and loss is 0.00010418143938295543

 step 33 is completed and loss is 0.00011365817772457376

 step 34 is completed and loss is 7.593330519739538e-05

 step 35 is completed and loss is 0.0002179472940042615

 step 36 is completed and loss is 2.0205750843160786e-05

 step 37 is completed and loss is 7.396660657832399e-05

 step 38 is completed and loss is 0.0001298080023843795

 step 39 is completed and loss is 7.188049494288862e-05

 step 40 is completed and loss is 0.00012212221918161958

 step 41 is completed and loss is 0.00012896975385956466

 step 42 is completed and loss is 8.928377064876258e-05

 step 43 is completed and loss is 7.46810546843335e-05

 step 44 is completed and loss is 2.551034231146332e-05

 step 45 is completed and loss is 0.00021085409389343113

 step 46 is completed and loss is 2.64640329987742e-05

 step 47 is completed and loss is 8.940295811044052e-05

 step 48 is completed and loss is 0.0004882955108769238

 step 49 is completed and loss is 0.00010084582754643634

 step 50 is completed and loss is 9.804466390050948e-05

 step 51 is completed and loss is 7.384740456473082e-05

 step 52 is completed and loss is 0.0025878676678985357

 step 53 is completed and loss is 0.0004387485096231103

 step 54 is completed and loss is 5.3642252169083804e-05

 step 55 is completed and loss is 0.0019206710858270526

 step 56 is completed and loss is 4.970898589817807e-05

 step 57 is completed and loss is 0.00016395191778428853

 step 58 is completed and loss is 5.799301288789138e-05

 step 59 is completed and loss is 0.00026697819703258574

 step 60 is completed and loss is 0.00014053707127459347

 step 61 is completed and loss is 0.00010519296483835205

 step 62 is completed and loss is 0.0001059689384419471

 step 63 is completed and loss is 0.0007041310309432447

 step 64 is completed and loss is 0.00028126031975261867

 step 65 is completed and loss is 9.923611651174724e-05

 step 66 is completed and loss is 0.0008093914366327226

 step 67 is completed and loss is 6.848243356216699e-05

 step 68 is completed and loss is 0.0002189027436543256

 step 69 is completed and loss is 0.00014548424223903567

 step 70 is completed and loss is 0.00020370108541101217

 step 71 is completed and loss is 0.00030123512260615826

 step 72 is completed and loss is 0.0006160283810459077

 step 73 is completed and loss is 0.00011377842747606337

 step 74 is completed and loss is 0.00010579234367469326

 step 75 is completed and loss is 0.00021300383377820253

 step 76 is completed and loss is 0.00013791563105769455

 step 77 is completed and loss is 9.130943362833932e-05

 step 78 is completed and loss is 0.00020644751202780753

 step 79 is completed and loss is 0.0005796167533844709

 step 80 is completed and loss is 0.00033991847885772586

 step 81 is completed and loss is 0.0001174734061351046

 step 82 is completed and loss is 0.00011532797361724079

 step 83 is completed and loss is 0.0001606795412953943

 step 84 is completed and loss is 0.00012361038534436375

 step 85 is completed and loss is 0.00014983485743869096

 step 86 is completed and loss is 0.00010501786891836673

 step 87 is completed and loss is 0.00016532852896489203

 step 88 is completed and loss is 0.0002515988890081644

 step 89 is completed and loss is 6.198658957146108e-05

 step 90 is completed and loss is 0.000767785357311368

 step 91 is completed and loss is 0.00011455061758169904
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:37,  1.30it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.40it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.40it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.42it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.48it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:28,  1.55it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.58it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.56it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.51it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.52it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.46it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.46it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.50it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.53it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.51it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.48it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.49it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.51it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.52it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.50it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.46it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:19,  1.47it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.47it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.46it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.47it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.48it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.50it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.53it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:12,  1.54it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.50it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.49it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.50it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.50it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.52it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.53it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.53it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.52it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.49it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.55it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.55it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.59it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.60it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.57it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.58it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.62it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.60it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.56it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 24: train_perplexity=1.0003, train_epoch_loss=0.0003, epcoh time 305.6695980080003s
Training Epoch24:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch24:   1%|[34m          [0m| 1/92 [00:03<05:04,  3.35s/it]Training Epoch24:   2%|[34mâ–         [0m| 2/92 [00:06<04:54,  3.27s/it]Training Epoch24:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:45,  3.21s/it]Training Epoch24:   4%|[34mâ–         [0m| 4/92 [00:12<04:41,  3.20s/it]Training Epoch24:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:39,  3.22s/it]Training Epoch24:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:39,  3.25s/it]Training Epoch24:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:35,  3.24s/it]Training Epoch24:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch24:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:36,  3.33s/it]Training Epoch24:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:34,  3.34s/it]Training Epoch24:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:30,  3.34s/it]Training Epoch24:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:26,  3.33s/it]Training Epoch24:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:22,  3.32s/it]Training Epoch24:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.34s/it]Training Epoch24:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:17,  3.35s/it]Training Epoch24:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:12,  3.32s/it]Training Epoch24:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.29s/it]Training Epoch24:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:06,  3.33s/it]Training Epoch24:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:04,  3.35s/it]Training Epoch24:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:02,  3.36s/it]Training Epoch24:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:57,  3.35s/it]Training Epoch24:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:53,  3.34s/it]Training Epoch24:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:50,  3.34s/it]Training Epoch24:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:46,  3.33s/it]Training Epoch24:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.34s/it]Training Epoch24:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:39,  3.33s/it]Training Epoch24:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:35,  3.31s/it]Training Epoch24:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.31s/it]Training Epoch24:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:28,  3.31s/it]Training Epoch24:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:24,  3.31s/it]Training Epoch24:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.31s/it]Training Epoch24:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:18,  3.31s/it]Training Epoch24:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:14,  3.30s/it]Training Epoch24:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.31s/it]Training Epoch24:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.31s/it]Training Epoch24:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:05,  3.31s/it]Training Epoch24:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:01,  3.31s/it]Training Epoch24:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:59,  3.32s/it]Training Epoch24:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:55,  3.32s/it]Training Epoch24:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.29s/it]Training Epoch24:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:48,  3.31s/it]Training Epoch24:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.30s/it]Training Epoch24:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:40,  3.29s/it]Training Epoch24:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:37,  3.28s/it]Training Epoch24:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:33,  3.27s/it]Training Epoch24:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:31,  3.29s/it]Training Epoch24:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:27,  3.28s/it]Training Epoch24:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:24,  3.28s/it]Training Epoch24:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:20,  3.27s/it]Training Epoch24:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:16,  3.25s/it]Training Epoch24:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:14,  3.27s/it]Training Epoch24:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.29s/it]Training Epoch24:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:07,  3.26s/it]Training Epoch24:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:04,  3.29s/it]Training Epoch24:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.29s/it]Training Epoch24:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.31s/it]Training Epoch24:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:57,  3.35s/it]Training Epoch24:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:53,  3.35s/it]Training Epoch24:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:51,  3.36s/it]Training Epoch24:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:47,  3.35s/it]Training Epoch24:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:44,  3.37s/it]Training Epoch24:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:41,  3.38s/it]Training Epoch24:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:37,  3.37s/it]Training Epoch24:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:34,  3.37s/it]Training Epoch24:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:30,  3.34s/it]Training Epoch24:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.32s/it]Training Epoch24:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:23,  3.33s/it]Training Epoch24:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:20,  3.35s/it]Training Epoch24:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.34s/it]Training Epoch24:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:13,  3.34s/it]Training Epoch24:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:10,  3.35s/it]Training Epoch24:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.35s/it]Training Epoch24:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:03,  3.34s/it]Training Epoch24:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.33s/it]Training Epoch24:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.33s/it]Training Epoch24:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:53,  3.33s/it]Training Epoch24:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:50,  3.34s/it]Training Epoch24:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.34s/it]Training Epoch24:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:42,  3.30s/it]Training Epoch24:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.28s/it]Training Epoch24:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.29s/it]Training Epoch24:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:32,  3.28s/it]Training Epoch24:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:29,  3.30s/it]Training Epoch24:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.32s/it]Training Epoch24:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.33s/it]Training Epoch24:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:19,  3.31s/it]Training Epoch24:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.30s/it]Training Epoch24:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.30s/it]Training Epoch24:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.31s/it]Training Epoch24:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.32s/it]Training Epoch24:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.29s/it]Training Epoch24: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch24: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.0001163967463071458

 step 1 is completed and loss is 0.00019905727822333574

 step 2 is completed and loss is 4.523889219854027e-05

 step 3 is completed and loss is 0.00010549151193117723

 step 4 is completed and loss is 8.260655886260793e-05

 step 5 is completed and loss is 5.560928912018426e-05

 step 6 is completed and loss is 0.00036538398126140237

 step 7 is completed and loss is 5.894686182728037e-05

 step 8 is completed and loss is 0.0001103216563933529

 step 9 is completed and loss is 4.9828180635813624e-05

 step 10 is completed and loss is 0.0008877032669261098

 step 11 is completed and loss is 0.002472309395670891

 step 12 is completed and loss is 0.0002898446982726455

 step 13 is completed and loss is 7.194021600298584e-05

 step 14 is completed and loss is 4.529844591161236e-05

 step 15 is completed and loss is 4.207999518257566e-05

 step 16 is completed and loss is 0.00018975394777953625

 step 17 is completed and loss is 0.00013219057291280478

 step 18 is completed and loss is 6.967538502067327e-05

 step 19 is completed and loss is 0.0003350563929416239

 step 20 is completed and loss is 5.334473098628223e-05

 step 21 is completed and loss is 6.192723958520219e-05

 step 22 is completed and loss is 0.0005180285079404712

 step 23 is completed and loss is 0.00010364676563767716

 step 24 is completed and loss is 6.830450729466975e-05

 step 25 is completed and loss is 0.0002971186477225274

 step 26 is completed and loss is 8.50510477903299e-05

 step 27 is completed and loss is 0.00023236623383127153

 step 28 is completed and loss is 0.00015102022734936327

 step 29 is completed and loss is 9.697179484646767e-05

 step 30 is completed and loss is 0.00013624549319501966

 step 31 is completed and loss is 1.9132867237203754e-05

 step 32 is completed and loss is 0.00011884127161465585

 step 33 is completed and loss is 9.828304609982297e-05

 step 34 is completed and loss is 0.0001452445867471397

 step 35 is completed and loss is 0.00021389650646597147

 step 36 is completed and loss is 1.7940816178452224e-05

 step 37 is completed and loss is 5.757639155490324e-05

 step 38 is completed and loss is 9.750764002092183e-05

 step 39 is completed and loss is 6.252327875699848e-05

 step 40 is completed and loss is 0.0001275452523259446

 step 41 is completed and loss is 7.009130058577284e-05

 step 42 is completed and loss is 7.86748860264197e-05

 step 43 is completed and loss is 7.30722167645581e-05

 step 44 is completed and loss is 3.123213900835253e-05

 step 45 is completed and loss is 0.0003195946919731796

 step 46 is completed and loss is 2.5927591195795685e-05

 step 47 is completed and loss is 7.998611545190215e-05

 step 48 is completed and loss is 0.0007004702929407358

 step 49 is completed and loss is 7.527779962401837e-05

 step 50 is completed and loss is 0.00011032201291527599

 step 51 is completed and loss is 7.82578281359747e-05

 step 52 is completed and loss is 0.0022270549088716507

 step 53 is completed and loss is 0.00032990879844874144

 step 54 is completed and loss is 4.3033523979829624e-05

 step 55 is completed and loss is 0.0016790865920484066

 step 56 is completed and loss is 6.454971298808232e-05

 step 57 is completed and loss is 0.000144525634823367

 step 58 is completed and loss is 6.752877379767597e-05

 step 59 is completed and loss is 0.0003388223412912339

 step 60 is completed and loss is 0.00011318213364575058

 step 61 is completed and loss is 6.52639937470667e-05

 step 62 is completed and loss is 0.00010662504791980609

 step 63 is completed and loss is 0.0004799557791557163

 step 64 is completed and loss is 0.00035601796116679907

 step 65 is completed and loss is 9.959383169189095e-05

 step 66 is completed and loss is 0.001021269941702485

 step 67 is completed and loss is 7.867351814638823e-05

 step 68 is completed and loss is 0.0002115741081070155

 step 69 is completed and loss is 0.0002696068841032684

 step 70 is completed and loss is 0.00022831070236861706

 step 71 is completed and loss is 0.0002581003063824028

 step 72 is completed and loss is 0.0006414433009922504

 step 73 is completed and loss is 9.524368215352297e-05

 step 74 is completed and loss is 0.00011949988402193412

 step 75 is completed and loss is 0.00033825746504589915

 step 76 is completed and loss is 0.00013940549979452044

 step 77 is completed and loss is 7.13441040716134e-05

 step 78 is completed and loss is 0.00019029740360565484

 step 79 is completed and loss is 0.0008964642183855176

 step 80 is completed and loss is 0.00040105366497300565

 step 81 is completed and loss is 0.00010084590030601248

 step 82 is completed and loss is 0.00019756355322897434

 step 83 is completed and loss is 0.00017361145000904799

 step 84 is completed and loss is 0.00011872319009853527

 step 85 is completed and loss is 0.00014852374442853034

 step 86 is completed and loss is 0.0001225396408699453

 step 87 is completed and loss is 0.00012718774087261409

 step 88 is completed and loss is 0.0002572039084043354

 step 89 is completed and loss is 7.801904575899243e-05

 step 90 is completed and loss is 0.0005775273311883211

 step 91 is completed and loss is 0.00018850051856134087
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.34it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.47it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:30,  1.52it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.53it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.57it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:29,  1.52it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.55it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.53it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:27,  1.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.50it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.47it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.46it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.43it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.46it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:22,  1.52it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:20,  1.60it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:19,  1.61it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.62it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.58it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.59it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.61it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.57it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.53it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.52it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.57it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.60it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.56it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.58it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.59it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.57it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.54it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.59it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.62it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:07,  1.64it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.61it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.61it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.56it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.50it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.48it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.50it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.51it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.50it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.51it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.51it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.51it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.51it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 25: train_perplexity=1.0003, train_epoch_loss=0.0003, epcoh time 305.1805412599988s
Training Epoch25:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch25:   1%|[34m          [0m| 1/92 [00:03<04:57,  3.26s/it]Training Epoch25:   2%|[34mâ–         [0m| 2/92 [00:06<04:52,  3.25s/it]Training Epoch25:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:50,  3.26s/it]Training Epoch25:   4%|[34mâ–         [0m| 4/92 [00:12<04:45,  3.24s/it]Training Epoch25:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:43,  3.25s/it]Training Epoch25:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:38,  3.24s/it]Training Epoch25:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.26s/it]Training Epoch25:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:34,  3.27s/it]Training Epoch25:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.29s/it]Training Epoch25:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:31,  3.31s/it]Training Epoch25:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.29s/it]Training Epoch25:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.28s/it]Training Epoch25:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.29s/it]Training Epoch25:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.30s/it]Training Epoch25:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.30s/it]Training Epoch25:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:08,  3.27s/it]Training Epoch25:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:05,  3.27s/it]Training Epoch25:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:02,  3.27s/it]Training Epoch25:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.28s/it]Training Epoch25:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.29s/it]Training Epoch25:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:53,  3.29s/it]Training Epoch25:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch25:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:46,  3.28s/it]Training Epoch25:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:44,  3.30s/it]Training Epoch25:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.29s/it]Training Epoch25:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:37,  3.29s/it]Training Epoch25:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:33,  3.28s/it]Training Epoch25:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:29,  3.28s/it]Training Epoch25:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:26,  3.28s/it]Training Epoch25:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:21,  3.25s/it]Training Epoch25:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:17,  3.24s/it]Training Epoch25:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:14,  3.23s/it]Training Epoch25:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:11,  3.25s/it]Training Epoch25:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:08,  3.25s/it]Training Epoch25:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:06,  3.27s/it]Training Epoch25:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:02,  3.26s/it]Training Epoch25:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:59,  3.27s/it]Training Epoch25:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:57,  3.29s/it]Training Epoch25:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:53,  3.28s/it]Training Epoch25:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:10<02:48,  3.25s/it]Training Epoch25:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:46,  3.27s/it]Training Epoch25:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:44,  3.29s/it]Training Epoch25:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:41,  3.30s/it]Training Epoch25:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:39,  3.33s/it]Training Epoch25:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:35,  3.31s/it]Training Epoch25:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:32,  3.31s/it]Training Epoch25:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:29,  3.32s/it]Training Epoch25:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:25,  3.30s/it]Training Epoch25:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:21,  3.29s/it]Training Epoch25:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:17,  3.28s/it]Training Epoch25:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:14,  3.28s/it]Training Epoch25:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:11,  3.28s/it]Training Epoch25:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:07,  3.27s/it]Training Epoch25:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:04,  3.28s/it]Training Epoch25:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:01,  3.29s/it]Training Epoch25:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:58,  3.29s/it]Training Epoch25:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:54,  3.28s/it]Training Epoch25:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:50,  3.26s/it]Training Epoch25:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:47,  3.27s/it]Training Epoch25:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:44,  3.25s/it]Training Epoch25:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:41,  3.28s/it]Training Epoch25:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:38,  3.27s/it]Training Epoch25:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:34,  3.27s/it]Training Epoch25:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:31,  3.26s/it]Training Epoch25:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:32<01:27,  3.25s/it]Training Epoch25:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.28s/it]Training Epoch25:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:21,  3.27s/it]Training Epoch25:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:19,  3.31s/it]Training Epoch25:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:15,  3.29s/it]Training Epoch25:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:12,  3.29s/it]Training Epoch25:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:09,  3.30s/it]Training Epoch25:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:05,  3.28s/it]Training Epoch25:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.30s/it]Training Epoch25:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:59,  3.33s/it]Training Epoch25:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:56,  3.31s/it]Training Epoch25:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:53,  3.32s/it]Training Epoch25:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.31s/it]Training Epoch25:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:46,  3.30s/it]Training Epoch25:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.31s/it]Training Epoch25:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.31s/it]Training Epoch25:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.32s/it]Training Epoch25:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:33,  3.32s/it]Training Epoch25:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:30,  3.34s/it]Training Epoch25:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.36s/it]Training Epoch25:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.35s/it]Training Epoch25:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.33s/it]Training Epoch25:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.33s/it]Training Epoch25:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.31s/it]Training Epoch25:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.31s/it]Training Epoch25:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.30s/it]Training Epoch25:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.29s/it]Training Epoch25: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.27s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch25: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 0.00011979375994997099

 step 1 is completed and loss is 0.00030106244958005846

 step 2 is completed and loss is 4.95302228955552e-05

 step 3 is completed and loss is 8.18318294477649e-05

 step 4 is completed and loss is 7.646790618309751e-05

 step 5 is completed and loss is 5.82914799451828e-05

 step 6 is completed and loss is 0.0005941760609857738

 step 7 is completed and loss is 5.5549800890730694e-05

 step 8 is completed and loss is 0.000145661091664806

 step 9 is completed and loss is 3.4033615520456806e-05

 step 10 is completed and loss is 0.0019961686339229345

 step 11 is completed and loss is 0.002541980938985944

 step 12 is completed and loss is 0.0002922897692769766

 step 13 is completed and loss is 6.282130925683305e-05

 step 14 is completed and loss is 5.173540921532549e-05

 step 15 is completed and loss is 5.757642793469131e-05

 step 16 is completed and loss is 0.000161153293447569

 step 17 is completed and loss is 0.00011067889863625169

 step 18 is completed and loss is 7.164168346207589e-05

 step 19 is completed and loss is 0.00016162724932655692

 step 20 is completed and loss is 7.64099313528277e-05

 step 21 is completed and loss is 7.015212759142742e-05

 step 22 is completed and loss is 0.0006032441160641611

 step 23 is completed and loss is 0.00012152601993875578

 step 24 is completed and loss is 7.062871009111404e-05

 step 25 is completed and loss is 0.00019071032875217497

 step 26 is completed and loss is 6.431117799365893e-05

 step 27 is completed and loss is 0.0002546551404520869

 step 28 is completed and loss is 0.0002774522581603378

 step 29 is completed and loss is 0.00011193119280505925

 step 30 is completed and loss is 0.00012402830179780722

 step 31 is completed and loss is 1.788120061974041e-05

 step 32 is completed and loss is 8.445532148471102e-05

 step 33 is completed and loss is 9.4587478088215e-05

 step 34 is completed and loss is 8.874681952875108e-05

 step 35 is completed and loss is 0.00023742776829749346

 step 36 is completed and loss is 1.615270593902096e-05

 step 37 is completed and loss is 6.270209996728227e-05

 step 38 is completed and loss is 8.987961336970329e-05

 step 39 is completed and loss is 5.566905019804835e-05

 step 40 is completed and loss is 0.00013231326011009514

 step 41 is completed and loss is 5.590676300926134e-05

 step 42 is completed and loss is 7.682743307668716e-05

 step 43 is completed and loss is 8.517024980392307e-05

 step 44 is completed and loss is 2.6940804673358798e-05

 step 45 is completed and loss is 0.00030636301380582154

 step 46 is completed and loss is 1.7881211533676833e-05

 step 47 is completed and loss is 7.99266344984062e-05

 step 48 is completed and loss is 0.0005470621981658041

 step 49 is completed and loss is 8.654217526782304e-05

 step 50 is completed and loss is 0.00011246752546867356

 step 51 is completed and loss is 7.122494571376592e-05

 step 52 is completed and loss is 0.0015929285436868668

 step 53 is completed and loss is 0.0003483736072666943

 step 54 is completed and loss is 4.500025897868909e-05

 step 55 is completed and loss is 0.0012973739067092538

 step 56 is completed and loss is 4.2020292312372476e-05

 step 57 is completed and loss is 0.00020697501895483583

 step 58 is completed and loss is 7.319090218516067e-05

 step 59 is completed and loss is 0.0003288756124675274

 step 60 is completed and loss is 0.00010197832307312638

 step 61 is completed and loss is 7.801804167684168e-05

 step 62 is completed and loss is 9.053305984707549e-05

 step 63 is completed and loss is 0.00023266920470632613

 step 64 is completed and loss is 0.0002884090645238757

 step 65 is completed and loss is 9.232313459506258e-05

 step 66 is completed and loss is 0.0004087542474735528

 step 67 is completed and loss is 7.682615250814706e-05

 step 68 is completed and loss is 0.00022194231860339642

 step 69 is completed and loss is 0.00018254932365380228

 step 70 is completed and loss is 0.00019571595476008952

 step 71 is completed and loss is 0.0001900556671898812

 step 72 is completed and loss is 0.0006029934738762677

 step 73 is completed and loss is 8.916454680729657e-05

 step 74 is completed and loss is 0.00011556586832739413

 step 75 is completed and loss is 0.0002150298241758719

 step 76 is completed and loss is 0.00014757004100829363

 step 77 is completed and loss is 7.968791760504246e-05

 step 78 is completed and loss is 0.00020418257918208838

 step 79 is completed and loss is 0.001114988699555397

 step 80 is completed and loss is 0.0003667977871373296

 step 81 is completed and loss is 0.00010156109783565626

 step 82 is completed and loss is 0.00015215727034956217

 step 83 is completed and loss is 0.0001820748730096966

 step 84 is completed and loss is 0.00013868644600734115

 step 85 is completed and loss is 0.00014959646796341985

 step 86 is completed and loss is 0.00010871296399272978

 step 87 is completed and loss is 0.00017456380010116845

 step 88 is completed and loss is 0.00022532478033099324

 step 89 is completed and loss is 8.028392039705068e-05

 step 90 is completed and loss is 0.0009136406006291509

 step 91 is completed and loss is 0.0001627590972930193
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.43it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.47it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.51it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.52it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.55it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.56it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.54it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.56it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.53it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.54it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.56it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.55it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.52it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.55it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:23,  1.50it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.49it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.47it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:22,  1.45it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.50it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.53it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.48it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.48it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.51it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.51it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.52it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.52it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.53it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.58it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.60it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.60it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.57it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.57it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.53it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.57it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.58it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.58it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.59it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.58it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.57it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.55it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.55it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.55it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.51it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.52it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.52it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.55it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.58it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 26: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 302.64255796700127s
Training Epoch26:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch26:   1%|[34m          [0m| 1/92 [00:03<05:02,  3.32s/it]Training Epoch26:   2%|[34mâ–         [0m| 2/92 [00:06<04:55,  3.28s/it]Training Epoch26:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:54,  3.31s/it]Training Epoch26:   4%|[34mâ–         [0m| 4/92 [00:13<04:51,  3.31s/it]Training Epoch26:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:48,  3.31s/it]Training Epoch26:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.31s/it]Training Epoch26:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch26:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.31s/it]Training Epoch26:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:36,  3.33s/it]Training Epoch26:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.34s/it]Training Epoch26:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.32s/it]Training Epoch26:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:26,  3.33s/it]Training Epoch26:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:21,  3.31s/it]Training Epoch26:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.32s/it]Training Epoch26:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch26:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:10,  3.30s/it]Training Epoch26:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.30s/it]Training Epoch26:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.31s/it]Training Epoch26:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:05,  3.37s/it]Training Epoch26:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:02,  3.36s/it]Training Epoch26:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:56,  3.33s/it]Training Epoch26:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.29s/it]Training Epoch26:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:46,  3.29s/it]Training Epoch26:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:44,  3.30s/it]Training Epoch26:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:42,  3.32s/it]Training Epoch26:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:40,  3.34s/it]Training Epoch26:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:37,  3.35s/it]Training Epoch26:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:34,  3.36s/it]Training Epoch26:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:31,  3.35s/it]Training Epoch26:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:27,  3.35s/it]Training Epoch26:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:23,  3.34s/it]Training Epoch26:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:20,  3.35s/it]Training Epoch26:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:15,  3.31s/it]Training Epoch26:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:13,  3.34s/it]Training Epoch26:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:09,  3.33s/it]Training Epoch26:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:07,  3.34s/it]Training Epoch26:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.31s/it]Training Epoch26:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:59,  3.32s/it]Training Epoch26:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:56,  3.32s/it]Training Epoch26:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.29s/it]Training Epoch26:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:48,  3.31s/it]Training Epoch26:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:47,  3.34s/it]Training Epoch26:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:42,  3.32s/it]Training Epoch26:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:39,  3.33s/it]Training Epoch26:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:35,  3.32s/it]Training Epoch26:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:32,  3.32s/it]Training Epoch26:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:30,  3.34s/it]Training Epoch26:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:27,  3.34s/it]Training Epoch26:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:23,  3.33s/it]Training Epoch26:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:19,  3.33s/it]Training Epoch26:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:16,  3.32s/it]Training Epoch26:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:12,  3.32s/it]Training Epoch26:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:09,  3.32s/it]Training Epoch26:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:06,  3.32s/it]Training Epoch26:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:02,  3.32s/it]Training Epoch26:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<01:59,  3.31s/it]Training Epoch26:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:56,  3.32s/it]Training Epoch26:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.32s/it]Training Epoch26:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:49,  3.33s/it]Training Epoch26:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:46,  3.34s/it]Training Epoch26:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:42,  3.32s/it]Training Epoch26:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:39,  3.31s/it]Training Epoch26:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:35,  3.28s/it]Training Epoch26:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:31,  3.28s/it]Training Epoch26:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:28,  3.28s/it]Training Epoch26:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:25,  3.29s/it]Training Epoch26:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:22,  3.32s/it]Training Epoch26:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:20,  3.36s/it]Training Epoch26:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:17,  3.37s/it]Training Epoch26:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:13,  3.36s/it]Training Epoch26:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:10,  3.34s/it]Training Epoch26:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.33s/it]Training Epoch26:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:03,  3.36s/it]Training Epoch26:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:06<01:00,  3.38s/it]Training Epoch26:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:57,  3.37s/it]Training Epoch26:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:53,  3.37s/it]Training Epoch26:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:16<00:50,  3.34s/it]Training Epoch26:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:46,  3.35s/it]Training Epoch26:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:43,  3.35s/it]Training Epoch26:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:26<00:40,  3.35s/it]Training Epoch26:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:29<00:36,  3.36s/it]Training Epoch26:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.35s/it]Training Epoch26:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:36<00:29,  3.32s/it]Training Epoch26:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:26,  3.32s/it]Training Epoch26:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.33s/it]Training Epoch26:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:46<00:19,  3.32s/it]Training Epoch26:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.30s/it]Training Epoch26:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:52<00:13,  3.32s/it]Training Epoch26:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:56<00:10,  3.35s/it]Training Epoch26:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.33s/it]Training Epoch26:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.32s/it]Training Epoch26: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch26: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.33s/it]

 step 0 is completed and loss is 9.381076961290091e-05

 step 1 is completed and loss is 0.0001759354636305943

 step 2 is completed and loss is 3.856344847008586e-05

 step 3 is completed and loss is 9.16654389584437e-05

 step 4 is completed and loss is 8.773170702625066e-05

 step 5 is completed and loss is 6.54433824820444e-05

 step 6 is completed and loss is 0.000864539120811969

 step 7 is completed and loss is 5.966177559457719e-05

 step 8 is completed and loss is 8.564817835576832e-05

 step 9 is completed and loss is 4.303349123802036e-05

 step 10 is completed and loss is 0.0005692955455742776

 step 11 is completed and loss is 0.0009345614816993475

 step 12 is completed and loss is 0.00027930017677135766

 step 13 is completed and loss is 6.472854875028133e-05

 step 14 is completed and loss is 6.0914026107639074e-05

 step 15 is completed and loss is 4.2437604861333966e-05

 step 16 is completed and loss is 0.00019541294022928923

 step 17 is completed and loss is 0.00017587185720913112

 step 18 is completed and loss is 5.161628359928727e-05

 step 19 is completed and loss is 0.00023068502196110785

 step 20 is completed and loss is 6.097366349422373e-05

 step 21 is completed and loss is 5.024544952902943e-05

 step 22 is completed and loss is 0.00046836212277412415

 step 23 is completed and loss is 0.00013797370775137097

 step 24 is completed and loss is 6.514573760796338e-05

 step 25 is completed and loss is 0.0002131722867488861

 step 26 is completed and loss is 6.949638191144913e-05

 step 27 is completed and loss is 0.00017283839406445622

 step 28 is completed and loss is 0.00026678823633119464

 step 29 is completed and loss is 0.00010370658128522336

 step 30 is completed and loss is 0.00014482648111879826

 step 31 is completed and loss is 1.8119613741873764e-05

 step 32 is completed and loss is 0.00011401408119127154

 step 33 is completed and loss is 9.542216139379889e-05

 step 34 is completed and loss is 6.288084841798991e-05

 step 35 is completed and loss is 0.00017867653514258564

 step 36 is completed and loss is 1.722558226902038e-05

 step 37 is completed and loss is 8.153580711223185e-05

 step 38 is completed and loss is 0.00010984466644003987

 step 39 is completed and loss is 6.800651317462325e-05

 step 40 is completed and loss is 0.00012814166257157922

 step 41 is completed and loss is 4.9112390115624294e-05

 step 42 is completed and loss is 6.377485260600224e-05

 step 43 is completed and loss is 5.7397155615035444e-05

 step 44 is completed and loss is 3.081487011513673e-05

 step 45 is completed and loss is 0.0002306392416357994

 step 46 is completed and loss is 2.3901131498860195e-05

 step 47 is completed and loss is 8.540977432858199e-05

 step 48 is completed and loss is 0.0006238716305233538

 step 49 is completed and loss is 8.487307059112936e-05

 step 50 is completed and loss is 9.959406452253461e-05

 step 51 is completed and loss is 6.681445665890351e-05

 step 52 is completed and loss is 0.0020511711481958628

 step 53 is completed and loss is 0.0002532842627260834

 step 54 is completed and loss is 4.440432894625701e-05

 step 55 is completed and loss is 0.0014823864912614226

 step 56 is completed and loss is 4.714613169198856e-05

 step 57 is completed and loss is 0.00020619886345230043

 step 58 is completed and loss is 6.854192906757817e-05

 step 59 is completed and loss is 0.00021019423729740083

 step 60 is completed and loss is 0.0001091301382984966

 step 61 is completed and loss is 6.335663783829659e-05

 step 62 is completed and loss is 9.8162199719809e-05

 step 63 is completed and loss is 0.0003673100145533681

 step 64 is completed and loss is 0.00045160946319811046

 step 65 is completed and loss is 9.649485582485795e-05

 step 66 is completed and loss is 0.0007983122486621141

 step 67 is completed and loss is 5.030469401390292e-05

 step 68 is completed and loss is 0.0002847501018550247

 step 69 is completed and loss is 0.00017289791139774024

 step 70 is completed and loss is 0.00018225083476863801

 step 71 is completed and loss is 0.0001619283139007166

 step 72 is completed and loss is 0.0005082640564069152

 step 73 is completed and loss is 0.0001030509447446093

 step 74 is completed and loss is 0.00010203776764683425

 step 75 is completed and loss is 0.0002724147052504122

 step 76 is completed and loss is 0.0001389287644997239

 step 77 is completed and loss is 8.368112321477383e-05

 step 78 is completed and loss is 0.00020900655363220721

 step 79 is completed and loss is 0.0008619079017080367

 step 80 is completed and loss is 0.0002508422185201198

 step 81 is completed and loss is 9.399185364600271e-05

 step 82 is completed and loss is 0.00025839870795607567

 step 83 is completed and loss is 0.00014333757280837744

 step 84 is completed and loss is 0.00016919597692321986

 step 85 is completed and loss is 0.00016878610767889768

 step 86 is completed and loss is 9.822363062994555e-05

 step 87 is completed and loss is 0.0001830851542763412

 step 88 is completed and loss is 0.00020774673612322658

 step 89 is completed and loss is 6.37748817098327e-05

 step 90 is completed and loss is 0.0005379320937208831

 step 91 is completed and loss is 0.00021549046505242586
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.44it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.45it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.54it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.54it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.54it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.52it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.49it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.49it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:27,  1.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.50it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.50it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.46it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.47it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.46it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.45it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.51it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.53it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.48it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:21,  1.45it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.45it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.47it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.48it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.48it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.45it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:17,  1.46it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.48it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.58it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:12,  1.60it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:11,  1.65it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.61it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.57it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.59it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.56it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.60it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.62it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.60it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.63it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.67it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.68it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:04,  1.62it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.64it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.58it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.57it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.57it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.55it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.50it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.54it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 27: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 306.34602307500063s
Training Epoch27:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch27:   1%|[34m          [0m| 1/92 [00:03<05:01,  3.32s/it]Training Epoch27:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.31s/it]Training Epoch27:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:52,  3.29s/it]Training Epoch27:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.27s/it]Training Epoch27:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.27s/it]Training Epoch27:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.27s/it]Training Epoch27:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.26s/it]Training Epoch27:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.28s/it]Training Epoch27:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.31s/it]Training Epoch27:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:29,  3.29s/it]Training Epoch27:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.29s/it]Training Epoch27:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:20,  3.26s/it]Training Epoch27:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:16,  3.25s/it]Training Epoch27:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:13,  3.25s/it]Training Epoch27:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:11,  3.26s/it]Training Epoch27:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:07,  3.26s/it]Training Epoch27:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:04,  3.25s/it]Training Epoch27:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:00,  3.25s/it]Training Epoch27:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:57,  3.26s/it]Training Epoch27:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:54,  3.25s/it]Training Epoch27:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:50,  3.25s/it]Training Epoch27:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:50,  3.30s/it]Training Epoch27:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.30s/it]Training Epoch27:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:46,  3.32s/it]Training Epoch27:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.33s/it]Training Epoch27:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:38,  3.32s/it]Training Epoch27:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.31s/it]Training Epoch27:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:30,  3.29s/it]Training Epoch27:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:27,  3.30s/it]Training Epoch27:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:25,  3.31s/it]Training Epoch27:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:19,  3.27s/it]Training Epoch27:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:16,  3.27s/it]Training Epoch27:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:13,  3.28s/it]Training Epoch27:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:09,  3.26s/it]Training Epoch27:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:05,  3.26s/it]Training Epoch27:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:03,  3.27s/it]Training Epoch27:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:00,  3.29s/it]Training Epoch27:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:57,  3.29s/it]Training Epoch27:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:53,  3.27s/it]Training Epoch27:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:49,  3.26s/it]Training Epoch27:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:45,  3.24s/it]Training Epoch27:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:42,  3.26s/it]Training Epoch27:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:40,  3.28s/it]Training Epoch27:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:37,  3.28s/it]Training Epoch27:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.27s/it]Training Epoch27:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:30,  3.28s/it]Training Epoch27:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.29s/it]Training Epoch27:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:24,  3.30s/it]Training Epoch27:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:22,  3.31s/it]Training Epoch27:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:19,  3.31s/it]Training Epoch27:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:15,  3.31s/it]Training Epoch27:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:12,  3.31s/it]Training Epoch27:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:09,  3.32s/it]Training Epoch27:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:05,  3.31s/it]Training Epoch27:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:01,  3.30s/it]Training Epoch27:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:58,  3.30s/it]Training Epoch27:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:56,  3.31s/it]Training Epoch27:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:52,  3.31s/it]Training Epoch27:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:49,  3.31s/it]Training Epoch27:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:46,  3.33s/it]Training Epoch27:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:42,  3.32s/it]Training Epoch27:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:39,  3.30s/it]Training Epoch27:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:35,  3.30s/it]Training Epoch27:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:32,  3.32s/it]Training Epoch27:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:28,  3.29s/it]Training Epoch27:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.28s/it]Training Epoch27:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.30s/it]Training Epoch27:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:19,  3.30s/it]Training Epoch27:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:14,  3.25s/it]Training Epoch27:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:10,  3.22s/it]Training Epoch27:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:07,  3.22s/it]Training Epoch27:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:04,  3.22s/it]Training Epoch27:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:01,  3.22s/it]Training Epoch27:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:58,  3.24s/it]Training Epoch27:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:55,  3.26s/it]Training Epoch27:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:52,  3.26s/it]Training Epoch27:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:48,  3.26s/it]Training Epoch27:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:45,  3.27s/it]Training Epoch27:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.26s/it]Training Epoch27:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.26s/it]Training Epoch27:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.28s/it]Training Epoch27:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:28<00:32,  3.26s/it]Training Epoch27:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.26s/it]Training Epoch27:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.27s/it]Training Epoch27:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:38<00:22,  3.27s/it]Training Epoch27:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:41<00:19,  3.26s/it]Training Epoch27:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.25s/it]Training Epoch27:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:48<00:12,  3.23s/it]Training Epoch27:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:51<00:09,  3.24s/it]Training Epoch27:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:54<00:06,  3.25s/it]Training Epoch27:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:58<00:03,  3.27s/it]Training Epoch27: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.25s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch27: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.28s/it]

 step 0 is completed and loss is 0.00012468012573663145

 step 1 is completed and loss is 0.00024279646459035575

 step 2 is completed and loss is 4.559649096336216e-05

 step 3 is completed and loss is 0.00012330946628935635

 step 4 is completed and loss is 8.314261503983289e-05

 step 5 is completed and loss is 7.122451643226668e-05

 step 6 is completed and loss is 0.0002869924937840551

 step 7 is completed and loss is 7.670719787711278e-05

 step 8 is completed and loss is 7.086740515660495e-05

 step 9 is completed and loss is 4.47024212917313e-05

 step 10 is completed and loss is 0.0006312090554274619

 step 11 is completed and loss is 0.0013235541991889477

 step 12 is completed and loss is 0.00022049648396205157

 step 13 is completed and loss is 7.146337884478271e-05

 step 14 is completed and loss is 4.601372347678989e-05

 step 15 is completed and loss is 4.875540980719961e-05

 step 16 is completed and loss is 0.00015650309796910733

 step 17 is completed and loss is 0.00014268115046434104

 step 18 is completed and loss is 5.5549975513713434e-05

 step 19 is completed and loss is 0.00021263069356791675

 step 20 is completed and loss is 5.662280091200955e-05

 step 21 is completed and loss is 5.930465704295784e-05

 step 22 is completed and loss is 0.0004719424759969115

 step 23 is completed and loss is 0.00010221619595540687

 step 24 is completed and loss is 7.211901538539678e-05

 step 25 is completed and loss is 0.00023539277026429772

 step 26 is completed and loss is 7.563518011011183e-05

 step 27 is completed and loss is 0.00018344422278460115

 step 28 is completed and loss is 0.00017151910287793726

 step 29 is completed and loss is 0.00010030956764239818

 step 30 is completed and loss is 0.00013278971891850233

 step 31 is completed and loss is 1.6748725101933815e-05

 step 32 is completed and loss is 7.885296508902684e-05

 step 33 is completed and loss is 0.0001025139499688521

 step 34 is completed and loss is 8.171438821591437e-05

 step 35 is completed and loss is 0.0002099020202877

 step 36 is completed and loss is 1.6212306945817545e-05

 step 37 is completed and loss is 6.46688713459298e-05

 step 38 is completed and loss is 0.00010090477007906884

 step 39 is completed and loss is 5.668240555678494e-05

 step 40 is completed and loss is 0.00011801023356383666

 step 41 is completed and loss is 3.9755199395585805e-05

 step 42 is completed and loss is 5.626519487123005e-05

 step 43 is completed and loss is 7.027023093542084e-05

 step 44 is completed and loss is 3.540419493219815e-05

 step 45 is completed and loss is 0.00027627864619717

 step 46 is completed and loss is 2.223223782493733e-05

 step 47 is completed and loss is 7.772142998874187e-05

 step 48 is completed and loss is 0.0007941778167150915

 step 49 is completed and loss is 8.475413778796792e-05

 step 50 is completed and loss is 8.916451770346612e-05

 step 51 is completed and loss is 7.593317423015833e-05

 step 52 is completed and loss is 0.0015163638163357973

 step 53 is completed and loss is 0.00034658590448088944

 step 54 is completed and loss is 4.0589849959360436e-05

 step 55 is completed and loss is 0.001263647573068738

 step 56 is completed and loss is 5.608631909126416e-05

 step 57 is completed and loss is 0.00018760899547487497

 step 58 is completed and loss is 7.038955664029345e-05

 step 59 is completed and loss is 0.000494399864692241

 step 60 is completed and loss is 0.00010626926814438775

 step 61 is completed and loss is 9.63136408245191e-05

 step 62 is completed and loss is 8.17130203358829e-05

 step 63 is completed and loss is 0.0006256521446630359

 step 64 is completed and loss is 0.00027881842106580734

 step 65 is completed and loss is 0.00012164524378022179

 step 66 is completed and loss is 0.0007651048363186419

 step 67 is completed and loss is 6.001949077472091e-05

 step 68 is completed and loss is 0.00023505119315814227

 step 69 is completed and loss is 0.00021246366668492556

 step 70 is completed and loss is 0.00021538040891755372

 step 71 is completed and loss is 0.00017974525690078735

 step 72 is completed and loss is 0.0005543433362618089

 step 73 is completed and loss is 9.697203495306894e-05

 step 74 is completed and loss is 0.00011449345765868202

 step 75 is completed and loss is 0.00026651256484910846

 step 76 is completed and loss is 0.00012754580529872328

 step 77 is completed and loss is 8.15353196230717e-05

 step 78 is completed and loss is 0.0002340955543331802

 step 79 is completed and loss is 0.0006097685545682907

 step 80 is completed and loss is 0.00030930020147934556

 step 81 is completed and loss is 0.00013255063095130026

 step 82 is completed and loss is 0.00017861483502201736

 step 83 is completed and loss is 0.00019131052249576896

 step 84 is completed and loss is 0.0001315362605964765

 step 85 is completed and loss is 0.00016437610611319542

 step 86 is completed and loss is 0.000102037942269817

 step 87 is completed and loss is 0.00014006088895257562

 step 88 is completed and loss is 0.00031070230761542916

 step 89 is completed and loss is 7.050963176880032e-05

 step 90 is completed and loss is 0.0008657469297759235

 step 91 is completed and loss is 0.00011109407205367461
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:29,  1.65it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:28,  1.70it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:29,  1.61it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.53it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.50it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:29,  1.49it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.51it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.53it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:27,  1.52it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.54it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.58it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.59it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.60it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.59it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:20,  1.62it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:20,  1.62it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.59it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.59it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:18,  1.62it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.59it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:13<00:17,  1.59it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:16,  1.60it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:16,  1.56it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.53it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.51it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.51it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.50it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:12,  1.51it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.53it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.56it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.58it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.62it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.58it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:24<00:06,  1.57it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.60it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.58it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:05,  1.55it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.59it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.60it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.62it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.62it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:29<00:01,  1.62it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.59it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.57it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.57it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 28: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 301.70993836100024s
Training Epoch28:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch28:   1%|[34m          [0m| 1/92 [00:03<05:02,  3.32s/it]Training Epoch28:   2%|[34mâ–         [0m| 2/92 [00:06<04:56,  3.29s/it]Training Epoch28:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:52,  3.28s/it]Training Epoch28:   4%|[34mâ–         [0m| 4/92 [00:13<04:45,  3.24s/it]Training Epoch28:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:43,  3.26s/it]Training Epoch28:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.29s/it]Training Epoch28:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.31s/it]Training Epoch28:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.31s/it]Training Epoch28:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.30s/it]Training Epoch28:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.28s/it]Training Epoch28:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:24,  3.27s/it]Training Epoch28:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.26s/it]Training Epoch28:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:17,  3.26s/it]Training Epoch28:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:14,  3.26s/it]Training Epoch28:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:10,  3.26s/it]Training Epoch28:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:04,  3.22s/it]Training Epoch28:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:01,  3.22s/it]Training Epoch28:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<03:57,  3.21s/it]Training Epoch28:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:01<03:54,  3.22s/it]Training Epoch28:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:53,  3.24s/it]Training Epoch28:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:50,  3.24s/it]Training Epoch28:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:47,  3.25s/it]Training Epoch28:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:14<03:44,  3.25s/it]Training Epoch28:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:42,  3.28s/it]Training Epoch28:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:39,  3.28s/it]Training Epoch28:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:36,  3.28s/it]Training Epoch28:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:33,  3.28s/it]Training Epoch28:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:30,  3.30s/it]Training Epoch28:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:26,  3.27s/it]Training Epoch28:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:21,  3.26s/it]Training Epoch28:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:18,  3.26s/it]Training Epoch28:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:15,  3.26s/it]Training Epoch28:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:11,  3.25s/it]Training Epoch28:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:08,  3.25s/it]Training Epoch28:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:04,  3.25s/it]Training Epoch28:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:01,  3.25s/it]Training Epoch28:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:00<03:00,  3.28s/it]Training Epoch28:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:58,  3.31s/it]Training Epoch28:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:56,  3.33s/it]Training Epoch28:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:10<02:51,  3.30s/it]Training Epoch28:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:47,  3.28s/it]Training Epoch28:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:44,  3.30s/it]Training Epoch28:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:40,  3.28s/it]Training Epoch28:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:23<02:37,  3.29s/it]Training Epoch28:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.27s/it]Training Epoch28:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:30,  3.26s/it]Training Epoch28:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:27,  3.27s/it]Training Epoch28:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:36<02:23,  3.26s/it]Training Epoch28:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:19,  3.25s/it]Training Epoch28:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:16,  3.24s/it]Training Epoch28:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:46<02:13,  3.25s/it]Training Epoch28:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:49<02:10,  3.25s/it]Training Epoch28:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:07,  3.27s/it]Training Epoch28:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:03,  3.26s/it]Training Epoch28:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:59<02:00,  3.26s/it]Training Epoch28:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:02<01:57,  3.27s/it]Training Epoch28:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:54,  3.27s/it]Training Epoch28:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:09<01:51,  3.27s/it]Training Epoch28:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:12<01:47,  3.27s/it]Training Epoch28:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:15<01:43,  3.24s/it]Training Epoch28:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:40,  3.25s/it]Training Epoch28:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:22<01:37,  3.25s/it]Training Epoch28:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:25<01:34,  3.27s/it]Training Epoch28:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:28<01:31,  3.27s/it]Training Epoch28:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:32<01:27,  3.25s/it]Training Epoch28:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:35<01:24,  3.26s/it]Training Epoch28:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:38<01:21,  3.27s/it]Training Epoch28:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:18,  3.28s/it]Training Epoch28:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:45<01:15,  3.27s/it]Training Epoch28:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:48<01:12,  3.28s/it]Training Epoch28:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:51<01:08,  3.28s/it]Training Epoch28:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:55<01:05,  3.28s/it]Training Epoch28:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:58<01:02,  3.29s/it]Training Epoch28:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:01<00:59,  3.29s/it]Training Epoch28:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:05<00:55,  3.28s/it]Training Epoch28:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:08<00:52,  3.30s/it]Training Epoch28:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:11<00:49,  3.29s/it]Training Epoch28:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:14<00:45,  3.28s/it]Training Epoch28:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:18<00:42,  3.28s/it]Training Epoch28:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:21<00:39,  3.28s/it]Training Epoch28:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:24<00:36,  3.27s/it]Training Epoch28:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:28<00:32,  3.26s/it]Training Epoch28:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:31<00:29,  3.27s/it]Training Epoch28:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:34<00:26,  3.28s/it]Training Epoch28:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:37<00:22,  3.27s/it]Training Epoch28:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:41<00:19,  3.26s/it]Training Epoch28:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:44<00:16,  3.26s/it]Training Epoch28:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:47<00:13,  3.27s/it]Training Epoch28:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:50<00:09,  3.29s/it]Training Epoch28:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:54<00:06,  3.29s/it]Training Epoch28:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:57<00:03,  3.28s/it]Training Epoch28: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:00<00:00,  3.27s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch28: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:00<00:00,  3.27s/it]

 step 0 is completed and loss is 0.0001286721380893141

 step 1 is completed and loss is 0.00018261023797094822

 step 2 is completed and loss is 4.207999154459685e-05

 step 3 is completed and loss is 0.00010650387412169948

 step 4 is completed and loss is 9.51213005464524e-05

 step 5 is completed and loss is 6.437068805098534e-05

 step 6 is completed and loss is 0.0006649655988439918

 step 7 is completed and loss is 5.1318100304342806e-05

 step 8 is completed and loss is 6.884099275339395e-05

 step 9 is completed and loss is 4.815918509848416e-05

 step 10 is completed and loss is 0.0006032269448041916

 step 11 is completed and loss is 0.0014408719725906849

 step 12 is completed and loss is 0.0002753699372988194

 step 13 is completed and loss is 8.123782754410058e-05

 step 14 is completed and loss is 4.8814876208780333e-05

 step 15 is completed and loss is 4.3987260141875595e-05

 step 16 is completed and loss is 0.0003157029568683356

 step 17 is completed and loss is 0.00014881588867865503

 step 18 is completed and loss is 6.16293036728166e-05

 step 19 is completed and loss is 0.00017038632358890027

 step 20 is completed and loss is 5.8291610912419856e-05

 step 21 is completed and loss is 6.162910722196102e-05

 step 22 is completed and loss is 0.00036372465547174215

 step 23 is completed and loss is 0.0001360055321129039

 step 24 is completed and loss is 7.444327638950199e-05

 step 25 is completed and loss is 0.00027668054099194705

 step 26 is completed and loss is 8.225029887398705e-05

 step 27 is completed and loss is 0.0002289146650582552

 step 28 is completed and loss is 0.00013487123942468315

 step 29 is completed and loss is 9.262128878617659e-05

 step 30 is completed and loss is 0.00010239486437058076

 step 31 is completed and loss is 1.5437450201716274e-05

 step 32 is completed and loss is 8.397856436204165e-05

 step 33 is completed and loss is 9.446845797356218e-05

 step 34 is completed and loss is 8.92828538781032e-05

 step 35 is completed and loss is 0.00019756713300012052

 step 36 is completed and loss is 1.8894452296081e-05

 step 37 is completed and loss is 8.636323764221743e-05

 step 38 is completed and loss is 0.00011800962965935469

 step 39 is completed and loss is 6.818523979745805e-05

 step 40 is completed and loss is 0.00012832056381739676

 step 41 is completed and loss is 4.941039878758602e-05

 step 42 is completed and loss is 7.766183989588171e-05

 step 43 is completed and loss is 5.829131987411529e-05

 step 44 is completed and loss is 2.5808352802414447e-05

 step 45 is completed and loss is 0.00021633728465531021

 step 46 is completed and loss is 1.871564563771244e-05

 step 47 is completed and loss is 0.00010042871872428805

 step 48 is completed and loss is 0.0004584997077472508

 step 49 is completed and loss is 8.350260031875223e-05

 step 50 is completed and loss is 8.701879414729774e-05

 step 51 is completed and loss is 6.294049671851099e-05

 step 52 is completed and loss is 0.0013278265250846744

 step 53 is completed and loss is 0.0003089973470196128

 step 54 is completed and loss is 4.4523447286337614e-05

 step 55 is completed and loss is 0.0010021572234109044

 step 56 is completed and loss is 4.36891641584225e-05

 step 57 is completed and loss is 0.00018284098769072443

 step 58 is completed and loss is 6.311845208983868e-05

 step 59 is completed and loss is 0.00021019579435233027

 step 60 is completed and loss is 0.00010328936332371086

 step 61 is completed and loss is 8.707628876436502e-05

 step 62 is completed and loss is 8.290493133245036e-05

 step 63 is completed and loss is 0.0002427940780762583

 step 64 is completed and loss is 0.00021739405929110944

 step 65 is completed and loss is 0.00010370636300649494

 step 66 is completed and loss is 0.0009662003722041845

 step 67 is completed and loss is 6.609866977669299e-05

 step 68 is completed and loss is 0.0002180099836550653

 step 69 is completed and loss is 0.0001383913477184251

 step 70 is completed and loss is 0.00020173541270196438

 step 71 is completed and loss is 0.00017420350923202932

 step 72 is completed and loss is 0.000543154077604413

 step 73 is completed and loss is 9.214447345584631e-05

 step 74 is completed and loss is 0.00014625821495428681

 step 75 is completed and loss is 0.00021884353191126138

 step 76 is completed and loss is 0.0001655671512708068

 step 77 is completed and loss is 6.991349800955504e-05

 step 78 is completed and loss is 0.00024839659454301

 step 79 is completed and loss is 0.0009187881951220334

 step 80 is completed and loss is 0.00033545581391081214

 step 81 is completed and loss is 9.333607158623636e-05

 step 82 is completed and loss is 0.00023367107496596873

 step 83 is completed and loss is 0.0001805249776225537

 step 84 is completed and loss is 0.00012694732868112624

 step 85 is completed and loss is 0.00012933371181134135

 step 86 is completed and loss is 0.00011062010162277147

 step 87 is completed and loss is 0.0001733143872115761

 step 88 is completed and loss is 0.00018552217807155102

 step 89 is completed and loss is 7.247633038787171e-05

 step 90 is completed and loss is 0.0008867555297911167

 step 91 is completed and loss is 0.00010698156984290108
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.47it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.54it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.54it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.52it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.54it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:29,  1.50it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.50it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.51it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.54it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.54it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.50it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.52it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.53it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.50it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.50it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.51it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.52it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.55it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.54it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.50it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.46it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.47it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.49it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.49it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.56it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.56it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.54it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.54it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.58it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.61it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:09,  1.64it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.62it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.59it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.57it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.55it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.54it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.59it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.59it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.59it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.59it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.59it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.57it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.56it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.56it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 29: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 301.049254218s
Training Epoch29:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch29:   1%|[34m          [0m| 1/92 [00:03<04:57,  3.27s/it]Training Epoch29:   2%|[34mâ–         [0m| 2/92 [00:06<04:49,  3.21s/it]Training Epoch29:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:47,  3.23s/it]Training Epoch29:   4%|[34mâ–         [0m| 4/92 [00:12<04:45,  3.24s/it]Training Epoch29:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:43,  3.26s/it]Training Epoch29:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.27s/it]Training Epoch29:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.26s/it]Training Epoch29:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:33,  3.25s/it]Training Epoch29:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:32,  3.28s/it]Training Epoch29:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.28s/it]Training Epoch29:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:24,  3.27s/it]Training Epoch29:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.29s/it]Training Epoch29:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:18,  3.27s/it]Training Epoch29:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:15,  3.28s/it]Training Epoch29:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.29s/it]Training Epoch29:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.28s/it]Training Epoch29:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:05,  3.27s/it]Training Epoch29:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:03,  3.29s/it]Training Epoch29:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:01,  3.30s/it]Training Epoch29:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:58,  3.31s/it]Training Epoch29:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:54,  3.30s/it]Training Epoch29:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.31s/it]Training Epoch29:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:48,  3.31s/it]Training Epoch29:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:47,  3.35s/it]Training Epoch29:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.34s/it]Training Epoch29:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:39,  3.32s/it]Training Epoch29:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.31s/it]Training Epoch29:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:32,  3.31s/it]Training Epoch29:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:30,  3.33s/it]Training Epoch29:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:26,  3.33s/it]Training Epoch29:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:22,  3.32s/it]Training Epoch29:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:18,  3.31s/it]Training Epoch29:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:15,  3.31s/it]Training Epoch29:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:10,  3.28s/it]Training Epoch29:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:06,  3.28s/it]Training Epoch29:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:04,  3.29s/it]Training Epoch29:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:02,  3.32s/it]Training Epoch29:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.31s/it]Training Epoch29:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.30s/it]Training Epoch29:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:51,  3.29s/it]Training Epoch29:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:47,  3.29s/it]Training Epoch29:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:44,  3.29s/it]Training Epoch29:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:41,  3.30s/it]Training Epoch29:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:38,  3.30s/it]Training Epoch29:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:33,  3.27s/it]Training Epoch29:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:29,  3.26s/it]Training Epoch29:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:26,  3.26s/it]Training Epoch29:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:23,  3.26s/it]Training Epoch29:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:20,  3.27s/it]Training Epoch29:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:16,  3.26s/it]Training Epoch29:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:14,  3.27s/it]Training Epoch29:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.30s/it]Training Epoch29:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.30s/it]Training Epoch29:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:04,  3.27s/it]Training Epoch29:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:00,  3.26s/it]Training Epoch29:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:57,  3.26s/it]Training Epoch29:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:54,  3.28s/it]Training Epoch29:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:52,  3.30s/it]Training Epoch29:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:48,  3.30s/it]Training Epoch29:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:44,  3.28s/it]Training Epoch29:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:42,  3.30s/it]Training Epoch29:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:39,  3.30s/it]Training Epoch29:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:35,  3.28s/it]Training Epoch29:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:31,  3.26s/it]Training Epoch29:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:28,  3.27s/it]Training Epoch29:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.28s/it]Training Epoch29:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.29s/it]Training Epoch29:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:19,  3.32s/it]Training Epoch29:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:16,  3.32s/it]Training Epoch29:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.31s/it]Training Epoch29:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:09,  3.32s/it]Training Epoch29:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:06,  3.32s/it]Training Epoch29:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:03,  3.34s/it]Training Epoch29:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:59,  3.33s/it]Training Epoch29:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:56,  3.32s/it]Training Epoch29:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:53,  3.33s/it]Training Epoch29:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:50,  3.34s/it]Training Epoch29:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.35s/it]Training Epoch29:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:43,  3.35s/it]Training Epoch29:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:40,  3.35s/it]Training Epoch29:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:37,  3.38s/it]Training Epoch29:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.37s/it]Training Epoch29:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:30,  3.37s/it]Training Epoch29:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.36s/it]Training Epoch29:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.37s/it]Training Epoch29:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.32s/it]Training Epoch29:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.33s/it]Training Epoch29:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.34s/it]Training Epoch29:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.32s/it]Training Epoch29:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.33s/it]Training Epoch29:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.32s/it]Training Epoch29: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch29: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.00017115907394327223

 step 1 is completed and loss is 0.0002334403106942773

 step 2 is completed and loss is 3.808660403592512e-05

 step 3 is completed and loss is 0.00010596759966574609

 step 4 is completed and loss is 7.956710760481656e-05

 step 5 is completed and loss is 4.6669279981870204e-05

 step 6 is completed and loss is 0.000669786473736167

 step 7 is completed and loss is 5.876805880689062e-05

 step 8 is completed and loss is 7.813857519067824e-05

 step 9 is completed and loss is 4.3808395275846124e-05

 step 10 is completed and loss is 0.0013963283272460103

 step 11 is completed and loss is 0.0009167392854578793

 step 12 is completed and loss is 0.0002452252374496311

 step 13 is completed and loss is 7.903258665464818e-05

 step 14 is completed and loss is 5.60267835680861e-05

 step 15 is completed and loss is 4.589452510117553e-05

 step 16 is completed and loss is 0.00030592764960601926

 step 17 is completed and loss is 0.00011926049774046987

 step 18 is completed and loss is 5.7099554396700114e-05

 step 19 is completed and loss is 0.00018319758237339556

 step 20 is completed and loss is 4.607332084560767e-05

 step 21 is completed and loss is 8.421696111327037e-05

 step 22 is completed and loss is 0.0003912435786332935

 step 23 is completed and loss is 0.00010883210052270442

 step 24 is completed and loss is 6.913888501003385e-05

 step 25 is completed and loss is 0.00027924415189772844

 step 26 is completed and loss is 6.46686676191166e-05

 step 27 is completed and loss is 0.0002064491854980588

 step 28 is completed and loss is 0.00012688629794865847

 step 29 is completed and loss is 9.983278869185597e-05

 step 30 is completed and loss is 0.00013469616533257067

 step 31 is completed and loss is 1.7344767911708914e-05

 step 32 is completed and loss is 6.979388126637787e-05

 step 33 is completed and loss is 9.44686762522906e-05

 step 34 is completed and loss is 6.758929521311074e-05

 step 35 is completed and loss is 0.00019291782518848777

 step 36 is completed and loss is 2.0861398297711276e-05

 step 37 is completed and loss is 9.071378008229658e-05

 step 38 is completed and loss is 9.458744898438454e-05

 step 39 is completed and loss is 6.419207784347236e-05

 step 40 is completed and loss is 0.00010895103332586586

 step 41 is completed and loss is 3.796714008785784e-05

 step 42 is completed and loss is 7.861541234888136e-05

 step 43 is completed and loss is 7.378689770121127e-05

 step 44 is completed and loss is 2.467589183652308e-05

 step 45 is completed and loss is 0.00020507318549789488

 step 46 is completed and loss is 2.902694177464582e-05

 step 47 is completed and loss is 9.875984687823802e-05

 step 48 is completed and loss is 0.0005593321984633803

 step 49 is completed and loss is 7.909209671197459e-05

 step 50 is completed and loss is 9.923636389430612e-05

 step 51 is completed and loss is 6.603971996810287e-05

 step 52 is completed and loss is 0.0019597026985138655

 step 53 is completed and loss is 0.0003982906346209347

 step 54 is completed and loss is 3.34375181409996e-05

 step 55 is completed and loss is 0.0018122526817023754

 step 56 is completed and loss is 3.677538188640028e-05

 step 57 is completed and loss is 0.0004286295152269304

 step 58 is completed and loss is 6.007893171044998e-05

 step 59 is completed and loss is 0.0001149704767158255

 step 60 is completed and loss is 0.00012325476564001292

 step 61 is completed and loss is 0.00011049667955376208

 step 62 is completed and loss is 7.897213799878955e-05

 step 63 is completed and loss is 0.0008167112828232348

 step 64 is completed and loss is 0.00026714144041761756

 step 65 is completed and loss is 8.07608594186604e-05

 step 66 is completed and loss is 0.0007256455719470978

 step 67 is completed and loss is 4.815913416678086e-05

 step 68 is completed and loss is 0.0001596680231159553

 step 69 is completed and loss is 0.00021681106591131538

 step 70 is completed and loss is 0.00018493225798010826

 step 71 is completed and loss is 0.0003244614927098155

 step 72 is completed and loss is 0.0004627588205039501

 step 73 is completed and loss is 9.33365008677356e-05

 step 74 is completed and loss is 0.00011228842049604282

 step 75 is completed and loss is 0.00021687777189072222

 step 76 is completed and loss is 0.00014220627781469375

 step 77 is completed and loss is 7.74230866227299e-05

 step 78 is completed and loss is 0.00021038112754467875

 step 79 is completed and loss is 0.0009056315757334232

 step 80 is completed and loss is 0.00032157322857528925

 step 81 is completed and loss is 8.743607759242877e-05

 step 82 is completed and loss is 0.00020280822354834527

 step 83 is completed and loss is 0.00017390999710187316

 step 84 is completed and loss is 0.0002227619697805494

 step 85 is completed and loss is 0.0001399419124936685

 step 86 is completed and loss is 9.297892393078655e-05

 step 87 is completed and loss is 0.00015460155555047095

 step 88 is completed and loss is 0.00018373600323684514

 step 89 is completed and loss is 8.397907367907465e-05

 step 90 is completed and loss is 0.0007234369404613972

 step 91 is completed and loss is 0.00013248866889625788
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.38it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:35,  1.36it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.47it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.49it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.47it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.46it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.45it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.44it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.50it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.51it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.50it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.48it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.44it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:25,  1.42it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:25,  1.36it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:25,  1.36it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:23,  1.43it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.47it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:20,  1.50it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.52it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:18,  1.58it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.59it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:16,  1.61it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.63it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.60it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.51it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.51it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.54it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.49it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.47it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.44it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.47it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:11,  1.45it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.49it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.46it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:09,  1.44it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.47it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.45it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.52it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.53it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.51it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.43it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.42it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.42it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.40it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.39it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.43it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.44it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.40it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.47it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 30: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.06263935599964s
Training Epoch30:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch30:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.29s/it]Training Epoch30:   2%|[34mâ–         [0m| 2/92 [00:06<04:59,  3.33s/it]Training Epoch30:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:54,  3.31s/it]Training Epoch30:   4%|[34mâ–         [0m| 4/92 [00:13<04:50,  3.30s/it]Training Epoch30:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:48,  3.31s/it]Training Epoch30:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:45,  3.33s/it]Training Epoch30:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:42,  3.33s/it]Training Epoch30:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:43,  3.37s/it]Training Epoch30:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:37,  3.34s/it]Training Epoch30:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:31,  3.31s/it]Training Epoch30:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch30:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch30:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:21,  3.31s/it]Training Epoch30:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.31s/it]Training Epoch30:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.31s/it]Training Epoch30:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.28s/it]Training Epoch30:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.31s/it]Training Epoch30:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:06,  3.33s/it]Training Epoch30:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:04,  3.35s/it]Training Epoch30:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:00,  3.35s/it]Training Epoch30:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:57,  3.35s/it]Training Epoch30:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:55,  3.36s/it]Training Epoch30:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:51,  3.35s/it]Training Epoch30:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:48,  3.36s/it]Training Epoch30:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:43,  3.34s/it]Training Epoch30:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:40,  3.34s/it]Training Epoch30:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:36,  3.34s/it]Training Epoch30:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:33,  3.34s/it]Training Epoch30:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:30,  3.34s/it]Training Epoch30:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.31s/it]Training Epoch30:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:21,  3.30s/it]Training Epoch30:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:17,  3.29s/it]Training Epoch30:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:13,  3.28s/it]Training Epoch30:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.29s/it]Training Epoch30:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:07,  3.28s/it]Training Epoch30:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:04,  3.30s/it]Training Epoch30:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<02:59,  3.27s/it]Training Epoch30:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:55,  3.25s/it]Training Epoch30:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:53,  3.28s/it]Training Epoch30:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:50,  3.27s/it]Training Epoch30:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:46,  3.27s/it]Training Epoch30:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:43,  3.27s/it]Training Epoch30:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:39,  3.26s/it]Training Epoch30:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:37,  3.28s/it]Training Epoch30:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:34,  3.28s/it]Training Epoch30:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:30,  3.28s/it]Training Epoch30:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:27,  3.28s/it]Training Epoch30:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:24,  3.27s/it]Training Epoch30:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:22,  3.31s/it]Training Epoch30:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.29s/it]Training Epoch30:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:14,  3.27s/it]Training Epoch30:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.28s/it]Training Epoch30:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:07,  3.28s/it]Training Epoch30:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:02,  3.24s/it]Training Epoch30:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<01:59,  3.23s/it]Training Epoch30:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:56,  3.23s/it]Training Epoch30:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:53,  3.25s/it]Training Epoch30:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:50,  3.26s/it]Training Epoch30:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:48,  3.28s/it]Training Epoch30:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:44,  3.28s/it]Training Epoch30:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:40,  3.26s/it]Training Epoch30:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.30s/it]Training Epoch30:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:35,  3.30s/it]Training Epoch30:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:33,  3.33s/it]Training Epoch30:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.33s/it]Training Epoch30:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:27,  3.35s/it]Training Epoch30:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.31s/it]Training Epoch30:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:20,  3.33s/it]Training Epoch30:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.34s/it]Training Epoch30:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:13,  3.32s/it]Training Epoch30:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.33s/it]Training Epoch30:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.34s/it]Training Epoch30:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:03,  3.32s/it]Training Epoch30:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.32s/it]Training Epoch30:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.31s/it]Training Epoch30:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.31s/it]Training Epoch30:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.29s/it]Training Epoch30:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:45,  3.28s/it]Training Epoch30:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.29s/it]Training Epoch30:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.29s/it]Training Epoch30:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:35,  3.27s/it]Training Epoch30:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:32,  3.28s/it]Training Epoch30:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.30s/it]Training Epoch30:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.32s/it]Training Epoch30:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.33s/it]Training Epoch30:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.31s/it]Training Epoch30:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.29s/it]Training Epoch30:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.30s/it]Training Epoch30:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.31s/it]Training Epoch30:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.32s/it]Training Epoch30:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.33s/it]Training Epoch30: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.33s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch30: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.00011758909386117011

 step 1 is completed and loss is 0.00024482313892804086

 step 2 is completed and loss is 4.291440563974902e-05

 step 3 is completed and loss is 0.0001066831246134825

 step 4 is completed and loss is 6.717073119943962e-05

 step 5 is completed and loss is 5.042417615186423e-05

 step 6 is completed and loss is 0.0004105918051209301

 step 7 is completed and loss is 5.2390951168490574e-05

 step 8 is completed and loss is 6.508615479106084e-05

 step 9 is completed and loss is 4.494075255934149e-05

 step 10 is completed and loss is 0.000433519744547084

 step 11 is completed and loss is 0.0009580431506037712

 step 12 is completed and loss is 0.0002518373366910964

 step 13 is completed and loss is 6.216570182004943e-05

 step 14 is completed and loss is 4.404679566505365e-05

 step 15 is completed and loss is 5.0424259825376794e-05

 step 16 is completed and loss is 0.00022711082419846207

 step 17 is completed and loss is 0.0001551937748445198

 step 18 is completed and loss is 5.793395030195825e-05

 step 19 is completed and loss is 0.00017336569726467133

 step 20 is completed and loss is 5.465594949782826e-05

 step 21 is completed and loss is 5.7695571740623564e-05

 step 22 is completed and loss is 0.0012533359695225954

 step 23 is completed and loss is 9.405170567333698e-05

 step 24 is completed and loss is 7.211897900560871e-05

 step 25 is completed and loss is 0.0002492197963874787

 step 26 is completed and loss is 7.027108949841931e-05

 step 27 is completed and loss is 0.0002407124702585861

 step 28 is completed and loss is 0.00015495304251089692

 step 29 is completed and loss is 9.405169112142175e-05

 step 30 is completed and loss is 0.00012468376371543854

 step 31 is completed and loss is 1.645071097300388e-05

 step 32 is completed and loss is 9.226193651556969e-05

 step 33 is completed and loss is 8.660154708195478e-05

 step 34 is completed and loss is 9.691179729998112e-05

 step 35 is completed and loss is 0.00015633075963705778

 step 36 is completed and loss is 1.4841439224255737e-05

 step 37 is completed and loss is 5.179505387786776e-05

 step 38 is completed and loss is 0.0001332639076281339

 step 39 is completed and loss is 6.574171857209876e-05

 step 40 is completed and loss is 0.0001261747966054827

 step 41 is completed and loss is 4.4761982280761003e-05

 step 42 is completed and loss is 7.450302655342966e-05

 step 43 is completed and loss is 8.135641837725416e-05

 step 44 is completed and loss is 3.069573358516209e-05

 step 45 is completed and loss is 0.00028295285301283

 step 46 is completed and loss is 2.3126283849705942e-05

 step 47 is completed and loss is 7.039059710223228e-05

 step 48 is completed and loss is 0.0005303422803990543

 step 49 is completed and loss is 7.366861973423511e-05

 step 50 is completed and loss is 8.135700772982091e-05

 step 51 is completed and loss is 7.75426160544157e-05

 step 52 is completed and loss is 0.001335970126092434

 step 53 is completed and loss is 0.00037923900526948273

 step 54 is completed and loss is 3.886134072672576e-05

 step 55 is completed and loss is 0.001806778134778142

 step 56 is completed and loss is 4.738451025332324e-05

 step 57 is completed and loss is 0.00015829065523575991

 step 58 is completed and loss is 6.144949293229729e-05

 step 59 is completed and loss is 0.0003412619116716087

 step 60 is completed and loss is 0.00011628136417130008

 step 61 is completed and loss is 0.00010108086280524731

 step 62 is completed and loss is 0.00010644547000993043

 step 63 is completed and loss is 0.0008578645065426826

 step 64 is completed and loss is 0.0002384278632234782

 step 65 is completed and loss is 0.000126590981381014

 step 66 is completed and loss is 0.0004753460525535047

 step 67 is completed and loss is 4.6371063945116475e-05

 step 68 is completed and loss is 0.00020752145792357624

 step 69 is completed and loss is 0.00014155007374938577

 step 70 is completed and loss is 0.00023027589486446232

 step 71 is completed and loss is 0.00022509197879116982

 step 72 is completed and loss is 0.0004990205052308738

 step 73 is completed and loss is 0.00010710379865486175

 step 74 is completed and loss is 0.00010257332178298384

 step 75 is completed and loss is 0.0002557291882112622

 step 76 is completed and loss is 0.00015603250358253717

 step 77 is completed and loss is 7.515835022786632e-05

 step 78 is completed and loss is 0.00018856936367228627

 step 79 is completed and loss is 0.0006372955394908786

 step 80 is completed and loss is 0.00039878065581433475

 step 81 is completed and loss is 0.00013815166312269866

 step 82 is completed and loss is 0.00014095267397351563

 step 83 is completed and loss is 0.0002275396545883268

 step 84 is completed and loss is 9.804345609154552e-05

 step 85 is completed and loss is 0.00014053787162993103

 step 86 is completed and loss is 0.00011419598013162613

 step 87 is completed and loss is 0.00014220616139937192

 step 88 is completed and loss is 8.725663064979017e-05

 step 89 is completed and loss is 6.234442116692662e-05

 step 90 is completed and loss is 0.0009541782201267779

 step 91 is completed and loss is 0.00013618201774079353
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.41it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.42it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.48it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.56it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.57it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:27,  1.58it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.56it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.56it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.55it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.56it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.61it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.56it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.56it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.56it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.61it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:20,  1.58it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.55it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.55it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.53it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.53it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.55it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.56it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.53it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.52it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.54it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.50it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.50it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.48it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:12,  1.49it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.50it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.52it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.49it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.49it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.50it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.52it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.56it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.57it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.57it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.57it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.55it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.59it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.59it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:02,  1.47it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.49it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.51it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 31: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.2964031629999s
Training Epoch31:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch31:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.29s/it]Training Epoch31:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.30s/it]Training Epoch31:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:53,  3.30s/it]Training Epoch31:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.28s/it]Training Epoch31:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.30s/it]Training Epoch31:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:42,  3.29s/it]Training Epoch31:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.31s/it]Training Epoch31:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.33s/it]Training Epoch31:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:36,  3.33s/it]Training Epoch31:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:30,  3.30s/it]Training Epoch31:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:27,  3.30s/it]Training Epoch31:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch31:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.29s/it]Training Epoch31:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.31s/it]Training Epoch31:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:16,  3.33s/it]Training Epoch31:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.31s/it]Training Epoch31:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.32s/it]Training Epoch31:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:03,  3.29s/it]Training Epoch31:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.33s/it]Training Epoch31:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.32s/it]Training Epoch31:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:53,  3.29s/it]Training Epoch31:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch31:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.29s/it]Training Epoch31:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:44,  3.30s/it]Training Epoch31:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:41,  3.31s/it]Training Epoch31:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.28s/it]Training Epoch31:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:32,  3.27s/it]Training Epoch31:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:29,  3.28s/it]Training Epoch31:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:27,  3.29s/it]Training Epoch31:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:24,  3.30s/it]Training Epoch31:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.31s/it]Training Epoch31:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:17,  3.30s/it]Training Epoch31:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:13,  3.28s/it]Training Epoch31:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.30s/it]Training Epoch31:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.31s/it]Training Epoch31:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:05,  3.32s/it]Training Epoch31:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.31s/it]Training Epoch31:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:57,  3.29s/it]Training Epoch31:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:53,  3.28s/it]Training Epoch31:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:49,  3.27s/it]Training Epoch31:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:46,  3.26s/it]Training Epoch31:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:43,  3.27s/it]Training Epoch31:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:40,  3.27s/it]Training Epoch31:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:36,  3.26s/it]Training Epoch31:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:33,  3.26s/it]Training Epoch31:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:30,  3.27s/it]Training Epoch31:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:26,  3.27s/it]Training Epoch31:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:22,  3.23s/it]Training Epoch31:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:17,  3.20s/it]Training Epoch31:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:15,  3.22s/it]Training Epoch31:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:12,  3.24s/it]Training Epoch31:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:09,  3.23s/it]Training Epoch31:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:06,  3.23s/it]Training Epoch31:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:02,  3.22s/it]Training Epoch31:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<01:59,  3.22s/it]Training Epoch31:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:56,  3.23s/it]Training Epoch31:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:53,  3.24s/it]Training Epoch31:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:50,  3.26s/it]Training Epoch31:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:48,  3.28s/it]Training Epoch31:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:45,  3.28s/it]Training Epoch31:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:41,  3.28s/it]Training Epoch31:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:39,  3.31s/it]Training Epoch31:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:36,  3.31s/it]Training Epoch31:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:32,  3.31s/it]Training Epoch31:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:29,  3.32s/it]Training Epoch31:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:26,  3.32s/it]Training Epoch31:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.31s/it]Training Epoch31:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:18,  3.28s/it]Training Epoch31:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:15,  3.30s/it]Training Epoch31:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:12,  3.30s/it]Training Epoch31:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:09,  3.33s/it]Training Epoch31:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:07,  3.35s/it]Training Epoch31:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:03,  3.34s/it]Training Epoch31:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:59,  3.33s/it]Training Epoch31:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:56,  3.34s/it]Training Epoch31:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:53,  3.35s/it]Training Epoch31:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:50,  3.34s/it]Training Epoch31:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:46,  3.32s/it]Training Epoch31:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.31s/it]Training Epoch31:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:39,  3.31s/it]Training Epoch31:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:36,  3.34s/it]Training Epoch31:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.33s/it]Training Epoch31:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.33s/it]Training Epoch31:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.29s/it]Training Epoch31:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.30s/it]Training Epoch31:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.28s/it]Training Epoch31:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.28s/it]Training Epoch31:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.29s/it]Training Epoch31:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.30s/it]Training Epoch31:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.31s/it]Training Epoch31:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.30s/it]Training Epoch31: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.30s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch31: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 0.0001467877154937014

 step 1 is completed and loss is 0.0002402903774054721

 step 2 is completed and loss is 3.308003215352073e-05

 step 3 is completed and loss is 0.00010352492972742766

 step 4 is completed and loss is 7.986491254996508e-05

 step 5 is completed and loss is 5.113942825119011e-05

 step 6 is completed and loss is 0.0006485962658189237

 step 7 is completed and loss is 5.8470141084399074e-05

 step 8 is completed and loss is 9.172727004624903e-05

 step 9 is completed and loss is 3.552371708792634e-05

 step 10 is completed and loss is 0.0004345269117038697

 step 11 is completed and loss is 0.0008324438822455704

 step 12 is completed and loss is 0.00036382791586220264

 step 13 is completed and loss is 7.664840086363256e-05

 step 14 is completed and loss is 4.1841452912194654e-05

 step 15 is completed and loss is 3.576214658096433e-05

 step 16 is completed and loss is 0.00023175888054538518

 step 17 is completed and loss is 0.0001439914049115032

 step 18 is completed and loss is 6.80661469232291e-05

 step 19 is completed and loss is 0.00022716780949849635

 step 20 is completed and loss is 4.9291818868368864e-05

 step 21 is completed and loss is 6.645685789408162e-05

 step 22 is completed and loss is 0.0005257060402072966

 step 23 is completed and loss is 0.000123491496196948

 step 24 is completed and loss is 6.824491720180959e-05

 step 25 is completed and loss is 0.0003530511457938701

 step 26 is completed and loss is 0.0001005461672320962

 step 27 is completed and loss is 0.00020001197117380798

 step 28 is completed and loss is 0.0001609116734471172

 step 29 is completed and loss is 7.599296804983169e-05

 step 30 is completed and loss is 0.0001312990061705932

 step 31 is completed and loss is 1.8536808056524023e-05

 step 32 is completed and loss is 6.115231371950358e-05

 step 33 is completed and loss is 8.42177469166927e-05

 step 34 is completed and loss is 0.00011395668116165325

 step 35 is completed and loss is 0.0001597258378751576

 step 36 is completed and loss is 1.3589762602350675e-05

 step 37 is completed and loss is 6.627816765103489e-05

 step 38 is completed and loss is 8.463491394650191e-05

 step 39 is completed and loss is 6.598005711566657e-05

 step 40 is completed and loss is 0.0001135998172685504

 step 41 is completed and loss is 7.313040987355635e-05

 step 42 is completed and loss is 7.223813736345619e-05

 step 43 is completed and loss is 6.264210242079571e-05

 step 44 is completed and loss is 2.1993771952111274e-05

 step 45 is completed and loss is 0.0002236071741208434

 step 46 is completed and loss is 2.4795135686872527e-05

 step 47 is completed and loss is 7.939021452330053e-05

 step 48 is completed and loss is 0.0003932802064809948

 step 49 is completed and loss is 8.684015483595431e-05

 step 50 is completed and loss is 8.725738007342443e-05

 step 51 is completed and loss is 5.5371070629917085e-05

 step 52 is completed and loss is 0.0015320224920287728

 step 53 is completed and loss is 0.0002963607257697731

 step 54 is completed and loss is 5.3642525017494336e-05

 step 55 is completed and loss is 0.001229558722116053

 step 56 is completed and loss is 4.559640365187079e-05

 step 57 is completed and loss is 0.0003254119073972106

 step 58 is completed and loss is 5.7098728575510904e-05

 step 59 is completed and loss is 0.0003072501567658037

 step 60 is completed and loss is 9.983235213439912e-05

 step 61 is completed and loss is 0.00010143833787878975

 step 62 is completed and loss is 8.302422793349251e-05

 step 63 is completed and loss is 0.00039692045538686216

 step 64 is completed and loss is 0.00039860582910478115

 step 65 is completed and loss is 0.00011252678086748347

 step 66 is completed and loss is 0.0004968949942849576

 step 67 is completed and loss is 6.139039760455489e-05

 step 68 is completed and loss is 0.0001898227201309055

 step 69 is completed and loss is 0.00017319453763775527

 step 70 is completed and loss is 0.00016711578064132482

 step 71 is completed and loss is 0.00015370534674730152

 step 72 is completed and loss is 0.0009042706806212664

 step 73 is completed and loss is 9.208489791490138e-05

 step 74 is completed and loss is 9.893829701468349e-05

 step 75 is completed and loss is 0.000234575301874429

 step 76 is completed and loss is 0.00012700929073616862

 step 77 is completed and loss is 6.55032490612939e-05

 step 78 is completed and loss is 0.0001763534382916987

 step 79 is completed and loss is 0.0007478630868718028

 step 80 is completed and loss is 0.00027241569478064775

 step 81 is completed and loss is 0.00013344342005439103

 step 82 is completed and loss is 0.00020358318579383194

 step 83 is completed and loss is 0.0001481653016526252

 step 84 is completed and loss is 0.00015841005370020866

 step 85 is completed and loss is 0.00016056202002801

 step 86 is completed and loss is 0.00012134769349358976

 step 87 is completed and loss is 0.00013582910469267517

 step 88 is completed and loss is 0.00028716734959743917

 step 89 is completed and loss is 6.139051401987672e-05

 step 90 is completed and loss is 0.0007528687128797174

 step 91 is completed and loss is 0.0001156824582722038
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.41it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.43it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.45it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.45it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.45it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.43it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.43it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.45it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.49it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.49it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.48it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.48it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.46it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.46it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.47it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.49it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.49it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.50it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.48it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:19,  1.46it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:16,  1.53it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.50it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.47it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.50it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.50it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.49it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:13,  1.45it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.42it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.44it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:11,  1.44it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.44it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.45it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.50it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.49it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.48it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.54it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.51it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.50it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.50it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.53it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.52it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.54it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.52it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.48it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.52it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.48it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 32: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 303.27871732399944s
Training Epoch32:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch32:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.29s/it]Training Epoch32:   2%|[34mâ–         [0m| 2/92 [00:06<04:55,  3.29s/it]Training Epoch32:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:53,  3.29s/it]Training Epoch32:   4%|[34mâ–         [0m| 4/92 [00:13<04:46,  3.26s/it]Training Epoch32:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.27s/it]Training Epoch32:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.28s/it]Training Epoch32:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:38,  3.28s/it]Training Epoch32:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch32:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.30s/it]Training Epoch32:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:29,  3.28s/it]Training Epoch32:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.29s/it]Training Epoch32:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.30s/it]Training Epoch32:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:21,  3.31s/it]Training Epoch32:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.32s/it]Training Epoch32:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.29s/it]Training Epoch32:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.28s/it]Training Epoch32:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:05,  3.28s/it]Training Epoch32:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.30s/it]Training Epoch32:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:01,  3.30s/it]Training Epoch32:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:57,  3.29s/it]Training Epoch32:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.31s/it]Training Epoch32:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:52,  3.32s/it]Training Epoch32:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:49,  3.33s/it]Training Epoch32:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:46,  3.33s/it]Training Epoch32:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.33s/it]Training Epoch32:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:39,  3.32s/it]Training Epoch32:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:36,  3.33s/it]Training Epoch32:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:32,  3.32s/it]Training Epoch32:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:28,  3.31s/it]Training Epoch32:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:23,  3.29s/it]Training Epoch32:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:19,  3.28s/it]Training Epoch32:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:16,  3.27s/it]Training Epoch32:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:13,  3.28s/it]Training Epoch32:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:09,  3.27s/it]Training Epoch32:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:06,  3.27s/it]Training Epoch32:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:03,  3.27s/it]Training Epoch32:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:59,  3.26s/it]Training Epoch32:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:56,  3.27s/it]Training Epoch32:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.29s/it]Training Epoch32:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:52,  3.31s/it]Training Epoch32:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.32s/it]Training Epoch32:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:46,  3.34s/it]Training Epoch32:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:43,  3.34s/it]Training Epoch32:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:39,  3.32s/it]Training Epoch32:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:35,  3.31s/it]Training Epoch32:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:33,  3.33s/it]Training Epoch32:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:30,  3.34s/it]Training Epoch32:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:26,  3.32s/it]Training Epoch32:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:21,  3.30s/it]Training Epoch32:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.31s/it]Training Epoch32:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:14,  3.29s/it]Training Epoch32:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:10,  3.27s/it]Training Epoch32:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:07,  3.28s/it]Training Epoch32:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.31s/it]Training Epoch32:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.30s/it]Training Epoch32:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:59,  3.31s/it]Training Epoch32:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.33s/it]Training Epoch32:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.30s/it]Training Epoch32:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.31s/it]Training Epoch32:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:46,  3.33s/it]Training Epoch32:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:43,  3.33s/it]Training Epoch32:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.31s/it]Training Epoch32:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.33s/it]Training Epoch32:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:33,  3.32s/it]Training Epoch32:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.32s/it]Training Epoch32:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.33s/it]Training Epoch32:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.31s/it]Training Epoch32:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.32s/it]Training Epoch32:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.33s/it]Training Epoch32:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:13,  3.35s/it]Training Epoch32:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:10,  3.34s/it]Training Epoch32:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.28s/it]Training Epoch32:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.29s/it]Training Epoch32:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:58,  3.27s/it]Training Epoch32:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:55,  3.29s/it]Training Epoch32:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.29s/it]Training Epoch32:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.28s/it]Training Epoch32:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.31s/it]Training Epoch32:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.29s/it]Training Epoch32:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:40,  3.37s/it]Training Epoch32:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.35s/it]Training Epoch32:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.36s/it]Training Epoch32:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:30,  3.35s/it]Training Epoch32:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.32s/it]Training Epoch32:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.34s/it]Training Epoch32:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.33s/it]Training Epoch32:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.32s/it]Training Epoch32:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.32s/it]Training Epoch32:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.32s/it]Training Epoch32:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.31s/it]Training Epoch32:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.31s/it]Training Epoch32: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch32: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.00012098536535631865

 step 1 is completed and loss is 0.00018731955788098276

 step 2 is completed and loss is 3.4927674278151244e-05

 step 3 is completed and loss is 9.744619455887005e-05

 step 4 is completed and loss is 8.016284846235067e-05

 step 5 is completed and loss is 5.2689050789922476e-05

 step 6 is completed and loss is 0.0004043439985252917

 step 7 is completed and loss is 5.310605774866417e-05

 step 8 is completed and loss is 8.475414506392553e-05

 step 9 is completed and loss is 4.273540253052488e-05

 step 10 is completed and loss is 0.001162720494903624

 step 11 is completed and loss is 0.0008040968095883727

 step 12 is completed and loss is 0.00032159630791284144

 step 13 is completed and loss is 6.425166066037491e-05

 step 14 is completed and loss is 5.22122900292743e-05

 step 15 is completed and loss is 4.2199197196168825e-05

 step 16 is completed and loss is 0.00024206524540204555

 step 17 is completed and loss is 0.00011979645933024585

 step 18 is completed and loss is 6.091406976338476e-05

 step 19 is completed and loss is 0.000243374117417261

 step 20 is completed and loss is 4.1007100662682205e-05

 step 21 is completed and loss is 7.360892777796835e-05

 step 22 is completed and loss is 0.0002454114437568933

 step 23 is completed and loss is 9.035626135300845e-05

 step 24 is completed and loss is 7.313206879189238e-05

 step 25 is completed and loss is 0.00020095375657547265

 step 26 is completed and loss is 7.843620551284403e-05

 step 27 is completed and loss is 0.0002411905734334141

 step 28 is completed and loss is 0.00020244240295141935

 step 29 is completed and loss is 7.170180469984189e-05

 step 30 is completed and loss is 0.00011973731307080016

 step 31 is completed and loss is 1.7881187886814587e-05

 step 32 is completed and loss is 7.980679220054299e-05

 step 33 is completed and loss is 8.999784768093377e-05

 step 34 is completed and loss is 7.420502515742555e-05

 step 35 is completed and loss is 0.00019983066886197776

 step 36 is completed and loss is 1.5437477486557327e-05

 step 37 is completed and loss is 6.657617632299662e-05

 step 38 is completed and loss is 9.339526877738535e-05

 step 39 is completed and loss is 5.632454849546775e-05

 step 40 is completed and loss is 0.00010907030809903517

 step 41 is completed and loss is 3.826510510407388e-05

 step 42 is completed and loss is 9.303833940066397e-05

 step 43 is completed and loss is 6.699267396470532e-05

 step 44 is completed and loss is 2.3781849449733272e-05

 step 45 is completed and loss is 0.0002862261317204684

 step 46 is completed and loss is 2.4020349883357994e-05

 step 47 is completed and loss is 6.508614751510322e-05

 step 48 is completed and loss is 0.00033502301084809005

 step 49 is completed and loss is 8.135699317790568e-05

 step 50 is completed and loss is 8.898551459424198e-05

 step 51 is completed and loss is 5.8768368035089225e-05

 step 52 is completed and loss is 0.002486541634425521

 step 53 is completed and loss is 0.000314236938720569

 step 54 is completed and loss is 4.631156480172649e-05

 step 55 is completed and loss is 0.0011516286758705974

 step 56 is completed and loss is 3.8444253732450306e-05

 step 57 is completed and loss is 0.00037211005110293627

 step 58 is completed and loss is 6.431017391150817e-05

 step 59 is completed and loss is 0.0006461624288931489

 step 60 is completed and loss is 9.756797226145864e-05

 step 61 is completed and loss is 9.506165952188894e-05

 step 62 is completed and loss is 9.780473192222416e-05

 step 63 is completed and loss is 0.00037600944051519036

 step 64 is completed and loss is 0.0004841859336011112

 step 65 is completed and loss is 9.92959103314206e-05

 step 66 is completed and loss is 0.0005475106881931424

 step 67 is completed and loss is 5.656282519339584e-05

 step 68 is completed and loss is 0.00019125176186207682

 step 69 is completed and loss is 0.0001543630351079628

 step 70 is completed and loss is 0.00019345352484378964

 step 71 is completed and loss is 0.00018641987117007375

 step 72 is completed and loss is 0.0005957201356068254

 step 73 is completed and loss is 9.017768752528355e-05

 step 74 is completed and loss is 0.00010978544014506042

 step 75 is completed and loss is 0.00032240134896710515

 step 76 is completed and loss is 0.00012516180868260562

 step 77 is completed and loss is 7.265498425113037e-05

 step 78 is completed and loss is 0.0001638984540477395

 step 79 is completed and loss is 0.0006297059007920325

 step 80 is completed and loss is 0.0002596626291051507

 step 81 is completed and loss is 9.572011913405731e-05

 step 82 is completed and loss is 0.00016467181558255106

 step 83 is completed and loss is 0.0001718236890155822

 step 84 is completed and loss is 8.856807107804343e-05

 step 85 is completed and loss is 0.00015269544383045286

 step 86 is completed and loss is 0.00010382589971413836

 step 87 is completed and loss is 0.0001370805548503995

 step 88 is completed and loss is 0.00016180876991711557

 step 89 is completed and loss is 6.758904783055186e-05

 step 90 is completed and loss is 0.0008217270951718092

 step 91 is completed and loss is 0.00024462511646561325
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:32,  1.50it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.52it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.56it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:28,  1.64it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:26,  1.68it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:26,  1.67it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:26,  1.61it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.57it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.62it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:23,  1.67it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:06<00:22,  1.71it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:22,  1.70it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:07<00:22,  1.66it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.60it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.55it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:09<00:21,  1.55it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.57it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:19,  1.60it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:11<00:18,  1.63it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:18,  1.62it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.60it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:13<00:17,  1.56it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:18,  1.50it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.47it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:16,  1.53it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.59it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:16<00:14,  1.59it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:13,  1.61it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.61it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:18<00:12,  1.61it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:11,  1.62it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.59it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:20<00:10,  1.58it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.58it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:21<00:09,  1.55it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:22<00:09,  1.53it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.52it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:23<00:07,  1.53it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:24<00:07,  1.56it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:25<00:05,  1.54it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:05,  1.51it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.47it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:27<00:04,  1.48it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.50it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.56it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:29<00:01,  1.57it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.57it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.54it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.52it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.57it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 33: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.5861845159998s
Training Epoch33:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch33:   1%|[34m          [0m| 1/92 [00:03<05:06,  3.37s/it]Training Epoch33:   2%|[34mâ–         [0m| 2/92 [00:06<04:58,  3.31s/it]Training Epoch33:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:52,  3.29s/it]Training Epoch33:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.28s/it]Training Epoch33:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.29s/it]Training Epoch33:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.31s/it]Training Epoch33:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.34s/it]Training Epoch33:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:40,  3.34s/it]Training Epoch33:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:37,  3.34s/it]Training Epoch33:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:34,  3.34s/it]Training Epoch33:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.33s/it]Training Epoch33:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.32s/it]Training Epoch33:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:22,  3.32s/it]Training Epoch33:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.30s/it]Training Epoch33:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:12,  3.28s/it]Training Epoch33:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:06,  3.24s/it]Training Epoch33:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:03,  3.25s/it]Training Epoch33:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:02,  3.27s/it]Training Epoch33:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.28s/it]Training Epoch33:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.28s/it]Training Epoch33:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:52,  3.28s/it]Training Epoch33:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:47,  3.25s/it]Training Epoch33:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:43,  3.24s/it]Training Epoch33:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:41,  3.25s/it]Training Epoch33:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:38,  3.25s/it]Training Epoch33:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.28s/it]Training Epoch33:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.30s/it]Training Epoch33:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:29,  3.28s/it]Training Epoch33:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:26,  3.28s/it]Training Epoch33:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:23,  3.29s/it]Training Epoch33:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:18,  3.26s/it]Training Epoch33:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:16,  3.28s/it]Training Epoch33:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:12,  3.26s/it]Training Epoch33:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:07,  3.24s/it]Training Epoch33:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:03,  3.22s/it]Training Epoch33:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:01,  3.23s/it]Training Epoch33:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:58,  3.24s/it]Training Epoch33:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:54,  3.24s/it]Training Epoch33:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:52,  3.25s/it]Training Epoch33:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:49,  3.26s/it]Training Epoch33:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:46,  3.27s/it]Training Epoch33:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:44,  3.29s/it]Training Epoch33:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:40,  3.28s/it]Training Epoch33:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:37,  3.28s/it]Training Epoch33:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.27s/it]Training Epoch33:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:30,  3.27s/it]Training Epoch33:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:26,  3.26s/it]Training Epoch33:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:23,  3.26s/it]Training Epoch33:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:20,  3.26s/it]Training Epoch33:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:16,  3.24s/it]Training Epoch33:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:46<02:12,  3.24s/it]Training Epoch33:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:10,  3.25s/it]Training Epoch33:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:07,  3.26s/it]Training Epoch33:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:03,  3.26s/it]Training Epoch33:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:59<01:59,  3.24s/it]Training Epoch33:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:57,  3.25s/it]Training Epoch33:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:54,  3.28s/it]Training Epoch33:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:09<01:50,  3.26s/it]Training Epoch33:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:47,  3.27s/it]Training Epoch33:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:44,  3.27s/it]Training Epoch33:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:40,  3.24s/it]Training Epoch33:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:22<01:37,  3.23s/it]Training Epoch33:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:34,  3.24s/it]Training Epoch33:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:30,  3.24s/it]Training Epoch33:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:32<01:27,  3.25s/it]Training Epoch33:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:35<01:24,  3.25s/it]Training Epoch33:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:21,  3.25s/it]Training Epoch33:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:17,  3.24s/it]Training Epoch33:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:45<01:15,  3.27s/it]Training Epoch33:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:48<01:11,  3.27s/it]Training Epoch33:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:08,  3.25s/it]Training Epoch33:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:55<01:04,  3.24s/it]Training Epoch33:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:58<01:01,  3.25s/it]Training Epoch33:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:01<00:58,  3.27s/it]Training Epoch33:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:05<00:55,  3.29s/it]Training Epoch33:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:08<00:52,  3.29s/it]Training Epoch33:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:11<00:49,  3.29s/it]Training Epoch33:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:46,  3.29s/it]Training Epoch33:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:18<00:42,  3.28s/it]Training Epoch33:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:21<00:39,  3.32s/it]Training Epoch33:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.31s/it]Training Epoch33:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:28<00:33,  3.32s/it]Training Epoch33:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:31<00:29,  3.31s/it]Training Epoch33:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.31s/it]Training Epoch33:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:38<00:23,  3.30s/it]Training Epoch33:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:41<00:19,  3.27s/it]Training Epoch33:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:44<00:16,  3.26s/it]Training Epoch33:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:48<00:13,  3.27s/it]Training Epoch33:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:51<00:09,  3.30s/it]Training Epoch33:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:54<00:06,  3.32s/it]Training Epoch33:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:58<00:03,  3.33s/it]Training Epoch33: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.34s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch33: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.28s/it]

 step 0 is completed and loss is 0.00014070951147004962

 step 1 is completed and loss is 0.00020120185217820108

 step 2 is completed and loss is 3.737140286830254e-05

 step 3 is completed and loss is 0.00010966303671011701

 step 4 is completed and loss is 6.81243691360578e-05

 step 5 is completed and loss is 4.750371954287402e-05

 step 6 is completed and loss is 0.00023885173141025007

 step 7 is completed and loss is 4.941082443110645e-05

 step 8 is completed and loss is 7.944948447402567e-05

 step 9 is completed and loss is 4.464259109226987e-05

 step 10 is completed and loss is 0.0011871809838339686

 step 11 is completed and loss is 0.0008670215611346066

 step 12 is completed and loss is 0.0002470721665304154

 step 13 is completed and loss is 5.942405550740659e-05

 step 14 is completed and loss is 4.2079824197571725e-05

 step 15 is completed and loss is 4.207999518257566e-05

 step 16 is completed and loss is 0.0001482808729633689

 step 17 is completed and loss is 0.00011884325795108452

 step 18 is completed and loss is 5.930484621785581e-05

 step 19 is completed and loss is 0.00021215606830082834

 step 20 is completed and loss is 4.3391242797952145e-05

 step 21 is completed and loss is 6.192721775732934e-05

 step 22 is completed and loss is 0.000304443237837404

 step 23 is completed and loss is 0.00010859237227123231

 step 24 is completed and loss is 6.2880790210329e-05

 step 25 is completed and loss is 0.0002492747735232115

 step 26 is completed and loss is 5.441748726298101e-05

 step 27 is completed and loss is 0.0001512651506345719

 step 28 is completed and loss is 0.00016502224025316536

 step 29 is completed and loss is 8.731699199415743e-05

 step 30 is completed and loss is 0.00010448128159623593

 step 31 is completed and loss is 1.5556670405203477e-05

 step 32 is completed and loss is 7.34297136659734e-05

 step 33 is completed and loss is 7.098645437508821e-05

 step 34 is completed and loss is 9.399201371707022e-05

 step 35 is completed and loss is 0.00013815375859849155

 step 36 is completed and loss is 2.2053418433642946e-05

 step 37 is completed and loss is 7.378782902378589e-05

 step 38 is completed and loss is 0.00011687667574733496

 step 39 is completed and loss is 5.7814653700916097e-05

 step 40 is completed and loss is 9.971356485038996e-05

 step 41 is completed and loss is 3.90995446650777e-05

 step 42 is completed and loss is 6.961571489227936e-05

 step 43 is completed and loss is 5.370214057620615e-05

 step 44 is completed and loss is 2.568917625467293e-05

 step 45 is completed and loss is 0.00016407606017310172

 step 46 is completed and loss is 2.2232252376852557e-05

 step 47 is completed and loss is 6.836418469902128e-05

 step 48 is completed and loss is 0.00042800663504749537

 step 49 is completed and loss is 8.70785370352678e-05

 step 50 is completed and loss is 8.701879414729774e-05

 step 51 is completed and loss is 6.317887891782448e-05

 step 52 is completed and loss is 0.00244141579605639

 step 53 is completed and loss is 0.0003520130121614784

 step 54 is completed and loss is 3.808646943070926e-05

 step 55 is completed and loss is 0.0017140150303021073

 step 56 is completed and loss is 4.833819548366591e-05

 step 57 is completed and loss is 0.0005684495554305613

 step 58 is completed and loss is 5.495324148796499e-05

 step 59 is completed and loss is 0.00029301168979145586

 step 60 is completed and loss is 0.00010597120854072273

 step 61 is completed and loss is 8.37388652144e-05

 step 62 is completed and loss is 8.189204527297989e-05

 step 63 is completed and loss is 0.0005607741768471897

 step 64 is completed and loss is 0.00025981420185416937

 step 65 is completed and loss is 9.560127364238724e-05

 step 66 is completed and loss is 0.0006639188504777849

 step 67 is completed and loss is 7.712405204074457e-05

 step 68 is completed and loss is 0.00017671205569058657

 step 69 is completed and loss is 0.00012313530896790326

 step 70 is completed and loss is 0.00018761513638310134

 step 71 is completed and loss is 0.0001296888804063201

 step 72 is completed and loss is 0.0005114112282171845

 step 73 is completed and loss is 8.111863280646503e-05

 step 74 is completed and loss is 0.00011365929822204635

 step 75 is completed and loss is 0.00020513657364062965

 step 76 is completed and loss is 0.00012593662540894002

 step 77 is completed and loss is 6.931758252903819e-05

 step 78 is completed and loss is 0.00023266651260200888

 step 79 is completed and loss is 0.0012180808698758483

 step 80 is completed and loss is 0.0002816517371684313

 step 81 is completed and loss is 9.02963729458861e-05

 step 82 is completed and loss is 0.0001296895497944206

 step 83 is completed and loss is 0.0001797485165297985

 step 84 is completed and loss is 0.00013832867261953652

 step 85 is completed and loss is 0.00013171759201213717

 step 86 is completed and loss is 0.0001287377526750788

 step 87 is completed and loss is 0.00014619847934227437

 step 88 is completed and loss is 0.00029288692167028785

 step 89 is completed and loss is 7.93900981079787e-05

 step 90 is completed and loss is 0.0006639247294515371

 step 91 is completed and loss is 0.00015304626140277833
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.36it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.40it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.51it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.51it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.53it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.51it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.51it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.50it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.51it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.49it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:25,  1.52it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.50it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.55it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.54it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.54it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.55it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.57it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.57it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.57it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.55it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.49it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.53it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.57it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.56it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.51it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.54it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.54it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.53it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.48it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.47it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.49it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.51it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.50it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.48it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.45it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.46it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.46it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.46it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.44it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.44it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.49it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.48it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.51it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.53it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.54it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 34: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 301.79233231800026s
Training Epoch34:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch34:   1%|[34m          [0m| 1/92 [00:03<04:57,  3.27s/it]Training Epoch34:   2%|[34mâ–         [0m| 2/92 [00:06<04:51,  3.24s/it]Training Epoch34:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:50,  3.26s/it]Training Epoch34:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.26s/it]Training Epoch34:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.27s/it]Training Epoch34:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.26s/it]Training Epoch34:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:34,  3.24s/it]Training Epoch34:   9%|[34mâ–Š         [0m| 8/92 [00:25<04:30,  3.22s/it]Training Epoch34:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:27,  3.22s/it]Training Epoch34:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:24,  3.23s/it]Training Epoch34:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:21,  3.23s/it]Training Epoch34:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:38<04:18,  3.23s/it]Training Epoch34:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:14,  3.22s/it]Training Epoch34:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:11,  3.22s/it]Training Epoch34:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:48<04:09,  3.25s/it]Training Epoch34:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:51<04:06,  3.24s/it]Training Epoch34:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:03,  3.25s/it]Training Epoch34:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:02,  3.28s/it]Training Epoch34:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:01<03:57,  3.26s/it]Training Epoch34:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:04<03:54,  3.26s/it]Training Epoch34:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:51,  3.25s/it]Training Epoch34:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:48,  3.27s/it]Training Epoch34:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:14<03:46,  3.28s/it]Training Epoch34:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:43,  3.29s/it]Training Epoch34:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:40,  3.29s/it]Training Epoch34:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:37,  3.29s/it]Training Epoch34:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:27<03:33,  3.29s/it]Training Epoch34:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:30,  3.29s/it]Training Epoch34:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:26,  3.28s/it]Training Epoch34:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:22,  3.27s/it]Training Epoch34:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:19,  3.27s/it]Training Epoch34:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:18,  3.30s/it]Training Epoch34:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:14,  3.30s/it]Training Epoch34:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:10,  3.28s/it]Training Epoch34:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:07,  3.28s/it]Training Epoch34:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:02,  3.26s/it]Training Epoch34:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:00<02:58,  3.25s/it]Training Epoch34:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:03<02:55,  3.26s/it]Training Epoch34:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:52,  3.26s/it]Training Epoch34:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:10<02:50,  3.29s/it]Training Epoch34:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:48,  3.30s/it]Training Epoch34:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:43,  3.28s/it]Training Epoch34:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:38,  3.24s/it]Training Epoch34:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:23<02:35,  3.24s/it]Training Epoch34:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:26<02:32,  3.25s/it]Training Epoch34:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:29,  3.25s/it]Training Epoch34:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:25,  3.23s/it]Training Epoch34:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:36<02:21,  3.22s/it]Training Epoch34:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:39<02:18,  3.22s/it]Training Epoch34:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:42<02:15,  3.22s/it]Training Epoch34:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:46<02:12,  3.24s/it]Training Epoch34:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:49<02:09,  3.25s/it]Training Epoch34:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:52<02:06,  3.25s/it]Training Epoch34:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:55<02:03,  3.26s/it]Training Epoch34:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:59<02:01,  3.28s/it]Training Epoch34:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:02<01:56,  3.24s/it]Training Epoch34:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:05<01:53,  3.25s/it]Training Epoch34:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:08<01:51,  3.27s/it]Training Epoch34:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:12<01:48,  3.28s/it]Training Epoch34:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:15<01:45,  3.30s/it]Training Epoch34:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:18<01:42,  3.31s/it]Training Epoch34:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:22<01:38,  3.30s/it]Training Epoch34:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:25<01:36,  3.32s/it]Training Epoch34:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:28<01:31,  3.28s/it]Training Epoch34:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:32<01:28,  3.28s/it]Training Epoch34:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:35<01:25,  3.29s/it]Training Epoch34:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:38<01:21,  3.26s/it]Training Epoch34:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:41<01:18,  3.27s/it]Training Epoch34:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:45<01:14,  3.26s/it]Training Epoch34:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:48<01:11,  3.24s/it]Training Epoch34:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:51<01:08,  3.26s/it]Training Epoch34:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:54<01:05,  3.29s/it]Training Epoch34:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:58<01:02,  3.30s/it]Training Epoch34:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:01<00:59,  3.29s/it]Training Epoch34:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:04<00:55,  3.29s/it]Training Epoch34:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:08<00:52,  3.29s/it]Training Epoch34:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:11<00:49,  3.28s/it]Training Epoch34:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:14<00:45,  3.28s/it]Training Epoch34:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:17<00:42,  3.30s/it]Training Epoch34:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:21<00:39,  3.31s/it]Training Epoch34:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:24<00:36,  3.32s/it]Training Epoch34:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:28<00:33,  3.33s/it]Training Epoch34:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:31<00:30,  3.34s/it]Training Epoch34:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:34<00:26,  3.35s/it]Training Epoch34:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:38<00:23,  3.34s/it]Training Epoch34:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:41<00:19,  3.29s/it]Training Epoch34:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:44<00:16,  3.28s/it]Training Epoch34:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:47<00:13,  3.30s/it]Training Epoch34:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:51<00:09,  3.32s/it]Training Epoch34:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:54<00:06,  3.32s/it]Training Epoch34:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:57<00:03,  3.35s/it]Training Epoch34: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.37s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch34: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.28s/it]

 step 0 is completed and loss is 0.00013671783381141722

 step 1 is completed and loss is 0.0001842192723415792

 step 2 is completed and loss is 3.457003549556248e-05

 step 3 is completed and loss is 0.00011353648005751893

 step 4 is completed and loss is 8.85062909219414e-05

 step 5 is completed and loss is 5.131816942594014e-05

 step 6 is completed and loss is 0.0007287794724106789

 step 7 is completed and loss is 5.4834272305015475e-05

 step 8 is completed and loss is 7.694653322687373e-05

 step 9 is completed and loss is 4.207983874948695e-05

 step 10 is completed and loss is 0.0004133264592383057

 step 11 is completed and loss is 0.0016254056245088577

 step 12 is completed and loss is 0.00021787680452689528

 step 13 is completed and loss is 7.724463648628443e-05

 step 14 is completed and loss is 5.93643489992246e-05

 step 15 is completed and loss is 4.637133679352701e-05

 step 16 is completed and loss is 0.00010322865273337811

 step 17 is completed and loss is 0.00013004745414946228

 step 18 is completed and loss is 4.9232199671678245e-05

 step 19 is completed and loss is 0.00016472507559228688

 step 20 is completed and loss is 6.925800698809326e-05

 step 21 is completed and loss is 8.332353172590956e-05

 step 22 is completed and loss is 0.0005433372571133077

 step 23 is completed and loss is 0.00010686517634894699

 step 24 is completed and loss is 6.770848267478868e-05

 step 25 is completed and loss is 0.00024046117323450744

 step 26 is completed and loss is 9.726878488436341e-05

 step 27 is completed and loss is 0.00017152720829471946

 step 28 is completed and loss is 0.0001357064611511305

 step 29 is completed and loss is 8.904533751774579e-05

 step 30 is completed and loss is 0.00010907009709626436

 step 31 is completed and loss is 1.5556663129245862e-05

 step 32 is completed and loss is 0.00016609505109954625

 step 33 is completed and loss is 9.446842886973172e-05

 step 34 is completed and loss is 8.25488823466003e-05

 step 35 is completed and loss is 0.00023129346664063632

 step 36 is completed and loss is 1.5735471606603824e-05

 step 37 is completed and loss is 6.13313022768125e-05

 step 38 is completed and loss is 8.475407958030701e-05

 step 39 is completed and loss is 6.139087054179981e-05

 step 40 is completed and loss is 9.917690476868302e-05

 step 41 is completed and loss is 5.376117769628763e-05

 step 42 is completed and loss is 7.331102096941322e-05

 step 43 is completed and loss is 6.055612175259739e-05

 step 44 is completed and loss is 2.3007014533504844e-05

 step 45 is completed and loss is 0.00019274192163720727

 step 46 is completed and loss is 1.99673195311334e-05

 step 47 is completed and loss is 6.747017323505133e-05

 step 48 is completed and loss is 0.0007109884172677994

 step 49 is completed and loss is 8.254901331383735e-05

 step 50 is completed and loss is 8.833017636789009e-05

 step 51 is completed and loss is 6.502654287032783e-05

 step 52 is completed and loss is 0.0013804720947518945

 step 53 is completed and loss is 0.0002562024164944887

 step 54 is completed and loss is 3.7788406189065427e-05

 step 55 is completed and loss is 0.001708206138573587

 step 56 is completed and loss is 6.586062954738736e-05

 step 57 is completed and loss is 0.00026196317048743367

 step 58 is completed and loss is 6.28205161774531e-05

 step 59 is completed and loss is 0.00031594294705428183

 step 60 is completed and loss is 9.768703603185713e-05

 step 61 is completed and loss is 0.00010429913527332246

 step 62 is completed and loss is 9.577816672390327e-05

 step 63 is completed and loss is 0.0002182439056923613

 step 64 is completed and loss is 0.00026862986851483583

 step 65 is completed and loss is 0.00010394491255283356

 step 66 is completed and loss is 0.0005433394690044224

 step 67 is completed and loss is 6.705218402203172e-05

 step 68 is completed and loss is 0.00026836368488147855

 step 69 is completed and loss is 0.00014435153570957482

 step 70 is completed and loss is 0.0001877325412351638

 step 71 is completed and loss is 0.00022938294569030404

 step 72 is completed and loss is 0.000361567857908085

 step 73 is completed and loss is 8.570779755245894e-05

 step 74 is completed and loss is 0.0001058516645571217

 step 75 is completed and loss is 0.00020418445637915283

 step 76 is completed and loss is 0.00014637790445704013

 step 77 is completed and loss is 6.663534441031516e-05

 step 78 is completed and loss is 0.00019935649470426142

 step 79 is completed and loss is 0.0006888546631671488

 step 80 is completed and loss is 0.00030232788412831724

 step 81 is completed and loss is 0.00010287229088135064

 step 82 is completed and loss is 0.00017259616288356483

 step 83 is completed and loss is 0.00017360941274091601

 step 84 is completed and loss is 0.000151320084114559

 step 85 is completed and loss is 0.0001538873475510627

 step 86 is completed and loss is 0.00012587709352374077

 step 87 is completed and loss is 0.00014303968055173755

 step 88 is completed and loss is 0.00012474253890104592

 step 89 is completed and loss is 6.025823677191511e-05

 step 90 is completed and loss is 0.0008087294409051538

 step 91 is completed and loss is 0.00013731379294767976
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.39it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.43it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:30,  1.54it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.51it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.49it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.50it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.49it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.51it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.53it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.54it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.54it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.53it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.52it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.50it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:23,  1.48it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:23,  1.46it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.47it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.47it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.50it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.50it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.46it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:19,  1.45it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.45it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.46it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.49it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.47it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.51it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.48it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.44it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:14,  1.42it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.43it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.43it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.45it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.51it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.45it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.51it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.47it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.43it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.43it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.45it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.47it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.47it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.46it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.45it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.46it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.49it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.48it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.44it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.47it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.44it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.47it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 35: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 301.6839871150005s
Training Epoch35:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch35:   1%|[34m          [0m| 1/92 [00:03<05:08,  3.39s/it]Training Epoch35:   2%|[34mâ–         [0m| 2/92 [00:06<04:58,  3.32s/it]Training Epoch35:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:58,  3.35s/it]Training Epoch35:   4%|[34mâ–         [0m| 4/92 [00:13<04:55,  3.36s/it]Training Epoch35:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:51,  3.35s/it]Training Epoch35:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:46,  3.33s/it]Training Epoch35:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.33s/it]Training Epoch35:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.33s/it]Training Epoch35:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:36,  3.33s/it]Training Epoch35:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:32,  3.32s/it]Training Epoch35:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.32s/it]Training Epoch35:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:26,  3.33s/it]Training Epoch35:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:22,  3.32s/it]Training Epoch35:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.34s/it]Training Epoch35:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.31s/it]Training Epoch35:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:12,  3.32s/it]Training Epoch35:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.32s/it]Training Epoch35:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.30s/it]Training Epoch35:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:02,  3.33s/it]Training Epoch35:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:59,  3.32s/it]Training Epoch35:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:57,  3.35s/it]Training Epoch35:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:54,  3.35s/it]Training Epoch35:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:51,  3.36s/it]Training Epoch35:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:20<03:48,  3.36s/it]Training Epoch35:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:44,  3.35s/it]Training Epoch35:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:41,  3.36s/it]Training Epoch35:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:37,  3.35s/it]Training Epoch35:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:32,  3.33s/it]Training Epoch35:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:31,  3.35s/it]Training Epoch35:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:40<03:27,  3.35s/it]Training Epoch35:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:23,  3.34s/it]Training Epoch35:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:17,  3.29s/it]Training Epoch35:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:13,  3.28s/it]Training Epoch35:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:10,  3.28s/it]Training Epoch35:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:07,  3.30s/it]Training Epoch35:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:04,  3.29s/it]Training Epoch35:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<02:59,  3.26s/it]Training Epoch35:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:56,  3.27s/it]Training Epoch35:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:53,  3.27s/it]Training Epoch35:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:50,  3.27s/it]Training Epoch35:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:47,  3.29s/it]Training Epoch35:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:43,  3.27s/it]Training Epoch35:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:42,  3.31s/it]Training Epoch35:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:39,  3.32s/it]Training Epoch35:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.32s/it]Training Epoch35:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:31,  3.30s/it]Training Epoch35:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:28,  3.29s/it]Training Epoch35:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:23,  3.27s/it]Training Epoch35:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:18,  3.23s/it]Training Epoch35:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:16,  3.26s/it]Training Epoch35:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:13,  3.26s/it]Training Epoch35:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:10,  3.25s/it]Training Epoch35:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:08,  3.28s/it]Training Epoch35:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.30s/it]Training Epoch35:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:01,  3.30s/it]Training Epoch35:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:58,  3.30s/it]Training Epoch35:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:55,  3.31s/it]Training Epoch35:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.30s/it]Training Epoch35:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.31s/it]Training Epoch35:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.31s/it]Training Epoch35:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:42,  3.32s/it]Training Epoch35:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.32s/it]Training Epoch35:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.32s/it]Training Epoch35:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.32s/it]Training Epoch35:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.31s/it]Training Epoch35:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.33s/it]Training Epoch35:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.31s/it]Training Epoch35:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:20,  3.34s/it]Training Epoch35:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.34s/it]Training Epoch35:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:13,  3.32s/it]Training Epoch35:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.30s/it]Training Epoch35:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:05,  3.29s/it]Training Epoch35:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.31s/it]Training Epoch35:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.31s/it]Training Epoch35:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.30s/it]Training Epoch35:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.29s/it]Training Epoch35:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.29s/it]Training Epoch35:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.30s/it]Training Epoch35:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:42,  3.30s/it]Training Epoch35:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.33s/it]Training Epoch35:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.33s/it]Training Epoch35:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.32s/it]Training Epoch35:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.33s/it]Training Epoch35:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.32s/it]Training Epoch35:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.30s/it]Training Epoch35:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.25s/it]Training Epoch35:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.24s/it]Training Epoch35:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.30s/it]Training Epoch35:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.31s/it]Training Epoch35:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.33s/it]Training Epoch35:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.31s/it]Training Epoch35: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.30s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch35: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.00010567008575890213

 step 1 is completed and loss is 0.00019226461881771684

 step 2 is completed and loss is 3.6596549762180075e-05

 step 3 is completed and loss is 0.00010650440526660532

 step 4 is completed and loss is 7.515689503634349e-05

 step 5 is completed and loss is 6.019859210937284e-05

 step 6 is completed and loss is 0.0010102423839271069

 step 7 is completed and loss is 7.29525345377624e-05

 step 8 is completed and loss is 9.42900514928624e-05

 step 9 is completed and loss is 4.6311422920553014e-05

 step 10 is completed and loss is 0.0010436165612190962

 step 11 is completed and loss is 0.0005478826351463795

 step 12 is completed and loss is 0.0002840066736098379

 step 13 is completed and loss is 5.262951890472323e-05

 step 14 is completed and loss is 4.5238848542794585e-05

 step 15 is completed and loss is 4.23184028477408e-05

 step 16 is completed and loss is 0.00019124237587675452

 step 17 is completed and loss is 0.0001315968984272331

 step 18 is completed and loss is 5.322552897268906e-05

 step 19 is completed and loss is 0.0001528664433863014

 step 20 is completed and loss is 4.2854819184867665e-05

 step 21 is completed and loss is 5.566911568166688e-05

 step 22 is completed and loss is 0.0003111205296590924

 step 23 is completed and loss is 0.00010012996790464967

 step 24 is completed and loss is 6.949659291421995e-05

 step 25 is completed and loss is 0.00022967469703871757

 step 26 is completed and loss is 6.586062227142975e-05

 step 27 is completed and loss is 0.00016568713181186467

 step 28 is completed and loss is 0.00013636208313982934

 step 29 is completed and loss is 7.61121918912977e-05

 step 30 is completed and loss is 0.000104600127087906

 step 31 is completed and loss is 1.7285159628954716e-05

 step 32 is completed and loss is 9.440774738322943e-05

 step 33 is completed and loss is 7.706558972131461e-05

 step 34 is completed and loss is 7.474099402315915e-05

 step 35 is completed and loss is 0.00013863008643966168

 step 36 is completed and loss is 1.5437466572620906e-05

 step 37 is completed and loss is 7.319178257603198e-05

 step 38 is completed and loss is 9.172622230835259e-05

 step 39 is completed and loss is 5.10798636241816e-05

 step 40 is completed and loss is 9.822302672546357e-05

 step 41 is completed and loss is 6.389278860297054e-05

 step 42 is completed and loss is 8.093971700873226e-05

 step 43 is completed and loss is 6.401274004019797e-05

 step 44 is completed and loss is 3.111294427071698e-05

 step 45 is completed and loss is 0.00020966175361536443

 step 46 is completed and loss is 2.1218984329607338e-05

 step 47 is completed and loss is 7.468175317626446e-05

 step 48 is completed and loss is 0.00047517428174614906

 step 49 is completed and loss is 7.778096187394112e-05

 step 50 is completed and loss is 7.110573642421514e-05

 step 51 is completed and loss is 6.568213575519621e-05

 step 52 is completed and loss is 0.001684812013991177

 step 53 is completed and loss is 0.00022980656649451703

 step 54 is completed and loss is 4.1900857468135655e-05

 step 55 is completed and loss is 0.00114855554420501

 step 56 is completed and loss is 4.637124948203564e-05

 step 57 is completed and loss is 0.0003923020849470049

 step 58 is completed and loss is 5.3761050367029384e-05

 step 59 is completed and loss is 0.0002729919506236911

 step 60 is completed and loss is 9.142918861471117e-05

 step 61 is completed and loss is 6.138996832305565e-05

 step 62 is completed and loss is 7.980583177413791e-05

 step 63 is completed and loss is 0.00041931754094548523

 step 64 is completed and loss is 0.00017592495714779943

 step 65 is completed and loss is 0.00010132251190952957

 step 66 is completed and loss is 0.0005244144122116268

 step 67 is completed and loss is 6.860184657853097e-05

 step 68 is completed and loss is 0.0001718847342999652

 step 69 is completed and loss is 0.00013684129226021469

 step 70 is completed and loss is 0.00019780700677074492

 step 71 is completed and loss is 0.0001916049513965845

 step 72 is completed and loss is 0.0006798539543524384

 step 73 is completed and loss is 9.154854342341423e-05

 step 74 is completed and loss is 0.00011616147094173357

 step 75 is completed and loss is 0.00018594920402392745

 step 76 is completed and loss is 0.00016336244880221784

 step 77 is completed and loss is 8.308485121233389e-05

 step 78 is completed and loss is 0.00020060772658325732

 step 79 is completed and loss is 0.000745270517654717

 step 80 is completed and loss is 0.0003157354658469558

 step 81 is completed and loss is 0.00010024986113421619

 step 82 is completed and loss is 0.00016061821952462196

 step 83 is completed and loss is 0.0001836829469539225

 step 84 is completed and loss is 0.00013451547420118004

 step 85 is completed and loss is 0.00015722469834145159

 step 86 is completed and loss is 8.40390202938579e-05

 step 87 is completed and loss is 0.0001576404320076108

 step 88 is completed and loss is 0.00031462954939343035

 step 89 is completed and loss is 5.829145447933115e-05

 step 90 is completed and loss is 0.0006720128003507853

 step 91 is completed and loss is 8.20111672510393e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.48it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.44it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.47it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.56it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.56it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.55it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.57it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.59it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.61it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:24,  1.63it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.52it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:25,  1.47it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.46it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.45it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:23,  1.46it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.48it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.50it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.50it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.50it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.46it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.45it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:19,  1.46it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.50it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.47it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.48it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.48it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.48it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.48it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.49it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.49it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.49it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.54it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.59it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.57it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.58it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.60it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.59it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.58it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.53it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.56it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.57it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.60it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.60it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.60it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 36: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.84521252299965s
Training Epoch36:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch36:   1%|[34m          [0m| 1/92 [00:03<05:05,  3.36s/it]Training Epoch36:   2%|[34mâ–         [0m| 2/92 [00:06<04:56,  3.30s/it]Training Epoch36:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:55,  3.32s/it]Training Epoch36:   4%|[34mâ–         [0m| 4/92 [00:13<04:51,  3.32s/it]Training Epoch36:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:48,  3.31s/it]Training Epoch36:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:45,  3.32s/it]Training Epoch36:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.31s/it]Training Epoch36:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.33s/it]Training Epoch36:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.30s/it]Training Epoch36:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:29,  3.29s/it]Training Epoch36:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.31s/it]Training Epoch36:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:26,  3.34s/it]Training Epoch36:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.33s/it]Training Epoch36:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.32s/it]Training Epoch36:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch36:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.28s/it]Training Epoch36:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.31s/it]Training Epoch36:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:03,  3.29s/it]Training Epoch36:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:00,  3.30s/it]Training Epoch36:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:57,  3.29s/it]Training Epoch36:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.31s/it]Training Epoch36:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:52,  3.32s/it]Training Epoch36:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:49,  3.33s/it]Training Epoch36:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:46,  3.33s/it]Training Epoch36:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.34s/it]Training Epoch36:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:38,  3.32s/it]Training Epoch36:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.31s/it]Training Epoch36:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.31s/it]Training Epoch36:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:28,  3.31s/it]Training Epoch36:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.32s/it]Training Epoch36:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:22,  3.32s/it]Training Epoch36:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:18,  3.31s/it]Training Epoch36:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:15,  3.32s/it]Training Epoch36:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:13,  3.33s/it]Training Epoch36:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:09,  3.32s/it]Training Epoch36:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:05,  3.32s/it]Training Epoch36:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:01,  3.30s/it]Training Epoch36:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.31s/it]Training Epoch36:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:55,  3.31s/it]Training Epoch36:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.31s/it]Training Epoch36:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.32s/it]Training Epoch36:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:46,  3.33s/it]Training Epoch36:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:42,  3.31s/it]Training Epoch36:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:39,  3.33s/it]Training Epoch36:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.33s/it]Training Epoch36:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:32,  3.33s/it]Training Epoch36:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.32s/it]Training Epoch36:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:26,  3.34s/it]Training Epoch36:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:23,  3.33s/it]Training Epoch36:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:20,  3.34s/it]Training Epoch36:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:17,  3.35s/it]Training Epoch36:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:13,  3.35s/it]Training Epoch36:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:10,  3.34s/it]Training Epoch36:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:06,  3.33s/it]Training Epoch36:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:03,  3.34s/it]Training Epoch36:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<02:00,  3.33s/it]Training Epoch36:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:56,  3.32s/it]Training Epoch36:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.31s/it]Training Epoch36:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.33s/it]Training Epoch36:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:46,  3.34s/it]Training Epoch36:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:43,  3.33s/it]Training Epoch36:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.33s/it]Training Epoch36:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:36,  3.33s/it]Training Epoch36:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:32,  3.31s/it]Training Epoch36:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:28,  3.29s/it]Training Epoch36:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:25,  3.30s/it]Training Epoch36:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:22,  3.30s/it]Training Epoch36:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.32s/it]Training Epoch36:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:15,  3.30s/it]Training Epoch36:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:13,  3.33s/it]Training Epoch36:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.31s/it]Training Epoch36:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.31s/it]Training Epoch36:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:02,  3.31s/it]Training Epoch36:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.32s/it]Training Epoch36:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.35s/it]Training Epoch36:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:53,  3.34s/it]Training Epoch36:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.33s/it]Training Epoch36:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.33s/it]Training Epoch36:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:43,  3.33s/it]Training Epoch36:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.32s/it]Training Epoch36:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.33s/it]Training Epoch36:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.34s/it]Training Epoch36:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:29,  3.32s/it]Training Epoch36:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.31s/it]Training Epoch36:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:22,  3.28s/it]Training Epoch36:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:19,  3.28s/it]Training Epoch36:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.29s/it]Training Epoch36:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.30s/it]Training Epoch36:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:09,  3.30s/it]Training Epoch36:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.32s/it]Training Epoch36:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.31s/it]Training Epoch36: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch36: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 0.0001239646808244288

 step 1 is completed and loss is 0.00020650718943215907

 step 2 is completed and loss is 3.600055060815066e-05

 step 3 is completed and loss is 0.0001241434074472636

 step 4 is completed and loss is 7.837488374207169e-05

 step 5 is completed and loss is 5.572843656409532e-05

 step 6 is completed and loss is 0.0005429222946986556

 step 7 is completed and loss is 7.229676702991128e-05

 step 8 is completed and loss is 8.672094554640353e-05

 step 9 is completed and loss is 4.5953951484989375e-05

 step 10 is completed and loss is 0.0011181875597685575

 step 11 is completed and loss is 0.0020382360089570284

 step 12 is completed and loss is 0.00035340661997906864

 step 13 is completed and loss is 7.641007687197998e-05

 step 14 is completed and loss is 5.292749119689688e-05

 step 15 is completed and loss is 4.2199197196168825e-05

 step 16 is completed and loss is 0.0001453607255825773

 step 17 is completed and loss is 0.00013505297829397023

 step 18 is completed and loss is 6.222530646482483e-05

 step 19 is completed and loss is 0.00019988066924270242

 step 20 is completed and loss is 5.066261292085983e-05

 step 21 is completed and loss is 6.0198810388101265e-05

 step 22 is completed and loss is 0.00033024323056451976

 step 23 is completed and loss is 9.005848551169038e-05

 step 24 is completed and loss is 6.454969116020948e-05

 step 25 is completed and loss is 0.00014655383711215109

 step 26 is completed and loss is 6.788723840145394e-05

 step 27 is completed and loss is 0.00013130001025274396

 step 28 is completed and loss is 0.00015846933820284903

 step 29 is completed and loss is 0.00010102469241246581

 step 30 is completed and loss is 0.0001401780464220792

 step 31 is completed and loss is 1.853681715147104e-05

 step 32 is completed and loss is 0.00017998006660491228

 step 33 is completed and loss is 8.940271800383925e-05

 step 34 is completed and loss is 8.356152102351189e-05

 step 35 is completed and loss is 0.00013261115236673504

 step 36 is completed and loss is 1.4245400961954147e-05

 step 37 is completed and loss is 6.711257447022945e-05

 step 38 is completed and loss is 9.23824991332367e-05

 step 39 is completed and loss is 5.072223211755045e-05

 step 40 is completed and loss is 0.0001310618536081165

 step 41 is completed and loss is 0.00011383331730030477

 step 42 is completed and loss is 7.348979124799371e-05

 step 43 is completed and loss is 5.954266816843301e-05

 step 44 is completed and loss is 2.5212297259713523e-05

 step 45 is completed and loss is 0.0003828467451967299

 step 46 is completed and loss is 2.4973982363007963e-05

 step 47 is completed and loss is 7.956901390571147e-05

 step 48 is completed and loss is 0.0005558826960623264

 step 49 is completed and loss is 9.911756205838174e-05

 step 50 is completed and loss is 9.333628986496478e-05

 step 51 is completed and loss is 6.896004197187722e-05

 step 52 is completed and loss is 0.0023387684486806393

 step 53 is completed and loss is 0.0003014856483787298

 step 54 is completed and loss is 4.19009302277118e-05

 step 55 is completed and loss is 0.0009587995009496808

 step 56 is completed and loss is 4.196077861706726e-05

 step 57 is completed and loss is 0.00019320887804497033

 step 58 is completed and loss is 5.703931674361229e-05

 step 59 is completed and loss is 0.00015930586960166693

 step 60 is completed and loss is 0.00010030958219431341

 step 61 is completed and loss is 6.985287473071367e-05

 step 62 is completed and loss is 0.00010686245514079928

 step 63 is completed and loss is 0.00027366046560928226

 step 64 is completed and loss is 0.00038162851706147194

 step 65 is completed and loss is 9.375311492476612e-05

 step 66 is completed and loss is 0.0003647897974587977

 step 67 is completed and loss is 4.970863301423378e-05

 step 68 is completed and loss is 0.00015871375217102468

 step 69 is completed and loss is 0.00013636585208587348

 step 70 is completed and loss is 0.00020495265198405832

 step 71 is completed and loss is 0.0002356366312596947

 step 72 is completed and loss is 0.0005357119953259826

 step 73 is completed and loss is 9.786592272575945e-05

 step 74 is completed and loss is 0.00012986799993086606

 step 75 is completed and loss is 0.00016979919746518135

 step 76 is completed and loss is 0.00013308829511515796

 step 77 is completed and loss is 8.803169475868344e-05

 step 78 is completed and loss is 0.00018719924264587462

 step 79 is completed and loss is 0.0010629607131704688

 step 80 is completed and loss is 0.00030304212123155594

 step 81 is completed and loss is 0.00011991699284408242

 step 82 is completed and loss is 0.00019375045667402446

 step 83 is completed and loss is 0.00017742475029081106

 step 84 is completed and loss is 0.0001014402077998966

 step 85 is completed and loss is 0.00015424491721205413

 step 86 is completed and loss is 8.093983342405409e-05

 step 87 is completed and loss is 0.0001553159672766924

 step 88 is completed and loss is 0.0003622238873504102

 step 89 is completed and loss is 6.502606993308291e-05

 step 90 is completed and loss is 0.0005751457065343857

 step 91 is completed and loss is 0.00010006926459027454
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.47it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.44it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.44it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.41it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.42it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:30,  1.43it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.47it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.45it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.48it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.46it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.49it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.55it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.55it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.52it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.55it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:20,  1.60it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:20,  1.57it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.54it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:18,  1.54it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.53it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.55it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.55it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.50it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.49it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.49it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.53it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.51it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.51it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.53it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.58it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.60it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.57it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.59it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.56it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.55it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.52it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.49it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.49it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.49it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.50it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.50it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 37: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.53406016199915s
Training Epoch37:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch37:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.25s/it]Training Epoch37:   2%|[34mâ–         [0m| 2/92 [00:06<04:47,  3.19s/it]Training Epoch37:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:44,  3.20s/it]Training Epoch37:   4%|[34mâ–         [0m| 4/92 [00:12<04:43,  3.22s/it]Training Epoch37:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:41,  3.23s/it]Training Epoch37:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:36,  3.22s/it]Training Epoch37:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:35,  3.25s/it]Training Epoch37:   9%|[34mâ–Š         [0m| 8/92 [00:25<04:33,  3.25s/it]Training Epoch37:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.27s/it]Training Epoch37:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.28s/it]Training Epoch37:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:27,  3.31s/it]Training Epoch37:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch37:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.30s/it]Training Epoch37:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.30s/it]Training Epoch37:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch37:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.31s/it]Training Epoch37:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:07,  3.29s/it]Training Epoch37:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:04,  3.30s/it]Training Epoch37:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.28s/it]Training Epoch37:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.28s/it]Training Epoch37:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:52,  3.27s/it]Training Epoch37:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:48,  3.27s/it]Training Epoch37:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.27s/it]Training Epoch37:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:42,  3.27s/it]Training Epoch37:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:39,  3.27s/it]Training Epoch37:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:38,  3.31s/it]Training Epoch37:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:35,  3.31s/it]Training Epoch37:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:30,  3.28s/it]Training Epoch37:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:25,  3.26s/it]Training Epoch37:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:22,  3.26s/it]Training Epoch37:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:19,  3.27s/it]Training Epoch37:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:14,  3.24s/it]Training Epoch37:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:11,  3.25s/it]Training Epoch37:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:09,  3.26s/it]Training Epoch37:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:06,  3.27s/it]Training Epoch37:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:03,  3.28s/it]Training Epoch37:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:00,  3.28s/it]Training Epoch37:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:57,  3.28s/it]Training Epoch37:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:53,  3.27s/it]Training Epoch37:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:10<02:48,  3.25s/it]Training Epoch37:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:45,  3.25s/it]Training Epoch37:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:43,  3.27s/it]Training Epoch37:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:41,  3.29s/it]Training Epoch37:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:23<02:37,  3.28s/it]Training Epoch37:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.26s/it]Training Epoch37:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:30,  3.27s/it]Training Epoch37:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:28,  3.31s/it]Training Epoch37:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:25,  3.30s/it]Training Epoch37:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:21,  3.29s/it]Training Epoch37:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:18,  3.30s/it]Training Epoch37:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:15,  3.29s/it]Training Epoch37:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:10,  3.25s/it]Training Epoch37:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:07,  3.26s/it]Training Epoch37:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:03,  3.24s/it]Training Epoch37:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:59<01:59,  3.23s/it]Training Epoch37:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:56,  3.23s/it]Training Epoch37:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:54,  3.26s/it]Training Epoch37:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:09<01:50,  3.26s/it]Training Epoch37:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:48,  3.29s/it]Training Epoch37:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:45,  3.29s/it]Training Epoch37:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:42,  3.31s/it]Training Epoch37:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:22<01:38,  3.29s/it]Training Epoch37:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:35,  3.28s/it]Training Epoch37:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:31,  3.27s/it]Training Epoch37:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:32<01:28,  3.26s/it]Training Epoch37:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.28s/it]Training Epoch37:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:21,  3.27s/it]Training Epoch37:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:19,  3.30s/it]Training Epoch37:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:16,  3.33s/it]Training Epoch37:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:13,  3.32s/it]Training Epoch37:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:09,  3.32s/it]Training Epoch37:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:55<01:05,  3.30s/it]Training Epoch37:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.28s/it]Training Epoch37:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:59,  3.30s/it]Training Epoch37:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:05<00:56,  3.30s/it]Training Epoch37:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:52,  3.31s/it]Training Epoch37:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.32s/it]Training Epoch37:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:46,  3.31s/it]Training Epoch37:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:43,  3.34s/it]Training Epoch37:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.32s/it]Training Epoch37:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.31s/it]Training Epoch37:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:33,  3.31s/it]Training Epoch37:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.31s/it]Training Epoch37:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.30s/it]Training Epoch37:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:38<00:23,  3.30s/it]Training Epoch37:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.29s/it]Training Epoch37:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.26s/it]Training Epoch37:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:48<00:13,  3.27s/it]Training Epoch37:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.30s/it]Training Epoch37:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.31s/it]Training Epoch37:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:58<00:03,  3.31s/it]Training Epoch37: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch37: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.28s/it]

 step 0 is completed and loss is 0.00011901830293936655

 step 1 is completed and loss is 0.0002048974420176819

 step 2 is completed and loss is 3.7252182664815336e-05

 step 3 is completed and loss is 9.810143092181534e-05

 step 4 is completed and loss is 7.152132457122207e-05

 step 5 is completed and loss is 6.818501424277201e-05

 step 6 is completed and loss is 0.00033357524080201983

 step 7 is completed and loss is 5.227163273957558e-05

 step 8 is completed and loss is 7.003299833741039e-05

 step 9 is completed and loss is 4.3331587221473455e-05

 step 10 is completed and loss is 0.000709670246578753

 step 11 is completed and loss is 0.0010598101653158665

 step 12 is completed and loss is 0.00021596721489913762

 step 13 is completed and loss is 7.110578007996082e-05

 step 14 is completed and loss is 5.340421921573579e-05

 step 15 is completed and loss is 3.4689302992774174e-05

 step 16 is completed and loss is 0.00015835136582609266

 step 17 is completed and loss is 0.00010388479131506756

 step 18 is completed and loss is 4.523887037066743e-05

 step 19 is completed and loss is 0.0001901680661831051

 step 20 is completed and loss is 4.720575816463679e-05

 step 21 is completed and loss is 6.603964720852673e-05

 step 22 is completed and loss is 0.0004478276241570711

 step 23 is completed and loss is 0.00012444502499420196

 step 24 is completed and loss is 7.0330745074898e-05

 step 25 is completed and loss is 0.00022538438497576863

 step 26 is completed and loss is 7.301239384105429e-05

 step 27 is completed and loss is 0.00022331366199068725

 step 28 is completed and loss is 0.00013248715549707413

 step 29 is completed and loss is 9.411129576619714e-05

 step 30 is completed and loss is 0.00013457619934342802

 step 31 is completed and loss is 1.7046748325810768e-05

 step 32 is completed and loss is 7.867403473937884e-05

 step 33 is completed and loss is 8.684002386871725e-05

 step 34 is completed and loss is 5.429833254311234e-05

 step 35 is completed and loss is 0.00018451749929226935

 step 36 is completed and loss is 1.7463986296206713e-05

 step 37 is completed and loss is 9.422992297913879e-05

 step 38 is completed and loss is 0.00011008203728124499

 step 39 is completed and loss is 9.363421122543514e-05

 step 40 is completed and loss is 8.165497274603695e-05

 step 41 is completed and loss is 4.0172348235500976e-05

 step 42 is completed and loss is 6.949660019017756e-05

 step 43 is completed and loss is 5.781444633612409e-05

 step 44 is completed and loss is 2.151695662178099e-05

 step 45 is completed and loss is 0.00021741085220128298

 step 46 is completed and loss is 1.984810660360381e-05

 step 47 is completed and loss is 7.748301140964031e-05

 step 48 is completed and loss is 0.000591736868955195

 step 49 is completed and loss is 7.843663479434326e-05

 step 50 is completed and loss is 9.089284139918163e-05

 step 51 is completed and loss is 6.663571548415348e-05

 step 52 is completed and loss is 0.0011903063859790564

 step 53 is completed and loss is 0.00035963428672403097

 step 54 is completed and loss is 3.59409095835872e-05

 step 55 is completed and loss is 0.0012715681223198771

 step 56 is completed and loss is 4.851687845075503e-05

 step 57 is completed and loss is 0.00017032772302627563

 step 58 is completed and loss is 5.3165233111940324e-05

 step 59 is completed and loss is 0.00017241663590539247

 step 60 is completed and loss is 0.00010305093019269407

 step 61 is completed and loss is 7.694481610087678e-05

 step 62 is completed and loss is 8.302443893626332e-05

 step 63 is completed and loss is 0.0005090685444884002

 step 64 is completed and loss is 0.0003791287017520517

 step 65 is completed and loss is 9.685258555691689e-05

 step 66 is completed and loss is 0.0007204760913737118

 step 67 is completed and loss is 7.623021519975737e-05

 step 68 is completed and loss is 0.00020489899907261133

 step 69 is completed and loss is 0.00016431523545179516

 step 70 is completed and loss is 0.00021335486962925643

 step 71 is completed and loss is 0.0001737267739372328

 step 72 is completed and loss is 0.0005386830889619887

 step 73 is completed and loss is 7.360900053754449e-05

 step 74 is completed and loss is 0.00011276511213509366

 step 75 is completed and loss is 0.0002483412390574813

 step 76 is completed and loss is 0.00014292138803284615

 step 77 is completed and loss is 8.368078852072358e-05

 step 78 is completed and loss is 0.00022557750344276428

 step 79 is completed and loss is 0.0004500665527302772

 step 80 is completed and loss is 0.00034385710023343563

 step 81 is completed and loss is 9.578002209309489e-05

 step 82 is completed and loss is 0.00016079792112577707

 step 83 is completed and loss is 0.00016497068281751126

 step 84 is completed and loss is 8.940232510212809e-05

 step 85 is completed and loss is 0.00013493580627255142

 step 86 is completed and loss is 8.010543388081715e-05

 step 87 is completed and loss is 0.00016824812337290496

 step 88 is completed and loss is 0.0001981556706596166

 step 89 is completed and loss is 6.252310413401574e-05

 step 90 is completed and loss is 0.0007651069317944348

 step 91 is completed and loss is 0.00011234536941628903
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.41it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.48it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.50it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.47it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.52it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.54it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.54it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.59it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.63it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:24,  1.65it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:06<00:23,  1.63it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.58it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.54it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.52it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:23,  1.50it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.47it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.46it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:21,  1.47it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.49it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.50it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.54it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.54it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.51it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.53it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.55it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.55it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.59it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:11,  1.60it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.60it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.61it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:09,  1.61it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.65it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.61it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.61it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.65it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.67it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:05,  1.68it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.61it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:04,  1.61it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.62it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.59it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.58it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.55it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.57it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.58it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.56it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.56it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 38: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 302.3508034639999s
Training Epoch38:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch38:   1%|[34m          [0m| 1/92 [00:03<04:50,  3.20s/it]Training Epoch38:   2%|[34mâ–         [0m| 2/92 [00:06<04:50,  3.23s/it]Training Epoch38:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:47,  3.23s/it]Training Epoch38:   4%|[34mâ–         [0m| 4/92 [00:12<04:47,  3.26s/it]Training Epoch38:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.27s/it]Training Epoch38:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:42,  3.29s/it]Training Epoch38:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:40,  3.30s/it]Training Epoch38:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.29s/it]Training Epoch38:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.27s/it]Training Epoch38:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.28s/it]Training Epoch38:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:24,  3.26s/it]Training Epoch38:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.27s/it]Training Epoch38:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:17,  3.26s/it]Training Epoch38:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:13,  3.26s/it]Training Epoch38:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:11,  3.27s/it]Training Epoch38:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.29s/it]Training Epoch38:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:04,  3.26s/it]Training Epoch38:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:02,  3.27s/it]Training Epoch38:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.28s/it]Training Epoch38:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.29s/it]Training Epoch38:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:53,  3.29s/it]Training Epoch38:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:49,  3.28s/it]Training Epoch38:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.27s/it]Training Epoch38:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:41,  3.26s/it]Training Epoch38:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:37,  3.24s/it]Training Epoch38:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:35,  3.27s/it]Training Epoch38:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:31,  3.26s/it]Training Epoch38:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:29,  3.27s/it]Training Epoch38:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:27,  3.30s/it]Training Epoch38:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:23,  3.29s/it]Training Epoch38:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:20,  3.29s/it]Training Epoch38:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:19,  3.32s/it]Training Epoch38:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:16,  3.33s/it]Training Epoch38:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:13,  3.33s/it]Training Epoch38:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:09,  3.33s/it]Training Epoch38:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:05,  3.32s/it]Training Epoch38:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:02,  3.31s/it]Training Epoch38:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:58,  3.30s/it]Training Epoch38:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:55,  3.31s/it]Training Epoch38:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:51,  3.30s/it]Training Epoch38:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:48,  3.31s/it]Training Epoch38:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:45,  3.30s/it]Training Epoch38:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:41,  3.30s/it]Training Epoch38:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:38,  3.30s/it]Training Epoch38:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:35,  3.31s/it]Training Epoch38:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:30,  3.28s/it]Training Epoch38:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:27,  3.29s/it]Training Epoch38:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:24,  3.28s/it]Training Epoch38:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:20,  3.26s/it]Training Epoch38:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:16,  3.26s/it]Training Epoch38:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:12,  3.24s/it]Training Epoch38:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:10,  3.25s/it]Training Epoch38:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.31s/it]Training Epoch38:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:05,  3.31s/it]Training Epoch38:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:02,  3.31s/it]Training Epoch38:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<02:00,  3.35s/it]Training Epoch38:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:57,  3.36s/it]Training Epoch38:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:53,  3.34s/it]Training Epoch38:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:50,  3.35s/it]Training Epoch38:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:47,  3.35s/it]Training Epoch38:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:43,  3.33s/it]Training Epoch38:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:40,  3.34s/it]Training Epoch38:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:37,  3.37s/it]Training Epoch38:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:33,  3.36s/it]Training Epoch38:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:30,  3.34s/it]Training Epoch38:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:26,  3.34s/it]Training Epoch38:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.31s/it]Training Epoch38:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.33s/it]Training Epoch38:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.33s/it]Training Epoch38:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.31s/it]Training Epoch38:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.30s/it]Training Epoch38:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.31s/it]Training Epoch38:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:03,  3.33s/it]Training Epoch38:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.33s/it]Training Epoch38:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.34s/it]Training Epoch38:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:53,  3.34s/it]Training Epoch38:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:50,  3.34s/it]Training Epoch38:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.34s/it]Training Epoch38:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:43,  3.32s/it]Training Epoch38:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:39,  3.29s/it]Training Epoch38:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.28s/it]Training Epoch38:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:32,  3.26s/it]Training Epoch38:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.25s/it]Training Epoch38:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.26s/it]Training Epoch38:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:22,  3.25s/it]Training Epoch38:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.25s/it]Training Epoch38:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.25s/it]Training Epoch38:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.26s/it]Training Epoch38:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.27s/it]Training Epoch38:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.27s/it]Training Epoch38:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.28s/it]Training Epoch38: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch38: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.0001234881638083607

 step 1 is completed and loss is 0.0001987578289117664

 step 2 is completed and loss is 3.9695856685284525e-05

 step 3 is completed and loss is 0.00010572963219601661

 step 4 is completed and loss is 7.998396176844835e-05

 step 5 is completed and loss is 5.131813304615207e-05

 step 6 is completed and loss is 0.00037664014962501824

 step 7 is completed and loss is 5.858918302692473e-05

 step 8 is completed and loss is 8.004539995454252e-05

 step 9 is completed and loss is 4.774198168888688e-05

 step 10 is completed and loss is 0.0006734036142006516

 step 11 is completed and loss is 0.0009037860436365008

 step 12 is completed and loss is 0.00023425939434673637

 step 13 is completed and loss is 7.319179712794721e-05

 step 14 is completed and loss is 5.1258648454677314e-05

 step 15 is completed and loss is 3.71926071238704e-05

 step 16 is completed and loss is 0.00017759829643182456

 step 17 is completed and loss is 0.0001254586095456034

 step 18 is completed and loss is 5.543078441405669e-05

 step 19 is completed and loss is 0.00018569831445347518

 step 20 is completed and loss is 7.831674884073436e-05

 step 21 is completed and loss is 7.110579463187605e-05

 step 22 is completed and loss is 0.0003331604821141809

 step 23 is completed and loss is 0.00015007104957476258

 step 24 is completed and loss is 6.812559877289459e-05

 step 25 is completed and loss is 0.00041582793346606195

 step 26 is completed and loss is 7.664802978979424e-05

 step 27 is completed and loss is 0.0002883848501369357

 step 28 is completed and loss is 0.00010877013846766204

 step 29 is completed and loss is 9.870036592474207e-05

 step 30 is completed and loss is 0.00011985661694779992

 step 31 is completed and loss is 1.6748736015870236e-05

 step 32 is completed and loss is 5.1198865548940375e-05

 step 33 is completed and loss is 7.706567703280598e-05

 step 34 is completed and loss is 0.00011258529411861673

 step 35 is completed and loss is 0.00018099931185133755

 step 36 is completed and loss is 1.8417636965750717e-05

 step 37 is completed and loss is 6.246369594009593e-05

 step 38 is completed and loss is 9.321684774477035e-05

 step 39 is completed and loss is 6.55629119137302e-05

 step 40 is completed and loss is 0.00012802251148968935

 step 41 is completed and loss is 4.95296080771368e-05

 step 42 is completed and loss is 7.676771201658994e-05

 step 43 is completed and loss is 6.538340676343068e-05

 step 44 is completed and loss is 2.34838171309093e-05

 step 45 is completed and loss is 0.00018737709615379572

 step 46 is completed and loss is 2.884811328840442e-05

 step 47 is completed and loss is 8.546940807718784e-05

 step 48 is completed and loss is 0.00045462619164027274

 step 49 is completed and loss is 8.272772538475692e-05

 step 50 is completed and loss is 8.648227958474308e-05

 step 51 is completed and loss is 6.145048973849043e-05

 step 52 is completed and loss is 0.002417981158941984

 step 53 is completed and loss is 0.0002711578272283077

 step 54 is completed and loss is 4.899377381661907e-05

 step 55 is completed and loss is 0.001175776938907802

 step 56 is completed and loss is 4.8993817472364753e-05

 step 57 is completed and loss is 0.0002517192915547639

 step 58 is completed and loss is 7.390569953713566e-05

 step 59 is completed and loss is 0.00020715515711344779

 step 60 is completed and loss is 8.099939441308379e-05

 step 61 is completed and loss is 7.438203465426341e-05

 step 62 is completed and loss is 8.153438102453947e-05

 step 63 is completed and loss is 0.0005868247244507074

 step 64 is completed and loss is 0.00022740465647075325

 step 65 is completed and loss is 8.403892570640892e-05

 step 66 is completed and loss is 0.0005096417153254151

 step 67 is completed and loss is 5.531102215172723e-05

 step 68 is completed and loss is 0.00016670013428665698

 step 69 is completed and loss is 0.00015615133452229202

 step 70 is completed and loss is 0.00018195371376350522

 step 71 is completed and loss is 0.00021245911193545908

 step 72 is completed and loss is 0.000393372232792899

 step 73 is completed and loss is 8.73169774422422e-05

 step 74 is completed and loss is 0.00011425527918618172

 step 75 is completed and loss is 0.00027801579562947154

 step 76 is completed and loss is 0.00013714075612369925

 step 77 is completed and loss is 7.7542252256535e-05

 step 78 is completed and loss is 0.00017587753245607018

 step 79 is completed and loss is 0.0006308596348389983

 step 80 is completed and loss is 0.0002898745588026941

 step 81 is completed and loss is 0.00011097739479737356

 step 82 is completed and loss is 0.00019094634626526386

 step 83 is completed and loss is 0.0001590702886460349

 step 84 is completed and loss is 0.00010972438030876219

 step 85 is completed and loss is 0.00010561384988250211

 step 86 is completed and loss is 8.606540359323844e-05

 step 87 is completed and loss is 0.00013493464211933315

 step 88 is completed and loss is 0.00023164358572103083

 step 89 is completed and loss is 6.675478653050959e-05

 step 90 is completed and loss is 0.0006908813375048339

 step 91 is completed and loss is 0.00016472565766889602
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.38it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.38it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.43it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.41it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.41it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:31,  1.42it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:30,  1.40it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.41it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.42it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:28,  1.42it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.46it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.45it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:24,  1.49it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.51it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.50it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.47it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.48it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.47it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:20,  1.50it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.50it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.51it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:18,  1.51it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.50it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.50it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:16,  1.51it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.55it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.52it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.49it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:12,  1.46it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.45it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.49it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.49it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.49it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.47it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.48it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.48it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.48it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.51it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.55it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.55it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.57it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.59it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.62it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.57it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.54it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.52it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.52it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.54it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 39: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 303.4491792730005s
Training Epoch39:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch39:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.26s/it]Training Epoch39:   2%|[34mâ–         [0m| 2/92 [00:06<04:53,  3.26s/it]Training Epoch39:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:47,  3.23s/it]Training Epoch39:   4%|[34mâ–         [0m| 4/92 [00:12<04:45,  3.25s/it]Training Epoch39:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:42,  3.25s/it]Training Epoch39:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:38,  3.24s/it]Training Epoch39:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:33,  3.21s/it]Training Epoch39:   9%|[34mâ–Š         [0m| 8/92 [00:25<04:31,  3.24s/it]Training Epoch39:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:28,  3.24s/it]Training Epoch39:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:26,  3.25s/it]Training Epoch39:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:21,  3.23s/it]Training Epoch39:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:38<04:19,  3.24s/it]Training Epoch39:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:17,  3.25s/it]Training Epoch39:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:14,  3.27s/it]Training Epoch39:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:48<04:11,  3.26s/it]Training Epoch39:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:51<04:07,  3.25s/it]Training Epoch39:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:04,  3.26s/it]Training Epoch39:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:02,  3.27s/it]Training Epoch39:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:01<03:59,  3.28s/it]Training Epoch39:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:55,  3.27s/it]Training Epoch39:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:50,  3.25s/it]Training Epoch39:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:49,  3.27s/it]Training Epoch39:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:14<03:46,  3.29s/it]Training Epoch39:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:41,  3.26s/it]Training Epoch39:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:37,  3.24s/it]Training Epoch39:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:33,  3.23s/it]Training Epoch39:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:27<03:30,  3.24s/it]Training Epoch39:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:27,  3.24s/it]Training Epoch39:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:26,  3.28s/it]Training Epoch39:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:20,  3.24s/it]Training Epoch39:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:40<03:16,  3.22s/it]Training Epoch39:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:43<03:12,  3.22s/it]Training Epoch39:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:09,  3.21s/it]Training Epoch39:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:05,  3.20s/it]Training Epoch39:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:53<03:02,  3.20s/it]Training Epoch39:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:56<02:59,  3.20s/it]Training Epoch39:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [01:59<02:57,  3.22s/it]Training Epoch39:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:03<02:54,  3.24s/it]Training Epoch39:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:06<02:52,  3.25s/it]Training Epoch39:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:09<02:50,  3.28s/it]Training Epoch39:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:46,  3.26s/it]Training Epoch39:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:16<02:43,  3.26s/it]Training Epoch39:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:19<02:39,  3.25s/it]Training Epoch39:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:22<02:35,  3.25s/it]Training Epoch39:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:25<02:31,  3.22s/it]Training Epoch39:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:29<02:28,  3.22s/it]Training Epoch39:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:32<02:24,  3.22s/it]Training Epoch39:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:35<02:21,  3.22s/it]Training Epoch39:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:38<02:18,  3.22s/it]Training Epoch39:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:42<02:14,  3.21s/it]Training Epoch39:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:45<02:13,  3.25s/it]Training Epoch39:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:48<02:09,  3.25s/it]Training Epoch39:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:51<02:06,  3.24s/it]Training Epoch39:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:55<02:02,  3.22s/it]Training Epoch39:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:58<02:00,  3.25s/it]Training Epoch39:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:01<01:57,  3.27s/it]Training Epoch39:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:04<01:54,  3.26s/it]Training Epoch39:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:08<01:50,  3.26s/it]Training Epoch39:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:11<01:48,  3.28s/it]Training Epoch39:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:14<01:44,  3.26s/it]Training Epoch39:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:17<01:41,  3.27s/it]Training Epoch39:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:21<01:37,  3.24s/it]Training Epoch39:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:24<01:34,  3.24s/it]Training Epoch39:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:27<01:31,  3.26s/it]Training Epoch39:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:30<01:28,  3.26s/it]Training Epoch39:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:34<01:24,  3.26s/it]Training Epoch39:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:37<01:21,  3.25s/it]Training Epoch39:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:40<01:18,  3.27s/it]Training Epoch39:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:44<01:15,  3.27s/it]Training Epoch39:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:47<01:11,  3.24s/it]Training Epoch39:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:50<01:07,  3.23s/it]Training Epoch39:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:53<01:04,  3.25s/it]Training Epoch39:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:56<01:01,  3.25s/it]Training Epoch39:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:00<00:58,  3.26s/it]Training Epoch39:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:03<00:55,  3.28s/it]Training Epoch39:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:06<00:53,  3.31s/it]Training Epoch39:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:10<00:49,  3.28s/it]Training Epoch39:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:13<00:46,  3.29s/it]Training Epoch39:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:16<00:42,  3.27s/it]Training Epoch39:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:20<00:39,  3.29s/it]Training Epoch39:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:23<00:36,  3.28s/it]Training Epoch39:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:26<00:33,  3.32s/it]Training Epoch39:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:30<00:31,  3.45s/it]Training Epoch39:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:34<00:28,  3.52s/it]Training Epoch39:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:37<00:25,  3.60s/it]Training Epoch39:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:41<00:21,  3.63s/it]Training Epoch39:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:18,  3.67s/it]Training Epoch39:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:14,  3.74s/it]Training Epoch39:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:11,  3.75s/it]Training Epoch39:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:07,  3.70s/it]Training Epoch39:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.79s/it]Training Epoch39: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.77s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch39: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.0001304002944380045

 step 1 is completed and loss is 0.00017265854694414884

 step 2 is completed and loss is 4.023232395411469e-05

 step 3 is completed and loss is 7.02104953234084e-05

 step 4 is completed and loss is 0.00010030613339040428

 step 5 is completed and loss is 4.458324838196859e-05

 step 6 is completed and loss is 0.0004957523779012263

 step 7 is completed and loss is 5.590723594650626e-05

 step 8 is completed and loss is 6.943695188965648e-05

 step 9 is completed and loss is 4.470239218790084e-05

 step 10 is completed and loss is 0.0005312522989697754

 step 11 is completed and loss is 0.001527623157016933

 step 12 is completed and loss is 0.0002526102471165359

 step 13 is completed and loss is 7.343021570704877e-05

 step 14 is completed and loss is 4.2199186282232404e-05

 step 15 is completed and loss is 4.60137271147687e-05

 step 16 is completed and loss is 0.0001717001141514629

 step 17 is completed and loss is 0.00013106063124723732

 step 18 is completed and loss is 6.210611172718927e-05

 step 19 is completed and loss is 0.00020786332606803626

 step 20 is completed and loss is 4.517926208791323e-05

 step 21 is completed and loss is 8.701778278918937e-05

 step 22 is completed and loss is 0.0004352523246780038

 step 23 is completed and loss is 0.0001186658046208322

 step 24 is completed and loss is 6.693362956866622e-05

 step 25 is completed and loss is 0.000139938885695301

 step 26 is completed and loss is 8.523014548700303e-05

 step 27 is completed and loss is 0.0001574034831719473

 step 28 is completed and loss is 0.00010471800487721339

 step 29 is completed and loss is 0.00010936829494312406

 step 30 is completed and loss is 0.00014899755478836596

 step 31 is completed and loss is 1.7583170119905844e-05

 step 32 is completed and loss is 9.089172090170905e-05

 step 33 is completed and loss is 7.563534018117934e-05

 step 34 is completed and loss is 8.737609459785745e-05

 step 35 is completed and loss is 0.00023766591039020568

 step 36 is completed and loss is 1.5020247701613698e-05

 step 37 is completed and loss is 9.834230877459049e-05

 step 38 is completed and loss is 0.00010453978029545397

 step 39 is completed and loss is 5.31658879481256e-05

 step 40 is completed and loss is 0.00012599624460563064

 step 41 is completed and loss is 3.9457157981814817e-05

 step 42 is completed and loss is 7.146332791307941e-05

 step 43 is completed and loss is 5.4894051572773606e-05

 step 44 is completed and loss is 2.1099722289363854e-05

 step 45 is completed and loss is 0.00024279157514683902

 step 46 is completed and loss is 2.503356517991051e-05

 step 47 is completed and loss is 6.210608262335882e-05

 step 48 is completed and loss is 0.0004766104684676975

 step 49 is completed and loss is 7.307261694222689e-05

 step 50 is completed and loss is 9.482635505264625e-05

 step 51 is completed and loss is 5.984116796753369e-05

 step 52 is completed and loss is 0.002280417364090681

 step 53 is completed and loss is 0.00034884977503679693

 step 54 is completed and loss is 3.27819689118769e-05

 step 55 is completed and loss is 0.0012534480774775147

 step 56 is completed and loss is 4.4165914005134255e-05

 step 57 is completed and loss is 0.00022639663075096905

 step 58 is completed and loss is 5.823106403113343e-05

 step 59 is completed and loss is 0.0002582760062068701

 step 60 is completed and loss is 9.655444591771811e-05

 step 61 is completed and loss is 9.416812827112153e-05

 step 62 is completed and loss is 9.440697613172233e-05

 step 63 is completed and loss is 0.0005207457579672337

 step 64 is completed and loss is 0.0002546313335187733

 step 65 is completed and loss is 8.99392762221396e-05

 step 66 is completed and loss is 0.0006018198328092694

 step 67 is completed and loss is 5.3821167966816574e-05

 step 68 is completed and loss is 0.00021562357142101973

 step 69 is completed and loss is 0.00014125148300081491

 step 70 is completed and loss is 0.00019607561989687383

 step 71 is completed and loss is 0.0001814147544791922

 step 72 is completed and loss is 0.00028228017617948353

 step 73 is completed and loss is 8.350256393896416e-05

 step 74 is completed and loss is 0.00010585188283585012

 step 75 is completed and loss is 0.00016962042718660086

 step 76 is completed and loss is 0.00012009614874841645

 step 77 is completed and loss is 8.135686221066862e-05

 step 78 is completed and loss is 0.00019232340855523944

 step 79 is completed and loss is 0.0012339295353740454

 step 80 is completed and loss is 0.00029833411099389195

 step 81 is completed and loss is 0.00010448122338857502

 step 82 is completed and loss is 0.0001535857009002939

 step 83 is completed and loss is 0.00020281175966374576

 step 84 is completed and loss is 8.826979319564998e-05

 step 85 is completed and loss is 0.00017653337272349745

 step 86 is completed and loss is 0.00012611546844709665

 step 87 is completed and loss is 0.0001518599019618705

 step 88 is completed and loss is 0.0002003630215767771

 step 89 is completed and loss is 5.507289097295143e-05

 step 90 is completed and loss is 0.0006523075862787664

 step 91 is completed and loss is 0.00018945186457131058
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:01<00:52,  1.08s/it]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:02<00:49,  1.03s/it]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:40,  1.16it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:03<00:36,  1.25it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:04<00:33,  1.34it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:31,  1.38it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:05<00:35,  1.22it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:06<00:36,  1.15it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:07<00:34,  1.18it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:08<00:33,  1.20it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:09<00:31,  1.24it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:09<00:28,  1.31it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:10<00:26,  1.38it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:11<00:25,  1.40it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:11<00:24,  1.43it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:12<00:23,  1.47it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:13<00:22,  1.45it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:13<00:21,  1.48it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:14<00:20,  1.48it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:15<00:19,  1.55it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:15<00:18,  1.59it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:16<00:17,  1.61it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:16<00:16,  1.63it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:17<00:16,  1.58it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:18<00:16,  1.56it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:18<00:15,  1.54it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:19<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:20<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:20<00:14,  1.50it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:21<00:13,  1.49it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:22<00:12,  1.49it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:12,  1.48it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:23<00:11,  1.45it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:24<00:10,  1.51it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:09,  1.54it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:25<00:09,  1.55it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:26<00:08,  1.52it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:08,  1.49it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:27<00:07,  1.46it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:28<00:06,  1.50it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:06,  1.48it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:29<00:05,  1.45it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:30<00:04,  1.45it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:04,  1.45it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:31<00:03,  1.45it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:32<00:02,  1.46it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:32<00:01,  1.51it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:33<00:01,  1.53it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:34<00:00,  1.54it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.52it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.43it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.5800)
Epoch 40: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.75040752699897s
Training Epoch40:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch40:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.26s/it]Training Epoch40:   2%|[34mâ–         [0m| 2/92 [00:06<04:53,  3.26s/it]Training Epoch40:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.27s/it]Training Epoch40:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.26s/it]Training Epoch40:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:43,  3.26s/it]Training Epoch40:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.26s/it]Training Epoch40:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.26s/it]Training Epoch40:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch40:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.32s/it]Training Epoch40:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:32,  3.32s/it]Training Epoch40:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.31s/it]Training Epoch40:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch40:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:18,  3.27s/it]Training Epoch40:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.30s/it]Training Epoch40:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.30s/it]Training Epoch40:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.29s/it]Training Epoch40:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:06,  3.28s/it]Training Epoch40:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:03,  3.29s/it]Training Epoch40:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.28s/it]Training Epoch40:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.28s/it]Training Epoch40:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:56,  3.33s/it]Training Epoch40:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:54,  3.35s/it]Training Epoch40:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:50,  3.34s/it]Training Epoch40:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:48,  3.36s/it]Training Epoch40:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:44,  3.34s/it]Training Epoch40:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:40,  3.34s/it]Training Epoch40:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:37,  3.35s/it]Training Epoch40:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:34,  3.35s/it]Training Epoch40:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:30,  3.34s/it]Training Epoch40:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:26,  3.33s/it]Training Epoch40:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:22,  3.32s/it]Training Epoch40:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:18,  3.30s/it]Training Epoch40:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:14,  3.29s/it]Training Epoch40:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.30s/it]Training Epoch40:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:07,  3.30s/it]Training Epoch40:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:03,  3.27s/it]Training Epoch40:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<02:59,  3.26s/it]Training Epoch40:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:55,  3.26s/it]Training Epoch40:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:52,  3.26s/it]Training Epoch40:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:50,  3.28s/it]Training Epoch40:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:48,  3.31s/it]Training Epoch40:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:45,  3.31s/it]Training Epoch40:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:41,  3.30s/it]Training Epoch40:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.30s/it]Training Epoch40:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:35,  3.30s/it]Training Epoch40:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:31,  3.29s/it]Training Epoch40:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.32s/it]Training Epoch40:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.31s/it]Training Epoch40:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:21,  3.29s/it]Training Epoch40:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.30s/it]Training Epoch40:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.30s/it]Training Epoch40:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.30s/it]Training Epoch40:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.30s/it]Training Epoch40:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:04,  3.27s/it]Training Epoch40:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.28s/it]Training Epoch40:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:58,  3.30s/it]Training Epoch40:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.31s/it]Training Epoch40:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:53,  3.33s/it]Training Epoch40:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.33s/it]Training Epoch40:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:46,  3.33s/it]Training Epoch40:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.31s/it]Training Epoch40:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.32s/it]Training Epoch40:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.32s/it]Training Epoch40:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.31s/it]Training Epoch40:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.31s/it]Training Epoch40:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.30s/it]Training Epoch40:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.29s/it]Training Epoch40:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.31s/it]Training Epoch40:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.31s/it]Training Epoch40:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.27s/it]Training Epoch40:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.29s/it]Training Epoch40:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.31s/it]Training Epoch40:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:02,  3.28s/it]Training Epoch40:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.31s/it]Training Epoch40:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.31s/it]Training Epoch40:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:53,  3.35s/it]Training Epoch40:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:50,  3.37s/it]Training Epoch40:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:47,  3.37s/it]Training Epoch40:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.35s/it]Training Epoch40:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:40,  3.35s/it]Training Epoch40:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.33s/it]Training Epoch40:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.31s/it]Training Epoch40:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.33s/it]Training Epoch40:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.34s/it]Training Epoch40:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.37s/it]Training Epoch40:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:20,  3.35s/it]Training Epoch40:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.33s/it]Training Epoch40:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.33s/it]Training Epoch40:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:10,  3.35s/it]Training Epoch40:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.33s/it]Training Epoch40:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.34s/it]Training Epoch40: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.32s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch40: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 9.244008106179535e-05

 step 1 is completed and loss is 0.00020698114531114697

 step 2 is completed and loss is 3.9815055060898885e-05

 step 3 is completed and loss is 0.0001137745421146974

 step 4 is completed and loss is 8.320243068737909e-05

 step 5 is completed and loss is 4.6132841816870496e-05

 step 6 is completed and loss is 0.0003039700095541775

 step 7 is completed and loss is 6.776733789592981e-05

 step 8 is completed and loss is 8.660173625685275e-05

 step 9 is completed and loss is 5.0364440539851785e-05

 step 10 is completed and loss is 0.00045567075721919537

 step 11 is completed and loss is 0.0008938557584770024

 step 12 is completed and loss is 0.00030199607135728

 step 13 is completed and loss is 5.61459492018912e-05

 step 14 is completed and loss is 5.096052336739376e-05

 step 15 is completed and loss is 4.792098479811102e-05

 step 16 is completed and loss is 0.00024796597426757216

 step 17 is completed and loss is 0.00014333627768792212

 step 18 is completed and loss is 6.115243741078302e-05

 step 19 is completed and loss is 0.00015048311615828425

 step 20 is completed and loss is 5.3702329751104116e-05

 step 21 is completed and loss is 6.687402492389083e-05

 step 22 is completed and loss is 0.00032404702506028116

 step 23 is completed and loss is 8.964113658294082e-05

 step 24 is completed and loss is 6.323842535493895e-05

 step 25 is completed and loss is 0.0001393421262037009

 step 26 is completed and loss is 5.5966960644582286e-05

 step 27 is completed and loss is 0.00022945081582292914

 step 28 is completed and loss is 0.00011371609434718266

 step 29 is completed and loss is 8.099942351691425e-05

 step 30 is completed and loss is 9.04752014321275e-05

 step 31 is completed and loss is 1.8417609680909663e-05

 step 32 is completed and loss is 9.857943950919434e-05

 step 33 is completed and loss is 8.964109292719513e-05

 step 34 is completed and loss is 0.00010483842197572812

 step 35 is completed and loss is 0.0001755193225108087

 step 36 is completed and loss is 1.400698056386318e-05

 step 37 is completed and loss is 6.836417014710605e-05

 step 38 is completed and loss is 0.00010728171037044376

 step 39 is completed and loss is 5.644393968395889e-05

 step 40 is completed and loss is 9.041604062076658e-05

 step 41 is completed and loss is 2.539114939281717e-05

 step 42 is completed and loss is 7.390703103737906e-05

 step 43 is completed and loss is 5.078165850136429e-05

 step 44 is completed and loss is 2.39606924878899e-05

 step 45 is completed and loss is 0.00022497850295621902

 step 46 is completed and loss is 3.224535612389445e-05

 step 47 is completed and loss is 6.383453728631139e-05

 step 48 is completed and loss is 0.00042658031452447176

 step 49 is completed and loss is 7.85557713243179e-05

 step 50 is completed and loss is 7.77213936089538e-05

 step 51 is completed and loss is 7.927099068183452e-05

 step 52 is completed and loss is 0.001430812873877585

 step 53 is completed and loss is 0.00031917987507767975

 step 54 is completed and loss is 4.2795065382961184e-05

 step 55 is completed and loss is 0.001695728860795498

 step 56 is completed and loss is 4.947039997205138e-05

 step 57 is completed and loss is 0.00022192817414179444

 step 58 is completed and loss is 5.686041549779475e-05

 step 59 is completed and loss is 0.0006740273674950004

 step 60 is completed and loss is 9.274052717955783e-05

 step 61 is completed and loss is 9.190330456476659e-05

 step 62 is completed and loss is 9.142722410615534e-05

 step 63 is completed and loss is 0.0003349015023559332

 step 64 is completed and loss is 0.00027363430126570165

 step 65 is completed and loss is 9.85210353974253e-05

 step 66 is completed and loss is 0.0004743878962472081

 step 67 is completed and loss is 6.824436422903091e-05

 step 68 is completed and loss is 0.00020132356439717114

 step 69 is completed and loss is 0.00018433728837408125

 step 70 is completed and loss is 0.0002056725206784904

 step 71 is completed and loss is 0.00016747266636230052

 step 72 is completed and loss is 0.0005834542098455131

 step 73 is completed and loss is 7.164221460698172e-05

 step 74 is completed and loss is 0.00011598288256209344

 step 75 is completed and loss is 0.00017295766156166792

 step 76 is completed and loss is 0.00012766500003635883

 step 77 is completed and loss is 7.789969822624698e-05

 step 78 is completed and loss is 0.00021127573563717306

 step 79 is completed and loss is 0.0007264227606356144

 step 80 is completed and loss is 0.0002486396406311542

 step 81 is completed and loss is 8.3919643657282e-05

 step 82 is completed and loss is 0.00012003592564724386

 step 83 is completed and loss is 0.00017545983428135514

 step 84 is completed and loss is 0.00012855633394792676

 step 85 is completed and loss is 0.0001426833332516253

 step 86 is completed and loss is 0.00011944057769142091

 step 87 is completed and loss is 0.00014280098548624665

 step 88 is completed and loss is 0.00018909716163761914

 step 89 is completed and loss is 5.96622921875678e-05

 step 90 is completed and loss is 0.0010217673843726516

 step 91 is completed and loss is 0.0001106767012970522
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:29,  1.63it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:28,  1.71it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:27,  1.71it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:28,  1.63it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:27,  1.66it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:26,  1.66it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:25,  1.70it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:04<00:25,  1.64it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.57it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.55it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:06<00:25,  1.55it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.53it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.50it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:24,  1.49it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:23,  1.50it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:22,  1.47it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.47it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:21,  1.47it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:20,  1.48it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.50it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.51it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.52it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.52it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.52it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:16,  1.50it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.49it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:14,  1.48it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.48it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.47it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:12,  1.49it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.46it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.46it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.46it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.50it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.51it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.52it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.50it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:06,  1.50it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.53it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.57it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.57it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.57it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.55it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.53it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.51it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.55it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.56it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 41: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.83328612600053s
Training Epoch41:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch41:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.26s/it]Training Epoch41:   2%|[34mâ–         [0m| 2/92 [00:06<04:59,  3.33s/it]Training Epoch41:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:56,  3.33s/it]Training Epoch41:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.26s/it]Training Epoch41:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.27s/it]Training Epoch41:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.29s/it]Training Epoch41:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch41:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.32s/it]Training Epoch41:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:36,  3.33s/it]Training Epoch41:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:29,  3.29s/it]Training Epoch41:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:24,  3.26s/it]Training Epoch41:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.28s/it]Training Epoch41:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.30s/it]Training Epoch41:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.32s/it]Training Epoch41:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:16,  3.33s/it]Training Epoch41:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.31s/it]Training Epoch41:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.31s/it]Training Epoch41:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.32s/it]Training Epoch41:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.32s/it]Training Epoch41:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:59,  3.32s/it]Training Epoch41:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.32s/it]Training Epoch41:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:53,  3.33s/it]Training Epoch41:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:47,  3.30s/it]Training Epoch41:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:43,  3.29s/it]Training Epoch41:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:39,  3.27s/it]Training Epoch41:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:37,  3.30s/it]Training Epoch41:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:33,  3.28s/it]Training Epoch41:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.29s/it]Training Epoch41:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:26,  3.29s/it]Training Epoch41:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.32s/it]Training Epoch41:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:22,  3.32s/it]Training Epoch41:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:19,  3.32s/it]Training Epoch41:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:13,  3.28s/it]Training Epoch41:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.30s/it]Training Epoch41:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:09,  3.32s/it]Training Epoch41:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:05,  3.30s/it]Training Epoch41:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.32s/it]Training Epoch41:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:59,  3.33s/it]Training Epoch41:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:55,  3.31s/it]Training Epoch41:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.30s/it]Training Epoch41:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:48,  3.30s/it]Training Epoch41:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:44,  3.28s/it]Training Epoch41:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:40,  3.27s/it]Training Epoch41:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:35,  3.25s/it]Training Epoch41:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:33,  3.26s/it]Training Epoch41:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:31,  3.29s/it]Training Epoch41:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:28,  3.30s/it]Training Epoch41:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.30s/it]Training Epoch41:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.30s/it]Training Epoch41:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.30s/it]Training Epoch41:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.31s/it]Training Epoch41:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:12,  3.31s/it]Training Epoch41:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.30s/it]Training Epoch41:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.30s/it]Training Epoch41:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.30s/it]Training Epoch41:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:59,  3.31s/it]Training Epoch41:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:55,  3.31s/it]Training Epoch41:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.30s/it]Training Epoch41:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.30s/it]Training Epoch41:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.30s/it]Training Epoch41:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.29s/it]Training Epoch41:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:38,  3.28s/it]Training Epoch41:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:34,  3.25s/it]Training Epoch41:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:31,  3.27s/it]Training Epoch41:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:27,  3.26s/it]Training Epoch41:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:24,  3.25s/it]Training Epoch41:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:21,  3.27s/it]Training Epoch41:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:18,  3.28s/it]Training Epoch41:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:15,  3.30s/it]Training Epoch41:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.29s/it]Training Epoch41:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.26s/it]Training Epoch41:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.25s/it]Training Epoch41:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:01,  3.22s/it]Training Epoch41:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:57,  3.20s/it]Training Epoch41:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:54,  3.21s/it]Training Epoch41:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.25s/it]Training Epoch41:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:49,  3.27s/it]Training Epoch41:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:46,  3.29s/it]Training Epoch41:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.30s/it]Training Epoch41:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:39,  3.31s/it]Training Epoch41:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:36,  3.30s/it]Training Epoch41:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:32,  3.28s/it]Training Epoch41:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.29s/it]Training Epoch41:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.29s/it]Training Epoch41:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:22,  3.26s/it]Training Epoch41:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.27s/it]Training Epoch41:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.23s/it]Training Epoch41:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:12,  3.22s/it]Training Epoch41:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.23s/it]Training Epoch41:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.25s/it]Training Epoch41:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.24s/it]Training Epoch41: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.21s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch41: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 0.00010805376950884238

 step 1 is completed and loss is 0.00017766462406143546

 step 2 is completed and loss is 3.778861719183624e-05

 step 3 is completed and loss is 0.00010727906919782981

 step 4 is completed and loss is 9.529994713375345e-05

 step 5 is completed and loss is 4.8993664677254856e-05

 step 6 is completed and loss is 0.0004391257534734905

 step 7 is completed and loss is 5.697973756468855e-05

 step 8 is completed and loss is 9.84615326160565e-05

 step 9 is completed and loss is 4.26162441726774e-05

 step 10 is completed and loss is 0.0006586477975361049

 step 11 is completed and loss is 0.0011151356156915426

 step 12 is completed and loss is 0.00022055710724089295

 step 13 is completed and loss is 6.317892984952778e-05

 step 14 is completed and loss is 4.923209053231403e-05

 step 15 is completed and loss is 4.386805812828243e-05

 step 16 is completed and loss is 0.00027292745653539896

 step 17 is completed and loss is 9.714983752928674e-05

 step 18 is completed and loss is 5.346391844796017e-05

 step 19 is completed and loss is 0.00018736853962764144

 step 20 is completed and loss is 5.0066639232682064e-05

 step 21 is completed and loss is 6.0139242123113945e-05

 step 22 is completed and loss is 0.00040398730197921395

 step 23 is completed and loss is 0.00010877184104174376

 step 24 is completed and loss is 6.985416257521138e-05

 step 25 is completed and loss is 0.00014339473273139447

 step 26 is completed and loss is 5.2450606744969264e-05

 step 27 is completed and loss is 0.00016473211871925741

 step 28 is completed and loss is 0.0001394599094055593

 step 29 is completed and loss is 9.810439951252192e-05

 step 30 is completed and loss is 9.726954158395529e-05

 step 31 is completed and loss is 1.6927519027376547e-05

 step 32 is completed and loss is 8.284586510853842e-05

 step 33 is completed and loss is 8.10587516753003e-05

 step 34 is completed and loss is 6.919844599906355e-05

 step 35 is completed and loss is 0.00016645912546664476

 step 36 is completed and loss is 1.662953400227707e-05

 step 37 is completed and loss is 7.235737575683743e-05

 step 38 is completed and loss is 8.24892777018249e-05

 step 39 is completed and loss is 4.625212022801861e-05

 step 40 is completed and loss is 0.00010311057849321514

 step 41 is completed and loss is 4.452321445569396e-05

 step 42 is completed and loss is 5.972207145532593e-05

 step 43 is completed and loss is 4.8933921789284796e-05

 step 44 is completed and loss is 2.5093162548728287e-05

 step 45 is completed and loss is 0.00019041739869862795

 step 46 is completed and loss is 1.847725798143074e-05

 step 47 is completed and loss is 8.093981159618124e-05

 step 48 is completed and loss is 0.00037004746263846755

 step 49 is completed and loss is 8.987964247353375e-05

 step 50 is completed and loss is 8.546924073016271e-05

 step 51 is completed and loss is 6.580127228517085e-05

 step 52 is completed and loss is 0.0015549268573522568

 step 53 is completed and loss is 0.0003932870749849826

 step 54 is completed and loss is 4.070909562869929e-05

 step 55 is completed and loss is 0.0017764684744179249

 step 56 is completed and loss is 3.564294092939235e-05

 step 57 is completed and loss is 0.0002479632676113397

 step 58 is completed and loss is 5.2211496949894354e-05

 step 59 is completed and loss is 0.0004238798574078828

 step 60 is completed and loss is 0.00010698424011934549

 step 61 is completed and loss is 7.640842522960156e-05

 step 62 is completed and loss is 0.00011693412670865655

 step 63 is completed and loss is 0.00024786090943962336

 step 64 is completed and loss is 0.000283464090898633

 step 65 is completed and loss is 9.601825149729848e-05

 step 66 is completed and loss is 0.0003926183271687478

 step 67 is completed and loss is 5.4715274018235505e-05

 step 68 is completed and loss is 0.00020472044707275927

 step 69 is completed and loss is 0.00011437470675446093

 step 70 is completed and loss is 0.00016157308709807694

 step 71 is completed and loss is 0.00023724482161924243

 step 72 is completed and loss is 0.0004952229792252183

 step 73 is completed and loss is 0.00010090556315844879

 step 74 is completed and loss is 9.947468061000109e-05

 step 75 is completed and loss is 0.0002068060275632888

 step 76 is completed and loss is 0.00011866541171912104

 step 77 is completed and loss is 8.391957089770585e-05

 step 78 is completed and loss is 0.0002389803994446993

 step 79 is completed and loss is 0.0007127487915568054

 step 80 is completed and loss is 0.00027944688918069005

 step 81 is completed and loss is 0.00010239468247164041

 step 82 is completed and loss is 0.00015233687008731067

 step 83 is completed and loss is 0.0001596053916728124

 step 84 is completed and loss is 0.00011562404688447714

 step 85 is completed and loss is 0.00011586471373448148

 step 86 is completed and loss is 9.214453893946484e-05

 step 87 is completed and loss is 0.00014905900752637535

 step 88 is completed and loss is 0.00017604815366212279

 step 89 is completed and loss is 7.563496910734102e-05

 step 90 is completed and loss is 0.0006897713174112141

 step 91 is completed and loss is 9.911494998959824e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.40it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.42it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.46it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.52it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.49it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.50it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.50it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.49it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.48it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.49it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.50it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.61it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:22,  1.61it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.58it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.55it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.57it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.58it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.56it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.59it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.54it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.56it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.56it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:13,  1.58it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.58it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.54it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.54it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.55it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.50it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:10,  1.47it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.49it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.50it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:08,  1.48it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.48it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.46it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:06,  1.46it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.45it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.46it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:04,  1.49it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.48it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.47it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.43it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.45it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.46it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.48it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 42: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 302.52711809099856s
Training Epoch42:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch42:   1%|[34m          [0m| 1/92 [00:03<05:00,  3.30s/it]Training Epoch42:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.30s/it]Training Epoch42:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:54,  3.30s/it]Training Epoch42:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.28s/it]Training Epoch42:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.29s/it]Training Epoch42:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.27s/it]Training Epoch42:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.27s/it]Training Epoch42:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.27s/it]Training Epoch42:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:28,  3.24s/it]Training Epoch42:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:27,  3.27s/it]Training Epoch42:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:25,  3.28s/it]Training Epoch42:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.27s/it]Training Epoch42:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.29s/it]Training Epoch42:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:15,  3.28s/it]Training Epoch42:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.29s/it]Training Epoch42:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:08,  3.27s/it]Training Epoch42:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:04,  3.25s/it]Training Epoch42:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:01,  3.26s/it]Training Epoch42:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:01,  3.30s/it]Training Epoch42:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:58,  3.32s/it]Training Epoch42:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:55,  3.31s/it]Training Epoch42:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch42:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:46,  3.29s/it]Training Epoch42:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:42,  3.27s/it]Training Epoch42:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:39,  3.28s/it]Training Epoch42:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.28s/it]Training Epoch42:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:33,  3.28s/it]Training Epoch42:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:29,  3.27s/it]Training Epoch42:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:26,  3.28s/it]Training Epoch42:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:22,  3.27s/it]Training Epoch42:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:20,  3.28s/it]Training Epoch42:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:15,  3.27s/it]Training Epoch42:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:12,  3.27s/it]Training Epoch42:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:09,  3.26s/it]Training Epoch42:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:06,  3.27s/it]Training Epoch42:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:03,  3.28s/it]Training Epoch42:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:01,  3.31s/it]Training Epoch42:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:59,  3.32s/it]Training Epoch42:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:55,  3.32s/it]Training Epoch42:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:52,  3.31s/it]Training Epoch42:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:47,  3.29s/it]Training Epoch42:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:45,  3.31s/it]Training Epoch42:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:40,  3.28s/it]Training Epoch42:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:36,  3.26s/it]Training Epoch42:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.27s/it]Training Epoch42:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:31,  3.28s/it]Training Epoch42:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.31s/it]Training Epoch42:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:25,  3.30s/it]Training Epoch42:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:21,  3.29s/it]Training Epoch42:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:16,  3.26s/it]Training Epoch42:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:13,  3.27s/it]Training Epoch42:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:11,  3.28s/it]Training Epoch42:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:08,  3.29s/it]Training Epoch42:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:04,  3.29s/it]Training Epoch42:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:02,  3.30s/it]Training Epoch42:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:59,  3.31s/it]Training Epoch42:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:55,  3.31s/it]Training Epoch42:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:51,  3.29s/it]Training Epoch42:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:49,  3.31s/it]Training Epoch42:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:46,  3.32s/it]Training Epoch42:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:43,  3.33s/it]Training Epoch42:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:39,  3.30s/it]Training Epoch42:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:36,  3.32s/it]Training Epoch42:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:32,  3.29s/it]Training Epoch42:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:28,  3.29s/it]Training Epoch42:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.29s/it]Training Epoch42:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:21,  3.27s/it]Training Epoch42:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:18,  3.28s/it]Training Epoch42:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:15,  3.27s/it]Training Epoch42:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:12,  3.29s/it]Training Epoch42:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:09,  3.31s/it]Training Epoch42:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:06,  3.30s/it]Training Epoch42:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.29s/it]Training Epoch42:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:58,  3.25s/it]Training Epoch42:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:55,  3.25s/it]Training Epoch42:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:52,  3.27s/it]Training Epoch42:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.27s/it]Training Epoch42:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:45,  3.28s/it]Training Epoch42:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.27s/it]Training Epoch42:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.29s/it]Training Epoch42:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:36,  3.31s/it]Training Epoch42:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:33,  3.31s/it]Training Epoch42:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.32s/it]Training Epoch42:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.30s/it]Training Epoch42:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:22,  3.28s/it]Training Epoch42:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.28s/it]Training Epoch42:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.27s/it]Training Epoch42:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.27s/it]Training Epoch42:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.29s/it]Training Epoch42:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.30s/it]Training Epoch42:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:58<00:03,  3.28s/it]Training Epoch42: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch42: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 9.08311121747829e-05

 step 1 is completed and loss is 0.0001556153583806008

 step 2 is completed and loss is 4.2199186282232404e-05

 step 3 is completed and loss is 0.00010632564953994006

 step 4 is completed and loss is 8.06992975412868e-05

 step 5 is completed and loss is 6.139067409094423e-05

 step 6 is completed and loss is 0.0005670964601449668

 step 7 is completed and loss is 5.2986855735071003e-05

 step 8 is completed and loss is 7.450287375831977e-05

 step 9 is completed and loss is 4.738441202789545e-05

 step 10 is completed and loss is 0.0003769357281271368

 step 11 is completed and loss is 0.0012136729201301932

 step 12 is completed and loss is 0.00025439669843763113

 step 13 is completed and loss is 6.222519732546061e-05

 step 14 is completed and loss is 4.309313226258382e-05

 step 15 is completed and loss is 4.792098479811102e-05

 step 16 is completed and loss is 0.0001492927985964343

 step 17 is completed and loss is 0.00014017822104506195

 step 18 is completed and loss is 4.345083289081231e-05

 step 19 is completed and loss is 0.00018391237244941294

 step 20 is completed and loss is 4.684812665800564e-05

 step 21 is completed and loss is 5.870882159797475e-05

 step 22 is completed and loss is 0.00045853856136091053

 step 23 is completed and loss is 0.0001244450395461172

 step 24 is completed and loss is 7.116520282579586e-05

 step 25 is completed and loss is 0.0002958625555038452

 step 26 is completed and loss is 6.538378511322662e-05

 step 27 is completed and loss is 0.0001675938256084919

 step 28 is completed and loss is 0.0001514959440100938

 step 29 is completed and loss is 9.19656376936473e-05

 step 30 is completed and loss is 8.517129754181951e-05

 step 31 is completed and loss is 1.597388109075837e-05

 step 32 is completed and loss is 6.43706152914092e-05

 step 33 is completed and loss is 9.357423550682142e-05

 step 34 is completed and loss is 0.00011300168262096122

 step 35 is completed and loss is 0.0002306354872416705

 step 36 is completed and loss is 1.83580195880495e-05

 step 37 is completed and loss is 5.733800935558975e-05

 step 38 is completed and loss is 8.689953392604366e-05

 step 39 is completed and loss is 5.489429895533249e-05

 step 40 is completed and loss is 0.0001071037768269889

 step 41 is completed and loss is 5.012555266148411e-05

 step 42 is completed and loss is 7.17018119757995e-05

 step 43 is completed and loss is 7.348913641180843e-05

 step 44 is completed and loss is 2.3841454094508663e-05

 step 45 is completed and loss is 0.00014488716260530055

 step 46 is completed and loss is 2.4675977329025045e-05

 step 47 is completed and loss is 7.873458525864407e-05

 step 48 is completed and loss is 0.0006033837562426925

 step 49 is completed and loss is 8.195302507374436e-05

 step 50 is completed and loss is 8.07608594186604e-05

 step 51 is completed and loss is 5.704001523554325e-05

 step 52 is completed and loss is 0.00260179047472775

 step 53 is completed and loss is 0.00029642810113728046

 step 54 is completed and loss is 4.10665525123477e-05

 step 55 is completed and loss is 0.0016591966850683093

 step 56 is completed and loss is 4.36296068073716e-05

 step 57 is completed and loss is 0.00015846938185859472

 step 58 is completed and loss is 6.478701834566891e-05

 step 59 is completed and loss is 0.0003839687560684979

 step 60 is completed and loss is 0.00010746085899882019

 step 61 is completed and loss is 7.140269735828042e-05

 step 62 is completed and loss is 9.607584797777236e-05

 step 63 is completed and loss is 0.0005647556390613317

 step 64 is completed and loss is 0.0004033094737678766

 step 65 is completed and loss is 7.784059562254697e-05

 step 66 is completed and loss is 0.0007205881411209702

 step 67 is completed and loss is 5.245037391432561e-05

 step 68 is completed and loss is 0.00016872647393029183

 step 69 is completed and loss is 0.00019548051932360977

 step 70 is completed and loss is 0.0002043576823780313

 step 71 is completed and loss is 0.00020471325842663646

 step 72 is completed and loss is 0.0003993900027126074

 step 73 is completed and loss is 8.540979615645483e-05

 step 74 is completed and loss is 0.00011711598926922306

 step 75 is completed and loss is 0.00024291846784763038

 step 76 is completed and loss is 0.00013779626169707626

 step 77 is completed and loss is 8.856780914356932e-05

 step 78 is completed and loss is 0.00017820083303377032

 step 79 is completed and loss is 0.0008980365237221122

 step 80 is completed and loss is 0.0003225262917112559

 step 81 is completed and loss is 9.434917592443526e-05

 step 82 is completed and loss is 0.00018713469034992158

 step 83 is completed and loss is 0.00018266862025484443

 step 84 is completed and loss is 0.00014327435928862542

 step 85 is completed and loss is 0.0001774868869688362

 step 86 is completed and loss is 9.870042413240299e-05

 step 87 is completed and loss is 0.0001479258353356272

 step 88 is completed and loss is 0.00016568036517128348

 step 89 is completed and loss is 5.739735934184864e-05

 step 90 is completed and loss is 0.0008564043091610074

 step 91 is completed and loss is 9.929405496222898e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.41it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.39it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:34,  1.36it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.44it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.44it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.44it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.47it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.51it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:26,  1.53it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.54it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.52it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:24,  1.53it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.50it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.56it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.51it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.50it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.52it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.55it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.54it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.53it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.52it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.55it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.59it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.57it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.58it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:13,  1.60it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.60it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.59it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:11,  1.60it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.62it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.61it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:09,  1.66it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.64it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.62it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.57it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.56it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.58it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.56it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.58it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.55it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.61it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.60it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.58it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.55it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.56it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.58it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 43: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 302.57020184200155s
Training Epoch43:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch43:   1%|[34m          [0m| 1/92 [00:03<04:58,  3.28s/it]Training Epoch43:   2%|[34mâ–         [0m| 2/92 [00:06<04:55,  3.28s/it]Training Epoch43:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:54,  3.31s/it]Training Epoch43:   4%|[34mâ–         [0m| 4/92 [00:13<04:49,  3.29s/it]Training Epoch43:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.29s/it]Training Epoch43:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.27s/it]Training Epoch43:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.31s/it]Training Epoch43:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.32s/it]Training Epoch43:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:36,  3.33s/it]Training Epoch43:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:31,  3.31s/it]Training Epoch43:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:30,  3.34s/it]Training Epoch43:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:28,  3.35s/it]Training Epoch43:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.34s/it]Training Epoch43:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:19,  3.33s/it]Training Epoch43:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch43:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:14,  3.35s/it]Training Epoch43:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:10,  3.33s/it]Training Epoch43:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:07,  3.35s/it]Training Epoch43:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:04,  3.35s/it]Training Epoch43:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:01,  3.36s/it]Training Epoch43:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:57,  3.34s/it]Training Epoch43:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:54,  3.35s/it]Training Epoch43:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:50,  3.34s/it]Training Epoch43:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:46,  3.33s/it]Training Epoch43:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:43,  3.34s/it]Training Epoch43:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:40,  3.34s/it]Training Epoch43:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:35,  3.31s/it]Training Epoch43:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:31,  3.31s/it]Training Epoch43:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.32s/it]Training Epoch43:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.32s/it]Training Epoch43:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:22,  3.31s/it]Training Epoch43:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:18,  3.31s/it]Training Epoch43:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:14,  3.29s/it]Training Epoch43:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.31s/it]Training Epoch43:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:07,  3.30s/it]Training Epoch43:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:04,  3.30s/it]Training Epoch43:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:01,  3.30s/it]Training Epoch43:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:58,  3.30s/it]Training Epoch43:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:53,  3.28s/it]Training Epoch43:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:50,  3.28s/it]Training Epoch43:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:48,  3.30s/it]Training Epoch43:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.31s/it]Training Epoch43:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:41,  3.29s/it]Training Epoch43:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.29s/it]Training Epoch43:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:34,  3.30s/it]Training Epoch43:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:32,  3.32s/it]Training Epoch43:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.32s/it]Training Epoch43:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:26,  3.33s/it]Training Epoch43:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:24,  3.35s/it]Training Epoch43:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:20,  3.34s/it]Training Epoch43:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:15,  3.31s/it]Training Epoch43:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:12,  3.31s/it]Training Epoch43:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:10,  3.34s/it]Training Epoch43:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:07,  3.35s/it]Training Epoch43:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:03,  3.33s/it]Training Epoch43:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.33s/it]Training Epoch43:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:55,  3.31s/it]Training Epoch43:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.30s/it]Training Epoch43:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:48,  3.29s/it]Training Epoch43:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:44,  3.27s/it]Training Epoch43:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:41,  3.29s/it]Training Epoch43:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:38,  3.29s/it]Training Epoch43:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:35,  3.28s/it]Training Epoch43:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:32,  3.30s/it]Training Epoch43:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.30s/it]Training Epoch43:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.32s/it]Training Epoch43:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:22,  3.30s/it]Training Epoch43:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.31s/it]Training Epoch43:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:15,  3.30s/it]Training Epoch43:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.30s/it]Training Epoch43:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.30s/it]Training Epoch43:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.32s/it]Training Epoch43:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.30s/it]Training Epoch43:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.30s/it]Training Epoch43:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.32s/it]Training Epoch43:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.31s/it]Training Epoch43:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.31s/it]Training Epoch43:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.29s/it]Training Epoch43:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:42,  3.27s/it]Training Epoch43:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.29s/it]Training Epoch43:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.30s/it]Training Epoch43:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.30s/it]Training Epoch43:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.30s/it]Training Epoch43:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.33s/it]Training Epoch43:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.31s/it]Training Epoch43:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.31s/it]Training Epoch43:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.29s/it]Training Epoch43:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.29s/it]Training Epoch43:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.30s/it]Training Epoch43:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.29s/it]Training Epoch43:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.30s/it]Training Epoch43: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.30s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch43: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.00012336851796135306

 step 1 is completed and loss is 0.00020203605527058244

 step 2 is completed and loss is 4.082827945239842e-05

 step 3 is completed and loss is 7.68855243222788e-05

 step 4 is completed and loss is 7.360748713836074e-05

 step 5 is completed and loss is 5.9185367717873305e-05

 step 6 is completed and loss is 0.0009696115739643574

 step 7 is completed and loss is 5.525158849195577e-05

 step 8 is completed and loss is 9.673344902694225e-05

 step 9 is completed and loss is 5.584757309406996e-05

 step 10 is completed and loss is 0.0007184723508544266

 step 11 is completed and loss is 0.0006031489465385675

 step 12 is completed and loss is 0.00032916164491325617

 step 13 is completed and loss is 5.102025897940621e-05

 step 14 is completed and loss is 4.6252003812696785e-05

 step 15 is completed and loss is 3.9457496313843876e-05

 step 16 is completed and loss is 0.00020220536680426449

 step 17 is completed and loss is 0.00010060694330604747

 step 18 is completed and loss is 5.107982360641472e-05

 step 19 is completed and loss is 0.00014678826846648008

 step 20 is completed and loss is 4.660973354475573e-05

 step 21 is completed and loss is 6.323843990685418e-05

 step 22 is completed and loss is 0.0002939063706435263

 step 23 is completed and loss is 8.827002602629364e-05

 step 24 is completed and loss is 6.252329330891371e-05

 step 25 is completed and loss is 0.00014714877761434764

 step 26 is completed and loss is 7.539661601185799e-05

 step 27 is completed and loss is 0.0001950660371221602

 step 28 is completed and loss is 0.00015662092482671142

 step 29 is completed and loss is 9.250205039279535e-05

 step 30 is completed and loss is 0.00013493243022821844

 step 31 is completed and loss is 1.6271906133624725e-05

 step 32 is completed and loss is 9.959222370525822e-05

 step 33 is completed and loss is 9.595874871592969e-05

 step 34 is completed and loss is 7.307254418265074e-05

 step 35 is completed and loss is 0.00015895289834588766

 step 36 is completed and loss is 1.895403693197295e-05

 step 37 is completed and loss is 6.782778655178845e-05

 step 38 is completed and loss is 0.00011455160711193457

 step 39 is completed and loss is 7.354935223702341e-05

 step 40 is completed and loss is 8.701885235495865e-05

 step 41 is completed and loss is 4.184113277005963e-05

 step 42 is completed and loss is 7.116539927665144e-05

 step 43 is completed and loss is 7.283316517714411e-05

 step 44 is completed and loss is 2.4795104764052667e-05

 step 45 is completed and loss is 0.00020930518803652376

 step 46 is completed and loss is 2.0861356460954994e-05

 step 47 is completed and loss is 6.192730506882071e-05

 step 48 is completed and loss is 0.0003603362711146474

 step 49 is completed and loss is 8.219142182497308e-05

 step 50 is completed and loss is 8.785334648564458e-05

 step 51 is completed and loss is 6.884094182169065e-05

 step 52 is completed and loss is 0.0013023895444348454

 step 53 is completed and loss is 0.00023880430671852082

 step 54 is completed and loss is 3.78481054212898e-05

 step 55 is completed and loss is 0.0014189181383699179

 step 56 is completed and loss is 5.1616290875244886e-05

 step 57 is completed and loss is 0.00018903818272519857

 step 58 is completed and loss is 6.0376700275810435e-05

 step 59 is completed and loss is 0.00016896020679268986

 step 60 is completed and loss is 9.500527812633663e-05

 step 61 is completed and loss is 0.0001086491538444534

 step 62 is completed and loss is 9.631411376176402e-05

 step 63 is completed and loss is 0.00030959220021031797

 step 64 is completed and loss is 0.00025367754278704524

 step 65 is completed and loss is 8.523092401446775e-05

 step 66 is completed and loss is 0.00030903858714737

 step 67 is completed and loss is 4.9589456466492265e-05

 step 68 is completed and loss is 0.00016008451348170638

 step 69 is completed and loss is 0.00015472092491108924

 step 70 is completed and loss is 0.00018952168466057628

 step 71 is completed and loss is 0.00019470154074952006

 step 72 is completed and loss is 0.0004964008112438023

 step 73 is completed and loss is 9.142933413386345e-05

 step 74 is completed and loss is 9.941500320564955e-05

 step 75 is completed and loss is 0.00021860568085685372

 step 76 is completed and loss is 0.00016366096679121256

 step 77 is completed and loss is 7.843606726964936e-05

 step 78 is completed and loss is 0.00019518542103469372

 step 79 is completed and loss is 0.0009206066024489701

 step 80 is completed and loss is 0.00025084419758059084

 step 81 is completed and loss is 9.560111357131973e-05

 step 82 is completed and loss is 0.0001766471832524985

 step 83 is completed and loss is 0.00019321458239573985

 step 84 is completed and loss is 0.00010358552390243858

 step 85 is completed and loss is 0.00015209948469419032

 step 86 is completed and loss is 0.0001110968878492713

 step 87 is completed and loss is 0.0001537074858788401

 step 88 is completed and loss is 0.0002508830511942506

 step 89 is completed and loss is 6.615862366743386e-05

 step 90 is completed and loss is 0.0009827811736613512

 step 91 is completed and loss is 0.00013802878675051033
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:32,  1.52it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.54it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.54it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.53it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:29,  1.48it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.50it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.48it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.48it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.47it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.48it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.50it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.51it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.51it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.50it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.49it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.48it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.46it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.45it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:19,  1.46it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.48it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.47it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.48it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.48it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.48it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:15,  1.46it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.45it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.47it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.48it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.47it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.46it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.48it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.48it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.47it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.49it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.48it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.51it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.54it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.54it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.53it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.50it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.54it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.52it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.49it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.50it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.56it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.55it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 44: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.8819977429994s
Training Epoch44:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch44:   1%|[34m          [0m| 1/92 [00:03<04:57,  3.27s/it]Training Epoch44:   2%|[34mâ–         [0m| 2/92 [00:06<04:53,  3.26s/it]Training Epoch44:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.25s/it]Training Epoch44:   4%|[34mâ–         [0m| 4/92 [00:12<04:45,  3.24s/it]Training Epoch44:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.27s/it]Training Epoch44:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:45,  3.32s/it]Training Epoch44:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:45,  3.35s/it]Training Epoch44:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.31s/it]Training Epoch44:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.31s/it]Training Epoch44:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:30,  3.30s/it]Training Epoch44:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:24,  3.27s/it]Training Epoch44:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.29s/it]Training Epoch44:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:18,  3.27s/it]Training Epoch44:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:14,  3.27s/it]Training Epoch44:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:11,  3.27s/it]Training Epoch44:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:08,  3.27s/it]Training Epoch44:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:07,  3.30s/it]Training Epoch44:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.32s/it]Training Epoch44:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.32s/it]Training Epoch44:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:59,  3.33s/it]Training Epoch44:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.31s/it]Training Epoch44:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.30s/it]Training Epoch44:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.30s/it]Training Epoch44:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:43,  3.29s/it]Training Epoch44:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:39,  3.28s/it]Training Epoch44:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.29s/it]Training Epoch44:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:31,  3.26s/it]Training Epoch44:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:27,  3.25s/it]Training Epoch44:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:26,  3.27s/it]Training Epoch44:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:21,  3.26s/it]Training Epoch44:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:17,  3.23s/it]Training Epoch44:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:14,  3.23s/it]Training Epoch44:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:10,  3.24s/it]Training Epoch44:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:08,  3.24s/it]Training Epoch44:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:04,  3.24s/it]Training Epoch44:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:01,  3.24s/it]Training Epoch44:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:58,  3.25s/it]Training Epoch44:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:56,  3.26s/it]Training Epoch44:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:52,  3.26s/it]Training Epoch44:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:49,  3.25s/it]Training Epoch44:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:46,  3.27s/it]Training Epoch44:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:43,  3.28s/it]Training Epoch44:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:40,  3.28s/it]Training Epoch44:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:35,  3.24s/it]Training Epoch44:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:31,  3.21s/it]Training Epoch44:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:29,  3.24s/it]Training Epoch44:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:25,  3.24s/it]Training Epoch44:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:23,  3.26s/it]Training Epoch44:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:20,  3.27s/it]Training Epoch44:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:16,  3.25s/it]Training Epoch44:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:46<02:14,  3.28s/it]Training Epoch44:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:11,  3.29s/it]Training Epoch44:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:08,  3.28s/it]Training Epoch44:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:04,  3.28s/it]Training Epoch44:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:01,  3.28s/it]Training Epoch44:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:58,  3.29s/it]Training Epoch44:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:54,  3.28s/it]Training Epoch44:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:09<01:50,  3.26s/it]Training Epoch44:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:47,  3.27s/it]Training Epoch44:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:44,  3.26s/it]Training Epoch44:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:40,  3.23s/it]Training Epoch44:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:22<01:36,  3.23s/it]Training Epoch44:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:34,  3.27s/it]Training Epoch44:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:31,  3.26s/it]Training Epoch44:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:32<01:28,  3.27s/it]Training Epoch44:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:35<01:25,  3.29s/it]Training Epoch44:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:22,  3.29s/it]Training Epoch44:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:18,  3.29s/it]Training Epoch44:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:45<01:15,  3.28s/it]Training Epoch44:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:11,  3.26s/it]Training Epoch44:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:07,  3.24s/it]Training Epoch44:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:55<01:05,  3.27s/it]Training Epoch44:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:58<01:02,  3.27s/it]Training Epoch44:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:58,  3.26s/it]Training Epoch44:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:05<00:55,  3.27s/it]Training Epoch44:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:08<00:52,  3.27s/it]Training Epoch44:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:11<00:49,  3.27s/it]Training Epoch44:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:45,  3.27s/it]Training Epoch44:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:18<00:42,  3.29s/it]Training Epoch44:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:21<00:39,  3.29s/it]Training Epoch44:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.29s/it]Training Epoch44:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:28<00:32,  3.28s/it]Training Epoch44:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:31<00:29,  3.30s/it]Training Epoch44:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:34<00:26,  3.27s/it]Training Epoch44:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:38<00:22,  3.26s/it]Training Epoch44:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:41<00:19,  3.25s/it]Training Epoch44:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:44<00:16,  3.23s/it]Training Epoch44:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:47<00:12,  3.24s/it]Training Epoch44:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:51<00:09,  3.26s/it]Training Epoch44:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:54<00:06,  3.26s/it]Training Epoch44:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:57<00:03,  3.26s/it]Training Epoch44: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:00<00:00,  3.25s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch44: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:00<00:00,  3.27s/it]

 step 0 is completed and loss is 0.00011305956286378205

 step 1 is completed and loss is 0.00025524746160954237

 step 2 is completed and loss is 4.380843893159181e-05

 step 3 is completed and loss is 0.0001480986684327945

 step 4 is completed and loss is 7.563388498965651e-05

 step 5 is completed and loss is 4.54772416560445e-05

 step 6 is completed and loss is 0.0006525763892568648

 step 7 is completed and loss is 3.808660039794631e-05

 step 8 is completed and loss is 9.83426725724712e-05

 step 9 is completed and loss is 3.814614683506079e-05

 step 10 is completed and loss is 0.00024159210443031043

 step 11 is completed and loss is 0.001258297124877572

 step 12 is completed and loss is 0.00026023868122138083

 step 13 is completed and loss is 7.301302684936672e-05

 step 14 is completed and loss is 4.1126324504148215e-05

 step 15 is completed and loss is 4.434487345861271e-05

 step 16 is completed and loss is 0.00019606876594480127

 step 17 is completed and loss is 0.00017098370881285518

 step 18 is completed and loss is 4.601360342348926e-05

 step 19 is completed and loss is 0.00012485956540331244

 step 20 is completed and loss is 5.549022171180695e-05

 step 21 is completed and loss is 7.188051677076146e-05

 step 22 is completed and loss is 0.0004613990313373506

 step 23 is completed and loss is 0.0001565679267514497

 step 24 is completed and loss is 5.882803088752553e-05

 step 25 is completed and loss is 0.0003586480161175132

 step 26 is completed and loss is 7.164185080910102e-05

 step 27 is completed and loss is 0.00013612763723358512

 step 28 is completed and loss is 0.00013713608495891094

 step 29 is completed and loss is 0.00010865335934795439

 step 30 is completed and loss is 9.256124758394435e-05

 step 31 is completed and loss is 1.4543405995937064e-05

 step 32 is completed and loss is 7.319093128899112e-05

 step 33 is completed and loss is 6.651633884757757e-05

 step 34 is completed and loss is 7.515841571148485e-05

 step 35 is completed and loss is 0.00016467271780129522

 step 36 is completed and loss is 1.603349119250197e-05

 step 37 is completed and loss is 6.151010165922344e-05

 step 38 is completed and loss is 7.885332888690755e-05

 step 39 is completed and loss is 5.9006801166106015e-05

 step 40 is completed and loss is 0.00010960682993754745

 step 41 is completed and loss is 3.5344710340723395e-05

 step 42 is completed and loss is 5.960286580375396e-05

 step 43 is completed and loss is 5.5489970691269264e-05

 step 44 is completed and loss is 2.568909985711798e-05

 step 45 is completed and loss is 0.0002466672158334404

 step 46 is completed and loss is 2.0265364582883194e-05

 step 47 is completed and loss is 9.053530811797827e-05

 step 48 is completed and loss is 0.00037225199048407376

 step 49 is completed and loss is 7.056936010485515e-05

 step 50 is completed and loss is 8.761470962781459e-05

 step 51 is completed and loss is 6.329812458716333e-05

 step 52 is completed and loss is 0.0031032986007630825

 step 53 is completed and loss is 0.0002598386781755835

 step 54 is completed and loss is 3.76097195839975e-05

 step 55 is completed and loss is 0.0015658490592613816

 step 56 is completed and loss is 2.998068703163881e-05

 step 57 is completed and loss is 0.00017116307571996003

 step 58 is completed and loss is 7.211775664472952e-05

 step 59 is completed and loss is 0.00017605273751541972

 step 60 is completed and loss is 8.743602666072547e-05

 step 61 is completed and loss is 5.7396791817154735e-05

 step 62 is completed and loss is 8.814979810267687e-05

 step 63 is completed and loss is 0.00045224803034216166

 step 64 is completed and loss is 0.0003146183444187045

 step 65 is completed and loss is 9.595883602742106e-05

 step 66 is completed and loss is 0.0005931771593168378

 step 67 is completed and loss is 6.776741065550596e-05

 step 68 is completed and loss is 0.00021318302606232464

 step 69 is completed and loss is 0.00015883245214354247

 step 70 is completed and loss is 0.00018207042012363672

 step 71 is completed and loss is 0.00016407441580668092

 step 72 is completed and loss is 0.0006210238207131624

 step 73 is completed and loss is 9.119093738263473e-05

 step 74 is completed and loss is 0.0001109771546907723

 step 75 is completed and loss is 0.0002787848934531212

 step 76 is completed and loss is 0.0001310023362748325

 step 77 is completed and loss is 8.612418605480343e-05

 step 78 is completed and loss is 0.00017367169493809342

 step 79 is completed and loss is 0.0006834196392446756

 step 80 is completed and loss is 0.0002678863820619881

 step 81 is completed and loss is 9.071377280633897e-05

 step 82 is completed and loss is 0.0001991738099604845

 step 83 is completed and loss is 0.00017414621834177524

 step 84 is completed and loss is 7.712488149991259e-05

 step 85 is completed and loss is 0.0001472126314183697

 step 86 is completed and loss is 8.34430247778073e-05

 step 87 is completed and loss is 0.0001453643199056387

 step 88 is completed and loss is 0.00017575120727997273

 step 89 is completed and loss is 6.305963324848562e-05

 step 90 is completed and loss is 0.0017226390773430467

 step 91 is completed and loss is 0.0002111416106345132
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:37,  1.31it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.48it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:30,  1.52it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.49it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.47it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.46it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.45it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.46it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.48it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.48it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.51it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.49it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.52it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.59it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:20,  1.64it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:20,  1.64it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.59it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.56it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.54it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.52it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.52it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.50it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.49it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.49it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.48it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.46it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.45it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.44it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.44it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.48it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.56it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.55it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.54it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.47it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.47it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.48it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.49it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.49it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.51it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.51it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.51it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.52it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.51it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.50it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 45: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 301.15014816599796s
Training Epoch45:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch45:   1%|[34m          [0m| 1/92 [00:03<05:00,  3.30s/it]Training Epoch45:   2%|[34mâ–         [0m| 2/92 [00:06<04:53,  3.27s/it]Training Epoch45:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:50,  3.27s/it]Training Epoch45:   4%|[34mâ–         [0m| 4/92 [00:13<04:50,  3.30s/it]Training Epoch45:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.31s/it]Training Epoch45:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:42,  3.28s/it]Training Epoch45:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:39,  3.29s/it]Training Epoch45:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.29s/it]Training Epoch45:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.31s/it]Training Epoch45:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:30,  3.30s/it]Training Epoch45:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:25,  3.28s/it]Training Epoch45:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.29s/it]Training Epoch45:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.30s/it]Training Epoch45:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.31s/it]Training Epoch45:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.30s/it]Training Epoch45:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.30s/it]Training Epoch45:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.30s/it]Training Epoch45:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:03,  3.29s/it]Training Epoch45:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:58,  3.27s/it]Training Epoch45:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:54,  3.26s/it]Training Epoch45:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:52,  3.27s/it]Training Epoch45:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.29s/it]Training Epoch45:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.27s/it]Training Epoch45:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:43,  3.29s/it]Training Epoch45:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:41,  3.31s/it]Training Epoch45:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:37,  3.30s/it]Training Epoch45:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.31s/it]Training Epoch45:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.29s/it]Training Epoch45:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:30,  3.34s/it]Training Epoch45:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:25,  3.31s/it]Training Epoch45:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:20,  3.29s/it]Training Epoch45:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:18,  3.31s/it]Training Epoch45:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:14,  3.30s/it]Training Epoch45:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:10,  3.28s/it]Training Epoch45:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.30s/it]Training Epoch45:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:06,  3.32s/it]Training Epoch45:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:04,  3.35s/it]Training Epoch45:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<03:00,  3.35s/it]Training Epoch45:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:58,  3.36s/it]Training Epoch45:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:54,  3.36s/it]Training Epoch45:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:50,  3.34s/it]Training Epoch45:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:46,  3.33s/it]Training Epoch45:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:43,  3.34s/it]Training Epoch45:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:40,  3.34s/it]Training Epoch45:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:36,  3.32s/it]Training Epoch45:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:32,  3.32s/it]Training Epoch45:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:28,  3.30s/it]Training Epoch45:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:24,  3.29s/it]Training Epoch45:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.31s/it]Training Epoch45:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.32s/it]Training Epoch45:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:16,  3.32s/it]Training Epoch45:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:12,  3.32s/it]Training Epoch45:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:08,  3.30s/it]Training Epoch45:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.30s/it]Training Epoch45:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.30s/it]Training Epoch45:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.33s/it]Training Epoch45:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.33s/it]Training Epoch45:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.30s/it]Training Epoch45:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:48,  3.30s/it]Training Epoch45:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.30s/it]Training Epoch45:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.29s/it]Training Epoch45:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:38,  3.29s/it]Training Epoch45:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:35,  3.30s/it]Training Epoch45:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.32s/it]Training Epoch45:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.31s/it]Training Epoch45:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.32s/it]Training Epoch45:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.31s/it]Training Epoch45:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.32s/it]Training Epoch45:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.32s/it]Training Epoch45:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.30s/it]Training Epoch45:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.31s/it]Training Epoch45:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.28s/it]Training Epoch45:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.27s/it]Training Epoch45:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:58,  3.26s/it]Training Epoch45:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:55,  3.26s/it]Training Epoch45:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.30s/it]Training Epoch45:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.31s/it]Training Epoch45:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.29s/it]Training Epoch45:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.29s/it]Training Epoch45:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.30s/it]Training Epoch45:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.32s/it]Training Epoch45:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.32s/it]Training Epoch45:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.31s/it]Training Epoch45:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.30s/it]Training Epoch45:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.30s/it]Training Epoch45:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.30s/it]Training Epoch45:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.28s/it]Training Epoch45:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.29s/it]Training Epoch45:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.31s/it]Training Epoch45:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.30s/it]Training Epoch45:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.32s/it]Training Epoch45: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.32s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch45: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.00010108089918503538

 step 1 is completed and loss is 0.00020686426432803273

 step 2 is completed and loss is 4.082831583218649e-05

 step 3 is completed and loss is 0.00011252345575485379

 step 4 is completed and loss is 6.937583384569734e-05

 step 5 is completed and loss is 5.131813668413088e-05

 step 6 is completed and loss is 0.0007463378133252263

 step 7 is completed and loss is 5.268871973385103e-05

 step 8 is completed and loss is 7.492022996302694e-05

 step 9 is completed and loss is 4.3510328396223485e-05

 step 10 is completed and loss is 0.0008674467680975795

 step 11 is completed and loss is 0.0010192362824454904

 step 12 is completed and loss is 0.00021316870697773993

 step 13 is completed and loss is 6.19869097135961e-05

 step 14 is completed and loss is 4.762280877912417e-05

 step 15 is completed and loss is 3.862306402879767e-05

 step 16 is completed and loss is 0.00016889767721295357

 step 17 is completed and loss is 9.881869482342154e-05

 step 18 is completed and loss is 5.0543381803436205e-05

 step 19 is completed and loss is 0.0001398172607878223

 step 20 is completed and loss is 4.434483707882464e-05

 step 21 is completed and loss is 6.454956746893004e-05

 step 22 is completed and loss is 0.000537802348844707

 step 23 is completed and loss is 9.726989082992077e-05

 step 24 is completed and loss is 6.609914271393791e-05

 step 25 is completed and loss is 0.00015567027730867267

 step 26 is completed and loss is 8.314488513860852e-05

 step 27 is completed and loss is 0.00019250102923251688

 step 28 is completed and loss is 0.0001439292391296476

 step 29 is completed and loss is 8.874735067365691e-05

 step 30 is completed and loss is 0.00011365878162905574

 step 31 is completed and loss is 1.9788472854997963e-05

 step 32 is completed and loss is 9.53016133280471e-05

 step 33 is completed and loss is 8.123723819153383e-05

 step 34 is completed and loss is 8.874662307789549e-05

 step 35 is completed and loss is 0.00016532778681721538

 step 36 is completed and loss is 1.5258654457284138e-05

 step 37 is completed and loss is 7.503939559683204e-05

 step 38 is completed and loss is 7.944961544126272e-05

 step 39 is completed and loss is 6.562243652297184e-05

 step 40 is completed and loss is 0.00010442185157444328

 step 41 is completed and loss is 3.337780435686e-05

 step 42 is completed and loss is 7.742314483039081e-05

 step 43 is completed and loss is 4.976847776561044e-05

 step 44 is completed and loss is 2.211297396570444e-05

 step 45 is completed and loss is 0.00022152045858092606

 step 46 is completed and loss is 2.3245467673405074e-05

 step 47 is completed and loss is 7.41453404771164e-05

 step 48 is completed and loss is 0.00041079975198954344

 step 49 is completed and loss is 7.849620305933058e-05

 step 50 is completed and loss is 9.047544153872877e-05

 step 51 is completed and loss is 5.638440416078083e-05

 step 52 is completed and loss is 0.0014405599795281887

 step 53 is completed and loss is 0.00042613071855157614

 step 54 is completed and loss is 4.482140138861723e-05

 step 55 is completed and loss is 0.0012068914948031306

 step 56 is completed and loss is 6.186716927913949e-05

 step 57 is completed and loss is 0.00027673886506818235

 step 58 is completed and loss is 5.20924550073687e-05

 step 59 is completed and loss is 0.0003147503302898258

 step 60 is completed and loss is 0.00011842689855257049

 step 61 is completed and loss is 9.249922732124105e-05

 step 62 is completed and loss is 8.338200132129714e-05

 step 63 is completed and loss is 0.00033824745332822204

 step 64 is completed and loss is 0.00018361103138886392

 step 65 is completed and loss is 0.00010322961315978318

 step 66 is completed and loss is 0.000430491054430604

 step 67 is completed and loss is 5.2629045967478305e-05

 step 68 is completed and loss is 0.0002157450362574309

 step 69 is completed and loss is 0.00013982171367388219

 step 70 is completed and loss is 0.00020453297474887222

 step 71 is completed and loss is 0.00017837528139352798

 step 72 is completed and loss is 0.0006918131257407367

 step 73 is completed and loss is 8.91049494384788e-05

 step 74 is completed and loss is 0.00010221635602647439

 step 75 is completed and loss is 0.0002266498631797731

 step 76 is completed and loss is 0.0001380347239319235

 step 77 is completed and loss is 7.974736217875034e-05

 step 78 is completed and loss is 0.0001990570453926921

 step 79 is completed and loss is 0.0007528143469244242

 step 80 is completed and loss is 0.00029595274827443063

 step 81 is completed and loss is 0.00011109594197478145

 step 82 is completed and loss is 0.00010823531192727387

 step 83 is completed and loss is 0.00015638847253285348

 step 84 is completed and loss is 9.357383532915264e-05

 step 85 is completed and loss is 0.00015269544383045286

 step 86 is completed and loss is 8.713819261174649e-05

 step 87 is completed and loss is 0.00013409969687927514

 step 88 is completed and loss is 0.00027906440664082766

 step 89 is completed and loss is 6.526462675537914e-05

 step 90 is completed and loss is 0.0005562604637816548

 step 91 is completed and loss is 0.0001096033665817231
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.46it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:30,  1.55it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.52it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.52it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.52it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.54it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.54it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.54it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:27,  1.51it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.48it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.51it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.53it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.54it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.53it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.53it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.53it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.54it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.54it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.55it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.54it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.53it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.52it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.56it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.58it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.57it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.57it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.57it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.57it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.59it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.56it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.56it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.54it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.53it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.54it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.54it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.54it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.54it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.55it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.55it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.54it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.53it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.54it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.57it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.58it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 46: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.3249760350009s
Training Epoch46:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch46:   1%|[34m          [0m| 1/92 [00:03<04:57,  3.27s/it]Training Epoch46:   2%|[34mâ–         [0m| 2/92 [00:06<04:53,  3.26s/it]Training Epoch46:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.27s/it]Training Epoch46:   4%|[34mâ–         [0m| 4/92 [00:13<04:50,  3.30s/it]Training Epoch46:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:49,  3.33s/it]Training Epoch46:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.30s/it]Training Epoch46:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:39,  3.29s/it]Training Epoch46:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:34,  3.27s/it]Training Epoch46:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.28s/it]Training Epoch46:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:27,  3.26s/it]Training Epoch46:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:23,  3.26s/it]Training Epoch46:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:20,  3.25s/it]Training Epoch46:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:15,  3.24s/it]Training Epoch46:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:12,  3.24s/it]Training Epoch46:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:48<04:09,  3.24s/it]Training Epoch46:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:03,  3.21s/it]Training Epoch46:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:01,  3.22s/it]Training Epoch46:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<03:59,  3.24s/it]Training Epoch46:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:01<03:58,  3.27s/it]Training Epoch46:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.29s/it]Training Epoch46:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:52,  3.28s/it]Training Epoch46:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:48,  3.27s/it]Training Epoch46:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.26s/it]Training Epoch46:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:40,  3.25s/it]Training Epoch46:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:37,  3.24s/it]Training Epoch46:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:34,  3.25s/it]Training Epoch46:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:27<03:30,  3.23s/it]Training Epoch46:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:27,  3.24s/it]Training Epoch46:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:23,  3.23s/it]Training Epoch46:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:20,  3.23s/it]Training Epoch46:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:40<03:15,  3.20s/it]Training Epoch46:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:43<03:10,  3.18s/it]Training Epoch46:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:07,  3.17s/it]Training Epoch46:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:05,  3.19s/it]Training Epoch46:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:53<03:03,  3.21s/it]Training Epoch46:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:56<03:01,  3.25s/it]Training Epoch46:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:00<03:00,  3.28s/it]Training Epoch46:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:03<02:56,  3.26s/it]Training Epoch46:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:06<02:53,  3.27s/it]Training Epoch46:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:09<02:48,  3.24s/it]Training Epoch46:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:46,  3.27s/it]Training Epoch46:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:16<02:43,  3.27s/it]Training Epoch46:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:19<02:40,  3.28s/it]Training Epoch46:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:23<02:38,  3.29s/it]Training Epoch46:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:26<02:36,  3.33s/it]Training Epoch46:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:29<02:32,  3.32s/it]Training Epoch46:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:29,  3.33s/it]Training Epoch46:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:36<02:25,  3.30s/it]Training Epoch46:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:39<02:21,  3.30s/it]Training Epoch46:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:19,  3.32s/it]Training Epoch46:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:46<02:16,  3.33s/it]Training Epoch46:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:49<02:12,  3.32s/it]Training Epoch46:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:09,  3.33s/it]Training Epoch46:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:06,  3.32s/it]Training Epoch46:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:59<02:02,  3.30s/it]Training Epoch46:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:59,  3.32s/it]Training Epoch46:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:55,  3.31s/it]Training Epoch46:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:09<01:52,  3.30s/it]Training Epoch46:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:12<01:49,  3.32s/it]Training Epoch46:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:46,  3.33s/it]Training Epoch46:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:42,  3.32s/it]Training Epoch46:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:22<01:39,  3.32s/it]Training Epoch46:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:36,  3.34s/it]Training Epoch46:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:33,  3.34s/it]Training Epoch46:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:30,  3.34s/it]Training Epoch46:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:26,  3.32s/it]Training Epoch46:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:22,  3.31s/it]Training Epoch46:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:19,  3.32s/it]Training Epoch46:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:16,  3.33s/it]Training Epoch46:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:12,  3.32s/it]Training Epoch46:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:09,  3.31s/it]Training Epoch46:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:06,  3.31s/it]Training Epoch46:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:03,  3.33s/it]Training Epoch46:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:59,  3.31s/it]Training Epoch46:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:56,  3.31s/it]Training Epoch46:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:53,  3.32s/it]Training Epoch46:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.32s/it]Training Epoch46:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:46,  3.31s/it]Training Epoch46:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.30s/it]Training Epoch46:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.30s/it]Training Epoch46:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.29s/it]Training Epoch46:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:33,  3.30s/it]Training Epoch46:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.29s/it]Training Epoch46:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.31s/it]Training Epoch46:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.31s/it]Training Epoch46:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.27s/it]Training Epoch46:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.27s/it]Training Epoch46:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:48<00:13,  3.30s/it]Training Epoch46:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.32s/it]Training Epoch46:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.30s/it]Training Epoch46:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:58<00:03,  3.30s/it]Training Epoch46: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.30s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch46: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 0.00012545473873615265

 step 1 is completed and loss is 0.00020108386524952948

 step 2 is completed and loss is 3.629856655607e-05

 step 3 is completed and loss is 0.0001175290162791498

 step 4 is completed and loss is 7.259433186845854e-05

 step 5 is completed and loss is 5.733782745664939e-05

 step 6 is completed and loss is 0.0009321298566646874

 step 7 is completed and loss is 5.954277730779722e-05

 step 8 is completed and loss is 0.00012462501763366163

 step 9 is completed and loss is 3.9695794839644805e-05

 step 10 is completed and loss is 0.00040546656236983836

 step 11 is completed and loss is 0.0020032539032399654

 step 12 is completed and loss is 0.000261668668827042

 step 13 is completed and loss is 6.353652861434966e-05

 step 14 is completed and loss is 3.790773916989565e-05

 step 15 is completed and loss is 3.9219088648678735e-05

 step 16 is completed and loss is 0.00023497534857597202

 step 17 is completed and loss is 9.863960440270603e-05

 step 18 is completed and loss is 5.376194167183712e-05

 step 19 is completed and loss is 0.00012051087833242491

 step 20 is completed and loss is 4.815939246327616e-05

 step 21 is completed and loss is 7.819765596650541e-05

 step 22 is completed and loss is 0.0004575293278321624

 step 23 is completed and loss is 0.00010555417975410819

 step 24 is completed and loss is 5.978158151265234e-05

 step 25 is completed and loss is 0.00019690432236529887

 step 26 is completed and loss is 7.486021786462516e-05

 step 27 is completed and loss is 0.00012152606359450147

 step 28 is completed and loss is 0.00015239011554513127

 step 29 is completed and loss is 8.231057290686294e-05

 step 30 is completed and loss is 0.0001285582984564826

 step 31 is completed and loss is 1.8894450477091596e-05

 step 32 is completed and loss is 8.558703848393634e-05

 step 33 is completed and loss is 8.743592479731888e-05

 step 34 is completed and loss is 7.861538324505091e-05

 step 35 is completed and loss is 0.00017450505401939154

 step 36 is completed and loss is 1.913284904730972e-05

 step 37 is completed and loss is 6.693365139653906e-05

 step 38 is completed and loss is 9.119055903283879e-05

 step 39 is completed and loss is 6.55033509247005e-05

 step 40 is completed and loss is 8.010529563762248e-05

 step 41 is completed and loss is 8.874447667039931e-05

 step 42 is completed and loss is 6.645693792961538e-05

 step 43 is completed and loss is 6.347640010062605e-05

 step 44 is completed and loss is 2.5689118047012016e-05

 step 45 is completed and loss is 0.0002849142183549702

 step 46 is completed and loss is 2.4675951863173395e-05

 step 47 is completed and loss is 7.772131357342005e-05

 step 48 is completed and loss is 0.0003769057511817664

 step 49 is completed and loss is 8.785336103755981e-05

 step 50 is completed and loss is 8.260858885478228e-05

 step 51 is completed and loss is 5.656320718117058e-05

 step 52 is completed and loss is 0.002225442323833704

 step 53 is completed and loss is 0.0002652609837241471

 step 54 is completed and loss is 4.500013164943084e-05

 step 55 is completed and loss is 0.0013085457030683756

 step 56 is completed and loss is 3.6775367334485054e-05

 step 57 is completed and loss is 0.00021418393589556217

 step 58 is completed and loss is 5.5966374929994345e-05

 step 59 is completed and loss is 0.00021770401508547366

 step 60 is completed and loss is 0.00010305053001502529

 step 61 is completed and loss is 8.677848381921649e-05

 step 62 is completed and loss is 8.302445348817855e-05

 step 63 is completed and loss is 0.0006412610528059304

 step 64 is completed and loss is 0.0003937781148124486

 step 65 is completed and loss is 9.274041804019362e-05

 step 66 is completed and loss is 0.0005515717202797532

 step 67 is completed and loss is 8.862630784278736e-05

 step 68 is completed and loss is 0.00019518562476150692

 step 69 is completed and loss is 0.0001466739340685308

 step 70 is completed and loss is 0.0002016173821175471

 step 71 is completed and loss is 0.00016174971824511886

 step 72 is completed and loss is 0.0005078954272903502

 step 73 is completed and loss is 8.159539720509201e-05

 step 74 is completed and loss is 9.750822209753096e-05

 step 75 is completed and loss is 0.00020942864648532122

 step 76 is completed and loss is 0.00012945287744514644

 step 77 is completed and loss is 7.992572500370443e-05

 step 78 is completed and loss is 0.00027240783674642444

 step 79 is completed and loss is 0.0006969004170969129

 step 80 is completed and loss is 0.00018702188390307128

 step 81 is completed and loss is 8.773410809226334e-05

 step 82 is completed and loss is 0.00013856965233571827

 step 83 is completed and loss is 0.00015769951278343797

 step 84 is completed and loss is 0.00023205726756714284

 step 85 is completed and loss is 0.00013374387344811112

 step 86 is completed and loss is 8.523101132595912e-05

 step 87 is completed and loss is 0.00014214642578735948

 step 88 is completed and loss is 0.00024713072343729436

 step 89 is completed and loss is 6.794653018005192e-05

 step 90 is completed and loss is 0.0004740422882605344

 step 91 is completed and loss is 0.00018784456187859178
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:37,  1.29it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.44it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.46it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.51it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.56it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.56it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.56it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.56it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.61it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:24,  1.62it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.58it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.56it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.59it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.59it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.58it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.61it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:20,  1.63it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:19,  1.63it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.62it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:18,  1.60it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:17,  1.64it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:13<00:17,  1.62it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.57it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.58it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:15,  1.56it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.57it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.54it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:14,  1.54it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.54it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.52it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:12,  1.51it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:12,  1.48it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.49it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.53it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.54it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.52it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.50it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.51it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.53it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.54it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.55it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.58it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.59it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.59it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.59it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.56it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 47: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 302.5127928869988s
Training Epoch47:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch47:   1%|[34m          [0m| 1/92 [00:03<05:00,  3.30s/it]Training Epoch47:   2%|[34mâ–         [0m| 2/92 [00:06<04:52,  3.25s/it]Training Epoch47:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.25s/it]Training Epoch47:   4%|[34mâ–         [0m| 4/92 [00:13<04:46,  3.25s/it]Training Epoch47:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.30s/it]Training Epoch47:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:39,  3.25s/it]Training Epoch47:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:40,  3.31s/it]Training Epoch47:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.32s/it]Training Epoch47:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.29s/it]Training Epoch47:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:30,  3.30s/it]Training Epoch47:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch47:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.29s/it]Training Epoch47:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.29s/it]Training Epoch47:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:15,  3.27s/it]Training Epoch47:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:11,  3.27s/it]Training Epoch47:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:08,  3.27s/it]Training Epoch47:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:04,  3.26s/it]Training Epoch47:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:01,  3.27s/it]Training Epoch47:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:58,  3.27s/it]Training Epoch47:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:55,  3.27s/it]Training Epoch47:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:52,  3.28s/it]Training Epoch47:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.29s/it]Training Epoch47:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.27s/it]Training Epoch47:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:44,  3.30s/it]Training Epoch47:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:39,  3.27s/it]Training Epoch47:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:35,  3.26s/it]Training Epoch47:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:28,  3.21s/it]Training Epoch47:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:26,  3.23s/it]Training Epoch47:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:24,  3.24s/it]Training Epoch47:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:23,  3.28s/it]Training Epoch47:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:20,  3.28s/it]Training Epoch47:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:16,  3.28s/it]Training Epoch47:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:13,  3.27s/it]Training Epoch47:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:08,  3.24s/it]Training Epoch47:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:04,  3.24s/it]Training Epoch47:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:03,  3.27s/it]Training Epoch47:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:58,  3.25s/it]Training Epoch47:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:56,  3.28s/it]Training Epoch47:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:54,  3.29s/it]Training Epoch47:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:10<02:50,  3.27s/it]Training Epoch47:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:46,  3.27s/it]Training Epoch47:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:44,  3.28s/it]Training Epoch47:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:41,  3.30s/it]Training Epoch47:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:38,  3.30s/it]Training Epoch47:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.28s/it]Training Epoch47:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:31,  3.30s/it]Training Epoch47:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.31s/it]Training Epoch47:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:23,  3.27s/it]Training Epoch47:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:19,  3.24s/it]Training Epoch47:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:16,  3.24s/it]Training Epoch47:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:46<02:13,  3.25s/it]Training Epoch47:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:09,  3.25s/it]Training Epoch47:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:06,  3.25s/it]Training Epoch47:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:04,  3.27s/it]Training Epoch47:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:59<02:01,  3.27s/it]Training Epoch47:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:59,  3.31s/it]Training Epoch47:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:55,  3.31s/it]Training Epoch47:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:09<01:51,  3.28s/it]Training Epoch47:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:48,  3.28s/it]Training Epoch47:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:44,  3.27s/it]Training Epoch47:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:41,  3.27s/it]Training Epoch47:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:22<01:37,  3.26s/it]Training Epoch47:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:35,  3.28s/it]Training Epoch47:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:31,  3.27s/it]Training Epoch47:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:32<01:28,  3.28s/it]Training Epoch47:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.28s/it]Training Epoch47:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:21,  3.27s/it]Training Epoch47:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:18,  3.28s/it]Training Epoch47:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:45<01:15,  3.29s/it]Training Epoch47:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:11,  3.26s/it]Training Epoch47:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:08,  3.27s/it]Training Epoch47:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:55<01:05,  3.27s/it]Training Epoch47:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:58<01:01,  3.25s/it]Training Epoch47:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:58,  3.27s/it]Training Epoch47:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:05<00:55,  3.26s/it]Training Epoch47:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:08<00:52,  3.26s/it]Training Epoch47:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.28s/it]Training Epoch47:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:45,  3.25s/it]Training Epoch47:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:18<00:42,  3.26s/it]Training Epoch47:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:21<00:39,  3.29s/it]Training Epoch47:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.28s/it]Training Epoch47:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:28<00:32,  3.29s/it]Training Epoch47:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:31<00:29,  3.28s/it]Training Epoch47:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:34<00:26,  3.28s/it]Training Epoch47:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:38<00:22,  3.27s/it]Training Epoch47:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:41<00:19,  3.26s/it]Training Epoch47:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:44<00:16,  3.24s/it]Training Epoch47:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:47<00:13,  3.26s/it]Training Epoch47:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:51<00:09,  3.27s/it]Training Epoch47:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:54<00:06,  3.26s/it]Training Epoch47:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:57<00:03,  3.26s/it]Training Epoch47: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:00<00:00,  3.24s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch47: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:00<00:00,  3.27s/it]

 step 0 is completed and loss is 9.190342825604603e-05

 step 1 is completed and loss is 0.0001824322680477053

 step 2 is completed and loss is 4.0649494621902704e-05

 step 3 is completed and loss is 0.00010429933900013566

 step 4 is completed and loss is 6.997177843004465e-05

 step 5 is completed and loss is 5.411948950495571e-05

 step 6 is completed and loss is 0.0008960622362792492

 step 7 is completed and loss is 4.7384317440446466e-05

 step 8 is completed and loss is 7.879422628320754e-05

 step 9 is completed and loss is 4.7265257308026776e-05

 step 10 is completed and loss is 0.0014494734350591898

 step 11 is completed and loss is 0.0006011890363879502

 step 12 is completed and loss is 0.00024987076176330447

 step 13 is completed and loss is 7.140375964809209e-05

 step 14 is completed and loss is 5.0662631110753864e-05

 step 15 is completed and loss is 3.480850500636734e-05

 step 16 is completed and loss is 0.00019994156900793314

 step 17 is completed and loss is 0.0001343378098681569

 step 18 is completed and loss is 5.835123374708928e-05

 step 19 is completed and loss is 0.00021531220409087837

 step 20 is completed and loss is 4.458326657186262e-05

 step 21 is completed and loss is 6.758904783055186e-05

 step 22 is completed and loss is 0.0003305423306301236

 step 23 is completed and loss is 0.0001611549232620746

 step 24 is completed and loss is 6.294038030318916e-05

 step 25 is completed and loss is 0.00022037816233932972

 step 26 is completed and loss is 8.803163655102253e-05

 step 27 is completed and loss is 0.00020793877774849534

 step 28 is completed and loss is 0.00013230796321295202

 step 29 is completed and loss is 9.607805986888707e-05

 step 30 is completed and loss is 0.00010185909195570275

 step 31 is completed and loss is 1.7165946701425128e-05

 step 32 is completed and loss is 0.00014982782886363566

 step 33 is completed and loss is 7.885344530222937e-05

 step 34 is completed and loss is 0.00010251362982671708

 step 35 is completed and loss is 0.00018290815933141857

 step 36 is completed and loss is 1.5139450624701567e-05

 step 37 is completed and loss is 5.948365287622437e-05

 step 38 is completed and loss is 8.439645171165466e-05

 step 39 is completed and loss is 6.246371049201116e-05

 step 40 is completed and loss is 9.446871263207868e-05

 step 41 is completed and loss is 3.4152653825003654e-05

 step 42 is completed and loss is 8.49926145747304e-05

 step 43 is completed and loss is 6.001957808621228e-05

 step 44 is completed and loss is 2.2589796571992338e-05

 step 45 is completed and loss is 0.00022575032198801637

 step 46 is completed and loss is 2.1993830159772187e-05

 step 47 is completed and loss is 7.623143028467894e-05

 step 48 is completed and loss is 0.0005858196527697146

 step 49 is completed and loss is 7.813861884642392e-05

 step 50 is completed and loss is 9.834259253693745e-05

 step 51 is completed and loss is 6.317885708995163e-05

 step 52 is completed and loss is 0.002656677970662713

 step 53 is completed and loss is 0.00024744425900280476

 step 54 is completed and loss is 4.380835889605805e-05

 step 55 is completed and loss is 0.0016474260482937098

 step 56 is completed and loss is 3.6656179872807115e-05

 step 57 is completed and loss is 0.00031367246992886066

 step 58 is completed and loss is 5.703940405510366e-05

 step 59 is completed and loss is 0.00018701697990763932

 step 60 is completed and loss is 0.00010281262802891433

 step 61 is completed and loss is 8.719553443370387e-05

 step 62 is completed and loss is 6.866114563308656e-05

 step 63 is completed and loss is 0.00029171418282203376

 step 64 is completed and loss is 0.0005767098627984524

 step 65 is completed and loss is 9.840217535384e-05

 step 66 is completed and loss is 0.00047087809070944786

 step 67 is completed and loss is 6.031733937561512e-05

 step 68 is completed and loss is 0.0001699778949841857

 step 69 is completed and loss is 0.00013618695084005594

 step 70 is completed and loss is 0.00016949755081441253

 step 71 is completed and loss is 0.00013147652498446405

 step 72 is completed and loss is 0.0007166262366808951

 step 73 is completed and loss is 8.719778270460665e-05

 step 74 is completed and loss is 0.00012367167801130563

 step 75 is completed and loss is 0.0002224189811386168

 step 76 is completed and loss is 0.00011306361557217315

 step 77 is completed and loss is 6.925810885149986e-05

 step 78 is completed and loss is 0.000225513125769794

 step 79 is completed and loss is 0.0009129192912951112

 step 80 is completed and loss is 0.0002736671012826264

 step 81 is completed and loss is 0.00012176341260783374

 step 82 is completed and loss is 0.00014464854029938579

 step 83 is completed and loss is 0.00016056009917519987

 step 84 is completed and loss is 0.00020852129091508687

 step 85 is completed and loss is 0.0001284993631998077

 step 86 is completed and loss is 7.259582343976945e-05

 step 87 is completed and loss is 0.00011747352255042642

 step 88 is completed and loss is 0.00012915088154841214

 step 89 is completed and loss is 7.27741644368507e-05

 step 90 is completed and loss is 0.00048148445785045624

 step 91 is completed and loss is 8.409759902860969e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.48it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.49it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.50it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.51it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.50it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.53it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.52it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.60it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.60it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.59it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.60it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.61it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.59it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:20,  1.64it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:20,  1.62it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:19,  1.60it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.58it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.57it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.59it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:13<00:17,  1.61it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:16,  1.62it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:16,  1.53it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.56it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.56it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:14,  1.54it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.52it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.53it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:12,  1.54it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.52it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.53it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.53it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.56it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.55it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.52it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.51it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.54it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.52it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.53it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.51it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.53it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.56it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 48: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 301.24535195200224s
Training Epoch48:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch48:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.29s/it]Training Epoch48:   2%|[34mâ–         [0m| 2/92 [00:06<04:52,  3.25s/it]Training Epoch48:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.28s/it]Training Epoch48:   4%|[34mâ–         [0m| 4/92 [00:13<04:49,  3.29s/it]Training Epoch48:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.27s/it]Training Epoch48:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.26s/it]Training Epoch48:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.26s/it]Training Epoch48:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.29s/it]Training Epoch48:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:32,  3.28s/it]Training Epoch48:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.27s/it]Training Epoch48:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:24,  3.26s/it]Training Epoch48:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.30s/it]Training Epoch48:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:18,  3.27s/it]Training Epoch48:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:11,  3.23s/it]Training Epoch48:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:48<04:07,  3.21s/it]Training Epoch48:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:04,  3.22s/it]Training Epoch48:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:01,  3.22s/it]Training Epoch48:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<03:59,  3.23s/it]Training Epoch48:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:01<03:57,  3.25s/it]Training Epoch48:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:53,  3.24s/it]Training Epoch48:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:48,  3.23s/it]Training Epoch48:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:45,  3.23s/it]Training Epoch48:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:14<03:42,  3.23s/it]Training Epoch48:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:40,  3.24s/it]Training Epoch48:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:36,  3.23s/it]Training Epoch48:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:33,  3.24s/it]Training Epoch48:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:27<03:30,  3.24s/it]Training Epoch48:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:30<03:26,  3.23s/it]Training Epoch48:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:23,  3.22s/it]Training Epoch48:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:19,  3.22s/it]Training Epoch48:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:40<03:17,  3.23s/it]Training Epoch48:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:43<03:13,  3.22s/it]Training Epoch48:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:10,  3.23s/it]Training Epoch48:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:06,  3.22s/it]Training Epoch48:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:53<03:04,  3.24s/it]Training Epoch48:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:56<03:02,  3.25s/it]Training Epoch48:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:00<02:59,  3.26s/it]Training Epoch48:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:03<02:55,  3.25s/it]Training Epoch48:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:06<02:53,  3.27s/it]Training Epoch48:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:09<02:50,  3.27s/it]Training Epoch48:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:46,  3.27s/it]Training Epoch48:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:16<02:43,  3.26s/it]Training Epoch48:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:19<02:38,  3.24s/it]Training Epoch48:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:22<02:35,  3.24s/it]Training Epoch48:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:26<02:32,  3.25s/it]Training Epoch48:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:29<02:29,  3.26s/it]Training Epoch48:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:32<02:26,  3.26s/it]Training Epoch48:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:35<02:23,  3.26s/it]Training Epoch48:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:39<02:19,  3.23s/it]Training Epoch48:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:42<02:15,  3.22s/it]Training Epoch48:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:45<02:12,  3.22s/it]Training Epoch48:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:48<02:09,  3.23s/it]Training Epoch48:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:51<02:05,  3.21s/it]Training Epoch48:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:55<02:00,  3.17s/it]Training Epoch48:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:58<01:59,  3.22s/it]Training Epoch48:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:01<01:57,  3.26s/it]Training Epoch48:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:04<01:54,  3.26s/it]Training Epoch48:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:08<01:50,  3.26s/it]Training Epoch48:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:11<01:47,  3.26s/it]Training Epoch48:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:14<01:44,  3.25s/it]Training Epoch48:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:17<01:40,  3.26s/it]Training Epoch48:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:21<01:37,  3.25s/it]Training Epoch48:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:24<01:33,  3.23s/it]Training Epoch48:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:27<01:30,  3.24s/it]Training Epoch48:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:30<01:27,  3.24s/it]Training Epoch48:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:34<01:24,  3.23s/it]Training Epoch48:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:37<01:20,  3.22s/it]Training Epoch48:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:40<01:17,  3.23s/it]Training Epoch48:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:43<01:14,  3.24s/it]Training Epoch48:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:47<01:10,  3.22s/it]Training Epoch48:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:50<01:07,  3.22s/it]Training Epoch48:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:53<01:04,  3.25s/it]Training Epoch48:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:56<01:01,  3.25s/it]Training Epoch48:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:00<00:58,  3.27s/it]Training Epoch48:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:03<00:55,  3.28s/it]Training Epoch48:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:06<00:52,  3.28s/it]Training Epoch48:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:10<00:49,  3.30s/it]Training Epoch48:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:13<00:46,  3.30s/it]Training Epoch48:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:16<00:42,  3.29s/it]Training Epoch48:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:19<00:39,  3.29s/it]Training Epoch48:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:23<00:36,  3.28s/it]Training Epoch48:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:26<00:32,  3.27s/it]Training Epoch48:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:29<00:29,  3.28s/it]Training Epoch48:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:32<00:26,  3.27s/it]Training Epoch48:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:36<00:22,  3.26s/it]Training Epoch48:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:39<00:19,  3.22s/it]Training Epoch48:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:42<00:16,  3.22s/it]Training Epoch48:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:45<00:12,  3.23s/it]Training Epoch48:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:49<00:09,  3.26s/it]Training Epoch48:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:52<00:06,  3.25s/it]Training Epoch48:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:55<00:03,  3.25s/it]Training Epoch48: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:58<00:00,  3.26s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch48: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:58<00:00,  3.25s/it]

 step 0 is completed and loss is 8.588471973780543e-05

 step 1 is completed and loss is 0.0002001307875616476

 step 2 is completed and loss is 3.6477325920714065e-05

 step 3 is completed and loss is 0.00011031854228349403

 step 4 is completed and loss is 7.616999937454239e-05

 step 5 is completed and loss is 4.488112608669326e-05

 step 6 is completed and loss is 0.0007750259828753769

 step 7 is completed and loss is 5.1198854635003954e-05

 step 8 is completed and loss is 7.950935105327517e-05

 step 9 is completed and loss is 4.339116276241839e-05

 step 10 is completed and loss is 0.0006464514299295843

 step 11 is completed and loss is 0.000705493672285229

 step 12 is completed and loss is 0.00023557130771223456

 step 13 is completed and loss is 5.352351945475675e-05

 step 14 is completed and loss is 4.750362131744623e-05

 step 15 is completed and loss is 3.349725011503324e-05

 step 16 is completed and loss is 0.00023229596263263375

 step 17 is completed and loss is 0.00012504009646363556

 step 18 is completed and loss is 5.84704102948308e-05

 step 19 is completed and loss is 0.00019314797827973962

 step 20 is completed and loss is 5.209305527387187e-05

 step 21 is completed and loss is 7.170178287196904e-05

 step 22 is completed and loss is 0.0002541049325373024

 step 23 is completed and loss is 8.713814168004319e-05

 step 24 is completed and loss is 6.913893594173715e-05

 step 25 is completed and loss is 0.00011949769395869225

 step 26 is completed and loss is 5.858940858161077e-05

 step 27 is completed and loss is 0.0003027443599421531

 step 28 is completed and loss is 0.00013445325021166354

 step 29 is completed and loss is 7.629103492945433e-05

 step 30 is completed and loss is 0.00011747334792744368

 step 31 is completed and loss is 1.6212292393902317e-05

 step 32 is completed and loss is 7.414483843604103e-05

 step 33 is completed and loss is 7.861516496632248e-05

 step 34 is completed and loss is 7.623135024914518e-05

 step 35 is completed and loss is 0.00017587588808964938

 step 36 is completed and loss is 1.603349119250197e-05

 step 37 is completed and loss is 5.560955833061598e-05

 step 38 is completed and loss is 0.00010013020801125094

 step 39 is completed and loss is 4.6609697164967656e-05

 step 40 is completed and loss is 0.00010322986054234207

 step 41 is completed and loss is 5.1257895393064246e-05

 step 42 is completed and loss is 7.30130122974515e-05

 step 43 is completed and loss is 7.384673517663032e-05

 step 44 is completed and loss is 2.705994847929105e-05

 step 45 is completed and loss is 0.00018290788284502923

 step 46 is completed and loss is 2.3066690118866973e-05

 step 47 is completed and loss is 9.518393926555291e-05

 step 48 is completed and loss is 0.0004940647631883621

 step 49 is completed and loss is 7.325141632463783e-05

 step 50 is completed and loss is 8.028416777960956e-05

 step 51 is completed and loss is 5.566902837017551e-05

 step 52 is completed and loss is 0.0013409384991973639

 step 53 is completed and loss is 0.00032115011708810925

 step 54 is completed and loss is 4.4821346818935126e-05

 step 55 is completed and loss is 0.0009603548096492887

 step 56 is completed and loss is 4.2377974750706926e-05

 step 57 is completed and loss is 0.00029913874459452927

 step 58 is completed and loss is 6.40122962067835e-05

 step 59 is completed and loss is 0.00028484727954491973

 step 60 is completed and loss is 0.00010019011824624613

 step 61 is completed and loss is 0.00012491774396039546

 step 62 is completed and loss is 8.195186092052609e-05

 step 63 is completed and loss is 0.000701393757481128

 step 64 is completed and loss is 0.00039991753874346614

 step 65 is completed and loss is 7.956901390571147e-05

 step 66 is completed and loss is 0.0006274711340665817

 step 67 is completed and loss is 7.223705324577168e-05

 step 68 is completed and loss is 0.00018982270557899028

 step 69 is completed and loss is 0.00013988197315484285

 step 70 is completed and loss is 0.00018535050912760198

 step 71 is completed and loss is 0.00021120402379892766

 step 72 is completed and loss is 0.00045894141658209264

 step 73 is completed and loss is 8.046302536968142e-05

 step 74 is completed and loss is 9.619678894523531e-05

 step 75 is completed and loss is 0.0001998936932068318

 step 76 is completed and loss is 0.0001467355468776077

 step 77 is completed and loss is 6.78275537211448e-05

 step 78 is completed and loss is 0.0001881525677163154

 step 79 is completed and loss is 0.0006358589744195342

 step 80 is completed and loss is 0.00032151228515431285

 step 81 is completed and loss is 9.554099960951135e-05

 step 82 is completed and loss is 0.0001975628110812977

 step 83 is completed and loss is 0.00018404022557660937

 step 84 is completed and loss is 0.0001489364221924916

 step 85 is completed and loss is 0.00011073929636040702

 step 86 is completed and loss is 0.00012420836719684303

 step 87 is completed and loss is 0.00016335875261574984

 step 88 is completed and loss is 0.00023748292005620897

 step 89 is completed and loss is 5.179491199669428e-05

 step 90 is completed and loss is 0.0005577611736953259

 step 91 is completed and loss is 0.00014077004743739963
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.44it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.45it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.43it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.47it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.47it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.51it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.50it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:26,  1.54it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.52it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.51it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:24,  1.53it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.52it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.53it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.52it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.53it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.56it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.52it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.50it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.50it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.49it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.52it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.54it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.53it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.48it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.49it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.52it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.50it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.54it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.50it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.49it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.49it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.53it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.55it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.54it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.56it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:04,  1.60it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.61it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.57it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.56it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.53it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.54it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.52it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.53it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.52it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.52it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 49: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 299.1895679570007s
Training Epoch49:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch49:   1%|[34m          [0m| 1/92 [00:03<04:57,  3.27s/it]Training Epoch49:   2%|[34mâ–         [0m| 2/92 [00:06<04:54,  3.27s/it]Training Epoch49:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.28s/it]Training Epoch49:   4%|[34mâ–         [0m| 4/92 [00:13<04:46,  3.26s/it]Training Epoch49:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch49:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:42,  3.28s/it]Training Epoch49:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:38,  3.27s/it]Training Epoch49:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:33,  3.26s/it]Training Epoch49:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:30,  3.26s/it]Training Epoch49:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:25,  3.24s/it]Training Epoch49:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:23,  3.25s/it]Training Epoch49:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.27s/it]Training Epoch49:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:16,  3.25s/it]Training Epoch49:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:14,  3.26s/it]Training Epoch49:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.29s/it]Training Epoch49:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:08,  3.27s/it]Training Epoch49:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:03,  3.25s/it]Training Epoch49:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:01,  3.27s/it]Training Epoch49:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.28s/it]Training Epoch49:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:55,  3.27s/it]Training Epoch49:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:50,  3.25s/it]Training Epoch49:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:48,  3.26s/it]Training Epoch49:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.27s/it]Training Epoch49:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:43,  3.29s/it]Training Epoch49:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:40,  3.28s/it]Training Epoch49:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:37,  3.30s/it]Training Epoch49:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.30s/it]Training Epoch49:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:30,  3.29s/it]Training Epoch49:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:27,  3.29s/it]Training Epoch49:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:25,  3.32s/it]Training Epoch49:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:20,  3.29s/it]Training Epoch49:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:16,  3.27s/it]Training Epoch49:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:12,  3.26s/it]Training Epoch49:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:09,  3.26s/it]Training Epoch49:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:05,  3.25s/it]Training Epoch49:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:02,  3.25s/it]Training Epoch49:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:00<02:59,  3.25s/it]Training Epoch49:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:55,  3.25s/it]Training Epoch49:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:53,  3.27s/it]Training Epoch49:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:10<02:49,  3.26s/it]Training Epoch49:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:45,  3.24s/it]Training Epoch49:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:42,  3.25s/it]Training Epoch49:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:39,  3.25s/it]Training Epoch49:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:23<02:36,  3.25s/it]Training Epoch49:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:33,  3.27s/it]Training Epoch49:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:31,  3.29s/it]Training Epoch49:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:27,  3.29s/it]Training Epoch49:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:36<02:23,  3.26s/it]Training Epoch49:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:19,  3.24s/it]Training Epoch49:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:15,  3.23s/it]Training Epoch49:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:46<02:12,  3.24s/it]Training Epoch49:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:49<02:09,  3.24s/it]Training Epoch49:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:52<02:06,  3.23s/it]Training Epoch49:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:02,  3.23s/it]Training Epoch49:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:59<01:59,  3.24s/it]Training Epoch49:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:02<01:56,  3.24s/it]Training Epoch49:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:53,  3.26s/it]Training Epoch49:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:09<01:50,  3.26s/it]Training Epoch49:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:12<01:46,  3.24s/it]Training Epoch49:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:15<01:43,  3.24s/it]Training Epoch49:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:18<01:40,  3.24s/it]Training Epoch49:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:22<01:37,  3.24s/it]Training Epoch49:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:25<01:33,  3.23s/it]Training Epoch49:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:28<01:30,  3.25s/it]Training Epoch49:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:31<01:27,  3.23s/it]Training Epoch49:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:35<01:24,  3.25s/it]Training Epoch49:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:38<01:21,  3.26s/it]Training Epoch49:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:41<01:18,  3.26s/it]Training Epoch49:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:44<01:14,  3.25s/it]Training Epoch49:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:48<01:11,  3.27s/it]Training Epoch49:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:51<01:08,  3.28s/it]Training Epoch49:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:54<01:05,  3.28s/it]Training Epoch49:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:57<01:01,  3.24s/it]Training Epoch49:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:01<00:58,  3.25s/it]Training Epoch49:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:04<00:55,  3.25s/it]Training Epoch49:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:07<00:51,  3.23s/it]Training Epoch49:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:10<00:48,  3.23s/it]Training Epoch49:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:14<00:45,  3.24s/it]Training Epoch49:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:17<00:42,  3.26s/it]Training Epoch49:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:20<00:39,  3.29s/it]Training Epoch49:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:24<00:36,  3.31s/it]Training Epoch49:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:27<00:32,  3.30s/it]Training Epoch49:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:30<00:29,  3.29s/it]Training Epoch49:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:33<00:26,  3.28s/it]Training Epoch49:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:37<00:22,  3.27s/it]Training Epoch49:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:40<00:19,  3.25s/it]Training Epoch49:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:43<00:16,  3.25s/it]Training Epoch49:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:47<00:13,  3.29s/it]Training Epoch49:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:50<00:09,  3.31s/it]Training Epoch49:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:53<00:06,  3.33s/it]Training Epoch49:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:57<00:03,  3.32s/it]Training Epoch49: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:00<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch49: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:00<00:00,  3.26s/it]

 step 0 is completed and loss is 0.00011258239101152867

 step 1 is completed and loss is 0.00016008387319743633

 step 2 is completed and loss is 3.999385080533102e-05

 step 3 is completed and loss is 7.366726640611887e-05

 step 4 is completed and loss is 7.616986840730533e-05

 step 5 is completed and loss is 4.1245522879762575e-05

 step 6 is completed and loss is 0.00037098198663443327

 step 7 is completed and loss is 6.62177917547524e-05

 step 8 is completed and loss is 0.0001029913400998339

 step 9 is completed and loss is 4.8457215598318726e-05

 step 10 is completed and loss is 0.0002735276648309082

 step 11 is completed and loss is 0.0008365738322027028

 step 12 is completed and loss is 0.00026214390527457

 step 13 is completed and loss is 5.9364458138588816e-05

 step 14 is completed and loss is 3.8146165024954826e-05

 step 15 is completed and loss is 4.160317621426657e-05

 step 16 is completed and loss is 0.0001677047403063625

 step 17 is completed and loss is 0.00012855736713390797

 step 18 is completed and loss is 5.990084173390642e-05

 step 19 is completed and loss is 0.00018665319657884538

 step 20 is completed and loss is 5.0722235755529255e-05

 step 21 is completed and loss is 6.162926001707092e-05

 step 22 is completed and loss is 0.0004317392304074019

 step 23 is completed and loss is 0.00010686463792808354

 step 24 is completed and loss is 6.615881284233183e-05

 step 25 is completed and loss is 0.0002728669496718794

 step 26 is completed and loss is 7.110545266186818e-05

 step 27 is completed and loss is 0.00017605622997507453

 step 28 is completed and loss is 0.00020053594198543578

 step 29 is completed and loss is 8.618457650300115e-05

 step 30 is completed and loss is 0.00010710334754548967

 step 31 is completed and loss is 1.7642771126702428e-05

 step 32 is completed and loss is 8.207091013900936e-05

 step 33 is completed and loss is 8.827053534332663e-05

 step 34 is completed and loss is 5.543071165448055e-05

 step 35 is completed and loss is 0.00012814173533115536

 step 36 is completed and loss is 1.8298402210348286e-05

 step 37 is completed and loss is 5.978164335829206e-05

 step 38 is completed and loss is 8.052249177126214e-05

 step 39 is completed and loss is 5.727828829549253e-05

 step 40 is completed and loss is 9.92368150036782e-05

 step 41 is completed and loss is 5.0483176892157644e-05

 step 42 is completed and loss is 7.015220762696117e-05

 step 43 is completed and loss is 5.960226189927198e-05

 step 44 is completed and loss is 2.1934183678240515e-05

 step 45 is completed and loss is 0.00020930432947352529

 step 46 is completed and loss is 2.467597005306743e-05

 step 47 is completed and loss is 7.682736759306863e-05

 step 48 is completed and loss is 0.0005050074541941285

 step 49 is completed and loss is 7.140379602788016e-05

 step 50 is completed and loss is 8.791277650743723e-05

 step 51 is completed and loss is 5.62651694053784e-05

 step 52 is completed and loss is 0.0018259520875290036

 step 53 is completed and loss is 0.0002268285461468622

 step 54 is completed and loss is 3.594077134039253e-05

 step 55 is completed and loss is 0.0008699583122506738

 step 56 is completed and loss is 3.939782618544996e-05

 step 57 is completed and loss is 0.00029222626471892

 step 58 is completed and loss is 5.8231304137734696e-05

 step 59 is completed and loss is 0.00024058317649178207

 step 60 is completed and loss is 0.00011306358646834269

 step 61 is completed and loss is 8.183166210073978e-05

 step 62 is completed and loss is 8.070039621088654e-05

 step 63 is completed and loss is 0.00043796084355562925

 step 64 is completed and loss is 0.00020160659914836287

 step 65 is completed and loss is 9.303841216024011e-05

 step 66 is completed and loss is 0.0008813798776827753

 step 67 is completed and loss is 5.042402699473314e-05

 step 68 is completed and loss is 0.00021121648023836315

 step 69 is completed and loss is 0.000126532613649033

 step 70 is completed and loss is 0.00018475261458661407

 step 71 is completed and loss is 0.0002483269199728966

 step 72 is completed and loss is 0.0003824755840469152

 step 73 is completed and loss is 6.955619755899534e-05

 step 74 is completed and loss is 0.00010817621659953147

 step 75 is completed and loss is 0.00024702909286133945

 step 76 is completed and loss is 0.00012712861644104123

 step 77 is completed and loss is 6.919843144714832e-05

 step 78 is completed and loss is 0.000250243057962507

 step 79 is completed and loss is 0.0009470931836403906

 step 80 is completed and loss is 0.0002613918040879071

 step 81 is completed and loss is 0.00010018999455496669

 step 82 is completed and loss is 0.0001234914525412023

 step 83 is completed and loss is 0.00017343282524961978

 step 84 is completed and loss is 0.00014583743177354336

 step 85 is completed and loss is 0.0001479277852922678

 step 86 is completed and loss is 0.00010775939153973013

 step 87 is completed and loss is 0.0001706304756226018

 step 88 is completed and loss is 0.00029300907044671476

 step 89 is completed and loss is 5.996024265186861e-05

 step 90 is completed and loss is 0.0011535055236890912

 step 91 is completed and loss is 0.0001195561999338679
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:32,  1.52it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.46it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.47it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.45it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.47it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.47it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.47it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.48it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.48it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.51it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.48it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.47it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.46it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.47it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.48it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.50it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.48it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.48it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.47it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:19,  1.46it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.45it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:18,  1.44it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.44it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.45it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.47it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.52it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.47it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.46it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.52it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.53it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.54it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.51it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.49it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.48it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.49it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.50it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.53it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.54it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.59it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.60it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.58it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.55it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.54it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.56it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.57it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.63it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.61it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 50: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 300.65368305000084s
Training Epoch50:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch50:   1%|[34m          [0m| 1/92 [00:03<05:03,  3.33s/it]Training Epoch50:   2%|[34mâ–         [0m| 2/92 [00:06<04:58,  3.32s/it]Training Epoch50:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:58,  3.35s/it]Training Epoch50:   4%|[34mâ–         [0m| 4/92 [00:13<04:55,  3.36s/it]Training Epoch50:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:48,  3.32s/it]Training Epoch50:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:48,  3.36s/it]Training Epoch50:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:44,  3.34s/it]Training Epoch50:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.29s/it]Training Epoch50:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.30s/it]Training Epoch50:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:30,  3.30s/it]Training Epoch50:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.31s/it]Training Epoch50:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.28s/it]Training Epoch50:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:18,  3.27s/it]Training Epoch50:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:16,  3.29s/it]Training Epoch50:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:11,  3.27s/it]Training Epoch50:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.29s/it]Training Epoch50:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.31s/it]Training Epoch50:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.30s/it]Training Epoch50:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:00,  3.29s/it]Training Epoch50:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:53,  3.24s/it]Training Epoch50:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:48,  3.22s/it]Training Epoch50:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:47,  3.25s/it]Training Epoch50:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:46,  3.28s/it]Training Epoch50:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.32s/it]Training Epoch50:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:42,  3.32s/it]Training Epoch50:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:40,  3.33s/it]Training Epoch50:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:35,  3.31s/it]Training Epoch50:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.30s/it]Training Epoch50:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:28,  3.30s/it]Training Epoch50:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.31s/it]Training Epoch50:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.31s/it]Training Epoch50:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:20,  3.35s/it]Training Epoch50:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:16,  3.34s/it]Training Epoch50:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:13,  3.34s/it]Training Epoch50:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:11,  3.35s/it]Training Epoch50:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:06,  3.34s/it]Training Epoch50:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:03,  3.33s/it]Training Epoch50:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:59,  3.33s/it]Training Epoch50:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:56,  3.33s/it]Training Epoch50:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.31s/it]Training Epoch50:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.33s/it]Training Epoch50:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:46,  3.34s/it]Training Epoch50:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:44,  3.36s/it]Training Epoch50:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:41,  3.36s/it]Training Epoch50:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:37,  3.35s/it]Training Epoch50:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.34s/it]Training Epoch50:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:28,  3.31s/it]Training Epoch50:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:25,  3.31s/it]Training Epoch50:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:22,  3.31s/it]Training Epoch50:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.33s/it]Training Epoch50:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:17,  3.34s/it]Training Epoch50:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:14,  3.36s/it]Training Epoch50:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:11,  3.38s/it]Training Epoch50:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:08,  3.38s/it]Training Epoch50:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:03,  3.34s/it]Training Epoch50:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<02:00,  3.34s/it]Training Epoch50:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:55,  3.31s/it]Training Epoch50:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:53,  3.33s/it]Training Epoch50:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:50,  3.35s/it]Training Epoch50:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:47,  3.36s/it]Training Epoch50:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:44,  3.37s/it]Training Epoch50:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:40,  3.34s/it]Training Epoch50:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:37,  3.35s/it]Training Epoch50:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:32,  3.31s/it]Training Epoch50:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.31s/it]Training Epoch50:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:25,  3.30s/it]Training Epoch50:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:22,  3.32s/it]Training Epoch50:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:20,  3.35s/it]Training Epoch50:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:16,  3.35s/it]Training Epoch50:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:13,  3.35s/it]Training Epoch50:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.33s/it]Training Epoch50:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:07,  3.35s/it]Training Epoch50:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:03,  3.34s/it]Training Epoch50:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<01:00,  3.35s/it]Training Epoch50:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:56,  3.35s/it]Training Epoch50:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:53,  3.32s/it]Training Epoch50:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.31s/it]Training Epoch50:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:46,  3.33s/it]Training Epoch50:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:43,  3.34s/it]Training Epoch50:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:40,  3.34s/it]Training Epoch50:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:29<00:36,  3.36s/it]Training Epoch50:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.36s/it]Training Epoch50:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:36<00:30,  3.34s/it]Training Epoch50:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:26,  3.33s/it]Training Epoch50:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.32s/it]Training Epoch50:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:19,  3.30s/it]Training Epoch50:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.28s/it]Training Epoch50:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:52<00:13,  3.28s/it]Training Epoch50:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:09,  3.32s/it]Training Epoch50:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.32s/it]Training Epoch50:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.32s/it]Training Epoch50: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.33s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch50: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 0.00011025862477254122

 step 1 is completed and loss is 0.0001601447002030909

 step 2 is completed and loss is 3.719254891620949e-05

 step 3 is completed and loss is 0.00010412021219963208

 step 4 is completed and loss is 9.100905299419537e-05

 step 5 is completed and loss is 4.988760338164866e-05

 step 6 is completed and loss is 0.0006020366563461721

 step 7 is completed and loss is 6.09730341238901e-05

 step 8 is completed and loss is 8.004582923604175e-05

 step 9 is completed and loss is 4.6609573473688215e-05

 step 10 is completed and loss is 0.00034852864337153733

 step 11 is completed and loss is 0.0011200576554983854

 step 12 is completed and loss is 0.0002532070211600512

 step 13 is completed and loss is 6.258290522964671e-05

 step 14 is completed and loss is 5.4655894928146154e-05

 step 15 is completed and loss is 5.125868119648658e-05

 step 16 is completed and loss is 0.00024486874463036656

 step 17 is completed and loss is 0.00013320636935532093

 step 18 is completed and loss is 4.094740143045783e-05

 step 19 is completed and loss is 0.00013922115613240749

 step 20 is completed and loss is 5.042424891144037e-05

 step 21 is completed and loss is 5.608625360764563e-05

 step 22 is completed and loss is 0.00048094455269165337

 step 23 is completed and loss is 0.00014571932842954993

 step 24 is completed and loss is 7.581418321933597e-05

 step 25 is completed and loss is 0.0002325361710973084

 step 26 is completed and loss is 6.264248077059165e-05

 step 27 is completed and loss is 0.00018243290833197534

 step 28 is completed and loss is 9.935488924384117e-05

 step 29 is completed and loss is 8.588642231188715e-05

 step 30 is completed and loss is 6.997337914071977e-05

 step 31 is completed and loss is 1.7702370314509608e-05

 step 32 is completed and loss is 0.00014309544349089265

 step 33 is completed and loss is 8.177394920494407e-05

 step 34 is completed and loss is 0.0001309393992414698

 step 35 is completed and loss is 0.00019899604376405478

 step 36 is completed and loss is 1.5139459719648585e-05

 step 37 is completed and loss is 6.127169035607949e-05

 step 38 is completed and loss is 7.229750190163031e-05

 step 39 is completed and loss is 5.3463911172002554e-05

 step 40 is completed and loss is 0.00011616246774792671

 step 41 is completed and loss is 4.327153510530479e-05

 step 42 is completed and loss is 8.350261487066746e-05

 step 43 is completed and loss is 5.686075382982381e-05

 step 44 is completed and loss is 2.5152683519991115e-05

 step 45 is completed and loss is 0.00021013879450038075

 step 46 is completed and loss is 2.6702433387981728e-05

 step 47 is completed and loss is 8.290635014418513e-05

 step 48 is completed and loss is 0.0005304600927047431

 step 49 is completed and loss is 9.494568803347647e-05

 step 50 is completed and loss is 8.874725608620793e-05

 step 51 is completed and loss is 6.300002860371023e-05

 step 52 is completed and loss is 0.0015025519533082843

 step 53 is completed and loss is 0.00025608146097511053

 step 54 is completed and loss is 3.886120248353109e-05

 step 55 is completed and loss is 0.0018938957946375012

 step 56 is completed and loss is 4.7563298721797764e-05

 step 57 is completed and loss is 0.0003984352224506438

 step 58 is completed and loss is 5.86483656661585e-05

 step 59 is completed and loss is 0.00017229649529326707

 step 60 is completed and loss is 0.0001010247360682115

 step 61 is completed and loss is 0.0001098411885323003

 step 62 is completed and loss is 7.926972466520965e-05

 step 63 is completed and loss is 0.00030166294891387224

 step 64 is completed and loss is 0.00022275671653915197

 step 65 is completed and loss is 8.61843436723575e-05

 step 66 is completed and loss is 0.000680103781633079

 step 67 is completed and loss is 5.46555093023926e-05

 step 68 is completed and loss is 0.00017975131049752235

 step 69 is completed and loss is 0.00013445859076455235

 step 70 is completed and loss is 0.0001609160244697705

 step 71 is completed and loss is 0.00017021175881382078

 step 72 is completed and loss is 0.00046615194878540933

 step 73 is completed and loss is 9.178687469102442e-05

 step 74 is completed and loss is 0.00011210951197426766

 step 75 is completed and loss is 0.00016562757082283497

 step 76 is completed and loss is 0.00015627083485014737

 step 77 is completed and loss is 7.527750130975619e-05

 step 78 is completed and loss is 0.00019661433179862797

 step 79 is completed and loss is 0.0010019070468842983

 step 80 is completed and loss is 0.00026132940547540784

 step 81 is completed and loss is 0.00010024962830357254

 step 82 is completed and loss is 0.00014506510342471302

 step 83 is completed and loss is 0.0001870777050498873

 step 84 is completed and loss is 0.00022204710694495589

 step 85 is completed and loss is 0.00012194366718176752

 step 86 is completed and loss is 9.190614218823612e-05

 step 87 is completed and loss is 0.00014619887224398553

 step 88 is completed and loss is 0.00016168692673090845

 step 89 is completed and loss is 8.082021668087691e-05

 step 90 is completed and loss is 0.0007098005153238773

 step 91 is completed and loss is 0.00012420421990100294
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.37it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.40it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.45it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.43it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:31,  1.40it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:05<00:31,  1.37it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.41it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:29,  1.40it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:28,  1.41it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.46it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.45it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:25,  1.46it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.47it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.46it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.46it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.45it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:20,  1.52it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.58it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:18,  1.56it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.61it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:16,  1.63it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.53it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.53it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:14,  1.55it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.54it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.54it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.52it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.48it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.54it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.56it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.56it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:08,  1.58it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.59it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.57it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.61it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.58it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.56it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.55it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.55it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.54it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.54it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.54it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.51it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.47it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.46it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.50it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 51: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 306.1255218369988s
Training Epoch51:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch51:   1%|[34m          [0m| 1/92 [00:03<04:58,  3.28s/it]Training Epoch51:   2%|[34mâ–         [0m| 2/92 [00:06<04:59,  3.33s/it]Training Epoch51:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:58,  3.35s/it]Training Epoch51:   4%|[34mâ–         [0m| 4/92 [00:13<04:56,  3.37s/it]Training Epoch51:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:51,  3.35s/it]Training Epoch51:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:47,  3.35s/it]Training Epoch51:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:44,  3.34s/it]Training Epoch51:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:42,  3.36s/it]Training Epoch51:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:38,  3.35s/it]Training Epoch51:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:34,  3.35s/it]Training Epoch51:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.31s/it]Training Epoch51:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.29s/it]Training Epoch51:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:20,  3.29s/it]Training Epoch51:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.32s/it]Training Epoch51:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.31s/it]Training Epoch51:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:11,  3.31s/it]Training Epoch51:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.31s/it]Training Epoch51:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:06,  3.33s/it]Training Epoch51:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:02,  3.32s/it]Training Epoch51:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.31s/it]Training Epoch51:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.32s/it]Training Epoch51:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:53,  3.33s/it]Training Epoch51:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:50,  3.34s/it]Training Epoch51:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:46,  3.34s/it]Training Epoch51:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:42,  3.32s/it]Training Epoch51:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:38,  3.30s/it]Training Epoch51:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:35,  3.32s/it]Training Epoch51:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:34,  3.35s/it]Training Epoch51:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:31,  3.36s/it]Training Epoch51:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.32s/it]Training Epoch51:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:21,  3.30s/it]Training Epoch51:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:16,  3.28s/it]Training Epoch51:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:13,  3.27s/it]Training Epoch51:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:10,  3.28s/it]Training Epoch51:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:08,  3.30s/it]Training Epoch51:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:07,  3.34s/it]Training Epoch51:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.32s/it]Training Epoch51:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:58,  3.31s/it]Training Epoch51:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:54,  3.30s/it]Training Epoch51:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.30s/it]Training Epoch51:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:47,  3.28s/it]Training Epoch51:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.31s/it]Training Epoch51:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:43,  3.33s/it]Training Epoch51:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:40,  3.34s/it]Training Epoch51:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:37,  3.35s/it]Training Epoch51:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.33s/it]Training Epoch51:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:30,  3.34s/it]Training Epoch51:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:27,  3.36s/it]Training Epoch51:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:24,  3.36s/it]Training Epoch51:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:19,  3.33s/it]Training Epoch51:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:16,  3.33s/it]Training Epoch51:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:12,  3.31s/it]Training Epoch51:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:09,  3.31s/it]Training Epoch51:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:06,  3.32s/it]Training Epoch51:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:02,  3.31s/it]Training Epoch51:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<01:58,  3.30s/it]Training Epoch51:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:55,  3.30s/it]Training Epoch51:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.32s/it]Training Epoch51:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:50,  3.33s/it]Training Epoch51:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:47,  3.34s/it]Training Epoch51:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:43,  3.32s/it]Training Epoch51:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.31s/it]Training Epoch51:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:36,  3.34s/it]Training Epoch51:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:33,  3.34s/it]Training Epoch51:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:29,  3.32s/it]Training Epoch51:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:26,  3.32s/it]Training Epoch51:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:23,  3.33s/it]Training Epoch51:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:20,  3.34s/it]Training Epoch51:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:16,  3.33s/it]Training Epoch51:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:12,  3.31s/it]Training Epoch51:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.31s/it]Training Epoch51:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.31s/it]Training Epoch51:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:01,  3.26s/it]Training Epoch51:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:58,  3.27s/it]Training Epoch51:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:55,  3.28s/it]Training Epoch51:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:52,  3.31s/it]Training Epoch51:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.31s/it]Training Epoch51:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:45,  3.27s/it]Training Epoch51:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:42,  3.26s/it]Training Epoch51:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.28s/it]Training Epoch51:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.31s/it]Training Epoch51:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.32s/it]Training Epoch51:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:29,  3.33s/it]Training Epoch51:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.33s/it]Training Epoch51:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.32s/it]Training Epoch51:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:19,  3.29s/it]Training Epoch51:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.28s/it]Training Epoch51:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.29s/it]Training Epoch51:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:09,  3.31s/it]Training Epoch51:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.33s/it]Training Epoch51:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.30s/it]Training Epoch51: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch51: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 9.083081386052072e-05

 step 1 is completed and loss is 0.00023129498003982008

 step 2 is completed and loss is 3.9159433072200045e-05

 step 3 is completed and loss is 0.00012825473095290363

 step 4 is completed and loss is 6.758815288776532e-05

 step 5 is completed and loss is 4.7384470235556364e-05

 step 6 is completed and loss is 0.0004038058687001467

 step 7 is completed and loss is 4.410628025652841e-05

 step 8 is completed and loss is 7.241700950544327e-05

 step 9 is completed and loss is 3.8444144593086094e-05

 step 10 is completed and loss is 0.001015649875625968

 step 11 is completed and loss is 0.0013424495700746775

 step 12 is completed and loss is 0.0002510620397515595

 step 13 is completed and loss is 6.240411312319338e-05

 step 14 is completed and loss is 4.619253013515845e-05

 step 15 is completed and loss is 3.8742269680369645e-05

 step 16 is completed and loss is 0.0002223451592726633

 step 17 is completed and loss is 0.00012444553431123495

 step 18 is completed and loss is 5.4715550504624844e-05

 step 19 is completed and loss is 0.00035119897802360356

 step 20 is completed and loss is 4.607332084560767e-05

 step 21 is completed and loss is 6.985406798776239e-05

 step 22 is completed and loss is 0.0002510674821678549

 step 23 is completed and loss is 0.00012861695722676814

 step 24 is completed and loss is 7.331088272621855e-05

 step 25 is completed and loss is 0.00014881753304507583

 step 26 is completed and loss is 8.29057753435336e-05

 step 27 is completed and loss is 0.00014006081619299948

 step 28 is completed and loss is 0.00013755330292042345

 step 29 is completed and loss is 8.52310040500015e-05

 step 30 is completed and loss is 0.00011348017142154276

 step 31 is completed and loss is 1.7225558622158132e-05

 step 32 is completed and loss is 0.00011848367284983397

 step 33 is completed and loss is 8.284680370707065e-05

 step 34 is completed and loss is 6.621841748710722e-05

 step 35 is completed and loss is 0.00019464816432446241

 step 36 is completed and loss is 1.7821586880018003e-05

 step 37 is completed and loss is 6.407293403754011e-05

 step 38 is completed and loss is 0.00011616117262747139

 step 39 is completed and loss is 5.495383811648935e-05

 step 40 is completed and loss is 8.433699258603156e-05

 step 41 is completed and loss is 4.219880065647885e-05

 step 42 is completed and loss is 6.007967749610543e-05

 step 43 is completed and loss is 5.793357559014112e-05

 step 44 is completed and loss is 2.2887827071826905e-05

 step 45 is completed and loss is 0.0001604420831426978

 step 46 is completed and loss is 2.3543463612440974e-05

 step 47 is completed and loss is 7.444337825290859e-05

 step 48 is completed and loss is 0.0004891119315288961

 step 49 is completed and loss is 6.901979213580489e-05

 step 50 is completed and loss is 9.46474465308711e-05

 step 51 is completed and loss is 5.608638821286149e-05

 step 52 is completed and loss is 0.002840345026925206

 step 53 is completed and loss is 0.00026532376068644226

 step 54 is completed and loss is 3.856336115859449e-05

 step 55 is completed and loss is 0.0013177619548514485

 step 56 is completed and loss is 3.468928480288014e-05

 step 57 is completed and loss is 0.0002461769909132272

 step 58 is completed and loss is 6.234339525690302e-05

 step 59 is completed and loss is 0.00019392574904486537

 step 60 is completed and loss is 9.983268682844937e-05

 step 61 is completed and loss is 6.198579649208114e-05

 step 62 is completed and loss is 8.546783647034317e-05

 step 63 is completed and loss is 0.00021961762104183435

 step 64 is completed and loss is 0.00022823800100013614

 step 65 is completed and loss is 9.732955368235707e-05

 step 66 is completed and loss is 0.0008311675046570599

 step 67 is completed and loss is 5.131788566359319e-05

 step 68 is completed and loss is 0.0001503710518591106

 step 69 is completed and loss is 0.0001797504082787782

 step 70 is completed and loss is 0.00025244051357731223

 step 71 is completed and loss is 0.00012706840061582625

 step 72 is completed and loss is 0.00043232482858002186

 step 73 is completed and loss is 7.879421173129231e-05

 step 74 is completed and loss is 0.00010102434316650033

 step 75 is completed and loss is 0.00016967992996796966

 step 76 is completed and loss is 0.00013410099199973047

 step 77 is completed and loss is 8.23698501335457e-05

 step 78 is completed and loss is 0.0001591306208865717

 step 79 is completed and loss is 0.0005733589641749859

 step 80 is completed and loss is 0.0002475665824022144

 step 81 is completed and loss is 8.213144610635936e-05

 step 82 is completed and loss is 0.00020745419897139072

 step 83 is completed and loss is 0.00018284904945176095

 step 84 is completed and loss is 9.488489013165236e-05

 step 85 is completed and loss is 0.0001294529065489769

 step 86 is completed and loss is 9.810443589231e-05

 step 87 is completed and loss is 0.00012331399193499237

 step 88 is completed and loss is 0.00014929237659089267

 step 89 is completed and loss is 7.003237260505557e-05

 step 90 is completed and loss is 0.0006123605999164283

 step 91 is completed and loss is 9.637390030547976e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.33it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.43it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:30,  1.53it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.53it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.52it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.52it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.47it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.47it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.51it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.52it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.58it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.61it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:22,  1.63it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.66it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:20,  1.67it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:20,  1.60it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:19,  1.62it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:18,  1.65it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:18,  1.63it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.59it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.56it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.53it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.49it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:16,  1.48it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.48it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.51it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.55it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.52it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.49it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:12,  1.49it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.49it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.47it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:10,  1.47it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.47it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.45it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:08,  1.45it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.45it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.44it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.45it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.45it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.44it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.46it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.47it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.47it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.45it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.44it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.44it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.46it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.50it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 52: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.36657868199836s
Training Epoch52:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch52:   1%|[34m          [0m| 1/92 [00:03<05:04,  3.34s/it]Training Epoch52:   2%|[34mâ–         [0m| 2/92 [00:06<04:56,  3.30s/it]Training Epoch52:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:53,  3.29s/it]Training Epoch52:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.26s/it]Training Epoch52:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.30s/it]Training Epoch52:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:45,  3.32s/it]Training Epoch52:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:42,  3.32s/it]Training Epoch52:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.32s/it]Training Epoch52:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.32s/it]Training Epoch52:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.34s/it]Training Epoch52:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:31,  3.35s/it]Training Epoch52:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:26,  3.33s/it]Training Epoch52:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:22,  3.32s/it]Training Epoch52:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.33s/it]Training Epoch52:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:16,  3.33s/it]Training Epoch52:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:12,  3.32s/it]Training Epoch52:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.31s/it]Training Epoch52:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:07,  3.35s/it]Training Epoch52:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:03,  3.34s/it]Training Epoch52:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:00,  3.34s/it]Training Epoch52:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:57,  3.34s/it]Training Epoch52:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:53,  3.34s/it]Training Epoch52:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:50,  3.35s/it]Training Epoch52:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:47,  3.34s/it]Training Epoch52:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:44,  3.35s/it]Training Epoch52:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:42,  3.36s/it]Training Epoch52:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:35,  3.31s/it]Training Epoch52:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:32,  3.32s/it]Training Epoch52:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.32s/it]Training Epoch52:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:26,  3.33s/it]Training Epoch52:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:22,  3.33s/it]Training Epoch52:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:21,  3.35s/it]Training Epoch52:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:15,  3.32s/it]Training Epoch52:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:12,  3.31s/it]Training Epoch52:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:09,  3.32s/it]Training Epoch52:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:06,  3.34s/it]Training Epoch52:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:03,  3.34s/it]Training Epoch52:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<03:00,  3.34s/it]Training Epoch52:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:56,  3.33s/it]Training Epoch52:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:52,  3.33s/it]Training Epoch52:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:50,  3.35s/it]Training Epoch52:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:46,  3.34s/it]Training Epoch52:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:44,  3.35s/it]Training Epoch52:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:41,  3.36s/it]Training Epoch52:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:37,  3.34s/it]Training Epoch52:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:33,  3.35s/it]Training Epoch52:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:28,  3.31s/it]Training Epoch52:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:24,  3.29s/it]Training Epoch52:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:22,  3.31s/it]Training Epoch52:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:18,  3.30s/it]Training Epoch52:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:16,  3.32s/it]Training Epoch52:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:13,  3.34s/it]Training Epoch52:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:11,  3.36s/it]Training Epoch52:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:06,  3.32s/it]Training Epoch52:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:01,  3.29s/it]Training Epoch52:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<01:59,  3.31s/it]Training Epoch52:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:57,  3.34s/it]Training Epoch52:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:13<01:54,  3.35s/it]Training Epoch52:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:50,  3.36s/it]Training Epoch52:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:46,  3.34s/it]Training Epoch52:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:43,  3.34s/it]Training Epoch52:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:40,  3.34s/it]Training Epoch52:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:36,  3.33s/it]Training Epoch52:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:33<01:33,  3.33s/it]Training Epoch52:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:28,  3.29s/it]Training Epoch52:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:26,  3.32s/it]Training Epoch52:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:22,  3.31s/it]Training Epoch52:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:19,  3.32s/it]Training Epoch52:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:16,  3.31s/it]Training Epoch52:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:13,  3.32s/it]Training Epoch52:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:56<01:09,  3.30s/it]Training Epoch52:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:05,  3.29s/it]Training Epoch52:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:02,  3.30s/it]Training Epoch52:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:06<00:59,  3.30s/it]Training Epoch52:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:56,  3.30s/it]Training Epoch52:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:52,  3.30s/it]Training Epoch52:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.30s/it]Training Epoch52:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:45,  3.27s/it]Training Epoch52:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:42,  3.26s/it]Training Epoch52:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.25s/it]Training Epoch52:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.28s/it]Training Epoch52:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:32,  3.30s/it]Training Epoch52:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:29,  3.29s/it]Training Epoch52:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.28s/it]Training Epoch52:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.29s/it]Training Epoch52:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:19,  3.27s/it]Training Epoch52:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.27s/it]Training Epoch52:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.29s/it]Training Epoch52:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:09,  3.27s/it]Training Epoch52:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.32s/it]Training Epoch52:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.31s/it]Training Epoch52: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.30s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch52: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 0.0001451186981284991

 step 1 is completed and loss is 0.00020078732632100582

 step 2 is completed and loss is 4.1483945096842945e-05

 step 3 is completed and loss is 9.536011930322275e-05

 step 4 is completed and loss is 9.553854761179537e-05

 step 5 is completed and loss is 5.6443779612891376e-05

 step 6 is completed and loss is 0.000648053246550262

 step 7 is completed and loss is 4.1066694393521175e-05

 step 8 is completed and loss is 9.005847823573276e-05

 step 9 is completed and loss is 3.880183066939935e-05

 step 10 is completed and loss is 0.000619415775872767

 step 11 is completed and loss is 0.001670275116339326

 step 12 is completed and loss is 0.00023015042825136334

 step 13 is completed and loss is 6.186770042404532e-05

 step 14 is completed and loss is 5.4000109230400994e-05

 step 15 is completed and loss is 4.732496745418757e-05

 step 16 is completed and loss is 0.00017944311548490077

 step 17 is completed and loss is 0.0001282594312215224

 step 18 is completed and loss is 4.20203032263089e-05

 step 19 is completed and loss is 0.00022371458180714399

 step 20 is completed and loss is 5.078186222817749e-05

 step 21 is completed and loss is 6.335754733299837e-05

 step 22 is completed and loss is 0.0005617268034256995

 step 23 is completed and loss is 8.308499673148617e-05

 step 24 is completed and loss is 7.18804367352277e-05

 step 25 is completed and loss is 0.00027316954219713807

 step 26 is completed and loss is 6.615871097892523e-05

 step 27 is completed and loss is 0.00015519707812927663

 step 28 is completed and loss is 0.00012926927593071014

 step 29 is completed and loss is 8.237019937951118e-05

 step 30 is completed and loss is 9.685244003776461e-05

 step 31 is completed and loss is 1.668911863816902e-05

 step 32 is completed and loss is 7.962732343003154e-05

 step 33 is completed and loss is 9.166755626210943e-05

 step 34 is completed and loss is 7.122477836674079e-05

 step 35 is completed and loss is 0.00017301383195444942

 step 36 is completed and loss is 1.5258656276273541e-05

 step 37 is completed and loss is 4.857660678680986e-05

 step 38 is completed and loss is 8.749542757868767e-05

 step 39 is completed and loss is 5.09606470586732e-05

 step 40 is completed and loss is 9.25616841414012e-05

 step 41 is completed and loss is 7.611033652210608e-05

 step 42 is completed and loss is 7.533740426879376e-05

 step 43 is completed and loss is 7.599200762342662e-05

 step 44 is completed and loss is 2.253018828923814e-05

 step 45 is completed and loss is 0.00025137155898846686

 step 46 is completed and loss is 1.8954075130750425e-05

 step 47 is completed and loss is 7.4741430580616e-05

 step 48 is completed and loss is 0.0007903231307864189

 step 49 is completed and loss is 0.0001017399481497705

 step 50 is completed and loss is 9.2501868493855e-05

 step 51 is completed and loss is 6.389412010321394e-05

 step 52 is completed and loss is 0.001993377460166812

 step 53 is completed and loss is 0.00036839340464212

 step 54 is completed and loss is 3.451036536716856e-05

 step 55 is completed and loss is 0.001016246504150331

 step 56 is completed and loss is 4.9768546887207776e-05

 step 57 is completed and loss is 0.0003418476553633809

 step 58 is completed and loss is 6.341616244753823e-05

 step 59 is completed and loss is 0.00019118806812912226

 step 60 is completed and loss is 0.00011622216698015109

 step 61 is completed and loss is 6.401199061656371e-05

 step 62 is completed and loss is 9.273908653995022e-05

 step 63 is completed and loss is 0.00039602944161742926

 step 64 is completed and loss is 0.000296632235404104

 step 65 is completed and loss is 7.635052315890789e-05

 step 66 is completed and loss is 0.0007378975860774517

 step 67 is completed and loss is 7.438278407789767e-05

 step 68 is completed and loss is 0.00017891646712087095

 step 69 is completed and loss is 0.0002330207935301587

 step 70 is completed and loss is 0.0001904138916870579

 step 71 is completed and loss is 0.000157697475515306

 step 72 is completed and loss is 0.0006693580071441829

 step 73 is completed and loss is 8.517128298990428e-05

 step 74 is completed and loss is 0.00010656684753485024

 step 75 is completed and loss is 0.00019184894335921854

 step 76 is completed and loss is 0.00014661655586678535

 step 77 is completed and loss is 7.313206879189238e-05

 step 78 is completed and loss is 0.0001764730259310454

 step 79 is completed and loss is 0.0006581872003152966

 step 80 is completed and loss is 0.00029404452652670443

 step 81 is completed and loss is 9.017772390507162e-05

 step 82 is completed and loss is 0.00018356071086600423

 step 83 is completed and loss is 0.0002171722735511139

 step 84 is completed and loss is 8.105835877358913e-05

 step 85 is completed and loss is 0.0001691436773398891

 step 86 is completed and loss is 9.393251093570143e-05

 step 87 is completed and loss is 0.00016711617354303598

 step 88 is completed and loss is 0.000147564584040083

 step 89 is completed and loss is 5.578797936323099e-05

 step 90 is completed and loss is 0.00037278133095242083

 step 91 is completed and loss is 0.00019690088811330497
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.43it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.47it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.50it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.50it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.52it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.54it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.58it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.61it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:24,  1.64it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.62it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.59it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.56it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.57it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.58it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.57it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.58it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.57it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.56it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.56it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.56it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.57it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.56it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.56it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.57it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.54it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:14,  1.55it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.55it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.56it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:12,  1.55it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.54it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.55it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.58it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.58it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.57it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.61it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.58it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:24<00:07,  1.56it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.55it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:05,  1.54it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.56it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.51it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.52it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.50it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.52it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.53it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.57it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.59it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.56it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 53: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.52716478799994s
Training Epoch53:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch53:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.30s/it]Training Epoch53:   2%|[34mâ–         [0m| 2/92 [00:06<04:51,  3.24s/it]Training Epoch53:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.28s/it]Training Epoch53:   4%|[34mâ–         [0m| 4/92 [00:13<04:49,  3.29s/it]Training Epoch53:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.31s/it]Training Epoch53:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.31s/it]Training Epoch53:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.32s/it]Training Epoch53:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.33s/it]Training Epoch53:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:36,  3.34s/it]Training Epoch53:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.34s/it]Training Epoch53:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch53:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.32s/it]Training Epoch53:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:20,  3.30s/it]Training Epoch53:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.30s/it]Training Epoch53:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.31s/it]Training Epoch53:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.29s/it]Training Epoch53:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.31s/it]Training Epoch53:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.31s/it]Training Epoch53:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.29s/it]Training Epoch53:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:52,  3.23s/it]Training Epoch53:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:50,  3.24s/it]Training Epoch53:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:48,  3.27s/it]Training Epoch53:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:44,  3.26s/it]Training Epoch53:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:41,  3.26s/it]Training Epoch53:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:39,  3.27s/it]Training Epoch53:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.29s/it]Training Epoch53:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:33,  3.28s/it]Training Epoch53:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.28s/it]Training Epoch53:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:27,  3.29s/it]Training Epoch53:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:24,  3.30s/it]Training Epoch53:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.30s/it]Training Epoch53:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:18,  3.32s/it]Training Epoch53:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:15,  3.32s/it]Training Epoch53:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.32s/it]Training Epoch53:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:09,  3.32s/it]Training Epoch53:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:04,  3.30s/it]Training Epoch53:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:01,  3.30s/it]Training Epoch53:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:59,  3.33s/it]Training Epoch53:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:57,  3.35s/it]Training Epoch53:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:54,  3.35s/it]Training Epoch53:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:51,  3.37s/it]Training Epoch53:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:47,  3.36s/it]Training Epoch53:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:43,  3.34s/it]Training Epoch53:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:40,  3.34s/it]Training Epoch53:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:37,  3.34s/it]Training Epoch53:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.34s/it]Training Epoch53:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:31,  3.36s/it]Training Epoch53:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:28,  3.37s/it]Training Epoch53:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:24,  3.37s/it]Training Epoch53:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:21,  3.36s/it]Training Epoch53:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:18,  3.38s/it]Training Epoch53:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:14,  3.36s/it]Training Epoch53:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:10,  3.34s/it]Training Epoch53:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:06,  3.33s/it]Training Epoch53:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:03,  3.34s/it]Training Epoch53:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<02:00,  3.35s/it]Training Epoch53:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:56,  3.34s/it]Training Epoch53:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:53,  3.34s/it]Training Epoch53:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:51,  3.36s/it]Training Epoch53:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:46,  3.34s/it]Training Epoch53:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:43,  3.34s/it]Training Epoch53:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:40,  3.34s/it]Training Epoch53:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:37,  3.36s/it]Training Epoch53:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:34,  3.36s/it]Training Epoch53:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:30,  3.36s/it]Training Epoch53:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:27,  3.35s/it]Training Epoch53:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:23,  3.36s/it]Training Epoch53:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:20,  3.36s/it]Training Epoch53:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:17,  3.35s/it]Training Epoch53:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:13,  3.33s/it]Training Epoch53:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.32s/it]Training Epoch53:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.34s/it]Training Epoch53:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:03,  3.32s/it]Training Epoch53:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<01:00,  3.35s/it]Training Epoch53:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:57,  3.35s/it]Training Epoch53:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:53,  3.35s/it]Training Epoch53:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:16<00:50,  3.37s/it]Training Epoch53:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:46,  3.34s/it]Training Epoch53:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:43,  3.34s/it]Training Epoch53:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:26<00:39,  3.33s/it]Training Epoch53:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:29<00:36,  3.33s/it]Training Epoch53:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.31s/it]Training Epoch53:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:29,  3.33s/it]Training Epoch53:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:26,  3.33s/it]Training Epoch53:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.31s/it]Training Epoch53:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:19,  3.29s/it]Training Epoch53:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.31s/it]Training Epoch53:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:52<00:13,  3.31s/it]Training Epoch53:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:09,  3.31s/it]Training Epoch53:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.28s/it]Training Epoch53:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.29s/it]Training Epoch53: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch53: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 9.530081297270954e-05

 step 1 is completed and loss is 0.0001788561203284189

 step 2 is completed and loss is 3.55833035428077e-05

 step 3 is completed and loss is 9.011587098939344e-05

 step 4 is completed and loss is 9.196267637889832e-05

 step 5 is completed and loss is 5.471543408930302e-05

 step 6 is completed and loss is 0.0003738410014193505

 step 7 is completed and loss is 4.7563109546899796e-05

 step 8 is completed and loss is 9.142926137428731e-05

 step 9 is completed and loss is 4.5953813241794705e-05

 step 10 is completed and loss is 0.0003939122543670237

 step 11 is completed and loss is 0.0009628774714656174

 step 12 is completed and loss is 0.00027530916850082576

 step 13 is completed and loss is 5.286790110403672e-05

 step 14 is completed and loss is 4.058990452904254e-05

 step 15 is completed and loss is 4.1960789531003684e-05

 step 16 is completed and loss is 0.0001618066889932379

 step 17 is completed and loss is 0.0001338606234639883

 step 18 is completed and loss is 5.018584488425404e-05

 step 19 is completed and loss is 0.00019696187519002706

 step 20 is completed and loss is 4.917262413073331e-05

 step 21 is completed and loss is 5.2033377869520336e-05

 step 22 is completed and loss is 0.000307127513224259

 step 23 is completed and loss is 0.00014155023382045329

 step 24 is completed and loss is 7.623112469445914e-05

 step 25 is completed and loss is 0.00020065982243977487

 step 26 is completed and loss is 5.912595224799588e-05

 step 27 is completed and loss is 0.00017259997548535466

 step 28 is completed and loss is 0.00013779112487100065

 step 29 is completed and loss is 8.87471906025894e-05

 step 30 is completed and loss is 0.00011729357356671244

 step 31 is completed and loss is 1.734475517878309e-05

 step 32 is completed and loss is 8.707768574822694e-05

 step 33 is completed and loss is 9.369393228553236e-05

 step 34 is completed and loss is 8.147620974341407e-05

 step 35 is completed and loss is 0.00019703261204995215

 step 36 is completed and loss is 1.6510333807673305e-05

 step 37 is completed and loss is 6.109273090260103e-05

 step 38 is completed and loss is 0.00011478950182208791

 step 39 is completed and loss is 6.454972753999755e-05

 step 40 is completed and loss is 0.0001216455566463992

 step 41 is completed and loss is 5.727748794015497e-05

 step 42 is completed and loss is 7.176138751674443e-05

 step 43 is completed and loss is 6.63371683913283e-05

 step 44 is completed and loss is 2.3722241166979074e-05

 step 45 is completed and loss is 0.0002342730003874749

 step 46 is completed and loss is 2.7179225071449764e-05

 step 47 is completed and loss is 7.110580918379128e-05

 step 48 is completed and loss is 0.000471545266918838

 step 49 is completed and loss is 7.992661267053336e-05

 step 50 is completed and loss is 8.278739551315084e-05

 step 51 is completed and loss is 6.603974907193333e-05

 step 52 is completed and loss is 0.003083189483731985

 step 53 is completed and loss is 0.00036047014873474836

 step 54 is completed and loss is 3.713291516760364e-05

 step 55 is completed and loss is 0.001115429331548512

 step 56 is completed and loss is 4.3272008042549714e-05

 step 57 is completed and loss is 0.0004114195180591196

 step 58 is completed and loss is 5.5668308050371706e-05

 step 59 is completed and loss is 0.00038063255487941206

 step 60 is completed and loss is 0.00011008331784978509

 step 61 is completed and loss is 0.0001344518386758864

 step 62 is completed and loss is 9.798286919249222e-05

 step 63 is completed and loss is 0.0006600142223760486

 step 64 is completed and loss is 0.0002674390561878681

 step 65 is completed and loss is 9.834255615714937e-05

 step 66 is completed and loss is 0.0008287351229228079

 step 67 is completed and loss is 4.8218684241874143e-05

 step 68 is completed and loss is 0.0002248032542411238

 step 69 is completed and loss is 0.00012665122631005943

 step 70 is completed and loss is 0.00019124976824969053

 step 71 is completed and loss is 0.00018903847376350313

 step 72 is completed and loss is 0.0005081342533230782

 step 73 is completed and loss is 8.67805938469246e-05

 step 74 is completed and loss is 0.00010626892617437989

 step 75 is completed and loss is 0.00017963218851946294

 step 76 is completed and loss is 0.00015901183360256255

 step 77 is completed and loss is 7.110548904165626e-05

 step 78 is completed and loss is 0.00023320381296798587

 step 79 is completed and loss is 0.000780019792728126

 step 80 is completed and loss is 0.00027873076032847166

 step 81 is completed and loss is 0.00010346794442739338

 step 82 is completed and loss is 0.00012075081758666784

 step 83 is completed and loss is 0.00014250398089643568

 step 84 is completed and loss is 0.00011485016148071736

 step 85 is completed and loss is 0.00015352977789007127

 step 86 is completed and loss is 9.274052717955783e-05

 step 87 is completed and loss is 0.00015108581283129752

 step 88 is completed and loss is 0.00015507417265325785

 step 89 is completed and loss is 6.95557682774961e-05

 step 90 is completed and loss is 0.0004054225282743573

 step 91 is completed and loss is 8.904369315132499e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.36it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.44it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.42it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.42it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.46it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.44it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.43it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.45it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:27,  1.42it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.42it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:26,  1.39it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:25,  1.42it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.42it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.45it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:23,  1.42it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.40it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:22,  1.40it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:14<00:21,  1.42it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:20,  1.44it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:18,  1.49it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:16<00:18,  1.45it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.47it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:16,  1.52it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.56it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.47it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:15,  1.43it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:20<00:15,  1.40it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:14,  1.38it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:13,  1.45it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:12,  1.42it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.44it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.46it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:10,  1.47it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.49it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.51it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:07,  1.53it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.57it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.57it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.56it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:03,  1.55it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.59it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.56it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.56it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.54it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.53it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.47it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 54: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.9226254569985s
Training Epoch54:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch54:   1%|[34m          [0m| 1/92 [00:03<05:01,  3.32s/it]Training Epoch54:   2%|[34mâ–         [0m| 2/92 [00:06<04:55,  3.29s/it]Training Epoch54:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:53,  3.29s/it]Training Epoch54:   4%|[34mâ–         [0m| 4/92 [00:13<04:49,  3.29s/it]Training Epoch54:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.31s/it]Training Epoch54:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.30s/it]Training Epoch54:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch54:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.31s/it]Training Epoch54:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:32,  3.29s/it]Training Epoch54:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:27,  3.26s/it]Training Epoch54:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:25,  3.28s/it]Training Epoch54:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.29s/it]Training Epoch54:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.30s/it]Training Epoch54:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.30s/it]Training Epoch54:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.30s/it]Training Epoch54:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.28s/it]Training Epoch54:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:07,  3.30s/it]Training Epoch54:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:02,  3.28s/it]Training Epoch54:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:00,  3.30s/it]Training Epoch54:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:57,  3.30s/it]Training Epoch54:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:53,  3.29s/it]Training Epoch54:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.29s/it]Training Epoch54:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:46,  3.28s/it]Training Epoch54:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:41,  3.26s/it]Training Epoch54:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:38,  3.27s/it]Training Epoch54:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.28s/it]Training Epoch54:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:33,  3.28s/it]Training Epoch54:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.29s/it]Training Epoch54:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:28,  3.31s/it]Training Epoch54:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:25,  3.31s/it]Training Epoch54:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.30s/it]Training Epoch54:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:17,  3.30s/it]Training Epoch54:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:14,  3.30s/it]Training Epoch54:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.32s/it]Training Epoch54:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:10,  3.34s/it]Training Epoch54:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:07,  3.36s/it]Training Epoch54:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:04,  3.36s/it]Training Epoch54:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<03:00,  3.34s/it]Training Epoch54:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:57,  3.35s/it]Training Epoch54:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:53,  3.34s/it]Training Epoch54:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:50,  3.34s/it]Training Epoch54:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:45,  3.31s/it]Training Epoch54:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:41,  3.30s/it]Training Epoch54:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.31s/it]Training Epoch54:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:35,  3.30s/it]Training Epoch54:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:31,  3.29s/it]Training Epoch54:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:28,  3.30s/it]Training Epoch54:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:24,  3.29s/it]Training Epoch54:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:20,  3.28s/it]Training Epoch54:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:17,  3.28s/it]Training Epoch54:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:14,  3.29s/it]Training Epoch54:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.29s/it]Training Epoch54:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:07,  3.28s/it]Training Epoch54:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:04,  3.28s/it]Training Epoch54:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.30s/it]Training Epoch54:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:59,  3.32s/it]Training Epoch54:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.31s/it]Training Epoch54:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:53,  3.32s/it]Training Epoch54:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.32s/it]Training Epoch54:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.31s/it]Training Epoch54:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.31s/it]Training Epoch54:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:38,  3.29s/it]Training Epoch54:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:34,  3.28s/it]Training Epoch54:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:31,  3.28s/it]Training Epoch54:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.28s/it]Training Epoch54:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.30s/it]Training Epoch54:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.30s/it]Training Epoch54:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.30s/it]Training Epoch54:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:15,  3.29s/it]Training Epoch54:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.30s/it]Training Epoch54:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.29s/it]Training Epoch54:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.31s/it]Training Epoch54:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:03,  3.32s/it]Training Epoch54:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.33s/it]Training Epoch54:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.31s/it]Training Epoch54:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.31s/it]Training Epoch54:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.30s/it]Training Epoch54:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.29s/it]Training Epoch54:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.29s/it]Training Epoch54:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.29s/it]Training Epoch54:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.29s/it]Training Epoch54:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:32,  3.29s/it]Training Epoch54:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.30s/it]Training Epoch54:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.31s/it]Training Epoch54:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.32s/it]Training Epoch54:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.30s/it]Training Epoch54:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.31s/it]Training Epoch54:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.31s/it]Training Epoch54:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.29s/it]Training Epoch54:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.28s/it]Training Epoch54:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.28s/it]Training Epoch54: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch54: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.00010453780851094052

 step 1 is completed and loss is 0.00017510235193185508

 step 2 is completed and loss is 3.7907819205429405e-05

 step 3 is completed and loss is 9.476408013142645e-05

 step 4 is completed and loss is 5.781394793302752e-05

 step 5 is completed and loss is 4.345081833889708e-05

 step 6 is completed and loss is 0.001231185276992619

 step 7 is completed and loss is 5.811226583318785e-05

 step 8 is completed and loss is 8.105896995402873e-05

 step 9 is completed and loss is 4.237789835315198e-05

 step 10 is completed and loss is 0.000617341895122081

 step 11 is completed and loss is 0.0017028605798259377

 step 12 is completed and loss is 0.00022246486332733184

 step 13 is completed and loss is 6.580127228517085e-05

 step 14 is completed and loss is 5.1914230425609276e-05

 step 15 is completed and loss is 3.790783375734463e-05

 step 16 is completed and loss is 0.00020554338698275387

 step 17 is completed and loss is 0.00015793491911608726

 step 18 is completed and loss is 5.328493716660887e-05

 step 19 is completed and loss is 0.00019874912686645985

 step 20 is completed and loss is 4.696735413745046e-05

 step 21 is completed and loss is 7.104592805262655e-05

 step 22 is completed and loss is 0.000402553821913898

 step 23 is completed and loss is 0.00011181166337337345

 step 24 is completed and loss is 6.830457277828828e-05

 step 25 is completed and loss is 0.00018814534996636212

 step 26 is completed and loss is 5.829155270475894e-05

 step 27 is completed and loss is 0.00029839479248039424

 step 28 is completed and loss is 0.00015078199794515967

 step 29 is completed and loss is 9.047573257703334e-05

 step 30 is completed and loss is 0.00011240691674174741

 step 31 is completed and loss is 1.6271906133624725e-05

 step 32 is completed and loss is 0.00010835254215635359

 step 33 is completed and loss is 8.457526564598083e-05

 step 34 is completed and loss is 7.700610149186105e-05

 step 35 is completed and loss is 0.00021455019304994494

 step 36 is completed and loss is 1.8179234757553786e-05

 step 37 is completed and loss is 6.395368836820126e-05

 step 38 is completed and loss is 8.719708421267569e-05

 step 39 is completed and loss is 5.7516826927894726e-05

 step 40 is completed and loss is 0.00010555419430602342

 step 41 is completed and loss is 6.877998384879902e-05

 step 42 is completed and loss is 8.225102646974847e-05

 step 43 is completed and loss is 5.2807874453719705e-05

 step 44 is completed and loss is 2.551030775066465e-05

 step 45 is completed and loss is 0.00027442810824140906

 step 46 is completed and loss is 1.8775255739456043e-05

 step 47 is completed and loss is 0.00010412333358544856

 step 48 is completed and loss is 0.0005316878668963909

 step 49 is completed and loss is 7.289381755981594e-05

 step 50 is completed and loss is 8.236996654886752e-05

 step 51 is completed and loss is 5.960286580375396e-05

 step 52 is completed and loss is 0.0017933201743289828

 step 53 is completed and loss is 0.000341706327162683

 step 54 is completed and loss is 3.5642762668430805e-05

 step 55 is completed and loss is 0.0010661890264600515

 step 56 is completed and loss is 5.4775002354290336e-05

 step 57 is completed and loss is 0.0002511808124836534

 step 58 is completed and loss is 6.144952931208536e-05

 step 59 is completed and loss is 0.00047509116120636463

 step 60 is completed and loss is 0.00011407678539399058

 step 61 is completed and loss is 8.081874693743885e-05

 step 62 is completed and loss is 7.96868625911884e-05

 step 63 is completed and loss is 0.0003401471476536244

 step 64 is completed and loss is 0.00045696701272390783

 step 65 is completed and loss is 8.594599785283208e-05

 step 66 is completed and loss is 0.0005879902746528387

 step 67 is completed and loss is 6.460840813815594e-05

 step 68 is completed and loss is 0.00020406494149938226

 step 69 is completed and loss is 0.0001441722852177918

 step 70 is completed and loss is 0.00017390763969160616

 step 71 is completed and loss is 0.0001771251845639199

 step 72 is completed and loss is 0.0008233484695665538

 step 73 is completed and loss is 8.433699258603156e-05

 step 74 is completed and loss is 0.00012873737432528287

 step 75 is completed and loss is 0.00023082185362000018

 step 76 is completed and loss is 0.00013809405209030956

 step 77 is completed and loss is 6.842371658422053e-05

 step 78 is completed and loss is 0.00019524272647686303

 step 79 is completed and loss is 0.00046026401105336845

 step 80 is completed and loss is 0.00023010704899206758

 step 81 is completed and loss is 0.00010942733206320554

 step 82 is completed and loss is 0.00028973515145480633

 step 83 is completed and loss is 0.00015930875088088214

 step 84 is completed and loss is 9.113061969401315e-05

 step 85 is completed and loss is 0.00012540031457319856

 step 86 is completed and loss is 8.093983342405409e-05

 step 87 is completed and loss is 0.00014673580881208181

 step 88 is completed and loss is 0.00018176880257669836

 step 89 is completed and loss is 6.383404252119362e-05

 step 90 is completed and loss is 0.0006233250023797154

 step 91 is completed and loss is 8.451431494904682e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.37it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.41it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.44it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.44it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.47it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.46it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.48it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.48it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.51it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.49it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.48it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.51it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.51it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.48it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.48it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.49it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.50it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.49it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.48it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.49it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.48it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.48it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:17,  1.47it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.47it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.47it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.51it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.51it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.50it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.50it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.51it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.51it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.49it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.49it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.48it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.48it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.45it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:07,  1.41it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.44it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.45it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.46it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.47it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.48it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.50it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.54it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.55it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.61it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.64it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 55: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 303.8903319230012s
Training Epoch55:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch55:   1%|[34m          [0m| 1/92 [00:03<04:52,  3.22s/it]Training Epoch55:   2%|[34mâ–         [0m| 2/92 [00:06<04:51,  3.24s/it]Training Epoch55:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:47,  3.23s/it]Training Epoch55:   4%|[34mâ–         [0m| 4/92 [00:12<04:44,  3.24s/it]Training Epoch55:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:41,  3.24s/it]Training Epoch55:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:39,  3.25s/it]Training Epoch55:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:34,  3.23s/it]Training Epoch55:   9%|[34mâ–Š         [0m| 8/92 [00:25<04:31,  3.23s/it]Training Epoch55:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:28,  3.24s/it]Training Epoch55:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:27,  3.26s/it]Training Epoch55:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:29,  3.32s/it]Training Epoch55:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:26,  3.33s/it]Training Epoch55:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:23,  3.34s/it]Training Epoch55:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:19,  3.32s/it]Training Epoch55:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch55:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.31s/it]Training Epoch55:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:07,  3.30s/it]Training Epoch55:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.31s/it]Training Epoch55:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:00,  3.30s/it]Training Epoch55:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.28s/it]Training Epoch55:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:53,  3.29s/it]Training Epoch55:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:48,  3.27s/it]Training Epoch55:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.27s/it]Training Epoch55:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:44,  3.30s/it]Training Epoch55:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.29s/it]Training Epoch55:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.28s/it]Training Epoch55:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:33,  3.29s/it]Training Epoch55:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:30,  3.30s/it]Training Epoch55:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:27,  3.30s/it]Training Epoch55:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:23,  3.28s/it]Training Epoch55:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:20,  3.29s/it]Training Epoch55:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:16,  3.28s/it]Training Epoch55:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:13,  3.28s/it]Training Epoch55:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:10,  3.28s/it]Training Epoch55:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:05,  3.26s/it]Training Epoch55:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:03,  3.28s/it]Training Epoch55:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:01,  3.30s/it]Training Epoch55:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:58,  3.30s/it]Training Epoch55:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.30s/it]Training Epoch55:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:51,  3.29s/it]Training Epoch55:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:47,  3.28s/it]Training Epoch55:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:45,  3.30s/it]Training Epoch55:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:42,  3.31s/it]Training Epoch55:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:39,  3.32s/it]Training Epoch55:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:36,  3.32s/it]Training Epoch55:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:31,  3.29s/it]Training Epoch55:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.31s/it]Training Epoch55:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:25,  3.31s/it]Training Epoch55:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:21,  3.28s/it]Training Epoch55:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:17,  3.26s/it]Training Epoch55:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:13,  3.26s/it]Training Epoch55:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:09,  3.24s/it]Training Epoch55:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:06,  3.24s/it]Training Epoch55:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:03,  3.24s/it]Training Epoch55:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:00,  3.26s/it]Training Epoch55:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:57,  3.26s/it]Training Epoch55:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:53,  3.25s/it]Training Epoch55:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:50,  3.25s/it]Training Epoch55:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:47,  3.26s/it]Training Epoch55:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:44,  3.28s/it]Training Epoch55:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:42,  3.32s/it]Training Epoch55:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:39,  3.31s/it]Training Epoch55:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:35,  3.31s/it]Training Epoch55:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:32,  3.32s/it]Training Epoch55:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:29,  3.30s/it]Training Epoch55:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.29s/it]Training Epoch55:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.30s/it]Training Epoch55:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:19,  3.31s/it]Training Epoch55:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:15,  3.29s/it]Training Epoch55:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:12,  3.28s/it]Training Epoch55:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.28s/it]Training Epoch55:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:05,  3.28s/it]Training Epoch55:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.26s/it]Training Epoch55:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:59,  3.29s/it]Training Epoch55:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:55,  3.27s/it]Training Epoch55:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:52,  3.28s/it]Training Epoch55:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.27s/it]Training Epoch55:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:46,  3.29s/it]Training Epoch55:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.28s/it]Training Epoch55:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.27s/it]Training Epoch55:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.28s/it]Training Epoch55:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:32,  3.28s/it]Training Epoch55:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.29s/it]Training Epoch55:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.32s/it]Training Epoch55:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.33s/it]Training Epoch55:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.33s/it]Training Epoch55:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.31s/it]Training Epoch55:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.30s/it]Training Epoch55:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.31s/it]Training Epoch55:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.30s/it]Training Epoch55:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.29s/it]Training Epoch55: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch55: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 8.582478039897978e-05

 step 1 is completed and loss is 0.0001690835051704198

 step 2 is completed and loss is 3.5642937291413546e-05

 step 3 is completed and loss is 0.00012104497000109404

 step 4 is completed and loss is 7.319018914131448e-05

 step 5 is completed and loss is 4.9112888518720865e-05

 step 6 is completed and loss is 0.00028109143022447824

 step 7 is completed and loss is 4.905311288894154e-05

 step 8 is completed and loss is 7.301298319362104e-05

 step 9 is completed and loss is 4.172226908849552e-05

 step 10 is completed and loss is 0.0010230812476947904

 step 11 is completed and loss is 0.000922833220101893

 step 12 is completed and loss is 0.0002576157858129591

 step 13 is completed and loss is 5.6324795878026634e-05

 step 14 is completed and loss is 6.12716976320371e-05

 step 15 is completed and loss is 4.279521817807108e-05

 step 16 is completed and loss is 0.00014708867820445448

 step 17 is completed and loss is 0.00010632809426169842

 step 18 is completed and loss is 5.0185837608296424e-05

 step 19 is completed and loss is 0.0003600740747060627

 step 20 is completed and loss is 5.632466491078958e-05

 step 21 is completed and loss is 8.66009941091761e-05

 step 22 is completed and loss is 0.0003272081958130002

 step 23 is completed and loss is 0.00012861618597526103

 step 24 is completed and loss is 7.408568490063772e-05

 step 25 is completed and loss is 0.00021090736845508218

 step 26 is completed and loss is 6.627784750889987e-05

 step 27 is completed and loss is 0.00021258604829199612

 step 28 is completed and loss is 0.0001385658688377589

 step 29 is completed and loss is 9.411131031811237e-05

 step 30 is completed and loss is 0.00011020198871847242

 step 31 is completed and loss is 1.8894445020123385e-05

 step 32 is completed and loss is 8.511084888596088e-05

 step 33 is completed and loss is 8.45154354465194e-05

 step 34 is completed and loss is 8.093969518085942e-05

 step 35 is completed and loss is 0.000152158216224052

 step 36 is completed and loss is 1.6748734196880832e-05

 step 37 is completed and loss is 5.912595224799588e-05

 step 38 is completed and loss is 0.00010424223728477955

 step 39 is completed and loss is 5.864912236575037e-05

 step 40 is completed and loss is 0.0001320751616731286

 step 41 is completed and loss is 3.921871757484041e-05

 step 42 is completed and loss is 6.043727626092732e-05

 step 43 is completed and loss is 7.033016299828887e-05

 step 44 is completed and loss is 2.96228208753746e-05

 step 45 is completed and loss is 0.00022849223751109093

 step 46 is completed and loss is 2.0980565750505775e-05

 step 47 is completed and loss is 6.478815339505672e-05

 step 48 is completed and loss is 0.0006905411137267947

 step 49 is completed and loss is 9.125054930336773e-05

 step 50 is completed and loss is 9.077372669707984e-05

 step 51 is completed and loss is 5.102021896163933e-05

 step 52 is completed and loss is 0.0021532324608415365

 step 53 is completed and loss is 0.00022855587303638458

 step 54 is completed and loss is 4.3629275751300156e-05

 step 55 is completed and loss is 0.0012912675738334656

 step 56 is completed and loss is 4.76228233310394e-05

 step 57 is completed and loss is 0.00017253194528166205

 step 58 is completed and loss is 6.13898882875219e-05

 step 59 is completed and loss is 0.00028383434982970357

 step 60 is completed and loss is 9.440924623049796e-05

 step 61 is completed and loss is 8.034182246774435e-05

 step 62 is completed and loss is 0.00010769618529593572

 step 63 is completed and loss is 0.0004084756947122514

 step 64 is completed and loss is 0.0002195986162405461

 step 65 is completed and loss is 9.065424092113972e-05

 step 66 is completed and loss is 0.0007890965789556503

 step 67 is completed and loss is 5.173521276446991e-05

 step 68 is completed and loss is 0.00017188384663313627

 step 69 is completed and loss is 0.00013404147466644645

 step 70 is completed and loss is 0.00017152397776953876

 step 71 is completed and loss is 0.00022056122543290257

 step 72 is completed and loss is 0.0005436214269138873

 step 73 is completed and loss is 8.338340558111668e-05

 step 74 is completed and loss is 9.60773613769561e-05

 step 75 is completed and loss is 0.00018064520554617047

 step 76 is completed and loss is 0.00014149132766760886

 step 77 is completed and loss is 7.629054744029418e-05

 step 78 is completed and loss is 0.0001569847227074206

 step 79 is completed and loss is 0.0009519868763163686

 step 80 is completed and loss is 0.0002989261702168733

 step 81 is completed and loss is 8.618409628979862e-05

 step 82 is completed and loss is 0.0001687828334979713

 step 83 is completed and loss is 0.00013934497837908566

 step 84 is completed and loss is 0.00011985484161414206

 step 85 is completed and loss is 0.00017712931730784476

 step 86 is completed and loss is 0.00010942813969450071

 step 87 is completed and loss is 0.00018582511984277517

 step 88 is completed and loss is 0.0002422483521513641

 step 89 is completed and loss is 5.525178130483255e-05

 step 90 is completed and loss is 0.0004877940518781543

 step 91 is completed and loss is 0.00021519296569749713
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:32,  1.49it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.48it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.47it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.48it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.52it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.56it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.53it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.57it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.58it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.55it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.61it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:22,  1.62it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.60it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.56it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.53it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.52it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.50it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.48it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.51it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.50it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.48it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.50it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.51it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.50it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.52it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.51it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.51it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.51it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.50it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.49it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.52it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.51it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.52it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.58it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.59it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.57it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.52it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.53it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.51it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.53it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.50it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.52it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.49it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.52it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 56: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 302.54958431400155s
Training Epoch56:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch56:   1%|[34m          [0m| 1/92 [00:03<05:02,  3.32s/it]Training Epoch56:   2%|[34mâ–         [0m| 2/92 [00:06<04:55,  3.28s/it]Training Epoch56:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:53,  3.30s/it]Training Epoch56:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.28s/it]Training Epoch56:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch56:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.30s/it]Training Epoch56:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:39,  3.29s/it]Training Epoch56:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch56:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:32,  3.28s/it]Training Epoch56:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:30,  3.30s/it]Training Epoch56:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:27,  3.31s/it]Training Epoch56:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.30s/it]Training Epoch56:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:21,  3.31s/it]Training Epoch56:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:19,  3.33s/it]Training Epoch56:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:16,  3.33s/it]Training Epoch56:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:13,  3.33s/it]Training Epoch56:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:11,  3.35s/it]Training Epoch56:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:08,  3.36s/it]Training Epoch56:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:05,  3.37s/it]Training Epoch56:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:03,  3.38s/it]Training Epoch56:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:59,  3.37s/it]Training Epoch56:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:56,  3.37s/it]Training Epoch56:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:52,  3.36s/it]Training Epoch56:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:48,  3.36s/it]Training Epoch56:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:44,  3.35s/it]Training Epoch56:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:40,  3.34s/it]Training Epoch56:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:37,  3.35s/it]Training Epoch56:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:34,  3.34s/it]Training Epoch56:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:30,  3.34s/it]Training Epoch56:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:28,  3.36s/it]Training Epoch56:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:26,  3.38s/it]Training Epoch56:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:23,  3.39s/it]Training Epoch56:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:50<03:19,  3.38s/it]Training Epoch56:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:14,  3.35s/it]Training Epoch56:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:10,  3.34s/it]Training Epoch56:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [02:00<03:06,  3.33s/it]Training Epoch56:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:02,  3.32s/it]Training Epoch56:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:58,  3.31s/it]Training Epoch56:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:10<02:56,  3.33s/it]Training Epoch56:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:52,  3.32s/it]Training Epoch56:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:49,  3.33s/it]Training Epoch56:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:20<02:47,  3.35s/it]Training Epoch56:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:43,  3.33s/it]Training Epoch56:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:39,  3.31s/it]Training Epoch56:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:35,  3.31s/it]Training Epoch56:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:33,  3.34s/it]Training Epoch56:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:30,  3.35s/it]Training Epoch56:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:40<02:27,  3.35s/it]Training Epoch56:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:24,  3.36s/it]Training Epoch56:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:21,  3.36s/it]Training Epoch56:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:50<02:16,  3.34s/it]Training Epoch56:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:11,  3.30s/it]Training Epoch56:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:09,  3.31s/it]Training Epoch56:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:04,  3.28s/it]Training Epoch56:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:03<02:01,  3.29s/it]Training Epoch56:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<02:00,  3.34s/it]Training Epoch56:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:10<01:57,  3.35s/it]Training Epoch56:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:13<01:53,  3.33s/it]Training Epoch56:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:51,  3.37s/it]Training Epoch56:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:20<01:47,  3.36s/it]Training Epoch56:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:43,  3.33s/it]Training Epoch56:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:40,  3.34s/it]Training Epoch56:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:30<01:36,  3.34s/it]Training Epoch56:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:33<01:34,  3.36s/it]Training Epoch56:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:30,  3.34s/it]Training Epoch56:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:40<01:27,  3.36s/it]Training Epoch56:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:43<01:23,  3.35s/it]Training Epoch56:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:21,  3.39s/it]Training Epoch56:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:50<01:17,  3.39s/it]Training Epoch56:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:53<01:14,  3.40s/it]Training Epoch56:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:57<01:11,  3.39s/it]Training Epoch56:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [04:00<01:07,  3.38s/it]Training Epoch56:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:03<01:04,  3.37s/it]Training Epoch56:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:07<01:00,  3.37s/it]Training Epoch56:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:10<00:57,  3.37s/it]Training Epoch56:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:13<00:53,  3.37s/it]Training Epoch56:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:17<00:50,  3.40s/it]Training Epoch56:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:20<00:47,  3.37s/it]Training Epoch56:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:24<00:44,  3.40s/it]Training Epoch56:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:27<00:41,  3.42s/it]Training Epoch56:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:31<00:37,  3.40s/it]Training Epoch56:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:34<00:34,  3.40s/it]Training Epoch56:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:37<00:30,  3.39s/it]Training Epoch56:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:41<00:26,  3.37s/it]Training Epoch56:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:44<00:23,  3.37s/it]Training Epoch56:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:47<00:20,  3.35s/it]Training Epoch56:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:51<00:16,  3.34s/it]Training Epoch56:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:54<00:13,  3.32s/it]Training Epoch56:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:57<00:09,  3.32s/it]Training Epoch56:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [05:01<00:06,  3.33s/it]Training Epoch56:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:04<00:03,  3.35s/it]Training Epoch56: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:07<00:00,  3.37s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch56: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:07<00:00,  3.35s/it]

 step 0 is completed and loss is 0.00013254597433842719

 step 1 is completed and loss is 0.0002200341405114159

 step 2 is completed and loss is 4.035150777781382e-05

 step 3 is completed and loss is 7.015093433437869e-05

 step 4 is completed and loss is 8.904268179321662e-05

 step 5 is completed and loss is 5.8112407714361325e-05

 step 6 is completed and loss is 0.000771331659052521

 step 7 is completed and loss is 5.97217476752121e-05

 step 8 is completed and loss is 7.55758082959801e-05

 step 9 is completed and loss is 3.939773887395859e-05

 step 10 is completed and loss is 0.0005637488793581724

 step 11 is completed and loss is 0.0007630432955920696

 step 12 is completed and loss is 0.00025302774156443775

 step 13 is completed and loss is 5.847044667461887e-05

 step 14 is completed and loss is 5.4417560022557154e-05

 step 15 is completed and loss is 3.6238969187252223e-05

 step 16 is completed and loss is 0.00019183813128620386

 step 17 is completed and loss is 0.0001109165750676766

 step 18 is completed and loss is 4.947061825077981e-05

 step 19 is completed and loss is 0.0002107250184053555

 step 20 is completed and loss is 5.513276846613735e-05

 step 21 is completed and loss is 7.950896542752162e-05

 step 22 is completed and loss is 0.00048015417996793985

 step 23 is completed and loss is 0.0001099045475712046

 step 24 is completed and loss is 7.319160795304924e-05

 step 25 is completed and loss is 0.00012694770703092217

 step 26 is completed and loss is 5.376176704885438e-05

 step 27 is completed and loss is 0.00018302854732610285

 step 28 is completed and loss is 0.00016061309725046158

 step 29 is completed and loss is 7.944980461616069e-05

 step 30 is completed and loss is 0.00011336088937241584

 step 31 is completed and loss is 1.764276203175541e-05

 step 32 is completed and loss is 0.0001211055350722745

 step 33 is completed and loss is 8.570757927373052e-05

 step 34 is completed and loss is 6.1033249949105084e-05

 step 35 is completed and loss is 0.00015513744438067079

 step 36 is completed and loss is 1.3947379557066597e-05

 step 37 is completed and loss is 6.806617602705956e-05

 step 38 is completed and loss is 0.00012772272748406976

 step 39 is completed and loss is 5.3523464885074645e-05

 step 40 is completed and loss is 0.00010334898252040148

 step 41 is completed and loss is 6.0614820540649816e-05

 step 42 is completed and loss is 7.074818131513894e-05

 step 43 is completed and loss is 6.085425411583856e-05

 step 44 is completed and loss is 3.0397699447348714e-05

 step 45 is completed and loss is 0.00020716103608720005

 step 46 is completed and loss is 2.3722343030385673e-05

 step 47 is completed and loss is 6.717217911500484e-05

 step 48 is completed and loss is 0.00039744930109009147

 step 49 is completed and loss is 8.779378549661487e-05

 step 50 is completed and loss is 8.272765262518078e-05

 step 51 is completed and loss is 6.103329360485077e-05

 step 52 is completed and loss is 0.0014959877589717507

 step 53 is completed and loss is 0.0002589453652035445

 step 54 is completed and loss is 4.553672260954045e-05

 step 55 is completed and loss is 0.001301584648899734

 step 56 is completed and loss is 4.756312773679383e-05

 step 57 is completed and loss is 0.0003292199980933219

 step 58 is completed and loss is 5.173497265786864e-05

 step 59 is completed and loss is 0.0002835371415130794

 step 60 is completed and loss is 0.00011211000673938543

 step 61 is completed and loss is 7.015072333160788e-05

 step 62 is completed and loss is 8.165346662281081e-05

 step 63 is completed and loss is 0.0005968300392851233

 step 64 is completed and loss is 0.0004223059513606131

 step 65 is completed and loss is 8.856844215188175e-05

 step 66 is completed and loss is 0.0005538747645914555

 step 67 is completed and loss is 6.550272519234568e-05

 step 68 is completed and loss is 0.0002464315912220627

 step 69 is completed and loss is 0.00013606718857772648

 step 70 is completed and loss is 0.00016705490997992456

 step 71 is completed and loss is 0.00028884076164104044

 step 72 is completed and loss is 0.00046818458940833807

 step 73 is completed and loss is 7.700621063122526e-05

 step 74 is completed and loss is 0.00011556607205420732

 step 75 is completed and loss is 0.0002670492394827306

 step 76 is completed and loss is 0.00014697412552777678

 step 77 is completed and loss is 9.512398537481204e-05

 step 78 is completed and loss is 0.00018666293181013316

 step 79 is completed and loss is 0.0007693436928093433

 step 80 is completed and loss is 0.0002610330411698669

 step 81 is completed and loss is 8.517121750628576e-05

 step 82 is completed and loss is 0.0001364234194625169

 step 83 is completed and loss is 0.00018201128114014864

 step 84 is completed and loss is 8.892535697668791e-05

 step 85 is completed and loss is 0.0001641377166379243

 step 86 is completed and loss is 0.00011264643399044871

 step 87 is completed and loss is 0.00014041774556972086

 step 88 is completed and loss is 0.00019785856420639902

 step 89 is completed and loss is 5.7576071412768215e-05

 step 90 is completed and loss is 0.0006654623430222273

 step 91 is completed and loss is 0.00014178369019646198
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.36it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.39it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.43it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.41it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.44it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:31,  1.42it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.48it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.51it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.44it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:29,  1.38it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:27,  1.40it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:27,  1.41it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:26,  1.42it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:25,  1.40it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.41it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.42it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:23,  1.43it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.43it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:20,  1.51it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.56it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.50it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.47it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.43it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.48it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.45it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:15,  1.45it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.49it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.45it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:13,  1.44it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:12,  1.46it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.48it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.47it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:10,  1.44it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.45it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.49it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.50it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.49it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:05,  1.55it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.49it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.48it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:04,  1.47it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.47it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.45it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:32<00:02,  1.44it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.42it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.46it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.46it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.46it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 57: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 308.20120746799876s
Training Epoch57:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch57:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.26s/it]Training Epoch57:   2%|[34mâ–         [0m| 2/92 [00:06<04:53,  3.26s/it]Training Epoch57:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.25s/it]Training Epoch57:   4%|[34mâ–         [0m| 4/92 [00:13<04:52,  3.33s/it]Training Epoch57:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:48,  3.31s/it]Training Epoch57:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:45,  3.32s/it]Training Epoch57:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.33s/it]Training Epoch57:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.30s/it]Training Epoch57:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.31s/it]Training Epoch57:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:32,  3.32s/it]Training Epoch57:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:27,  3.30s/it]Training Epoch57:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.29s/it]Training Epoch57:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.30s/it]Training Epoch57:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:15,  3.28s/it]Training Epoch57:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.29s/it]Training Epoch57:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:08,  3.28s/it]Training Epoch57:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.29s/it]Training Epoch57:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.32s/it]Training Epoch57:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:00,  3.29s/it]Training Epoch57:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:59,  3.33s/it]Training Epoch57:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.32s/it]Training Epoch57:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:52,  3.32s/it]Training Epoch57:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:50,  3.34s/it]Training Epoch57:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:46,  3.33s/it]Training Epoch57:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.33s/it]Training Epoch57:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:39,  3.32s/it]Training Epoch57:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:36,  3.33s/it]Training Epoch57:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:32,  3.31s/it]Training Epoch57:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:29,  3.32s/it]Training Epoch57:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:26,  3.33s/it]Training Epoch57:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:23,  3.34s/it]Training Epoch57:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:20,  3.33s/it]Training Epoch57:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:16,  3.32s/it]Training Epoch57:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.31s/it]Training Epoch57:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.31s/it]Training Epoch57:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:05,  3.32s/it]Training Epoch57:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:01,  3.30s/it]Training Epoch57:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.30s/it]Training Epoch57:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:54,  3.29s/it]Training Epoch57:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.30s/it]Training Epoch57:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.32s/it]Training Epoch57:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.32s/it]Training Epoch57:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:42,  3.31s/it]Training Epoch57:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:40,  3.34s/it]Training Epoch57:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:35,  3.32s/it]Training Epoch57:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.34s/it]Training Epoch57:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:30,  3.34s/it]Training Epoch57:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:26,  3.34s/it]Training Epoch57:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:23,  3.34s/it]Training Epoch57:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.33s/it]Training Epoch57:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:17,  3.34s/it]Training Epoch57:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:12,  3.31s/it]Training Epoch57:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:08,  3.31s/it]Training Epoch57:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.30s/it]Training Epoch57:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:02,  3.31s/it]Training Epoch57:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.33s/it]Training Epoch57:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:57,  3.35s/it]Training Epoch57:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:53,  3.33s/it]Training Epoch57:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:51,  3.38s/it]Training Epoch57:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:48,  3.38s/it]Training Epoch57:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:44,  3.37s/it]Training Epoch57:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:40,  3.37s/it]Training Epoch57:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:38,  3.38s/it]Training Epoch57:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:34,  3.37s/it]Training Epoch57:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:31,  3.40s/it]Training Epoch57:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:27,  3.36s/it]Training Epoch57:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:23,  3.34s/it]Training Epoch57:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:20,  3.34s/it]Training Epoch57:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:16,  3.33s/it]Training Epoch57:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:13,  3.33s/it]Training Epoch57:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:56<01:10,  3.35s/it]Training Epoch57:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.34s/it]Training Epoch57:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:03,  3.32s/it]Training Epoch57:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.31s/it]Training Epoch57:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:56,  3.33s/it]Training Epoch57:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:53,  3.34s/it]Training Epoch57:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:16<00:49,  3.33s/it]Training Epoch57:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:46,  3.32s/it]Training Epoch57:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:43,  3.32s/it]Training Epoch57:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.31s/it]Training Epoch57:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:29<00:36,  3.33s/it]Training Epoch57:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.32s/it]Training Epoch57:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:29,  3.31s/it]Training Epoch57:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:26,  3.32s/it]Training Epoch57:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.33s/it]Training Epoch57:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:19,  3.31s/it]Training Epoch57:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.31s/it]Training Epoch57:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:52<00:13,  3.33s/it]Training Epoch57:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:10,  3.36s/it]Training Epoch57:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.36s/it]Training Epoch57:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.32s/it]Training Epoch57: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.30s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch57: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 8.081887062871829e-05

 step 1 is completed and loss is 0.00017051199392881244

 step 2 is completed and loss is 3.802702121902257e-05

 step 3 is completed and loss is 0.00010376296268077567

 step 4 is completed and loss is 8.487098239129409e-05

 step 5 is completed and loss is 6.359590770443901e-05

 step 6 is completed and loss is 0.0007215728983283043

 step 7 is completed and loss is 5.2569615945685655e-05

 step 8 is completed and loss is 7.199978426797315e-05

 step 9 is completed and loss is 4.41659358330071e-05

 step 10 is completed and loss is 0.0005034332862123847

 step 11 is completed and loss is 0.0016414063284173608

 step 12 is completed and loss is 0.00038175267400220037

 step 13 is completed and loss is 6.758936797268689e-05

 step 14 is completed and loss is 4.5358021452557296e-05

 step 15 is completed and loss is 3.2305197237292305e-05

 step 16 is completed and loss is 0.00012176214659120888

 step 17 is completed and loss is 0.00017241771274711937

 step 18 is completed and loss is 4.9112924898508936e-05

 step 19 is completed and loss is 0.00018015845853369683

 step 20 is completed and loss is 6.0437196225393564e-05

 step 21 is completed and loss is 7.468159310519695e-05

 step 22 is completed and loss is 0.0004564547853078693

 step 23 is completed and loss is 0.00010650771582731977

 step 24 is completed and loss is 7.36088550183922e-05

 step 25 is completed and loss is 0.0001735478435875848

 step 26 is completed and loss is 7.271475624293089e-05

 step 27 is completed and loss is 0.0002060319238808006

 step 28 is completed and loss is 0.00017461561947129667

 step 29 is completed and loss is 9.274043259210885e-05

 step 30 is completed and loss is 0.00010060727800009772

 step 31 is completed and loss is 1.6808324289740995e-05

 step 32 is completed and loss is 8.815010369289666e-05

 step 33 is completed and loss is 8.314488513860852e-05

 step 34 is completed and loss is 9.214404417434707e-05

 step 35 is completed and loss is 0.00018076214473694563

 step 36 is completed and loss is 1.8536853531259112e-05

 step 37 is completed and loss is 7.45626020943746e-05

 step 38 is completed and loss is 0.00011485017603263259

 step 39 is completed and loss is 6.896019476698712e-05

 step 40 is completed and loss is 0.00010740173456724733

 step 41 is completed and loss is 4.803952106158249e-05

 step 42 is completed and loss is 6.025846960255876e-05

 step 43 is completed and loss is 5.096027962281369e-05

 step 44 is completed and loss is 2.8192400350235403e-05

 step 45 is completed and loss is 0.00021383457351475954

 step 46 is completed and loss is 2.3603070076205768e-05

 step 47 is completed and loss is 7.730421202722937e-05

 step 48 is completed and loss is 0.0004565332783386111

 step 49 is completed and loss is 8.088019967544824e-05

 step 50 is completed and loss is 9.989208774641156e-05

 step 51 is completed and loss is 6.699337245663628e-05

 step 52 is completed and loss is 0.002387056825682521

 step 53 is completed and loss is 0.0003065535565838218

 step 54 is completed and loss is 3.862296944134869e-05

 step 55 is completed and loss is 0.0011218745494261384

 step 56 is completed and loss is 3.760973777389154e-05

 step 57 is completed and loss is 0.0001557875075377524

 step 58 is completed and loss is 6.043613393558189e-05

 step 59 is completed and loss is 0.0001491158182034269

 step 60 is completed and loss is 0.00010299131099600345

 step 61 is completed and loss is 6.240297807380557e-05

 step 62 is completed and loss is 9.214269812218845e-05

 step 63 is completed and loss is 0.0006195828318595886

 step 64 is completed and loss is 0.0001741378946462646

 step 65 is completed and loss is 0.0001076401022146456

 step 66 is completed and loss is 0.0007972439634613693

 step 67 is completed and loss is 5.519182013813406e-05

 step 68 is completed and loss is 0.00019572247401811182

 step 69 is completed and loss is 0.00012700931983999908

 step 70 is completed and loss is 0.00013219341053627431

 step 71 is completed and loss is 0.00016884230717550963

 step 72 is completed and loss is 0.0006812678766436875

 step 73 is completed and loss is 8.493298082612455e-05

 step 74 is completed and loss is 0.0001305243349634111

 step 75 is completed and loss is 0.0002175909176003188

 step 76 is completed and loss is 0.00013135971676092595

 step 77 is completed and loss is 6.574138387804851e-05

 step 78 is completed and loss is 0.00018570962129160762

 step 79 is completed and loss is 0.0013266446767374873

 step 80 is completed and loss is 0.00022218143567442894

 step 81 is completed and loss is 9.393225627718493e-05

 step 82 is completed and loss is 0.00015018893464002758

 step 83 is completed and loss is 0.0001748634676914662

 step 84 is completed and loss is 0.00011133340012747794

 step 85 is completed and loss is 0.00012516192509792745

 step 86 is completed and loss is 9.929640509653836e-05

 step 87 is completed and loss is 0.00012778324889950454

 step 88 is completed and loss is 0.00023706082720309496

 step 89 is completed and loss is 5.477506056195125e-05

 step 90 is completed and loss is 0.0004805225180462003

 step 91 is completed and loss is 0.00010513510642340407
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:31,  1.56it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.45it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.40it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.40it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:32,  1.41it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.47it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.46it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.44it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.49it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.54it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.52it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.52it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.54it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.59it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:20,  1.63it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:20,  1.61it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.58it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.63it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.66it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:17,  1.66it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.63it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:16,  1.59it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.54it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.56it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.54it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.47it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:14,  1.48it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.46it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.45it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.51it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.58it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.58it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.58it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.58it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.58it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.53it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.53it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.49it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.53it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.55it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.51it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.49it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.54it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.58it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.54it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 58: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 306.09607746000256s
Training Epoch58:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch58:   1%|[34m          [0m| 1/92 [00:03<05:00,  3.30s/it]Training Epoch58:   2%|[34mâ–         [0m| 2/92 [00:06<04:54,  3.27s/it]Training Epoch58:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.27s/it]Training Epoch58:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.27s/it]Training Epoch58:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:44,  3.27s/it]Training Epoch58:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.27s/it]Training Epoch58:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:38,  3.28s/it]Training Epoch58:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.29s/it]Training Epoch58:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.29s/it]Training Epoch58:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:27,  3.27s/it]Training Epoch58:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:25,  3.27s/it]Training Epoch58:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.26s/it]Training Epoch58:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:18,  3.27s/it]Training Epoch58:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.30s/it]Training Epoch58:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.30s/it]Training Epoch58:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.28s/it]Training Epoch58:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:04,  3.26s/it]Training Epoch58:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:01,  3.26s/it]Training Epoch58:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.28s/it]Training Epoch58:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:54,  3.26s/it]Training Epoch58:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:50,  3.25s/it]Training Epoch58:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:47,  3.25s/it]Training Epoch58:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.26s/it]Training Epoch58:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:43,  3.28s/it]Training Epoch58:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:39,  3.28s/it]Training Epoch58:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:34,  3.25s/it]Training Epoch58:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:31,  3.26s/it]Training Epoch58:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:29,  3.28s/it]Training Epoch58:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:26,  3.28s/it]Training Epoch58:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:23,  3.28s/it]Training Epoch58:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:21,  3.31s/it]Training Epoch58:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:18,  3.31s/it]Training Epoch58:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:15,  3.32s/it]Training Epoch58:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:12,  3.31s/it]Training Epoch58:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:07,  3.28s/it]Training Epoch58:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:03,  3.28s/it]Training Epoch58:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:00,  3.27s/it]Training Epoch58:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:57,  3.28s/it]Training Epoch58:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:54,  3.29s/it]Training Epoch58:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:51,  3.31s/it]Training Epoch58:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:48,  3.30s/it]Training Epoch58:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:44,  3.29s/it]Training Epoch58:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:39,  3.25s/it]Training Epoch58:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:35,  3.23s/it]Training Epoch58:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:32,  3.24s/it]Training Epoch58:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:28,  3.23s/it]Training Epoch58:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:26,  3.25s/it]Training Epoch58:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:22,  3.23s/it]Training Epoch58:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:19,  3.25s/it]Training Epoch58:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:17,  3.27s/it]Training Epoch58:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:14,  3.28s/it]Training Epoch58:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:11,  3.28s/it]Training Epoch58:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:07,  3.26s/it]Training Epoch58:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:04,  3.27s/it]Training Epoch58:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:01,  3.29s/it]Training Epoch58:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:59,  3.31s/it]Training Epoch58:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:56,  3.33s/it]Training Epoch58:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:53,  3.34s/it]Training Epoch58:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:50,  3.35s/it]Training Epoch58:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:46,  3.34s/it]Training Epoch58:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:43,  3.32s/it]Training Epoch58:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:38,  3.30s/it]Training Epoch58:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:35,  3.30s/it]Training Epoch58:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:31,  3.28s/it]Training Epoch58:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:28,  3.29s/it]Training Epoch58:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.28s/it]Training Epoch58:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:21,  3.27s/it]Training Epoch58:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:18,  3.26s/it]Training Epoch58:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:14,  3.25s/it]Training Epoch58:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:11,  3.27s/it]Training Epoch58:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:08,  3.27s/it]Training Epoch58:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:05,  3.26s/it]Training Epoch58:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:01,  3.26s/it]Training Epoch58:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:58,  3.24s/it]Training Epoch58:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:05<00:55,  3.24s/it]Training Epoch58:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:52,  3.25s/it]Training Epoch58:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:48,  3.25s/it]Training Epoch58:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:45,  3.24s/it]Training Epoch58:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:18<00:42,  3.26s/it]Training Epoch58:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.28s/it]Training Epoch58:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.28s/it]Training Epoch58:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:28<00:32,  3.28s/it]Training Epoch58:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.29s/it]Training Epoch58:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.30s/it]Training Epoch58:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:38<00:23,  3.29s/it]Training Epoch58:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:41<00:19,  3.28s/it]Training Epoch58:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.28s/it]Training Epoch58:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:48<00:13,  3.30s/it]Training Epoch58:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:51<00:09,  3.30s/it]Training Epoch58:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.30s/it]Training Epoch58:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:58<00:03,  3.30s/it]Training Epoch58: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.30s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch58: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.28s/it]

 step 0 is completed and loss is 9.059239528141916e-05

 step 1 is completed and loss is 0.00018112128600478172

 step 2 is completed and loss is 3.451049269642681e-05

 step 3 is completed and loss is 0.0001198528116219677

 step 4 is completed and loss is 8.111642819130793e-05

 step 5 is completed and loss is 4.2258754547219723e-05

 step 6 is completed and loss is 0.000568509625736624

 step 7 is completed and loss is 7.694572559557855e-05

 step 8 is completed and loss is 8.117820834740996e-05

 step 9 is completed and loss is 4.780158633366227e-05

 step 10 is completed and loss is 0.0007897770265117288

 step 11 is completed and loss is 0.0012552272528409958

 step 12 is completed and loss is 0.00023503271222580224

 step 13 is completed and loss is 6.735097849741578e-05

 step 14 is completed and loss is 3.540442048688419e-05

 step 15 is completed and loss is 4.327203714638017e-05

 step 16 is completed and loss is 0.000261247914750129

 step 17 is completed and loss is 0.00012933216930832714

 step 18 is completed and loss is 5.560957652051002e-05

 step 19 is completed and loss is 0.00010984233085764572

 step 20 is completed and loss is 4.4821659685112536e-05

 step 21 is completed and loss is 7.587367872474715e-05

 step 22 is completed and loss is 0.0005068951286375523

 step 23 is completed and loss is 0.00012432588846422732

 step 24 is completed and loss is 6.860231223981827e-05

 step 25 is completed and loss is 0.00014702965563628823

 step 26 is completed and loss is 8.397881174460053e-05

 step 27 is completed and loss is 0.00015543676272500306

 step 28 is completed and loss is 0.00011806593101937324

 step 29 is completed and loss is 7.819823076715693e-05

 step 30 is completed and loss is 0.00013588705041911453

 step 31 is completed and loss is 1.567586514283903e-05

 step 32 is completed and loss is 8.087897731456906e-05

 step 33 is completed and loss is 8.67803901201114e-05

 step 34 is completed and loss is 5.5490381782874465e-05

 step 35 is completed and loss is 0.0001826108491513878

 step 36 is completed and loss is 1.8298433133168146e-05

 step 37 is completed and loss is 5.990086356177926e-05

 step 38 is completed and loss is 8.028376760194078e-05

 step 39 is completed and loss is 5.048378079663962e-05

 step 40 is completed and loss is 0.0001129443699028343

 step 41 is completed and loss is 3.8443879020633176e-05

 step 42 is completed and loss is 7.72446219343692e-05

 step 43 is completed and loss is 5.775485624326393e-05

 step 44 is completed and loss is 2.616591882542707e-05

 step 45 is completed and loss is 0.00022569084831047803

 step 46 is completed and loss is 1.8536846255301498e-05

 step 47 is completed and loss is 9.47070075199008e-05

 step 48 is completed and loss is 0.0005424775881692767

 step 49 is completed and loss is 8.070141484495252e-05

 step 50 is completed and loss is 8.08801269158721e-05

 step 51 is completed and loss is 6.443054007831961e-05

 step 52 is completed and loss is 0.0020374804735183716

 step 53 is completed and loss is 0.00033140007872134447

 step 54 is completed and loss is 3.760972322197631e-05

 step 55 is completed and loss is 0.001507825800217688

 step 56 is completed and loss is 3.8324942579492927e-05

 step 57 is completed and loss is 0.00031379543361254036

 step 58 is completed and loss is 5.644332486554049e-05

 step 59 is completed and loss is 0.0003712828329298645

 step 60 is completed and loss is 0.00010120354272658005

 step 61 is completed and loss is 5.8231169532518834e-05

 step 62 is completed and loss is 7.17606017133221e-05

 step 63 is completed and loss is 0.0011102819116786122

 step 64 is completed and loss is 0.00024170181131921709

 step 65 is completed and loss is 7.92112696217373e-05

 step 66 is completed and loss is 0.0004926109686493874

 step 67 is completed and loss is 4.7086268750717863e-05

 step 68 is completed and loss is 0.00017063292034436017

 step 69 is completed and loss is 0.00014780675701331347

 step 70 is completed and loss is 0.00020697868603747338

 step 71 is completed and loss is 0.00018433229706715792

 step 72 is completed and loss is 0.0005412428290583193

 step 73 is completed and loss is 8.612495730631053e-05

 step 74 is completed and loss is 0.00010352770186727867

 step 75 is completed and loss is 0.00017748682876117527

 step 76 is completed and loss is 0.00012057290587108582

 step 77 is completed and loss is 7.611192268086597e-05

 step 78 is completed and loss is 0.00020555198716465384

 step 79 is completed and loss is 0.0006254830514080822

 step 80 is completed and loss is 0.0002887401496991515

 step 81 is completed and loss is 0.00010281247523380443

 step 82 is completed and loss is 0.0001688990741968155

 step 83 is completed and loss is 0.0001525155093986541

 step 84 is completed and loss is 9.601736383046955e-05

 step 85 is completed and loss is 0.0001262346631847322

 step 86 is completed and loss is 9.333651541965082e-05

 step 87 is completed and loss is 0.00015269409050233662

 step 88 is completed and loss is 0.00017277336155530065

 step 89 is completed and loss is 5.811262235511094e-05

 step 90 is completed and loss is 0.0007654102519154549

 step 91 is completed and loss is 0.00013886377564631402
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.37it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:35,  1.37it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.40it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.43it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.53it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.51it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.53it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.58it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.59it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.54it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.52it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.50it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:23,  1.49it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.48it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.48it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.48it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.48it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.48it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.50it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.48it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.48it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.48it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.48it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.47it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.46it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.47it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.49it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.52it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.51it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.54it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.52it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.51it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.51it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.55it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.56it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.60it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.62it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.62it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:04,  1.63it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.63it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.66it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:02,  1.68it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.70it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.67it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.68it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.71it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.73it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 59: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 301.9798997990001s
Training Epoch59:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch59:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.26s/it]Training Epoch59:   2%|[34mâ–         [0m| 2/92 [00:06<04:58,  3.31s/it]Training Epoch59:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:55,  3.32s/it]Training Epoch59:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.28s/it]Training Epoch59:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch59:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.26s/it]Training Epoch59:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:37,  3.27s/it]Training Epoch59:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:34,  3.27s/it]Training Epoch59:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.28s/it]Training Epoch59:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:29,  3.29s/it]Training Epoch59:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:27,  3.30s/it]Training Epoch59:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.28s/it]Training Epoch59:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.28s/it]Training Epoch59:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.30s/it]Training Epoch59:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.31s/it]Training Epoch59:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:12,  3.32s/it]Training Epoch59:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:10,  3.34s/it]Training Epoch59:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:07,  3.34s/it]Training Epoch59:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:03,  3.33s/it]Training Epoch59:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:59,  3.32s/it]Training Epoch59:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.31s/it]Training Epoch59:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch59:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.27s/it]Training Epoch59:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:42,  3.27s/it]Training Epoch59:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:38,  3.26s/it]Training Epoch59:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:33,  3.24s/it]Training Epoch59:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:30,  3.24s/it]Training Epoch59:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.28s/it]Training Epoch59:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:25,  3.26s/it]Training Epoch59:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:22,  3.26s/it]Training Epoch59:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:19,  3.27s/it]Training Epoch59:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:14,  3.24s/it]Training Epoch59:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:11,  3.24s/it]Training Epoch59:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:08,  3.25s/it]Training Epoch59:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:03,  3.22s/it]Training Epoch59:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:02,  3.25s/it]Training Epoch59:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:01,  3.30s/it]Training Epoch59:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:58,  3.30s/it]Training Epoch59:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:55,  3.31s/it]Training Epoch59:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:51,  3.30s/it]Training Epoch59:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:48,  3.30s/it]Training Epoch59:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:45,  3.30s/it]Training Epoch59:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:42,  3.31s/it]Training Epoch59:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:39,  3.32s/it]Training Epoch59:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:35,  3.30s/it]Training Epoch59:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:31,  3.30s/it]Training Epoch59:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.31s/it]Training Epoch59:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:24,  3.29s/it]Training Epoch59:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:20,  3.28s/it]Training Epoch59:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:18,  3.29s/it]Training Epoch59:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:14,  3.29s/it]Training Epoch59:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:11,  3.28s/it]Training Epoch59:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:07,  3.26s/it]Training Epoch59:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:04,  3.27s/it]Training Epoch59:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:01,  3.29s/it]Training Epoch59:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:58,  3.28s/it]Training Epoch59:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:55,  3.29s/it]Training Epoch59:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:52,  3.29s/it]Training Epoch59:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:48,  3.29s/it]Training Epoch59:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:45,  3.30s/it]Training Epoch59:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:42,  3.30s/it]Training Epoch59:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:38,  3.30s/it]Training Epoch59:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:35,  3.30s/it]Training Epoch59:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:31,  3.28s/it]Training Epoch59:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:28,  3.26s/it]Training Epoch59:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:24,  3.25s/it]Training Epoch59:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:20,  3.24s/it]Training Epoch59:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:17,  3.24s/it]Training Epoch59:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:14,  3.25s/it]Training Epoch59:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:11,  3.25s/it]Training Epoch59:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.25s/it]Training Epoch59:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:05,  3.27s/it]Training Epoch59:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.28s/it]Training Epoch59:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:58,  3.27s/it]Training Epoch59:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:55,  3.29s/it]Training Epoch59:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:52,  3.31s/it]Training Epoch59:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.30s/it]Training Epoch59:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:46,  3.31s/it]Training Epoch59:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.27s/it]Training Epoch59:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.26s/it]Training Epoch59:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:35,  3.24s/it]Training Epoch59:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:32,  3.27s/it]Training Epoch59:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.30s/it]Training Epoch59:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.29s/it]Training Epoch59:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.30s/it]Training Epoch59:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.28s/it]Training Epoch59:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.27s/it]Training Epoch59:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:48<00:13,  3.28s/it]Training Epoch59:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.28s/it]Training Epoch59:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.27s/it]Training Epoch59:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:58<00:03,  3.30s/it]Training Epoch59: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch59: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.28s/it]

 step 0 is completed and loss is 0.00011448943405412138

 step 1 is completed and loss is 0.00018856761744245887

 step 2 is completed and loss is 4.1066719859372824e-05

 step 3 is completed and loss is 9.184391819871962e-05

 step 4 is completed and loss is 7.104491669451818e-05

 step 5 is completed and loss is 4.237789835315198e-05

 step 6 is completed and loss is 0.000501479022204876

 step 7 is completed and loss is 8.016371430130675e-05

 step 8 is completed and loss is 8.403892570640892e-05

 step 9 is completed and loss is 4.249714402249083e-05

 step 10 is completed and loss is 0.0010779706062749028

 step 11 is completed and loss is 0.0006907828501425683

 step 12 is completed and loss is 0.00027786934515461326

 step 13 is completed and loss is 4.5834851334802806e-05

 step 14 is completed and loss is 3.9040223782649264e-05

 step 15 is completed and loss is 3.8980677345534787e-05

 step 16 is completed and loss is 0.00021471697255037725

 step 17 is completed and loss is 0.0001745006302371621

 step 18 is completed and loss is 6.180810305522755e-05

 step 19 is completed and loss is 0.0001390425459248945

 step 20 is completed and loss is 3.647737321443856e-05

 step 21 is completed and loss is 0.00010412249685032293

 step 22 is completed and loss is 0.00030891381902620196

 step 23 is completed and loss is 0.00010704367014113814

 step 24 is completed and loss is 7.158260268624872e-05

 step 25 is completed and loss is 0.00011794897727668285

 step 26 is completed and loss is 7.021168130449951e-05

 step 27 is completed and loss is 0.00017659289005678147

 step 28 is completed and loss is 0.00016591795429121703

 step 29 is completed and loss is 8.540980343241245e-05

 step 30 is completed and loss is 8.874728519003838e-05

 step 31 is completed and loss is 1.6391109966207296e-05

 step 32 is completed and loss is 0.00016681030683685094

 step 33 is completed and loss is 7.927082333480939e-05

 step 34 is completed and loss is 7.474125595763326e-05

 step 35 is completed and loss is 0.00023367739049717784

 step 36 is completed and loss is 2.1874629965168424e-05

 step 37 is completed and loss is 4.839776374865323e-05

 step 38 is completed and loss is 7.247635949170217e-05

 step 39 is completed and loss is 4.506004916038364e-05

 step 40 is completed and loss is 0.00012218185293022543

 step 41 is completed and loss is 3.18282181979157e-05

 step 42 is completed and loss is 6.23444575467147e-05

 step 43 is completed and loss is 6.836336251581088e-05

 step 44 is completed and loss is 2.556991057645064e-05

 step 45 is completed and loss is 0.00027568143559619784

 step 46 is completed and loss is 2.3901096938061528e-05

 step 47 is completed and loss is 6.603976362384856e-05

 step 48 is completed and loss is 0.0003557568124961108

 step 49 is completed and loss is 0.00010108361311722547

 step 50 is completed and loss is 9.154841245617718e-05

 step 51 is completed and loss is 6.544373172800988e-05

 step 52 is completed and loss is 0.0025920297484844923

 step 53 is completed and loss is 0.000327524496242404

 step 54 is completed and loss is 4.064934910275042e-05

 step 55 is completed and loss is 0.0016925816889852285

 step 56 is completed and loss is 4.094742325833067e-05

 step 57 is completed and loss is 0.00021882816508878022

 step 58 is completed and loss is 5.805251203128137e-05

 step 59 is completed and loss is 0.0005389380967244506

 step 60 is completed and loss is 0.00010084577661473304

 step 61 is completed and loss is 9.035386028699577e-05

 step 62 is completed and loss is 7.62898926041089e-05

 step 63 is completed and loss is 0.00036415073554962873

 step 64 is completed and loss is 0.00022007545339874923

 step 65 is completed and loss is 0.0001028719125315547

 step 66 is completed and loss is 0.0005900812684558332

 step 67 is completed and loss is 6.913823017384857e-05

 step 68 is completed and loss is 0.00022128756972961128

 step 69 is completed and loss is 0.00012158547178842127

 step 70 is completed and loss is 0.00016026223602239043

 step 71 is completed and loss is 0.00020179589046165347

 step 72 is completed and loss is 0.0005589259671978652

 step 73 is completed and loss is 7.825783541193232e-05

 step 74 is completed and loss is 0.00010394489800091833

 step 75 is completed and loss is 0.00018106205970980227

 step 76 is completed and loss is 0.00013433981803245842

 step 77 is completed and loss is 7.474113226635382e-05

 step 78 is completed and loss is 0.0002016206126427278

 step 79 is completed and loss is 0.0008823558455333114

 step 80 is completed and loss is 0.0002771819708868861

 step 81 is completed and loss is 0.0001052555744536221

 step 82 is completed and loss is 0.00012659151980187744

 step 83 is completed and loss is 0.0001683683367446065

 step 84 is completed and loss is 0.00012748352310154587

 step 85 is completed and loss is 0.00014137222024146467

 step 86 is completed and loss is 0.00014137222024146467

 step 87 is completed and loss is 0.00017772331193555146

 step 88 is completed and loss is 0.0002078064571833238

 step 89 is completed and loss is 7.199910760391504e-05

 step 90 is completed and loss is 0.0007064154488034546

 step 91 is completed and loss is 0.0001139544474426657
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.36it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.38it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.43it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.49it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.57it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.55it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.55it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.54it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.62it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:24,  1.64it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.62it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.59it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.57it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:22,  1.57it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.55it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.57it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.59it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.56it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.52it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.50it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.53it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.53it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.52it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.58it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.55it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.52it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:12,  1.50it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.51it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.56it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.60it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.57it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.57it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.58it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.56it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.50it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:04,  1.49it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.51it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.55it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.56it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.58it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.56it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 60: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 302.3966088929992s
Training Epoch60:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch60:   1%|[34m          [0m| 1/92 [00:03<05:02,  3.32s/it]Training Epoch60:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.30s/it]Training Epoch60:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:54,  3.31s/it]Training Epoch60:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.26s/it]Training Epoch60:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch60:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.31s/it]Training Epoch60:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch60:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.28s/it]Training Epoch60:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.27s/it]Training Epoch60:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:27,  3.27s/it]Training Epoch60:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.28s/it]Training Epoch60:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.29s/it]Training Epoch60:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:17,  3.27s/it]Training Epoch60:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:13,  3.25s/it]Training Epoch60:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:12,  3.28s/it]Training Epoch60:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.29s/it]Training Epoch60:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:07,  3.29s/it]Training Epoch60:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.30s/it]Training Epoch60:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:05,  3.36s/it]Training Epoch60:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<04:01,  3.35s/it]Training Epoch60:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:56,  3.33s/it]Training Epoch60:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:53,  3.34s/it]Training Epoch60:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:50,  3.34s/it]Training Epoch60:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:46,  3.34s/it]Training Epoch60:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.34s/it]Training Epoch60:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:42,  3.37s/it]Training Epoch60:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:38,  3.36s/it]Training Epoch60:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:35,  3.37s/it]Training Epoch60:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:31,  3.36s/it]Training Epoch60:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:26,  3.33s/it]Training Epoch60:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:24,  3.35s/it]Training Epoch60:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:18,  3.31s/it]Training Epoch60:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:16,  3.33s/it]Training Epoch60:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:15,  3.37s/it]Training Epoch60:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:12,  3.38s/it]Training Epoch60:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:09,  3.38s/it]Training Epoch60:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:04,  3.36s/it]Training Epoch60:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<03:00,  3.34s/it]Training Epoch60:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:56,  3.33s/it]Training Epoch60:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.32s/it]Training Epoch60:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:48,  3.31s/it]Training Epoch60:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:47,  3.35s/it]Training Epoch60:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:44,  3.36s/it]Training Epoch60:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:40,  3.33s/it]Training Epoch60:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.32s/it]Training Epoch60:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.34s/it]Training Epoch60:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:29,  3.31s/it]Training Epoch60:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:23,  3.26s/it]Training Epoch60:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:20,  3.26s/it]Training Epoch60:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:17,  3.28s/it]Training Epoch60:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:14,  3.29s/it]Training Epoch60:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:11,  3.28s/it]Training Epoch60:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:07,  3.28s/it]Training Epoch60:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:05,  3.31s/it]Training Epoch60:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:03,  3.34s/it]Training Epoch60:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<02:00,  3.35s/it]Training Epoch60:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:57,  3.36s/it]Training Epoch60:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:54,  3.36s/it]Training Epoch60:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.33s/it]Training Epoch60:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:44,  3.27s/it]Training Epoch60:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:40,  3.25s/it]Training Epoch60:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:38,  3.27s/it]Training Epoch60:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:34,  3.26s/it]Training Epoch60:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:31,  3.26s/it]Training Epoch60:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:27,  3.25s/it]Training Epoch60:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:25,  3.28s/it]Training Epoch60:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:23,  3.33s/it]Training Epoch60:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.33s/it]Training Epoch60:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.33s/it]Training Epoch60:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:12,  3.31s/it]Training Epoch60:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.29s/it]Training Epoch60:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:05,  3.28s/it]Training Epoch60:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.31s/it]Training Epoch60:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.29s/it]Training Epoch60:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.31s/it]Training Epoch60:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:53,  3.34s/it]Training Epoch60:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.31s/it]Training Epoch60:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.30s/it]Training Epoch60:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.33s/it]Training Epoch60:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.32s/it]Training Epoch60:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.32s/it]Training Epoch60:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.31s/it]Training Epoch60:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.28s/it]Training Epoch60:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.30s/it]Training Epoch60:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.29s/it]Training Epoch60:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.30s/it]Training Epoch60:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.31s/it]Training Epoch60:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.29s/it]Training Epoch60:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.28s/it]Training Epoch60:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.31s/it]Training Epoch60:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.32s/it]Training Epoch60: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.32s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch60: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.00010817329166457057

 step 1 is completed and loss is 0.00020168029004707932

 step 2 is completed and loss is 3.8503836549352854e-05

 step 3 is completed and loss is 0.0001087683776859194

 step 4 is completed and loss is 5.984020754112862e-05

 step 5 is completed and loss is 5.5311516916844994e-05

 step 6 is completed and loss is 0.00046746915904805064

 step 7 is completed and loss is 4.5536726247519255e-05

 step 8 is completed and loss is 9.816353122005239e-05

 step 9 is completed and loss is 3.838451812043786e-05

 step 10 is completed and loss is 0.0006046698545105755

 step 11 is completed and loss is 0.0011730454862117767

 step 12 is completed and loss is 0.0003186768153682351

 step 13 is completed and loss is 6.425174069590867e-05

 step 14 is completed and loss is 4.1305029299110174e-05

 step 15 is completed and loss is 3.480850500636734e-05

 step 16 is completed and loss is 0.000168419792316854

 step 17 is completed and loss is 0.0001236105163116008

 step 18 is completed and loss is 6.609936099266633e-05

 step 19 is completed and loss is 0.0001418438769178465

 step 20 is completed and loss is 5.14374696649611e-05

 step 21 is completed and loss is 6.3536390371155e-05

 step 22 is completed and loss is 0.0005242797778919339

 step 23 is completed and loss is 0.0001506081607658416

 step 24 is completed and loss is 7.182100671343505e-05

 step 25 is completed and loss is 0.0002293761062901467

 step 26 is completed and loss is 6.08541740803048e-05

 step 27 is completed and loss is 0.0002194963744841516

 step 28 is completed and loss is 0.00013093880261294544

 step 29 is completed and loss is 8.993920346256346e-05

 step 30 is completed and loss is 8.624399197287858e-05

 step 31 is completed and loss is 1.7702357581583783e-05

 step 32 is completed and loss is 0.000104955630376935

 step 33 is completed and loss is 8.749555854592472e-05

 step 34 is completed and loss is 9.291911555919796e-05

 step 35 is completed and loss is 0.0001685459865257144

 step 36 is completed and loss is 1.3470547855831683e-05

 step 37 is completed and loss is 5.57286839466542e-05

 step 38 is completed and loss is 9.166693780571222e-05

 step 39 is completed and loss is 6.598013715120032e-05

 step 40 is completed and loss is 9.238289931090549e-05

 step 41 is completed and loss is 5.989980127196759e-05

 step 42 is completed and loss is 8.278735913336277e-05

 step 43 is completed and loss is 5.352331936592236e-05

 step 44 is completed and loss is 3.242411185055971e-05

 step 45 is completed and loss is 0.00020245305495336652

 step 46 is completed and loss is 2.205342025263235e-05

 step 47 is completed and loss is 6.949658563826233e-05

 step 48 is completed and loss is 0.0005908759776502848

 step 49 is completed and loss is 7.86749878898263e-05

 step 50 is completed and loss is 8.844921103445813e-05

 step 51 is completed and loss is 6.246361590456218e-05

 step 52 is completed and loss is 0.0015212910948321223

 step 53 is completed and loss is 0.0002448848099447787

 step 54 is completed and loss is 4.3390929931774735e-05

 step 55 is completed and loss is 0.0014850200386717916

 step 56 is completed and loss is 5.417911597760394e-05

 step 57 is completed and loss is 0.00032308889785781503

 step 58 is completed and loss is 6.115150608820841e-05

 step 59 is completed and loss is 0.00034478094312362373

 step 60 is completed and loss is 9.423019218957052e-05

 step 61 is completed and loss is 8.224882913054898e-05

 step 62 is completed and loss is 7.86140954005532e-05

 step 63 is completed and loss is 0.0004431332927197218

 step 64 is completed and loss is 0.00035536137875169516

 step 65 is completed and loss is 9.345548460260034e-05

 step 66 is completed and loss is 0.00045926374150440097

 step 67 is completed and loss is 8.767245890339836e-05

 step 68 is completed and loss is 0.00019006090587936342

 step 69 is completed and loss is 0.00013076397590339184

 step 70 is completed and loss is 0.0001423243375029415

 step 71 is completed and loss is 0.00022568620624952018

 step 72 is completed and loss is 0.0004269657365512103

 step 73 is completed and loss is 9.381330164615065e-05

 step 74 is completed and loss is 0.00010227561870124191

 step 75 is completed and loss is 0.00020549551118165255

 step 76 is completed and loss is 0.00012313560000620782

 step 77 is completed and loss is 7.87339813541621e-05

 step 78 is completed and loss is 0.0001907743571791798

 step 79 is completed and loss is 0.0008011262980289757

 step 80 is completed and loss is 0.0002997661358676851

 step 81 is completed and loss is 0.00010102414671564475

 step 82 is completed and loss is 0.0001551358145661652

 step 83 is completed and loss is 0.00017313379794359207

 step 84 is completed and loss is 0.000144049379741773

 step 85 is completed and loss is 0.0001267114421352744

 step 86 is completed and loss is 9.214453893946484e-05

 step 87 is completed and loss is 0.00016473210416734219

 step 88 is completed and loss is 0.0002476084919180721

 step 89 is completed and loss is 5.841079109814018e-05

 step 90 is completed and loss is 0.0006283762631937861

 step 91 is completed and loss is 0.00016025522199925035
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.42it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.51it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:31,  1.51it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.48it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.53it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.55it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.54it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.55it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.59it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.58it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.59it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:22,  1.64it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.62it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.61it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.62it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:20,  1.63it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.59it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.58it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.57it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.57it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.59it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:16,  1.59it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:15,  1.59it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:14,  1.63it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:13,  1.66it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:13,  1.66it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:12,  1.62it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:18<00:12,  1.57it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:12,  1.57it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.57it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:20<00:10,  1.60it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:09,  1.60it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.59it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:22<00:08,  1.58it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.60it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:23<00:07,  1.60it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:24<00:06,  1.60it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:25<00:05,  1.56it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:05,  1.55it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.56it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:27<00:03,  1.57it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.61it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.58it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:29<00:01,  1.57it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.57it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:30<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.60it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.58it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 61: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.0776772600002s
Training Epoch61:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch61:   1%|[34m          [0m| 1/92 [00:03<04:58,  3.28s/it]Training Epoch61:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.31s/it]Training Epoch61:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:52,  3.29s/it]Training Epoch61:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.26s/it]Training Epoch61:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.29s/it]Training Epoch61:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.31s/it]Training Epoch61:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.33s/it]Training Epoch61:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.33s/it]Training Epoch61:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:36,  3.34s/it]Training Epoch61:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.33s/it]Training Epoch61:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.29s/it]Training Epoch61:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.30s/it]Training Epoch61:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.33s/it]Training Epoch61:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:21,  3.35s/it]Training Epoch61:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:16,  3.34s/it]Training Epoch61:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:13,  3.34s/it]Training Epoch61:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:09,  3.32s/it]Training Epoch61:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:09,  3.37s/it]Training Epoch61:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:03,  3.34s/it]Training Epoch61:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:59,  3.33s/it]Training Epoch61:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:56,  3.33s/it]Training Epoch61:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:50,  3.30s/it]Training Epoch61:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:45,  3.27s/it]Training Epoch61:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:42,  3.28s/it]Training Epoch61:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.28s/it]Training Epoch61:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:38,  3.32s/it]Training Epoch61:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:36,  3.33s/it]Training Epoch61:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:32,  3.31s/it]Training Epoch61:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.33s/it]Training Epoch61:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:28,  3.37s/it]Training Epoch61:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:26,  3.39s/it]Training Epoch61:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:19,  3.33s/it]Training Epoch61:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:16,  3.34s/it]Training Epoch61:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.32s/it]Training Epoch61:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:10,  3.34s/it]Training Epoch61:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:06,  3.33s/it]Training Epoch61:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:03,  3.33s/it]Training Epoch61:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:59,  3.32s/it]Training Epoch61:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:57,  3.35s/it]Training Epoch61:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:54,  3.35s/it]Training Epoch61:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:51,  3.37s/it]Training Epoch61:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:48,  3.38s/it]Training Epoch61:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:45,  3.39s/it]Training Epoch61:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:41,  3.37s/it]Training Epoch61:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:37,  3.36s/it]Training Epoch61:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:33,  3.33s/it]Training Epoch61:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:29,  3.33s/it]Training Epoch61:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:27,  3.34s/it]Training Epoch61:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:23,  3.34s/it]Training Epoch61:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:20,  3.34s/it]Training Epoch61:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:17,  3.35s/it]Training Epoch61:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:15,  3.40s/it]Training Epoch61:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:12,  3.41s/it]Training Epoch61:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [03:00<02:08,  3.39s/it]Training Epoch61:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:03<02:04,  3.37s/it]Training Epoch61:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<02:00,  3.34s/it]Training Epoch61:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:10<01:56,  3.32s/it]Training Epoch61:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:13<01:52,  3.31s/it]Training Epoch61:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:48,  3.29s/it]Training Epoch61:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:45,  3.28s/it]Training Epoch61:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:41,  3.28s/it]Training Epoch61:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:38,  3.28s/it]Training Epoch61:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:36,  3.32s/it]Training Epoch61:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:33<01:33,  3.32s/it]Training Epoch61:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:30,  3.35s/it]Training Epoch61:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:26,  3.33s/it]Training Epoch61:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:43<01:22,  3.31s/it]Training Epoch61:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:20,  3.37s/it]Training Epoch61:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:17,  3.37s/it]Training Epoch61:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:53<01:13,  3.34s/it]Training Epoch61:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:56<01:10,  3.35s/it]Training Epoch61:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.35s/it]Training Epoch61:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:03<01:03,  3.36s/it]Training Epoch61:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:06<01:00,  3.35s/it]Training Epoch61:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:56,  3.33s/it]Training Epoch61:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:13<00:53,  3.34s/it]Training Epoch61:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:16<00:49,  3.33s/it]Training Epoch61:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:20<00:46,  3.35s/it]Training Epoch61:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:23<00:43,  3.34s/it]Training Epoch61:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:26<00:40,  3.35s/it]Training Epoch61:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:30<00:36,  3.36s/it]Training Epoch61:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:33<00:33,  3.34s/it]Training Epoch61:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:36<00:30,  3.35s/it]Training Epoch61:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:40<00:26,  3.36s/it]Training Epoch61:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:43<00:23,  3.38s/it]Training Epoch61:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:46<00:20,  3.35s/it]Training Epoch61:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:50<00:16,  3.35s/it]Training Epoch61:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:53<00:13,  3.36s/it]Training Epoch61:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:56<00:10,  3.34s/it]Training Epoch61:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [05:00<00:06,  3.35s/it]Training Epoch61:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:03<00:03,  3.37s/it]Training Epoch61: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.33s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch61: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.34s/it]

 step 0 is completed and loss is 7.855465810280293e-05

 step 1 is completed and loss is 0.00016675812366884202

 step 2 is completed and loss is 4.714599344879389e-05

 step 3 is completed and loss is 0.00010310736251994967

 step 4 is completed and loss is 7.503755477955565e-05

 step 5 is completed and loss is 4.720569268101826e-05

 step 6 is completed and loss is 0.0014756289310753345

 step 7 is completed and loss is 5.793380114482716e-05

 step 8 is completed and loss is 8.004578558029607e-05

 step 9 is completed and loss is 4.160304524702951e-05

 step 10 is completed and loss is 0.00042869464959949255

 step 11 is completed and loss is 0.0006513117696158588

 step 12 is completed and loss is 0.00022943566727917641

 step 13 is completed and loss is 6.508615479106084e-05

 step 14 is completed and loss is 4.1185856389347464e-05

 step 15 is completed and loss is 3.433168603805825e-05

 step 16 is completed and loss is 0.0001532271271571517

 step 17 is completed and loss is 0.00014792318688705564

 step 18 is completed and loss is 4.893421646556817e-05

 step 19 is completed and loss is 0.00010304873285349458

 step 20 is completed and loss is 5.847039574291557e-05

 step 21 is completed and loss is 5.394074833020568e-05

 step 22 is completed and loss is 0.0005008830921724439

 step 23 is completed and loss is 0.00010245473094983026

 step 24 is completed and loss is 5.829145811730996e-05

 step 25 is completed and loss is 0.0002193675172748044

 step 26 is completed and loss is 6.401300197467208e-05

 step 27 is completed and loss is 0.0002247436495963484

 step 28 is completed and loss is 9.512323595117778e-05

 step 29 is completed and loss is 0.00010758046119008213

 step 30 is completed and loss is 8.612467354396358e-05

 step 31 is completed and loss is 2.187457721447572e-05

 step 32 is completed and loss is 6.645650137215853e-05

 step 33 is completed and loss is 7.81979106250219e-05

 step 34 is completed and loss is 7.229777111206204e-05

 step 35 is completed and loss is 0.00018970090604852885

 step 36 is completed and loss is 1.7463986296206713e-05

 step 37 is completed and loss is 6.884094909764826e-05

 step 38 is completed and loss is 6.842367292847484e-05

 step 39 is completed and loss is 4.392761911731213e-05

 step 40 is completed and loss is 0.00014012066822033376

 step 41 is completed and loss is 4.8278023314196616e-05

 step 42 is completed and loss is 5.793403397547081e-05

 step 43 is completed and loss is 6.288034637691453e-05

 step 44 is completed and loss is 2.3483822587877512e-05

 step 45 is completed and loss is 0.0002255161525681615

 step 46 is completed and loss is 2.5271949198213406e-05

 step 47 is completed and loss is 7.235725206555799e-05

 step 48 is completed and loss is 0.00038118037628009915

 step 49 is completed and loss is 7.843654748285189e-05

 step 50 is completed and loss is 8.272757986560464e-05

 step 51 is completed and loss is 5.835117190144956e-05

 step 52 is completed and loss is 0.0013059015618637204

 step 53 is completed and loss is 0.0003365219454281032

 step 54 is completed and loss is 4.070911381859332e-05

 step 55 is completed and loss is 0.002307301852852106

 step 56 is completed and loss is 4.523887037066743e-05

 step 57 is completed and loss is 0.00020089518511667848

 step 58 is completed and loss is 6.258194480324164e-05

 step 59 is completed and loss is 0.0002165706391679123

 step 60 is completed and loss is 9.583961218595505e-05

 step 61 is completed and loss is 6.436975672841072e-05

 step 62 is completed and loss is 9.339435200672597e-05

 step 63 is completed and loss is 0.0007004464860074222

 step 64 is completed and loss is 0.0003713853075169027

 step 65 is completed and loss is 9.428970224689692e-05

 step 66 is completed and loss is 0.00040893032564781606

 step 67 is completed and loss is 6.323780689854175e-05

 step 68 is completed and loss is 0.00019882089691236615

 step 69 is completed and loss is 0.0001481065119151026

 step 70 is completed and loss is 0.00014929586905054748

 step 71 is completed and loss is 0.00021269846183713526

 step 72 is completed and loss is 0.000531173893250525

 step 73 is completed and loss is 9.256166231352836e-05

 step 74 is completed and loss is 0.00012826007150579244

 step 75 is completed and loss is 0.0002129434869857505

 step 76 is completed and loss is 0.00013934550224803388

 step 77 is completed and loss is 8.129679190460593e-05

 step 78 is completed and loss is 0.0002157992566935718

 step 79 is completed and loss is 0.000593042466789484

 step 80 is completed and loss is 0.00024422918795607984

 step 81 is completed and loss is 0.00010597045184113085

 step 82 is completed and loss is 0.00011461263056844473

 step 83 is completed and loss is 0.00014065580035094172

 step 84 is completed and loss is 0.00014107067545410246

 step 85 is completed and loss is 0.0001284993631998077

 step 86 is completed and loss is 9.858122211880982e-05

 step 87 is completed and loss is 0.00013976285117678344

 step 88 is completed and loss is 0.0002067367167910561

 step 89 is completed and loss is 6.443024904001504e-05

 step 90 is completed and loss is 0.0007806475623510778

 step 91 is completed and loss is 0.0001245624152943492
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:39,  1.25it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.40it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.41it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.43it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.47it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.49it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.53it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.54it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:26,  1.54it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.54it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.53it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:24,  1.54it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.54it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.54it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.56it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.58it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:20,  1.58it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.57it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.59it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.57it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.57it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.56it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.57it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.57it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.56it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.58it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.57it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.57it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.58it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.54it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.54it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.57it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.60it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.59it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.59it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.58it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.60it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.58it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.58it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.56it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.54it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.54it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.55it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.53it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.55it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.54it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 62: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 307.2368904720024s
Training Epoch62:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch62:   1%|[34m          [0m| 1/92 [00:03<04:58,  3.28s/it]Training Epoch62:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.31s/it]Training Epoch62:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:52,  3.29s/it]Training Epoch62:   4%|[34mâ–         [0m| 4/92 [00:13<04:51,  3.31s/it]Training Epoch62:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:52,  3.36s/it]Training Epoch62:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:48,  3.36s/it]Training Epoch62:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:42,  3.33s/it]Training Epoch62:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.29s/it]Training Epoch62:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.30s/it]Training Epoch62:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:29,  3.29s/it]Training Epoch62:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.30s/it]Training Epoch62:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch62:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.29s/it]Training Epoch62:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:16,  3.28s/it]Training Epoch62:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.29s/it]Training Epoch62:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.30s/it]Training Epoch62:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.32s/it]Training Epoch62:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.31s/it]Training Epoch62:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.32s/it]Training Epoch62:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:57,  3.29s/it]Training Epoch62:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.30s/it]Training Epoch62:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:52,  3.32s/it]Training Epoch62:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:49,  3.33s/it]Training Epoch62:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:44,  3.31s/it]Training Epoch62:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.29s/it]Training Epoch62:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:38,  3.31s/it]Training Epoch62:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.31s/it]Training Epoch62:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:32,  3.32s/it]Training Epoch62:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:28,  3.32s/it]Training Epoch62:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:24,  3.30s/it]Training Epoch62:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.31s/it]Training Epoch62:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:18,  3.31s/it]Training Epoch62:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:15,  3.32s/it]Training Epoch62:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.31s/it]Training Epoch62:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:10,  3.34s/it]Training Epoch62:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:07,  3.35s/it]Training Epoch62:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:04,  3.35s/it]Training Epoch62:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<03:00,  3.35s/it]Training Epoch62:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:56,  3.33s/it]Training Epoch62:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.33s/it]Training Epoch62:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:48,  3.30s/it]Training Epoch62:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.30s/it]Training Epoch62:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:41,  3.29s/it]Training Epoch62:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:37,  3.28s/it]Training Epoch62:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:34,  3.29s/it]Training Epoch62:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.33s/it]Training Epoch62:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.33s/it]Training Epoch62:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:26,  3.32s/it]Training Epoch62:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:23,  3.33s/it]Training Epoch62:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.32s/it]Training Epoch62:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:16,  3.34s/it]Training Epoch62:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:13,  3.33s/it]Training Epoch62:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:08,  3.29s/it]Training Epoch62:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.29s/it]Training Epoch62:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:01,  3.28s/it]Training Epoch62:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:58,  3.29s/it]Training Epoch62:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:55,  3.31s/it]Training Epoch62:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:53,  3.33s/it]Training Epoch62:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.31s/it]Training Epoch62:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:46,  3.31s/it]Training Epoch62:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.30s/it]Training Epoch62:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.32s/it]Training Epoch62:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:35,  3.28s/it]Training Epoch62:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:31,  3.27s/it]Training Epoch62:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:28,  3.28s/it]Training Epoch62:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:25,  3.28s/it]Training Epoch62:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.29s/it]Training Epoch62:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.32s/it]Training Epoch62:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.31s/it]Training Epoch62:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.31s/it]Training Epoch62:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.31s/it]Training Epoch62:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.32s/it]Training Epoch62:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.29s/it]Training Epoch62:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:58,  3.27s/it]Training Epoch62:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:55,  3.28s/it]Training Epoch62:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.28s/it]Training Epoch62:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.29s/it]Training Epoch62:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:45,  3.27s/it]Training Epoch62:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:42,  3.25s/it]Training Epoch62:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:38,  3.24s/it]Training Epoch62:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:35,  3.27s/it]Training Epoch62:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:32,  3.29s/it]Training Epoch62:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.31s/it]Training Epoch62:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.32s/it]Training Epoch62:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.33s/it]Training Epoch62:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.29s/it]Training Epoch62:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.28s/it]Training Epoch62:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.28s/it]Training Epoch62:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.29s/it]Training Epoch62:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.29s/it]Training Epoch62:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.30s/it]Training Epoch62: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch62: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.30s/it]

 step 0 is completed and loss is 9.6492723969277e-05

 step 1 is completed and loss is 0.00019613737822510302

 step 2 is completed and loss is 3.522569386404939e-05

 step 3 is completed and loss is 9.035417315317318e-05

 step 4 is completed and loss is 7.46799778426066e-05

 step 5 is completed and loss is 4.368915324448608e-05

 step 6 is completed and loss is 0.00036276024184189737

 step 7 is completed and loss is 6.514509004773572e-05

 step 8 is completed and loss is 9.589911496732384e-05

 step 9 is completed and loss is 4.136460484005511e-05

 step 10 is completed and loss is 0.0005349298589862883

 step 11 is completed and loss is 0.0014911186881363392

 step 12 is completed and loss is 0.00023408113338518888

 step 13 is completed and loss is 8.332356810569763e-05

 step 14 is completed and loss is 5.01856702612713e-05

 step 15 is completed and loss is 3.528532761265524e-05

 step 16 is completed and loss is 0.0001421425404259935

 step 17 is completed and loss is 0.00010847375233424827

 step 18 is completed and loss is 5.1139384595444426e-05

 step 19 is completed and loss is 0.00023449797299690545

 step 20 is completed and loss is 5.096061431686394e-05

 step 21 is completed and loss is 6.99137308401987e-05

 step 22 is completed and loss is 0.0005501825944520533

 step 23 is completed and loss is 0.0001069246354745701

 step 24 is completed and loss is 6.907938222866505e-05

 step 25 is completed and loss is 0.00019267488096375018

 step 26 is completed and loss is 5.066260928288102e-05

 step 27 is completed and loss is 0.00015740279923193157

 step 28 is completed and loss is 0.00015292655734810978

 step 29 is completed and loss is 7.915182504802942e-05

 step 30 is completed and loss is 0.00011193082173122093

 step 31 is completed and loss is 1.782157414709218e-05

 step 32 is completed and loss is 9.262001549359411e-05

 step 33 is completed and loss is 0.00010382588516222313

 step 34 is completed and loss is 5.549035995500162e-05

 step 35 is completed and loss is 0.0002441036922391504

 step 36 is completed and loss is 1.8298425857210532e-05

 step 37 is completed and loss is 5.215265991864726e-05

 step 38 is completed and loss is 6.74701077514328e-05

 step 39 is completed and loss is 5.996018080622889e-05

 step 40 is completed and loss is 9.423046140000224e-05

 step 41 is completed and loss is 5.590681394096464e-05

 step 42 is completed and loss is 6.240411312319338e-05

 step 43 is completed and loss is 6.752898480044678e-05

 step 44 is completed and loss is 2.139774733223021e-05

 step 45 is completed and loss is 0.00020692301040980965

 step 46 is completed and loss is 2.253026468679309e-05

 step 47 is completed and loss is 8.040332613745704e-05

 step 48 is completed and loss is 0.0005293211434036493

 step 49 is completed and loss is 8.618460560683161e-05

 step 50 is completed and loss is 8.689959940966219e-05

 step 51 is completed and loss is 5.739759944844991e-05

 step 52 is completed and loss is 0.0018300415249541402

 step 53 is completed and loss is 0.00023677923309151083

 step 54 is completed and loss is 3.224550164304674e-05

 step 55 is completed and loss is 0.0009854561649262905

 step 56 is completed and loss is 3.4331667848164216e-05

 step 57 is completed and loss is 0.0002933020005002618

 step 58 is completed and loss is 5.90060226386413e-05

 step 59 is completed and loss is 0.00024409771140199155

 step 60 is completed and loss is 0.00011556557728908956

 step 61 is completed and loss is 5.9065605455543846e-05

 step 62 is completed and loss is 8.105763845378533e-05

 step 63 is completed and loss is 0.0004133089678362012

 step 64 is completed and loss is 0.0003504181222524494

 step 65 is completed and loss is 0.00010251418279949576

 step 66 is completed and loss is 0.0006276516360230744

 step 67 is completed and loss is 5.435748607851565e-05

 step 68 is completed and loss is 0.00018064523465000093

 step 69 is completed and loss is 0.00013088311243336648

 step 70 is completed and loss is 0.00017641081649344414

 step 71 is completed and loss is 0.0001806983636924997

 step 72 is completed and loss is 0.0005789847928099334

 step 73 is completed and loss is 8.17146064946428e-05

 step 74 is completed and loss is 0.00013451793347485363

 step 75 is completed and loss is 0.00016080040950328112

 step 76 is completed and loss is 0.00014310010010376573

 step 77 is completed and loss is 8.004558912944049e-05

 step 78 is completed and loss is 0.00020507484441623092

 step 79 is completed and loss is 0.0006176460301503539

 step 80 is completed and loss is 0.0002933297655545175

 step 81 is completed and loss is 8.171441731974483e-05

 step 82 is completed and loss is 0.00017152208602055907

 step 83 is completed and loss is 0.0001577595539856702

 step 84 is completed and loss is 0.00016067424439825118

 step 85 is completed and loss is 0.00012909532233607024

 step 86 is completed and loss is 8.868777513271198e-05

 step 87 is completed and loss is 0.00014899855887051672

 step 88 is completed and loss is 0.00020798870536964387

 step 89 is completed and loss is 7.956890476634726e-05

 step 90 is completed and loss is 0.0007746335468254983

 step 91 is completed and loss is 9.691067680250853e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.34it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.40it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.44it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.44it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.47it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.49it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.49it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.53it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.51it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.52it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.56it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.54it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.50it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.56it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.56it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.57it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.55it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.60it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.58it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.51it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.50it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.50it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.55it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.57it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.56it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.54it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.55it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.55it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.54it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.55it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.56it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.59it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.62it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:07,  1.65it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.69it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.70it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:05,  1.70it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.62it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:04,  1.64it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.57it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.61it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.59it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.64it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.59it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.59it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.55it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.57it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.56it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 63: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.31734494899865s
Training Epoch63:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch63:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.26s/it]Training Epoch63:   2%|[34mâ–         [0m| 2/92 [00:06<04:52,  3.24s/it]Training Epoch63:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:46,  3.22s/it]Training Epoch63:   4%|[34mâ–         [0m| 4/92 [00:12<04:45,  3.25s/it]Training Epoch63:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:41,  3.24s/it]Training Epoch63:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:38,  3.24s/it]Training Epoch63:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:35,  3.25s/it]Training Epoch63:   9%|[34mâ–Š         [0m| 8/92 [00:25<04:34,  3.26s/it]Training Epoch63:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.27s/it]Training Epoch63:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.27s/it]Training Epoch63:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:26,  3.29s/it]Training Epoch63:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.27s/it]Training Epoch63:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:17,  3.26s/it]Training Epoch63:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:15,  3.28s/it]Training Epoch63:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:48<04:12,  3.28s/it]Training Epoch63:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:07,  3.26s/it]Training Epoch63:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:04,  3.26s/it]Training Epoch63:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:01,  3.27s/it]Training Epoch63:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:01<03:57,  3.26s/it]Training Epoch63:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:53,  3.24s/it]Training Epoch63:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:49,  3.23s/it]Training Epoch63:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:45,  3.22s/it]Training Epoch63:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:14<03:42,  3.22s/it]Training Epoch63:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:40,  3.24s/it]Training Epoch63:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:37,  3.24s/it]Training Epoch63:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:34,  3.25s/it]Training Epoch63:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:27<03:28,  3.21s/it]Training Epoch63:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:30<03:26,  3.22s/it]Training Epoch63:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:25,  3.26s/it]Training Epoch63:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:22,  3.27s/it]Training Epoch63:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:40<03:18,  3.26s/it]Training Epoch63:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:14,  3.24s/it]Training Epoch63:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:09,  3.22s/it]Training Epoch63:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:05,  3.20s/it]Training Epoch63:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:53<03:03,  3.22s/it]Training Epoch63:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:56<03:01,  3.25s/it]Training Epoch63:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:00<02:59,  3.26s/it]Training Epoch63:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:03<02:55,  3.26s/it]Training Epoch63:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:06<02:51,  3.24s/it]Training Epoch63:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:09<02:48,  3.24s/it]Training Epoch63:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:45,  3.25s/it]Training Epoch63:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:16<02:41,  3.24s/it]Training Epoch63:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:19<02:38,  3.23s/it]Training Epoch63:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:22<02:35,  3.25s/it]Training Epoch63:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:26<02:33,  3.26s/it]Training Epoch63:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:29<02:29,  3.26s/it]Training Epoch63:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:32<02:26,  3.25s/it]Training Epoch63:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:35<02:23,  3.26s/it]Training Epoch63:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:39<02:20,  3.26s/it]Training Epoch63:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:42<02:17,  3.26s/it]Training Epoch63:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:45<02:12,  3.24s/it]Training Epoch63:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:48<02:09,  3.23s/it]Training Epoch63:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:52<02:06,  3.23s/it]Training Epoch63:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:55<02:02,  3.23s/it]Training Epoch63:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:58<01:59,  3.23s/it]Training Epoch63:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:01<01:57,  3.26s/it]Training Epoch63:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:05<01:55,  3.29s/it]Training Epoch63:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:08<01:52,  3.30s/it]Training Epoch63:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:11<01:48,  3.30s/it]Training Epoch63:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:15<01:44,  3.28s/it]Training Epoch63:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:18<01:41,  3.26s/it]Training Epoch63:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:21<01:37,  3.26s/it]Training Epoch63:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:24<01:34,  3.26s/it]Training Epoch63:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:28<01:30,  3.24s/it]Training Epoch63:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:31<01:26,  3.22s/it]Training Epoch63:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:34<01:24,  3.24s/it]Training Epoch63:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:37<01:21,  3.24s/it]Training Epoch63:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:41<01:18,  3.27s/it]Training Epoch63:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:44<01:14,  3.26s/it]Training Epoch63:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:47<01:11,  3.27s/it]Training Epoch63:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:50<01:08,  3.28s/it]Training Epoch63:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:54<01:05,  3.28s/it]Training Epoch63:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:57<01:02,  3.27s/it]Training Epoch63:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:00<00:58,  3.24s/it]Training Epoch63:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:03<00:55,  3.25s/it]Training Epoch63:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:07<00:51,  3.24s/it]Training Epoch63:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:10<00:48,  3.23s/it]Training Epoch63:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:13<00:45,  3.23s/it]Training Epoch63:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:16<00:42,  3.23s/it]Training Epoch63:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:19<00:38,  3.23s/it]Training Epoch63:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:23<00:35,  3.24s/it]Training Epoch63:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:26<00:32,  3.23s/it]Training Epoch63:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:29<00:29,  3.23s/it]Training Epoch63:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:32<00:25,  3.22s/it]Training Epoch63:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:36<00:22,  3.25s/it]Training Epoch63:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:39<00:19,  3.24s/it]Training Epoch63:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:42<00:16,  3.24s/it]Training Epoch63:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:45<00:13,  3.26s/it]Training Epoch63:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:49<00:09,  3.28s/it]Training Epoch63:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:52<00:06,  3.29s/it]Training Epoch63:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:55<00:03,  3.27s/it]Training Epoch63: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:59<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch63: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:59<00:00,  3.25s/it]

 step 0 is completed and loss is 0.000160016497829929

 step 1 is completed and loss is 0.00018439898849464953

 step 2 is completed and loss is 3.707338328240439e-05

 step 3 is completed and loss is 0.0001104372859117575

 step 4 is completed and loss is 6.0316993767628446e-05

 step 5 is completed and loss is 5.1437375077512115e-05

 step 6 is completed and loss is 0.0003724134876392782

 step 7 is completed and loss is 5.3463470976566896e-05

 step 8 is completed and loss is 8.141661965055391e-05

 step 9 is completed and loss is 4.726525003206916e-05

 step 10 is completed and loss is 0.0006317952647805214

 step 11 is completed and loss is 0.001213778741657734

 step 12 is completed and loss is 0.0003360701375640929

 step 13 is completed and loss is 6.37153279967606e-05

 step 14 is completed and loss is 4.017262835986912e-05

 step 15 is completed and loss is 3.683499380713329e-05

 step 16 is completed and loss is 0.00026440544752404094

 step 17 is completed and loss is 0.00013558784849010408

 step 18 is completed and loss is 4.821897891815752e-05

 step 19 is completed and loss is 0.00019624503329396248

 step 20 is completed and loss is 5.113945371704176e-05

 step 21 is completed and loss is 6.282119284151122e-05

 step 22 is completed and loss is 0.0003781962732318789

 step 23 is completed and loss is 0.0001267689949600026

 step 24 is completed and loss is 6.824498996138573e-05

 step 25 is completed and loss is 0.00026619492564350367

 step 26 is completed and loss is 5.2092935220571235e-05

 step 27 is completed and loss is 0.00013761762238573283

 step 28 is completed and loss is 0.0001665735908318311

 step 29 is completed and loss is 8.535019878763705e-05

 step 30 is completed and loss is 0.00010352750541642308

 step 31 is completed and loss is 1.5735471606603824e-05

 step 32 is completed and loss is 9.065333870239556e-05

 step 33 is completed and loss is 8.290616824524477e-05

 step 34 is completed and loss is 6.812553328927606e-05

 step 35 is completed and loss is 0.00022241301485337317

 step 36 is completed and loss is 1.6093097656266764e-05

 step 37 is completed and loss is 6.538415618706495e-05

 step 38 is completed and loss is 8.320423512486741e-05

 step 39 is completed and loss is 4.631170304492116e-05

 step 40 is completed and loss is 0.00010322983143851161

 step 41 is completed and loss is 8.3202074165456e-05

 step 42 is completed and loss is 6.0973681684117764e-05

 step 43 is completed and loss is 7.229719631141052e-05

 step 44 is completed and loss is 2.235140163975302e-05

 step 45 is completed and loss is 0.00020483661501202732

 step 46 is completed and loss is 2.1040174033259973e-05

 step 47 is completed and loss is 7.778103463351727e-05

 step 48 is completed and loss is 0.00037219238583929837

 step 49 is completed and loss is 8.779375639278442e-05

 step 50 is completed and loss is 9.095239511225373e-05

 step 51 is completed and loss is 5.155667895451188e-05

 step 52 is completed and loss is 0.001652256352826953

 step 53 is completed and loss is 0.00033943704329431057

 step 54 is completed and loss is 4.2914274672511965e-05

 step 55 is completed and loss is 0.0014215167611837387

 step 56 is completed and loss is 5.0602960982359946e-05

 step 57 is completed and loss is 0.00030795569182373583

 step 58 is completed and loss is 5.233100091572851e-05

 step 59 is completed and loss is 0.0003253580944146961

 step 60 is completed and loss is 0.00010555406333878636

 step 61 is completed and loss is 7.336910493904725e-05

 step 62 is completed and loss is 8.373970922548324e-05

 step 63 is completed and loss is 0.00031006280914880335

 step 64 is completed and loss is 0.0004019998596049845

 step 65 is completed and loss is 8.350249845534563e-05

 step 66 is completed and loss is 0.0005366172990761697

 step 67 is completed and loss is 5.6384149502264336e-05

 step 68 is completed and loss is 0.0001616943336557597

 step 69 is completed and loss is 0.00022670860926155

 step 70 is completed and loss is 0.00015668603009544313

 step 71 is completed and loss is 0.00016455008881166577

 step 72 is completed and loss is 0.00042595306877046824

 step 73 is completed and loss is 9.029696229845285e-05

 step 74 is completed and loss is 0.00011645983613561839

 step 75 is completed and loss is 0.00024017663963604718

 step 76 is completed and loss is 0.00011955976515309885

 step 77 is completed and loss is 6.419188139261678e-05

 step 78 is completed and loss is 0.00018088292563334107

 step 79 is completed and loss is 0.0010943744564428926

 step 80 is completed and loss is 0.00030727399280294776

 step 81 is completed and loss is 0.00010769905929919332

 step 82 is completed and loss is 0.00016181029786821455

 step 83 is completed and loss is 0.0002011406177189201

 step 84 is completed and loss is 0.0001710434735286981

 step 85 is completed and loss is 0.00017998983094003052

 step 86 is completed and loss is 9.178694017464295e-05

 step 87 is completed and loss is 0.00018117997387889773

 step 88 is completed and loss is 0.00017610812210477889

 step 89 is completed and loss is 5.7099467085208744e-05

 step 90 is completed and loss is 0.0004770146915689111

 step 91 is completed and loss is 7.962746894918382e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.44it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.52it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.48it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.54it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.57it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.56it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.60it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.56it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.55it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.53it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.52it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:23,  1.51it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.51it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.52it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.51it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.51it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.52it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.53it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.49it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.47it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.46it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:15,  1.45it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.45it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.45it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.45it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.47it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.48it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.53it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.57it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.57it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.56it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.52it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.52it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.50it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.53it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.52it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.51it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.50it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.49it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.48it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.49it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.52it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 64: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 299.42176658899916s
Training Epoch64:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch64:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.30s/it]Training Epoch64:   2%|[34mâ–         [0m| 2/92 [00:06<04:56,  3.30s/it]Training Epoch64:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:52,  3.28s/it]Training Epoch64:   4%|[34mâ–         [0m| 4/92 [00:13<04:46,  3.25s/it]Training Epoch64:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.29s/it]Training Epoch64:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.30s/it]Training Epoch64:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:42,  3.32s/it]Training Epoch64:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.32s/it]Training Epoch64:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:36,  3.33s/it]Training Epoch64:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:31,  3.31s/it]Training Epoch64:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.32s/it]Training Epoch64:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:27,  3.34s/it]Training Epoch64:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:25,  3.36s/it]Training Epoch64:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:21,  3.36s/it]Training Epoch64:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch64:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:11,  3.31s/it]Training Epoch64:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.31s/it]Training Epoch64:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:06,  3.32s/it]Training Epoch64:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:02,  3.32s/it]Training Epoch64:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:59,  3.32s/it]Training Epoch64:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:52,  3.28s/it]Training Epoch64:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:45,  3.23s/it]Training Epoch64:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:43,  3.24s/it]Training Epoch64:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:41,  3.26s/it]Training Epoch64:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:38,  3.26s/it]Training Epoch64:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:34,  3.26s/it]Training Epoch64:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:33,  3.28s/it]Training Epoch64:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.30s/it]Training Epoch64:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:28,  3.31s/it]Training Epoch64:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:24,  3.30s/it]Training Epoch64:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:19,  3.28s/it]Training Epoch64:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:16,  3.27s/it]Training Epoch64:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:14,  3.30s/it]Training Epoch64:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.31s/it]Training Epoch64:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:10,  3.34s/it]Training Epoch64:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:06,  3.34s/it]Training Epoch64:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.32s/it]Training Epoch64:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.31s/it]Training Epoch64:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.30s/it]Training Epoch64:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:48,  3.24s/it]Training Epoch64:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:44,  3.23s/it]Training Epoch64:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:39,  3.20s/it]Training Epoch64:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:38,  3.24s/it]Training Epoch64:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:37,  3.28s/it]Training Epoch64:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:34,  3.28s/it]Training Epoch64:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:30,  3.27s/it]Training Epoch64:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:27,  3.28s/it]Training Epoch64:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:23,  3.25s/it]Training Epoch64:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:21,  3.30s/it]Training Epoch64:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:18,  3.30s/it]Training Epoch64:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:15,  3.31s/it]Training Epoch64:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.28s/it]Training Epoch64:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.30s/it]Training Epoch64:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:05,  3.30s/it]Training Epoch64:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.28s/it]Training Epoch64:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:58,  3.28s/it]Training Epoch64:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:56,  3.32s/it]Training Epoch64:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:53,  3.34s/it]Training Epoch64:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:50,  3.35s/it]Training Epoch64:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:47,  3.35s/it]Training Epoch64:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.32s/it]Training Epoch64:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.32s/it]Training Epoch64:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:36,  3.31s/it]Training Epoch64:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.30s/it]Training Epoch64:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.30s/it]Training Epoch64:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.28s/it]Training Epoch64:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.28s/it]Training Epoch64:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.32s/it]Training Epoch64:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.31s/it]Training Epoch64:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.30s/it]Training Epoch64:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.31s/it]Training Epoch64:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.34s/it]Training Epoch64:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:03,  3.32s/it]Training Epoch64:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<01:00,  3.33s/it]Training Epoch64:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.31s/it]Training Epoch64:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.29s/it]Training Epoch64:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:49,  3.29s/it]Training Epoch64:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:45,  3.28s/it]Training Epoch64:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.31s/it]Training Epoch64:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:39,  3.28s/it]Training Epoch64:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.30s/it]Training Epoch64:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:32,  3.28s/it]Training Epoch64:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.25s/it]Training Epoch64:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.26s/it]Training Epoch64:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.29s/it]Training Epoch64:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.28s/it]Training Epoch64:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.29s/it]Training Epoch64:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.32s/it]Training Epoch64:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.32s/it]Training Epoch64:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.36s/it]Training Epoch64:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.36s/it]Training Epoch64: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.38s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch64: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 7.867343811085448e-05

 step 1 is completed and loss is 0.0001605022989679128

 step 2 is completed and loss is 3.737135557457805e-05

 step 3 is completed and loss is 8.928154420573264e-05

 step 4 is completed and loss is 7.944772369228303e-05

 step 5 is completed and loss is 4.476205140235834e-05

 step 6 is completed and loss is 0.0009883454767987132

 step 7 is completed and loss is 6.752904300810769e-05

 step 8 is completed and loss is 8.266822260338813e-05

 step 9 is completed and loss is 4.2258689063601196e-05

 step 10 is completed and loss is 0.0005853668553754687

 step 11 is completed and loss is 0.0005552122020162642

 step 12 is completed and loss is 0.0002616652345750481

 step 13 is completed and loss is 6.0735284932889044e-05

 step 14 is completed and loss is 4.142431862419471e-05

 step 15 is completed and loss is 4.660974445869215e-05

 step 16 is completed and loss is 0.0002297328901477158

 step 17 is completed and loss is 0.00018064017058350146

 step 18 is completed and loss is 5.185462941881269e-05

 step 19 is completed and loss is 0.0001740804291330278

 step 20 is completed and loss is 6.747006409568712e-05

 step 21 is completed and loss is 6.675483018625528e-05

 step 22 is completed and loss is 0.0004337120335549116

 step 23 is completed and loss is 0.0001286775805056095

 step 24 is completed and loss is 6.675490294583142e-05

 step 25 is completed and loss is 0.00015441857976838946

 step 26 is completed and loss is 4.702690421254374e-05

 step 27 is completed and loss is 0.00023803237127140164

 step 28 is completed and loss is 0.0001458952174289152

 step 29 is completed and loss is 8.701899787411094e-05

 step 30 is completed and loss is 0.0001158038794528693

 step 31 is completed and loss is 1.6510322893736884e-05

 step 32 is completed and loss is 7.408524834318087e-05

 step 33 is completed and loss is 8.302582136821002e-05

 step 34 is completed and loss is 6.365562148857862e-05

 step 35 is completed and loss is 0.00022616394562646747

 step 36 is completed and loss is 1.7583171938895248e-05

 step 37 is completed and loss is 6.3774932641536e-05

 step 38 is completed and loss is 6.776796362828463e-05

 step 39 is completed and loss is 5.7457153161522e-05

 step 40 is completed and loss is 9.172727004624903e-05

 step 41 is completed and loss is 4.7085828555282205e-05

 step 42 is completed and loss is 6.29405039944686e-05

 step 43 is completed and loss is 6.234368629520759e-05

 step 44 is completed and loss is 2.592756209196523e-05

 step 45 is completed and loss is 0.00020310927357058972

 step 46 is completed and loss is 2.1755400666734204e-05

 step 47 is completed and loss is 7.766173803247511e-05

 step 48 is completed and loss is 0.0005366428522393107

 step 49 is completed and loss is 7.551623275503516e-05

 step 50 is completed and loss is 9.166762174572796e-05

 step 51 is completed and loss is 6.389411282725632e-05

 step 52 is completed and loss is 0.0015660489443689585

 step 53 is completed and loss is 0.00027193210553377867

 step 54 is completed and loss is 4.3271807953715324e-05

 step 55 is completed and loss is 0.001313151908107102

 step 56 is completed and loss is 3.8324957131408155e-05

 step 57 is completed and loss is 0.000294968398520723

 step 58 is completed and loss is 5.870805398444645e-05

 step 59 is completed and loss is 0.0005158248241059482

 step 60 is completed and loss is 0.00011139484558952972

 step 61 is completed and loss is 4.917214755550958e-05

 step 62 is completed and loss is 8.040223474381492e-05

 step 63 is completed and loss is 0.0002896888763643801

 step 64 is completed and loss is 0.00029793952126055956

 step 65 is completed and loss is 8.749568951316178e-05

 step 66 is completed and loss is 0.0003644343523774296

 step 67 is completed and loss is 5.73971337871626e-05

 step 68 is completed and loss is 0.00017683104670140892

 step 69 is completed and loss is 0.00013785433839075267

 step 70 is completed and loss is 0.00014703134365845472

 step 71 is completed and loss is 0.00019803980831056833

 step 72 is completed and loss is 0.00042880786349996924

 step 73 is completed and loss is 7.980743248481303e-05

 step 74 is completed and loss is 0.00011473175254650414

 step 75 is completed and loss is 0.000224207469727844

 step 76 is completed and loss is 0.00010787858627736568

 step 77 is completed and loss is 8.278707537101582e-05

 step 78 is completed and loss is 0.00023564635193906724

 step 79 is completed and loss is 0.001212041825056076

 step 80 is completed and loss is 0.00032449280843138695

 step 81 is completed and loss is 0.00010316963744116947

 step 82 is completed and loss is 0.00011866486602229998

 step 83 is completed and loss is 0.00017933161871042103

 step 84 is completed and loss is 0.00010424108768347651

 step 85 is completed and loss is 0.00010895135346800089

 step 86 is completed and loss is 8.439661905867979e-05

 step 87 is completed and loss is 0.00013302748266141862

 step 88 is completed and loss is 0.00020560341363307089

 step 89 is completed and loss is 6.240382208488882e-05

 step 90 is completed and loss is 0.0007954169996082783

 step 91 is completed and loss is 0.00034142888034693897
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:30,  1.62it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.49it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.46it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.50it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.59it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:26,  1.65it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:26,  1.65it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:25,  1.65it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:24,  1.65it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:24,  1.61it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:06<00:24,  1.61it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.59it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.53it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:23,  1.54it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.55it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.53it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.50it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.51it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.56it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.56it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.56it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.59it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.59it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.61it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:15,  1.61it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.54it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.55it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:14,  1.56it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:12,  1.62it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.61it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:12,  1.58it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.57it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.55it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.57it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.52it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.50it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:09,  1.42it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:08,  1.45it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.47it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.54it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.57it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.53it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.56it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.59it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.54it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.51it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.50it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.49it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 65: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.07890942099766s
Training Epoch65:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch65:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.26s/it]Training Epoch65:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.31s/it]Training Epoch65:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:52,  3.29s/it]Training Epoch65:   4%|[34mâ–         [0m| 4/92 [00:13<04:50,  3.30s/it]Training Epoch65:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch65:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.29s/it]Training Epoch65:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:38,  3.28s/it]Training Epoch65:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.29s/it]Training Epoch65:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.29s/it]Training Epoch65:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:30,  3.29s/it]Training Epoch65:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.30s/it]Training Epoch65:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.28s/it]Training Epoch65:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:18,  3.27s/it]Training Epoch65:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:15,  3.27s/it]Training Epoch65:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:11,  3.26s/it]Training Epoch65:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:06,  3.24s/it]Training Epoch65:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:02,  3.23s/it]Training Epoch65:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<03:59,  3.23s/it]Training Epoch65:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:56,  3.24s/it]Training Epoch65:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:52,  3.23s/it]Training Epoch65:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:49,  3.23s/it]Training Epoch65:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:47,  3.24s/it]Training Epoch65:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:14<03:42,  3.22s/it]Training Epoch65:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:40,  3.24s/it]Training Epoch65:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:38,  3.26s/it]Training Epoch65:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:36,  3.29s/it]Training Epoch65:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:32,  3.28s/it]Training Epoch65:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:28,  3.26s/it]Training Epoch65:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:26,  3.28s/it]Training Epoch65:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:22,  3.27s/it]Training Epoch65:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:19,  3.28s/it]Training Epoch65:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:16,  3.28s/it]Training Epoch65:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:11,  3.24s/it]Training Epoch65:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:05,  3.21s/it]Training Epoch65:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:03,  3.22s/it]Training Epoch65:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:01,  3.25s/it]Training Epoch65:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:00<02:58,  3.24s/it]Training Epoch65:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:03<02:56,  3.28s/it]Training Epoch65:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:53,  3.28s/it]Training Epoch65:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:10<02:52,  3.31s/it]Training Epoch65:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:48,  3.31s/it]Training Epoch65:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:47,  3.35s/it]Training Epoch65:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:44,  3.36s/it]Training Epoch65:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:42,  3.38s/it]Training Epoch65:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:38,  3.38s/it]Training Epoch65:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:33,  3.35s/it]Training Epoch65:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:29,  3.33s/it]Training Epoch65:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:26,  3.34s/it]Training Epoch65:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:24,  3.36s/it]Training Epoch65:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:21,  3.37s/it]Training Epoch65:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:17,  3.34s/it]Training Epoch65:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:13,  3.34s/it]Training Epoch65:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:10,  3.35s/it]Training Epoch65:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:06,  3.32s/it]Training Epoch65:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:02,  3.30s/it]Training Epoch65:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:58,  3.30s/it]Training Epoch65:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:55,  3.29s/it]Training Epoch65:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:52,  3.31s/it]Training Epoch65:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.30s/it]Training Epoch65:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:45,  3.30s/it]Training Epoch65:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:42,  3.30s/it]Training Epoch65:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:39,  3.32s/it]Training Epoch65:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:37,  3.35s/it]Training Epoch65:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:33,  3.34s/it]Training Epoch65:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.33s/it]Training Epoch65:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:26,  3.32s/it]Training Epoch65:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:23,  3.33s/it]Training Epoch65:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:20,  3.34s/it]Training Epoch65:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.32s/it]Training Epoch65:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.29s/it]Training Epoch65:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.26s/it]Training Epoch65:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.27s/it]Training Epoch65:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:02,  3.27s/it]Training Epoch65:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:59,  3.30s/it]Training Epoch65:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:55,  3.29s/it]Training Epoch65:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.30s/it]Training Epoch65:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:50,  3.35s/it]Training Epoch65:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:46,  3.33s/it]Training Epoch65:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:43,  3.33s/it]Training Epoch65:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:40,  3.37s/it]Training Epoch65:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.36s/it]Training Epoch65:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.34s/it]Training Epoch65:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:30,  3.33s/it]Training Epoch65:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.30s/it]Training Epoch65:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.30s/it]Training Epoch65:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.32s/it]Training Epoch65:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.28s/it]Training Epoch65:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.30s/it]Training Epoch65:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.31s/it]Training Epoch65:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.32s/it]Training Epoch65:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.32s/it]Training Epoch65: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.32s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch65: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.00014011388702783734

 step 1 is completed and loss is 0.00014947594900149852

 step 2 is completed and loss is 3.772901982301846e-05

 step 3 is completed and loss is 0.00010733863746281713

 step 4 is completed and loss is 8.147412881953642e-05

 step 5 is completed and loss is 4.9589758418733254e-05

 step 6 is completed and loss is 0.0004158922820352018

 step 7 is completed and loss is 5.9363897889852524e-05

 step 8 is completed and loss is 6.395367381628603e-05

 step 9 is completed and loss is 4.2675877921283245e-05

 step 10 is completed and loss is 0.0006810292252339423

 step 11 is completed and loss is 0.0009954216657206416

 step 12 is completed and loss is 0.0002547537151258439

 step 13 is completed and loss is 5.894725472899154e-05

 step 14 is completed and loss is 4.2914398363791406e-05

 step 15 is completed and loss is 3.814624506048858e-05

 step 16 is completed and loss is 0.0001535841729491949

 step 17 is completed and loss is 0.00013410042447503656

 step 18 is completed and loss is 4.869573604082689e-05

 step 19 is completed and loss is 0.00013975783076602966

 step 20 is completed and loss is 4.631171395885758e-05

 step 21 is completed and loss is 7.402614573948085e-05

 step 22 is completed and loss is 0.0004138713120482862

 step 23 is completed and loss is 0.0001364830241072923

 step 24 is completed and loss is 6.413252413040027e-05

 step 25 is completed and loss is 0.00013797302381135523

 step 26 is completed and loss is 6.121197657193989e-05

 step 27 is completed and loss is 0.0002236105501651764

 step 28 is completed and loss is 0.00011514662764966488

 step 29 is completed and loss is 7.331102096941322e-05

 step 30 is completed and loss is 0.00015138089656829834

 step 31 is completed and loss is 1.823881029849872e-05

 step 32 is completed and loss is 9.542085172142833e-05

 step 33 is completed and loss is 8.082051499513909e-05

 step 34 is completed and loss is 7.509881106670946e-05

 step 35 is completed and loss is 0.00016413716366514564

 step 36 is completed and loss is 1.7463986296206713e-05

 step 37 is completed and loss is 7.223820284707472e-05

 step 38 is completed and loss is 0.00010167950676986948

 step 39 is completed and loss is 6.317879888229072e-05

 step 40 is completed and loss is 0.0001143746922025457

 step 41 is completed and loss is 4.4761665776604787e-05

 step 42 is completed and loss is 7.056936738081276e-05

 step 43 is completed and loss is 6.639659841312096e-05

 step 44 is completed and loss is 2.1338135411497205e-05

 step 45 is completed and loss is 0.00019583760877139866

 step 46 is completed and loss is 1.9430890461080708e-05

 step 47 is completed and loss is 6.937730358913541e-05

 step 48 is completed and loss is 0.000427470775321126

 step 49 is completed and loss is 8.397937926929444e-05

 step 50 is completed and loss is 9.017768024932593e-05

 step 51 is completed and loss is 5.8708748838398606e-05

 step 52 is completed and loss is 0.002184834098443389

 step 53 is completed and loss is 0.00039620892493985593

 step 54 is completed and loss is 3.3854725188575685e-05

 step 55 is completed and loss is 0.001179959625005722

 step 56 is completed and loss is 3.808658220805228e-05

 step 57 is completed and loss is 0.00017158046830445528

 step 58 is completed and loss is 6.627701804973185e-05

 step 59 is completed and loss is 0.0002440978860249743

 step 60 is completed and loss is 9.488606883678585e-05

 step 61 is completed and loss is 6.514457345474511e-05

 step 62 is completed and loss is 7.676690438529477e-05

 step 63 is completed and loss is 0.000415027083363384

 step 64 is completed and loss is 0.0002452161570545286

 step 65 is completed and loss is 9.875925024971366e-05

 step 66 is completed and loss is 0.0003737903607543558

 step 67 is completed and loss is 6.258228677324951e-05

 step 68 is completed and loss is 0.00021544758055824786

 step 69 is completed and loss is 0.0001663410512264818

 step 70 is completed and loss is 0.00018934289983008057

 step 71 is completed and loss is 0.00014864042168483138

 step 72 is completed and loss is 0.00044805044308304787

 step 73 is completed and loss is 8.749563858145848e-05

 step 74 is completed and loss is 0.00012051274825353175

 step 75 is completed and loss is 0.00021568512602243572

 step 76 is completed and loss is 0.0001310021907556802

 step 77 is completed and loss is 5.984121889923699e-05

 step 78 is completed and loss is 0.000190952472621575

 step 79 is completed and loss is 0.0006890400545671582

 step 80 is completed and loss is 0.00028707069577649236

 step 81 is completed and loss is 9.75079310592264e-05

 step 82 is completed and loss is 0.00011431469465605915

 step 83 is completed and loss is 0.00014387474220711738

 step 84 is completed and loss is 0.00015012720541562885

 step 85 is completed and loss is 0.00014435203047469258

 step 86 is completed and loss is 0.00011383838864276186

 step 87 is completed and loss is 0.0001276052207686007

 step 88 is completed and loss is 0.00019636786601040512

 step 89 is completed and loss is 6.913873949088156e-05

 step 90 is completed and loss is 0.0007300003198906779

 step 91 is completed and loss is 0.00013671795022673905
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.35it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.38it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.44it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.44it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.43it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.42it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.44it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.50it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.46it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.46it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.46it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.44it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:25,  1.43it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.44it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.43it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.43it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.44it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.49it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:20,  1.50it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.50it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.48it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:18,  1.53it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.56it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.52it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.53it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:14,  1.55it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.44it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:14,  1.42it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:13,  1.45it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.45it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.48it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.53it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.50it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.52it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.50it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.55it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.49it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.49it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.46it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.45it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.46it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.43it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.43it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.47it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.47it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.47it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 66: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 303.73315749099856s
Training Epoch66:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch66:   1%|[34m          [0m| 1/92 [00:03<05:04,  3.35s/it]Training Epoch66:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.30s/it]Training Epoch66:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:53,  3.29s/it]Training Epoch66:   4%|[34mâ–         [0m| 4/92 [00:13<04:49,  3.29s/it]Training Epoch66:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.29s/it]Training Epoch66:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:46,  3.33s/it]Training Epoch66:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.31s/it]Training Epoch66:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch66:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.30s/it]Training Epoch66:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:32,  3.33s/it]Training Epoch66:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.32s/it]Training Epoch66:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.32s/it]Training Epoch66:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:21,  3.32s/it]Training Epoch66:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:19,  3.33s/it]Training Epoch66:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.31s/it]Training Epoch66:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:11,  3.31s/it]Training Epoch66:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:06,  3.28s/it]Training Epoch66:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:03,  3.29s/it]Training Epoch66:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:59,  3.28s/it]Training Epoch66:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:57,  3.29s/it]Training Epoch66:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:56,  3.32s/it]Training Epoch66:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.30s/it]Training Epoch66:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:46,  3.29s/it]Training Epoch66:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.31s/it]Training Epoch66:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:42,  3.33s/it]Training Epoch66:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:39,  3.33s/it]Training Epoch66:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:36,  3.32s/it]Training Epoch66:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:33,  3.33s/it]Training Epoch66:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:28,  3.31s/it]Training Epoch66:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.32s/it]Training Epoch66:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.31s/it]Training Epoch66:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:20,  3.34s/it]Training Epoch66:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:17,  3.35s/it]Training Epoch66:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:14,  3.35s/it]Training Epoch66:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:10,  3.35s/it]Training Epoch66:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:06,  3.33s/it]Training Epoch66:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.31s/it]Training Epoch66:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:59,  3.32s/it]Training Epoch66:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:56,  3.33s/it]Training Epoch66:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.33s/it]Training Epoch66:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:50,  3.34s/it]Training Epoch66:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:46,  3.33s/it]Training Epoch66:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:43,  3.33s/it]Training Epoch66:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:39,  3.32s/it]Training Epoch66:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:35,  3.30s/it]Training Epoch66:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:32,  3.31s/it]Training Epoch66:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.31s/it]Training Epoch66:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:24,  3.28s/it]Training Epoch66:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:21,  3.29s/it]Training Epoch66:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.30s/it]Training Epoch66:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:16,  3.32s/it]Training Epoch66:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:13,  3.33s/it]Training Epoch66:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:08,  3.30s/it]Training Epoch66:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.30s/it]Training Epoch66:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:03,  3.33s/it]Training Epoch66:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.32s/it]Training Epoch66:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:55,  3.31s/it]Training Epoch66:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.30s/it]Training Epoch66:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.31s/it]Training Epoch66:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:46,  3.32s/it]Training Epoch66:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:43,  3.33s/it]Training Epoch66:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.32s/it]Training Epoch66:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:35,  3.30s/it]Training Epoch66:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:31,  3.28s/it]Training Epoch66:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.30s/it]Training Epoch66:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:25,  3.31s/it]Training Epoch66:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.29s/it]Training Epoch66:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.31s/it]Training Epoch66:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.31s/it]Training Epoch66:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.30s/it]Training Epoch66:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.31s/it]Training Epoch66:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:05,  3.30s/it]Training Epoch66:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.27s/it]Training Epoch66:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:58,  3.27s/it]Training Epoch66:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:55,  3.29s/it]Training Epoch66:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.31s/it]Training Epoch66:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.31s/it]Training Epoch66:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.31s/it]Training Epoch66:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:42,  3.31s/it]Training Epoch66:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.32s/it]Training Epoch66:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.29s/it]Training Epoch66:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.30s/it]Training Epoch66:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.30s/it]Training Epoch66:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.29s/it]Training Epoch66:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.30s/it]Training Epoch66:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.27s/it]Training Epoch66:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.27s/it]Training Epoch66:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.29s/it]Training Epoch66:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.30s/it]Training Epoch66:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.30s/it]Training Epoch66:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.31s/it]Training Epoch66: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch66: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.0001002470962703228

 step 1 is completed and loss is 0.00019208512094337493

 step 2 is completed and loss is 3.0278639314929023e-05

 step 3 is completed and loss is 7.330963853746653e-05

 step 4 is completed and loss is 7.944765093270689e-05

 step 5 is completed and loss is 5.3880961786489934e-05

 step 6 is completed and loss is 0.000412140681874007

 step 7 is completed and loss is 7.080693467287347e-05

 step 8 is completed and loss is 6.860258872620761e-05

 step 9 is completed and loss is 4.458311013877392e-05

 step 10 is completed and loss is 0.0004217269306536764

 step 11 is completed and loss is 0.0008752444409765303

 step 12 is completed and loss is 0.00027840875554829836

 step 13 is completed and loss is 6.329812458716333e-05

 step 14 is completed and loss is 4.714602982858196e-05

 step 15 is completed and loss is 4.2199197196168825e-05

 step 16 is completed and loss is 0.00020917646179441363

 step 17 is completed and loss is 0.00011878412624355406

 step 18 is completed and loss is 5.692071499652229e-05

 step 19 is completed and loss is 0.00020256242714822292

 step 20 is completed and loss is 5.543075894820504e-05

 step 21 is completed and loss is 5.9364232583902776e-05

 step 22 is completed and loss is 0.00035019865026697516

 step 23 is completed and loss is 0.00011532826465554535

 step 24 is completed and loss is 5.4715448641218245e-05

 step 25 is completed and loss is 0.0001346348290098831

 step 26 is completed and loss is 6.538368324982002e-05

 step 27 is completed and loss is 0.00017236174608115107

 step 28 is completed and loss is 0.0001391618570778519

 step 29 is completed and loss is 9.679321374278516e-05

 step 30 is completed and loss is 0.0001433971046935767

 step 31 is completed and loss is 1.9371265807421878e-05

 step 32 is completed and loss is 0.00010841281618922949

 step 33 is completed and loss is 9.428967314306647e-05

 step 34 is completed and loss is 6.866214971523732e-05

 step 35 is completed and loss is 0.0001653286744840443

 step 36 is completed and loss is 1.4662615285487846e-05

 step 37 is completed and loss is 5.6205557484645396e-05

 step 38 is completed and loss is 7.712531078141183e-05

 step 39 is completed and loss is 5.411950041889213e-05

 step 40 is completed and loss is 0.00010626940638758242

 step 41 is completed and loss is 3.939750240533613e-05

 step 42 is completed and loss is 7.253621879499406e-05

 step 43 is completed and loss is 5.3225274314172566e-05

 step 44 is completed and loss is 2.4616279915790074e-05

 step 45 is completed and loss is 0.0002196122077293694

 step 46 is completed and loss is 2.068255707854405e-05

 step 47 is completed and loss is 7.89730329415761e-05

 step 48 is completed and loss is 0.0005230668466538191

 step 49 is completed and loss is 8.189330401364714e-05

 step 50 is completed and loss is 0.0001049573183991015

 step 51 is completed and loss is 6.300007953541353e-05

 step 52 is completed and loss is 0.0023182486183941364

 step 53 is completed and loss is 0.00028670902247540653

 step 54 is completed and loss is 3.4748794860206544e-05

 step 55 is completed and loss is 0.001305506331846118

 step 56 is completed and loss is 3.689455479616299e-05

 step 57 is completed and loss is 0.00017664380720816553

 step 58 is completed and loss is 4.9172020226251334e-05

 step 59 is completed and loss is 0.0002554766833782196

 step 60 is completed and loss is 9.750823664944619e-05

 step 61 is completed and loss is 8.653981785755605e-05

 step 62 is completed and loss is 8.713637362234294e-05

 step 63 is completed and loss is 0.0006772240740247071

 step 64 is completed and loss is 0.0002986546896863729

 step 65 is completed and loss is 9.13695475901477e-05

 step 66 is completed and loss is 0.0005806182161904871

 step 67 is completed and loss is 6.270138692343608e-05

 step 68 is completed and loss is 0.0002349934948142618

 step 69 is completed and loss is 0.00014506635488942266

 step 70 is completed and loss is 0.0001767081266734749

 step 71 is completed and loss is 0.0001299867290072143

 step 72 is completed and loss is 0.0005142826703377068

 step 73 is completed and loss is 7.790023664711043e-05

 step 74 is completed and loss is 0.00010817609290825203

 step 75 is completed and loss is 0.00019858255109284073

 step 76 is completed and loss is 0.00012796245573554188

 step 77 is completed and loss is 7.289365748874843e-05

 step 78 is completed and loss is 0.00018398152315057814

 step 79 is completed and loss is 0.0006617578328587115

 step 80 is completed and loss is 0.0003253256727475673

 step 81 is completed and loss is 0.0001083548559108749

 step 82 is completed and loss is 0.00013988069258630276

 step 83 is completed and loss is 0.00013702023716177791

 step 84 is completed and loss is 0.00010638698586262763

 step 85 is completed and loss is 8.976056415122002e-05

 step 86 is completed and loss is 9.154854342341423e-05

 step 87 is completed and loss is 0.00012772405170835555

 step 88 is completed and loss is 0.00020089861936867237

 step 89 is completed and loss is 6.895989645272493e-05

 step 90 is completed and loss is 0.001390234217979014

 step 91 is completed and loss is 7.104547694325447e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.36it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.51it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.48it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.46it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.43it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.51it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.53it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.54it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.60it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:24,  1.61it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.61it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.62it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.57it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.56it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.58it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.61it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.57it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.54it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:18,  1.59it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.57it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.60it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.59it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.54it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.53it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.52it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.51it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.50it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.51it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.51it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.51it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.51it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.51it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.50it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.48it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.51it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.55it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.58it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.64it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.68it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.65it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.58it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.59it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.64it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.62it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.57it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.5800)
Epoch 67: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.70406576700043s
Training Epoch67:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch67:   1%|[34m          [0m| 1/92 [00:03<05:02,  3.32s/it]Training Epoch67:   2%|[34mâ–         [0m| 2/92 [00:06<04:52,  3.25s/it]Training Epoch67:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.26s/it]Training Epoch67:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.27s/it]Training Epoch67:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch67:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.27s/it]Training Epoch67:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:40,  3.30s/it]Training Epoch67:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.29s/it]Training Epoch67:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:32,  3.29s/it]Training Epoch67:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.27s/it]Training Epoch67:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:24,  3.27s/it]Training Epoch67:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:21,  3.26s/it]Training Epoch67:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:16,  3.25s/it]Training Epoch67:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:14,  3.26s/it]Training Epoch67:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:11,  3.27s/it]Training Epoch67:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:05,  3.23s/it]Training Epoch67:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:03,  3.24s/it]Training Epoch67:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:01,  3.26s/it]Training Epoch67:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:57,  3.26s/it]Training Epoch67:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:54,  3.26s/it]Training Epoch67:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:50,  3.25s/it]Training Epoch67:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:47,  3.26s/it]Training Epoch67:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:44,  3.25s/it]Training Epoch67:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:39,  3.24s/it]Training Epoch67:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:36,  3.23s/it]Training Epoch67:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:34,  3.25s/it]Training Epoch67:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:33,  3.28s/it]Training Epoch67:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:29,  3.27s/it]Training Epoch67:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:25,  3.27s/it]Training Epoch67:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:21,  3.26s/it]Training Epoch67:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:19,  3.27s/it]Training Epoch67:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:15,  3.26s/it]Training Epoch67:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:12,  3.26s/it]Training Epoch67:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:09,  3.27s/it]Training Epoch67:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:06,  3.27s/it]Training Epoch67:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:03,  3.27s/it]Training Epoch67:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:00<03:00,  3.28s/it]Training Epoch67:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:56,  3.26s/it]Training Epoch67:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:52,  3.25s/it]Training Epoch67:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:10<02:48,  3.25s/it]Training Epoch67:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:46,  3.26s/it]Training Epoch67:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:16<02:42,  3.24s/it]Training Epoch67:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:37,  3.22s/it]Training Epoch67:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:23<02:35,  3.23s/it]Training Epoch67:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:26<02:31,  3.23s/it]Training Epoch67:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:29<02:27,  3.21s/it]Training Epoch67:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:25,  3.23s/it]Training Epoch67:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:36<02:21,  3.22s/it]Training Epoch67:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:39<02:17,  3.19s/it]Training Epoch67:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:42<02:12,  3.16s/it]Training Epoch67:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:45<02:09,  3.16s/it]Training Epoch67:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:48<02:06,  3.15s/it]Training Epoch67:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:51<02:02,  3.15s/it]Training Epoch67:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:55<02:00,  3.17s/it]Training Epoch67:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:58<01:58,  3.20s/it]Training Epoch67:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:01<01:55,  3.21s/it]Training Epoch67:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:04<01:52,  3.21s/it]Training Epoch67:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:08<01:49,  3.22s/it]Training Epoch67:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:11<01:46,  3.23s/it]Training Epoch67:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:14<01:43,  3.24s/it]Training Epoch67:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:17<01:39,  3.23s/it]Training Epoch67:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:20<01:36,  3.21s/it]Training Epoch67:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:24<01:33,  3.23s/it]Training Epoch67:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:27<01:30,  3.23s/it]Training Epoch67:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:30<01:27,  3.23s/it]Training Epoch67:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:33<01:24,  3.25s/it]Training Epoch67:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:37<01:21,  3.24s/it]Training Epoch67:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:40<01:18,  3.26s/it]Training Epoch67:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:43<01:14,  3.24s/it]Training Epoch67:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:47<01:11,  3.26s/it]Training Epoch67:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:50<01:08,  3.26s/it]Training Epoch67:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:53<01:04,  3.23s/it]Training Epoch67:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:56<01:01,  3.22s/it]Training Epoch67:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [03:59<00:58,  3.23s/it]Training Epoch67:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:03<00:54,  3.22s/it]Training Epoch67:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:06<00:52,  3.27s/it]Training Epoch67:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:09<00:49,  3.28s/it]Training Epoch67:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:13<00:46,  3.29s/it]Training Epoch67:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:16<00:42,  3.30s/it]Training Epoch67:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:19<00:39,  3.31s/it]Training Epoch67:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:23<00:36,  3.32s/it]Training Epoch67:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:26<00:33,  3.31s/it]Training Epoch67:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:29<00:29,  3.31s/it]Training Epoch67:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:33<00:26,  3.32s/it]Training Epoch67:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:36<00:23,  3.32s/it]Training Epoch67:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:39<00:19,  3.28s/it]Training Epoch67:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:42<00:16,  3.28s/it]Training Epoch67:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:46<00:13,  3.32s/it]Training Epoch67:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:49<00:09,  3.31s/it]Training Epoch67:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:52<00:06,  3.31s/it]Training Epoch67:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:56<00:03,  3.31s/it]Training Epoch67: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:59<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch67: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:59<00:00,  3.25s/it]

 step 0 is completed and loss is 8.630159572931007e-05

 step 1 is completed and loss is 0.00022789965441916138

 step 2 is completed and loss is 3.582170029403642e-05

 step 3 is completed and loss is 0.00011127142352052033

 step 4 is completed and loss is 6.687284621875733e-05

 step 5 is completed and loss is 4.809967867913656e-05

 step 6 is completed and loss is 0.0007434231229126453

 step 7 is completed and loss is 6.830407801317051e-05

 step 8 is completed and loss is 7.027125684544444e-05

 step 9 is completed and loss is 4.0589839045424014e-05

 step 10 is completed and loss is 0.0006995475850999355

 step 11 is completed and loss is 0.0009615615126676857

 step 12 is completed and loss is 0.0002757870825007558

 step 13 is completed and loss is 7.646961603313684e-05

 step 14 is completed and loss is 5.012625115341507e-05

 step 15 is completed and loss is 4.768258077092469e-05

 step 16 is completed and loss is 0.00016764613974373788

 step 17 is completed and loss is 0.00012361077824607491

 step 18 is completed and loss is 6.049688090570271e-05

 step 19 is completed and loss is 0.00028865289641544223

 step 20 is completed and loss is 4.565604467643425e-05

 step 21 is completed and loss is 6.842342554591596e-05

 step 22 is completed and loss is 0.0004166087310295552

 step 23 is completed and loss is 9.345482976641506e-05

 step 24 is completed and loss is 6.288065196713433e-05

 step 25 is completed and loss is 0.0002036383666563779

 step 26 is completed and loss is 6.85426130075939e-05

 step 27 is completed and loss is 0.00031465350184589624

 step 28 is completed and loss is 0.00011043840640923008

 step 29 is completed and loss is 0.0001060308568412438

 step 30 is completed and loss is 8.910497126635164e-05

 step 31 is completed and loss is 1.764278204063885e-05

 step 32 is completed and loss is 8.618329593446106e-05

 step 33 is completed and loss is 8.648257062304765e-05

 step 34 is completed and loss is 8.141662692651153e-05

 step 35 is completed and loss is 0.0001998920924961567

 step 36 is completed and loss is 1.6391104509239085e-05

 step 37 is completed and loss is 7.784051558701321e-05

 step 38 is completed and loss is 8.368129783775657e-05

 step 39 is completed and loss is 5.936443631071597e-05

 step 40 is completed and loss is 0.00010817639849847183

 step 41 is completed and loss is 4.011281271232292e-05

 step 42 is completed and loss is 8.213176624849439e-05

 step 43 is completed and loss is 6.651551666436717e-05

 step 44 is completed and loss is 2.3066651920089498e-05

 step 45 is completed and loss is 0.00019703168072737753

 step 46 is completed and loss is 2.264943213958759e-05

 step 47 is completed and loss is 8.070142939686775e-05

 step 48 is completed and loss is 0.00047773405094631016

 step 49 is completed and loss is 9.303851402364671e-05

 step 50 is completed and loss is 9.506454080110416e-05

 step 51 is completed and loss is 4.9947440857067704e-05

 step 52 is completed and loss is 0.0014403077075257897

 step 53 is completed and loss is 0.0004534548206720501

 step 54 is completed and loss is 3.3556760172359645e-05

 step 55 is completed and loss is 0.000921324361115694

 step 56 is completed and loss is 5.4357667977456003e-05

 step 57 is completed and loss is 0.00018278129573445767

 step 58 is completed and loss is 6.0257501900196075e-05

 step 59 is completed and loss is 0.00028776651015505195

 step 60 is completed and loss is 0.00012051263183820993

 step 61 is completed and loss is 8.481150143779814e-05

 step 62 is completed and loss is 9.345356374979019e-05

 step 63 is completed and loss is 0.0004206212761346251

 step 64 is completed and loss is 0.00027125098858959973

 step 65 is completed and loss is 7.682727300561965e-05

 step 66 is completed and loss is 0.0005687152734026313

 step 67 is completed and loss is 7.050878048175946e-05

 step 68 is completed and loss is 0.00021985656348988414

 step 69 is completed and loss is 0.00012224142847117037

 step 70 is completed and loss is 0.00018016478861682117

 step 71 is completed and loss is 0.00021514028776437044

 step 72 is completed and loss is 0.0005255250725895166

 step 73 is completed and loss is 8.022463589441031e-05

 step 74 is completed and loss is 0.00010299103450961411

 step 75 is completed and loss is 0.0002335037279408425

 step 76 is completed and loss is 0.00013392261462286115

 step 77 is completed and loss is 7.04499107087031e-05

 step 78 is completed and loss is 0.00018237113545183092

 step 79 is completed and loss is 0.0009819281985983253

 step 80 is completed and loss is 0.0002120508288498968

 step 81 is completed and loss is 9.309805318480358e-05

 step 82 is completed and loss is 0.0001512020971858874

 step 83 is completed and loss is 0.00014375479076988995

 step 84 is completed and loss is 8.993831579573452e-05

 step 85 is completed and loss is 0.0001333863037871197

 step 86 is completed and loss is 8.666139910928905e-05

 step 87 is completed and loss is 0.00014351660502143204

 step 88 is completed and loss is 0.00017229304648935795

 step 89 is completed and loss is 6.586086237803102e-05

 step 90 is completed and loss is 0.0006197972106747329

 step 91 is completed and loss is 0.00016853856504894793
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:31,  1.54it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.50it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.45it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.45it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.47it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.53it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.53it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.54it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.54it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.53it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.59it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:22,  1.62it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:21,  1.65it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.63it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.57it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.54it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.52it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.54it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.59it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.63it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:16,  1.61it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:15,  1.64it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:15,  1.59it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.57it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.61it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:14,  1.56it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.55it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.57it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:11,  1.62it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.63it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.56it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.53it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.52it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.49it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.49it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:08,  1.48it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.47it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.44it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:06,  1.48it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.48it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.48it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:04,  1.49it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.52it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.53it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:02,  1.49it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.55it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.52it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 68: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 299.63115467100215s
Training Epoch68:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch68:   1%|[34m          [0m| 1/92 [00:03<05:00,  3.30s/it]Training Epoch68:   2%|[34mâ–         [0m| 2/92 [00:06<04:48,  3.21s/it]Training Epoch68:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.25s/it]Training Epoch68:   4%|[34mâ–         [0m| 4/92 [00:12<04:43,  3.22s/it]Training Epoch68:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:43,  3.26s/it]Training Epoch68:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.28s/it]Training Epoch68:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:40,  3.30s/it]Training Epoch68:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.32s/it]Training Epoch68:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:36,  3.33s/it]Training Epoch68:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:32,  3.32s/it]Training Epoch68:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.33s/it]Training Epoch68:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:27,  3.34s/it]Training Epoch68:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.30s/it]Training Epoch68:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:19,  3.32s/it]Training Epoch68:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:17,  3.34s/it]Training Epoch68:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.30s/it]Training Epoch68:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:10,  3.34s/it]Training Epoch68:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:06,  3.34s/it]Training Epoch68:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:01,  3.31s/it]Training Epoch68:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:55,  3.28s/it]Training Epoch68:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:53,  3.29s/it]Training Epoch68:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.31s/it]Training Epoch68:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:49,  3.32s/it]Training Epoch68:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.31s/it]Training Epoch68:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:42,  3.33s/it]Training Epoch68:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:39,  3.33s/it]Training Epoch68:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:36,  3.34s/it]Training Epoch68:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:35,  3.37s/it]Training Epoch68:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:31,  3.35s/it]Training Epoch68:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:28,  3.36s/it]Training Epoch68:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:23,  3.34s/it]Training Epoch68:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:20,  3.34s/it]Training Epoch68:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:16,  3.34s/it]Training Epoch68:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.31s/it]Training Epoch68:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:09,  3.33s/it]Training Epoch68:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:05,  3.31s/it]Training Epoch68:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.33s/it]Training Epoch68:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:59,  3.33s/it]Training Epoch68:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:55,  3.31s/it]Training Epoch68:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.29s/it]Training Epoch68:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:47,  3.29s/it]Training Epoch68:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:44,  3.30s/it]Training Epoch68:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:42,  3.31s/it]Training Epoch68:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:39,  3.32s/it]Training Epoch68:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.33s/it]Training Epoch68:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.34s/it]Training Epoch68:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:30,  3.35s/it]Training Epoch68:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:27,  3.35s/it]Training Epoch68:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:24,  3.35s/it]Training Epoch68:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.32s/it]Training Epoch68:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:17,  3.34s/it]Training Epoch68:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:11,  3.29s/it]Training Epoch68:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:06,  3.24s/it]Training Epoch68:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:02,  3.23s/it]Training Epoch68:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<01:59,  3.23s/it]Training Epoch68:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:56,  3.25s/it]Training Epoch68:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:54,  3.26s/it]Training Epoch68:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:51,  3.28s/it]Training Epoch68:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.31s/it]Training Epoch68:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.31s/it]Training Epoch68:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.31s/it]Training Epoch68:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.33s/it]Training Epoch68:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.34s/it]Training Epoch68:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:33,  3.34s/it]Training Epoch68:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:30,  3.34s/it]Training Epoch68:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.31s/it]Training Epoch68:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.31s/it]Training Epoch68:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.31s/it]Training Epoch68:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.32s/it]Training Epoch68:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.30s/it]Training Epoch68:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.31s/it]Training Epoch68:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.30s/it]Training Epoch68:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.30s/it]Training Epoch68:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.30s/it]Training Epoch68:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:55,  3.29s/it]Training Epoch68:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.29s/it]Training Epoch68:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.29s/it]Training Epoch68:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:45,  3.25s/it]Training Epoch68:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:42,  3.25s/it]Training Epoch68:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.28s/it]Training Epoch68:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.30s/it]Training Epoch68:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.31s/it]Training Epoch68:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:30,  3.35s/it]Training Epoch68:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.36s/it]Training Epoch68:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.35s/it]Training Epoch68:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:20,  3.34s/it]Training Epoch68:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.31s/it]Training Epoch68:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.31s/it]Training Epoch68:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.30s/it]Training Epoch68:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.31s/it]Training Epoch68:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.29s/it]Training Epoch68: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.26s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch68: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.00010090272553497925

 step 1 is completed and loss is 0.00016610350576229393

 step 2 is completed and loss is 3.5464134271023795e-05

 step 3 is completed and loss is 0.00013576389756053686

 step 4 is completed and loss is 7.086592086125165e-05

 step 5 is completed and loss is 5.936418892815709e-05

 step 6 is completed and loss is 0.0003640158392954618

 step 7 is completed and loss is 8.791113941697404e-05

 step 8 is completed and loss is 8.427739521721378e-05

 step 9 is completed and loss is 3.9874612411949784e-05

 step 10 is completed and loss is 0.00038021267391741276

 step 11 is completed and loss is 0.001254775794222951

 step 12 is completed and loss is 0.00021453987574204803

 step 13 is completed and loss is 6.0139267588965595e-05

 step 14 is completed and loss is 5.2808223699685186e-05

 step 15 is completed and loss is 4.0411134250462055e-05

 step 16 is completed and loss is 0.0002477271482348442

 step 17 is completed and loss is 0.00012188196706119925

 step 18 is completed and loss is 5.203349428484216e-05

 step 19 is completed and loss is 0.00013177283108234406

 step 20 is completed and loss is 3.534492861945182e-05

 step 21 is completed and loss is 8.231028914451599e-05

 step 22 is completed and loss is 0.0005208297516219318

 step 23 is completed and loss is 0.00010227589518763125

 step 24 is completed and loss is 7.658893446205184e-05

 step 25 is completed and loss is 0.00018731236923485994

 step 26 is completed and loss is 5.3285082685761154e-05

 step 27 is completed and loss is 0.0002240883477497846

 step 28 is completed and loss is 0.00013826786016579717

 step 29 is completed and loss is 8.73169774422422e-05

 step 30 is completed and loss is 0.00012218102347105742

 step 31 is completed and loss is 1.7225553165189922e-05

 step 32 is completed and loss is 7.164175622165203e-05

 step 33 is completed and loss is 8.26083414722234e-05

 step 34 is completed and loss is 0.00010418258898425847

 step 35 is completed and loss is 0.00018576934235170484

 step 36 is completed and loss is 1.5795085346326232e-05

 step 37 is completed and loss is 5.835122283315286e-05

 step 38 is completed and loss is 7.956891931826249e-05

 step 39 is completed and loss is 4.631164847523905e-05

 step 40 is completed and loss is 0.00010764018225017935

 step 41 is completed and loss is 3.611952342907898e-05

 step 42 is completed and loss is 7.420501788146794e-05

 step 43 is completed and loss is 6.389401823980734e-05

 step 44 is completed and loss is 1.847721796366386e-05

 step 45 is completed and loss is 0.0002537550462875515

 step 46 is completed and loss is 2.3960725229699165e-05

 step 47 is completed and loss is 7.050980639178306e-05

 step 48 is completed and loss is 0.000555994629394263

 step 49 is completed and loss is 7.325142360059544e-05

 step 50 is completed and loss is 9.709113510325551e-05

 step 51 is completed and loss is 5.4536732932319865e-05

 step 52 is completed and loss is 0.0013782097958028316

 step 53 is completed and loss is 0.000337411358486861

 step 54 is completed and loss is 3.981492045568302e-05

 step 55 is completed and loss is 0.0012889448553323746

 step 56 is completed and loss is 4.815937427338213e-05

 step 57 is completed and loss is 0.00020494690397754312

 step 58 is completed and loss is 5.5847362091299146e-05

 step 59 is completed and loss is 0.00038283661706373096

 step 60 is completed and loss is 0.00011944009747821838

 step 61 is completed and loss is 0.00010787471546791494

 step 62 is completed and loss is 8.588482887716964e-05

 step 63 is completed and loss is 0.0005598102579824626

 step 64 is completed and loss is 0.00026499765226617455

 step 65 is completed and loss is 8.505166624672711e-05

 step 66 is completed and loss is 0.0008563909796066582

 step 67 is completed and loss is 8.361994696315378e-05

 step 68 is completed and loss is 0.00017832097364589572

 step 69 is completed and loss is 0.00014786669635213912

 step 70 is completed and loss is 0.00015102607721928507

 step 71 is completed and loss is 0.00023605265596415848

 step 72 is completed and loss is 0.00042565359035506845

 step 73 is completed and loss is 9.45880965446122e-05

 step 74 is completed and loss is 0.00010638857929734513

 step 75 is completed and loss is 0.0002762842341326177

 step 76 is completed and loss is 0.000133386260131374

 step 77 is completed and loss is 7.122489478206262e-05

 step 78 is completed and loss is 0.00016717657854314893

 step 79 is completed and loss is 0.0007741312147118151

 step 80 is completed and loss is 0.00028570383437909186

 step 81 is completed and loss is 9.542217594571412e-05

 step 82 is completed and loss is 0.0001260539866052568

 step 83 is completed and loss is 0.00015328999143093824

 step 84 is completed and loss is 8.80911247804761e-05

 step 85 is completed and loss is 0.00012861855793744326

 step 86 is completed and loss is 0.0001081169830285944

 step 87 is completed and loss is 0.00013702100841328502

 step 88 is completed and loss is 0.00020929775200784206

 step 89 is completed and loss is 5.852992399013601e-05

 step 90 is completed and loss is 0.00046843188465572894

 step 91 is completed and loss is 0.0002553485392127186
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.38it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.43it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.44it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.44it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.44it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.46it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.46it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.49it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.51it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.51it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.51it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.49it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.50it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.53it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.52it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.51it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.50it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.48it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:21,  1.44it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:21,  1.41it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.45it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.48it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.48it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:18,  1.41it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:18,  1.38it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:18,  1.33it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:16,  1.38it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:16,  1.33it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:20<00:14,  1.42it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.49it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:12,  1.48it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.48it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.47it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.49it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.49it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.47it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.46it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:08,  1.46it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.43it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:07,  1.41it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:06,  1.43it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.44it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.50it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:04,  1.46it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.42it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.38it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:32<00:02,  1.36it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:33<00:01,  1.42it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.46it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.47it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.45it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 69: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.72364920999826s
Training Epoch69:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch69:   1%|[34m          [0m| 1/92 [00:03<05:03,  3.34s/it]Training Epoch69:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.30s/it]Training Epoch69:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.26s/it]Training Epoch69:   4%|[34mâ–         [0m| 4/92 [00:13<04:50,  3.31s/it]Training Epoch69:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.31s/it]Training Epoch69:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:42,  3.29s/it]Training Epoch69:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch69:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:42,  3.36s/it]Training Epoch69:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:39,  3.37s/it]Training Epoch69:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.33s/it]Training Epoch69:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.32s/it]Training Epoch69:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch69:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:20,  3.29s/it]Training Epoch69:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:19,  3.32s/it]Training Epoch69:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:16,  3.33s/it]Training Epoch69:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:11,  3.31s/it]Training Epoch69:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:09,  3.32s/it]Training Epoch69:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.32s/it]Training Epoch69:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:02,  3.33s/it]Training Epoch69:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:57,  3.30s/it]Training Epoch69:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.31s/it]Training Epoch69:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch69:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:45,  3.27s/it]Training Epoch69:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:41,  3.26s/it]Training Epoch69:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:37,  3.24s/it]Training Epoch69:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:35,  3.26s/it]Training Epoch69:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:32,  3.27s/it]Training Epoch69:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.29s/it]Training Epoch69:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:30,  3.34s/it]Training Epoch69:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:27,  3.34s/it]Training Epoch69:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.30s/it]Training Epoch69:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:15,  3.26s/it]Training Epoch69:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:12,  3.26s/it]Training Epoch69:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:09,  3.27s/it]Training Epoch69:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.31s/it]Training Epoch69:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:06,  3.32s/it]Training Epoch69:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:04,  3.36s/it]Training Epoch69:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<03:02,  3.37s/it]Training Epoch69:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:57,  3.36s/it]Training Epoch69:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.32s/it]Training Epoch69:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:48,  3.30s/it]Training Epoch69:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:44,  3.28s/it]Training Epoch69:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:41,  3.29s/it]Training Epoch69:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.31s/it]Training Epoch69:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:36,  3.32s/it]Training Epoch69:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.33s/it]Training Epoch69:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.33s/it]Training Epoch69:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:26,  3.33s/it]Training Epoch69:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:22,  3.32s/it]Training Epoch69:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.31s/it]Training Epoch69:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.29s/it]Training Epoch69:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:12,  3.32s/it]Training Epoch69:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:10,  3.33s/it]Training Epoch69:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:06,  3.32s/it]Training Epoch69:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.29s/it]Training Epoch69:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:58,  3.30s/it]Training Epoch69:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:54,  3.29s/it]Training Epoch69:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:51,  3.29s/it]Training Epoch69:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:48,  3.30s/it]Training Epoch69:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:46,  3.32s/it]Training Epoch69:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.30s/it]Training Epoch69:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.30s/it]Training Epoch69:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:35,  3.31s/it]Training Epoch69:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.29s/it]Training Epoch69:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.29s/it]Training Epoch69:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:25,  3.28s/it]Training Epoch69:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.29s/it]Training Epoch69:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.29s/it]Training Epoch69:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:15,  3.30s/it]Training Epoch69:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.30s/it]Training Epoch69:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.33s/it]Training Epoch69:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.33s/it]Training Epoch69:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.31s/it]Training Epoch69:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.32s/it]Training Epoch69:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.33s/it]Training Epoch69:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:53,  3.32s/it]Training Epoch69:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.31s/it]Training Epoch69:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.32s/it]Training Epoch69:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:42,  3.31s/it]Training Epoch69:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.32s/it]Training Epoch69:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.35s/it]Training Epoch69:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.33s/it]Training Epoch69:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.32s/it]Training Epoch69:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.28s/it]Training Epoch69:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:22,  3.25s/it]Training Epoch69:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.23s/it]Training Epoch69:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.26s/it]Training Epoch69:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.25s/it]Training Epoch69:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.25s/it]Training Epoch69:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.26s/it]Training Epoch69:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.26s/it]Training Epoch69: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.25s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch69: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.0001249178749276325

 step 1 is completed and loss is 0.00017516034131404012

 step 2 is completed and loss is 3.558333992259577e-05

 step 3 is completed and loss is 9.512168617220595e-05

 step 4 is completed and loss is 7.97458051238209e-05

 step 5 is completed and loss is 5.537090328289196e-05

 step 6 is completed and loss is 0.000560899032279849

 step 7 is completed and loss is 4.7920744691509753e-05

 step 8 is completed and loss is 6.723177648382261e-05

 step 9 is completed and loss is 3.6536908737616614e-05

 step 10 is completed and loss is 0.0008445936255156994

 step 11 is completed and loss is 0.0012978066224604845

 step 12 is completed and loss is 0.00023008929565548897

 step 13 is completed and loss is 6.210609717527404e-05

 step 14 is completed and loss is 4.070902650710195e-05

 step 15 is completed and loss is 2.9801878554280847e-05

 step 16 is completed and loss is 0.0002605931367725134

 step 17 is completed and loss is 0.00015996312140487134

 step 18 is completed and loss is 5.4000247473595664e-05

 step 19 is completed and loss is 0.0003019370778929442

 step 20 is completed and loss is 4.875538434134796e-05

 step 21 is completed and loss is 7.927080878289416e-05

 step 22 is completed and loss is 0.0006137719028629363

 step 23 is completed and loss is 0.00010281139111611992

 step 24 is completed and loss is 7.497979822801426e-05

 step 25 is completed and loss is 0.00016788470384199172

 step 26 is completed and loss is 6.270176527323201e-05

 step 27 is completed and loss is 0.0001950073055922985

 step 28 is completed and loss is 0.0002599361469037831

 step 29 is completed and loss is 9.87599923973903e-05

 step 30 is completed and loss is 0.00010334872058592737

 step 31 is completed and loss is 1.805998181225732e-05

 step 32 is completed and loss is 8.975893433671445e-05

 step 33 is completed and loss is 8.123769657686353e-05

 step 34 is completed and loss is 5.3702344303019345e-05

 step 35 is completed and loss is 0.00018564854690339416

 step 36 is completed and loss is 1.567589606565889e-05

 step 37 is completed and loss is 7.849594840081409e-05

 step 38 is completed and loss is 8.15950334072113e-05

 step 39 is completed and loss is 6.437094270950183e-05

 step 40 is completed and loss is 0.00010179942182730883

 step 41 is completed and loss is 4.9172056606039405e-05

 step 42 is completed and loss is 7.045009988360107e-05

 step 43 is completed and loss is 4.9827904149424285e-05

 step 44 is completed and loss is 2.5033488782355562e-05

 step 45 is completed and loss is 0.0003191108407918364

 step 46 is completed and loss is 2.771568688331172e-05

 step 47 is completed and loss is 8.177416020771489e-05

 step 48 is completed and loss is 0.0005051338230259717

 step 49 is completed and loss is 6.741058314219117e-05

 step 50 is completed and loss is 9.291863534599543e-05

 step 51 is completed and loss is 6.079473314457573e-05

 step 52 is completed and loss is 0.0025866844225674868

 step 53 is completed and loss is 0.00028015580028295517

 step 54 is completed and loss is 3.83844853786286e-05

 step 55 is completed and loss is 0.0010481167118996382

 step 56 is completed and loss is 4.207992969895713e-05

 step 57 is completed and loss is 0.00029133629868738353

 step 58 is completed and loss is 5.143692760611884e-05

 step 59 is completed and loss is 0.00048581050941720605

 step 60 is completed and loss is 0.00012224137026350945

 step 61 is completed and loss is 8.80894876900129e-05

 step 62 is completed and loss is 8.040190732572228e-05

 step 63 is completed and loss is 0.0002851631725206971

 step 64 is completed and loss is 0.0001669285265961662

 step 65 is completed and loss is 8.52310040500015e-05

 step 66 is completed and loss is 0.0006255737971514463

 step 67 is completed and loss is 7.545539847342297e-05

 step 68 is completed and loss is 0.0002133615198545158

 step 69 is completed and loss is 0.00015346959116868675

 step 70 is completed and loss is 0.00022372594685293734

 step 71 is completed and loss is 0.0001481026120018214

 step 72 is completed and loss is 0.0006117934244684875

 step 73 is completed and loss is 9.27998626139015e-05

 step 74 is completed and loss is 0.00010084541281685233

 step 75 is completed and loss is 0.00023522938136011362

 step 76 is completed and loss is 0.00011884432751685381

 step 77 is completed and loss is 7.50391191104427e-05

 step 78 is completed and loss is 0.0002066856250166893

 step 79 is completed and loss is 0.0009302531252615154

 step 80 is completed and loss is 0.00030351668829098344

 step 81 is completed and loss is 0.00011413572065066546

 step 82 is completed and loss is 0.00018790989997796714

 step 83 is completed and loss is 0.00016204998246394098

 step 84 is completed and loss is 0.0001379122113576159

 step 85 is completed and loss is 0.0001174142598756589

 step 86 is completed and loss is 0.00011872540198964998

 step 87 is completed and loss is 0.0001672355574555695

 step 88 is completed and loss is 0.00018027907935902476

 step 89 is completed and loss is 7.098581409081817e-05

 step 90 is completed and loss is 0.0007673697546124458

 step 91 is completed and loss is 0.00012766044528689235
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:31,  1.54it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:29,  1.61it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:29,  1.61it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:28,  1.60it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.56it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.55it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.57it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.58it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.58it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.56it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:06<00:24,  1.58it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.59it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.56it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:23,  1.52it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.52it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.54it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.53it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.54it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.56it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.57it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.58it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.58it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.54it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.51it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.53it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.57it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.56it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:12,  1.55it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.53it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.53it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.56it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.57it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.57it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.55it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.58it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.59it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.62it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:04,  1.63it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.60it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.62it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.62it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.66it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:29<00:01,  1.66it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.61it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.59it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.58it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.57it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 70: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.0416478829975s
Training Epoch70:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch70:   1%|[34m          [0m| 1/92 [00:03<04:53,  3.23s/it]Training Epoch70:   2%|[34mâ–         [0m| 2/92 [00:06<04:52,  3.24s/it]Training Epoch70:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:47,  3.23s/it]Training Epoch70:   4%|[34mâ–         [0m| 4/92 [00:12<04:43,  3.22s/it]Training Epoch70:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:40,  3.23s/it]Training Epoch70:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:38,  3.24s/it]Training Epoch70:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:36,  3.25s/it]Training Epoch70:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.28s/it]Training Epoch70:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.27s/it]Training Epoch70:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.27s/it]Training Epoch70:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:23,  3.25s/it]Training Epoch70:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:38<04:19,  3.24s/it]Training Epoch70:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:15,  3.24s/it]Training Epoch70:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:13,  3.25s/it]Training Epoch70:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:48<04:13,  3.29s/it]Training Epoch70:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:07,  3.26s/it]Training Epoch70:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:04,  3.26s/it]Training Epoch70:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:02,  3.28s/it]Training Epoch70:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:01<03:59,  3.28s/it]Training Epoch70:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:53,  3.24s/it]Training Epoch70:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:50,  3.24s/it]Training Epoch70:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:46,  3.24s/it]Training Epoch70:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:14<03:43,  3.24s/it]Training Epoch70:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:17<03:40,  3.24s/it]Training Epoch70:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:36,  3.24s/it]Training Epoch70:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:24<03:34,  3.26s/it]Training Epoch70:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:27<03:31,  3.25s/it]Training Epoch70:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:28,  3.26s/it]Training Epoch70:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:34<03:25,  3.26s/it]Training Epoch70:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:37<03:22,  3.26s/it]Training Epoch70:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:40<03:17,  3.24s/it]Training Epoch70:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:43<03:13,  3.23s/it]Training Epoch70:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:47<03:11,  3.25s/it]Training Epoch70:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:50<03:09,  3.26s/it]Training Epoch70:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:53<03:05,  3.26s/it]Training Epoch70:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:03,  3.27s/it]Training Epoch70:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:00<02:58,  3.25s/it]Training Epoch70:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:03<02:54,  3.22s/it]Training Epoch70:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:06<02:51,  3.24s/it]Training Epoch70:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:09<02:48,  3.24s/it]Training Epoch70:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:13<02:45,  3.24s/it]Training Epoch70:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:16<02:41,  3.24s/it]Training Epoch70:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:19<02:39,  3.25s/it]Training Epoch70:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:22<02:35,  3.24s/it]Training Epoch70:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:26<02:31,  3.22s/it]Training Epoch70:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:29<02:28,  3.22s/it]Training Epoch70:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:32<02:26,  3.26s/it]Training Epoch70:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:35<02:23,  3.26s/it]Training Epoch70:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:39<02:19,  3.24s/it]Training Epoch70:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:42<02:16,  3.24s/it]Training Epoch70:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:45<02:12,  3.24s/it]Training Epoch70:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:48<02:09,  3.23s/it]Training Epoch70:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:52<02:06,  3.24s/it]Training Epoch70:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:55<02:02,  3.23s/it]Training Epoch70:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [02:58<01:59,  3.24s/it]Training Epoch70:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:01<01:57,  3.26s/it]Training Epoch70:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:05<01:54,  3.27s/it]Training Epoch70:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:08<01:50,  3.26s/it]Training Epoch70:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:11<01:47,  3.25s/it]Training Epoch70:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:14<01:43,  3.25s/it]Training Epoch70:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:18<01:40,  3.25s/it]Training Epoch70:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:21<01:38,  3.28s/it]Training Epoch70:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:24<01:35,  3.29s/it]Training Epoch70:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:28<01:31,  3.28s/it]Training Epoch70:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:31<01:28,  3.26s/it]Training Epoch70:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:34<01:24,  3.26s/it]Training Epoch70:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:37<01:21,  3.25s/it]Training Epoch70:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:41<01:18,  3.26s/it]Training Epoch70:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:44<01:14,  3.26s/it]Training Epoch70:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:47<01:11,  3.26s/it]Training Epoch70:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:50<01:08,  3.27s/it]Training Epoch70:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:54<01:05,  3.28s/it]Training Epoch70:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:57<01:02,  3.28s/it]Training Epoch70:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:00<00:58,  3.28s/it]Training Epoch70:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:03<00:55,  3.27s/it]Training Epoch70:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:07<00:52,  3.27s/it]Training Epoch70:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:10<00:49,  3.27s/it]Training Epoch70:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:13<00:45,  3.28s/it]Training Epoch70:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:16<00:42,  3.24s/it]Training Epoch70:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:20<00:38,  3.24s/it]Training Epoch70:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:23<00:35,  3.24s/it]Training Epoch70:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:26<00:32,  3.27s/it]Training Epoch70:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:30<00:29,  3.28s/it]Training Epoch70:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:33<00:26,  3.28s/it]Training Epoch70:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:36<00:23,  3.31s/it]Training Epoch70:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:40<00:19,  3.30s/it]Training Epoch70:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:43<00:16,  3.30s/it]Training Epoch70:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:46<00:13,  3.28s/it]Training Epoch70:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:49<00:09,  3.28s/it]Training Epoch70:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:53<00:06,  3.27s/it]Training Epoch70:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:56<00:03,  3.30s/it]Training Epoch70: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:59<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch70: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [04:59<00:00,  3.26s/it]

 step 0 is completed and loss is 0.0001405907969456166

 step 1 is completed and loss is 0.00022473775607068092

 step 2 is completed and loss is 3.8205835153348744e-05

 step 3 is completed and loss is 7.128313154680654e-05

 step 4 is completed and loss is 8.201035234378651e-05

 step 5 is completed and loss is 5.0781691243173555e-05

 step 6 is completed and loss is 0.0003279810189269483

 step 7 is completed and loss is 5.2509996748995036e-05

 step 8 is completed and loss is 8.159535354934633e-05

 step 9 is completed and loss is 4.434465881786309e-05

 step 10 is completed and loss is 0.0006864097667858005

 step 11 is completed and loss is 0.0008181191515177488

 step 12 is completed and loss is 0.000398673873860389

 step 13 is completed and loss is 7.271495269378647e-05

 step 14 is completed and loss is 5.084145232103765e-05

 step 15 is completed and loss is 4.351044481154531e-05

 step 16 is completed and loss is 0.00022019963944330812

 step 17 is completed and loss is 0.00012927097850479186

 step 18 is completed and loss is 4.726524275611155e-05

 step 19 is completed and loss is 0.00023950466129463166

 step 20 is completed and loss is 5.841081292601302e-05

 step 21 is completed and loss is 5.137781772646122e-05

 step 22 is completed and loss is 0.0004354942648205906

 step 23 is completed and loss is 9.834261436481029e-05

 step 24 is completed and loss is 5.8708748838398606e-05

 step 25 is completed and loss is 0.00016997192869894207

 step 26 is completed and loss is 6.931748066563159e-05

 step 27 is completed and loss is 0.00030864166910760105

 step 28 is completed and loss is 0.0002091154601657763

 step 29 is completed and loss is 8.88665672391653e-05

 step 30 is completed and loss is 9.387244062963873e-05

 step 31 is completed and loss is 1.5735471606603824e-05

 step 32 is completed and loss is 7.783975888742134e-05

 step 33 is completed and loss is 6.830458005424589e-05

 step 34 is completed and loss is 5.715917359339073e-05

 step 35 is completed and loss is 0.00018767428991850466

 step 36 is completed and loss is 1.4543400538968854e-05

 step 37 is completed and loss is 6.162928184494376e-05

 step 38 is completed and loss is 6.305960414465517e-05

 step 39 is completed and loss is 5.87681497563608e-05

 step 40 is completed and loss is 8.624396286904812e-05

 step 41 is completed and loss is 2.8132908482803032e-05

 step 42 is completed and loss is 6.073528857086785e-05

 step 43 is completed and loss is 6.937679427210242e-05

 step 44 is completed and loss is 1.9788467398029752e-05

 step 45 is completed and loss is 0.0002700788900256157

 step 46 is completed and loss is 2.1695808754884638e-05

 step 47 is completed and loss is 8.332380093634129e-05

 step 48 is completed and loss is 0.0004775614070240408

 step 49 is completed and loss is 8.642299508210272e-05

 step 50 is completed and loss is 8.82108579389751e-05

 step 51 is completed and loss is 4.9649424909148365e-05

 step 52 is completed and loss is 0.0011662041069939733

 step 53 is completed and loss is 0.0003549902467057109

 step 54 is completed and loss is 3.28415262629278e-05

 step 55 is completed and loss is 0.0011543849250301719

 step 56 is completed and loss is 4.094747419003397e-05

 step 57 is completed and loss is 0.00031087439856491983

 step 58 is completed and loss is 6.0197733546374366e-05

 step 59 is completed and loss is 0.00023760111071169376

 step 60 is completed and loss is 0.00010716314136516303

 step 61 is completed and loss is 5.6621986004756764e-05

 step 62 is completed and loss is 7.587261643493548e-05

 step 63 is completed and loss is 0.0003574253642000258

 step 64 is completed and loss is 0.00038925468106754124

 step 65 is completed and loss is 0.00011151347280247137

 step 66 is completed and loss is 0.0005969277117401361

 step 67 is completed and loss is 5.471510303323157e-05

 step 68 is completed and loss is 0.0001574628840899095

 step 69 is completed and loss is 0.00014965602895244956

 step 70 is completed and loss is 0.0001827880332712084

 step 71 is completed and loss is 0.00018397536769043654

 step 72 is completed and loss is 0.00035876542096957564

 step 73 is completed and loss is 8.463498670607805e-05

 step 74 is completed and loss is 0.00011717539746314287

 step 75 is completed and loss is 0.00023630431678611785

 step 76 is completed and loss is 0.00012158606841694564

 step 77 is completed and loss is 7.53967760829255e-05

 step 78 is completed and loss is 0.0001889258564915508

 step 79 is completed and loss is 0.0007649291073903441

 step 80 is completed and loss is 0.0003081044997088611

 step 81 is completed and loss is 8.833000902086496e-05

 step 82 is completed and loss is 0.0001722984598018229

 step 83 is completed and loss is 0.00014870133600197732

 step 84 is completed and loss is 0.00011264455679338425

 step 85 is completed and loss is 0.00012742661056108773

 step 86 is completed and loss is 0.00010549465514486656

 step 87 is completed and loss is 0.0001546593994135037

 step 88 is completed and loss is 0.0002380165969952941

 step 89 is completed and loss is 6.0735183069482446e-05

 step 90 is completed and loss is 0.0007178594241850078

 step 91 is completed and loss is 0.00012021181464660913
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.36it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.52it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.49it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.49it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.46it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.45it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.45it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.47it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.55it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.62it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:22,  1.67it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:21,  1.70it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:20,  1.72it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:20,  1.73it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:19,  1.74it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:18,  1.75it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:18,  1.75it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:11<00:18,  1.69it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:17,  1.67it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:17,  1.67it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:13<00:16,  1.66it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:16,  1.65it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:14<00:15,  1.65it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:14,  1.68it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:14,  1.63it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:16<00:13,  1.64it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:13,  1.62it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.57it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:18<00:12,  1.55it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:12,  1.57it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:19<00:11,  1.56it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:20<00:11,  1.53it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.55it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:21<00:09,  1.56it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:22<00:08,  1.56it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.55it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:23<00:07,  1.57it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:24<00:06,  1.61it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:24<00:06,  1.63it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:25<00:05,  1.60it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:05,  1.54it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:27<00:03,  1.52it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.53it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.51it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:29<00:01,  1.53it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.54it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:30<00:00,  1.59it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.59it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.59it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 71: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 300.0716205229983s
Training Epoch71:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch71:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.29s/it]Training Epoch71:   2%|[34mâ–         [0m| 2/92 [00:06<04:55,  3.29s/it]Training Epoch71:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:52,  3.29s/it]Training Epoch71:   4%|[34mâ–         [0m| 4/92 [00:13<04:49,  3.30s/it]Training Epoch71:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.30s/it]Training Epoch71:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.29s/it]Training Epoch71:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch71:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch71:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.31s/it]Training Epoch71:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:32,  3.32s/it]Training Epoch71:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch71:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:26,  3.33s/it]Training Epoch71:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.33s/it]Training Epoch71:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:21,  3.35s/it]Training Epoch71:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:17,  3.34s/it]Training Epoch71:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:11,  3.31s/it]Training Epoch71:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:09,  3.32s/it]Training Epoch71:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:06,  3.33s/it]Training Epoch71:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:02,  3.32s/it]Training Epoch71:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.31s/it]Training Epoch71:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.31s/it]Training Epoch71:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.31s/it]Training Epoch71:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:47,  3.30s/it]Training Epoch71:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.32s/it]Training Epoch71:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:41,  3.31s/it]Training Epoch71:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:39,  3.32s/it]Training Epoch71:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:36,  3.32s/it]Training Epoch71:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:32,  3.33s/it]Training Epoch71:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.32s/it]Training Epoch71:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:24,  3.29s/it]Training Epoch71:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:19,  3.28s/it]Training Epoch71:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:16,  3.27s/it]Training Epoch71:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:11,  3.24s/it]Training Epoch71:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:08,  3.26s/it]Training Epoch71:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:05,  3.26s/it]Training Epoch71:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:02,  3.26s/it]Training Epoch71:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<02:59,  3.26s/it]Training Epoch71:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:57,  3.28s/it]Training Epoch71:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:53,  3.26s/it]Training Epoch71:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:49,  3.25s/it]Training Epoch71:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:45,  3.25s/it]Training Epoch71:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:42,  3.25s/it]Training Epoch71:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:38,  3.24s/it]Training Epoch71:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:36,  3.27s/it]Training Epoch71:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:32,  3.25s/it]Training Epoch71:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:29,  3.26s/it]Training Epoch71:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:27,  3.27s/it]Training Epoch71:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:23,  3.27s/it]Training Epoch71:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:20,  3.27s/it]Training Epoch71:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:15,  3.23s/it]Training Epoch71:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:13,  3.26s/it]Training Epoch71:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:10,  3.27s/it]Training Epoch71:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:07,  3.28s/it]Training Epoch71:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:03,  3.25s/it]Training Epoch71:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:00,  3.26s/it]Training Epoch71:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:57,  3.26s/it]Training Epoch71:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:55,  3.29s/it]Training Epoch71:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:51,  3.28s/it]Training Epoch71:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.30s/it]Training Epoch71:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:45,  3.30s/it]Training Epoch71:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:42,  3.30s/it]Training Epoch71:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:39,  3.32s/it]Training Epoch71:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:36,  3.33s/it]Training Epoch71:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:33,  3.34s/it]Training Epoch71:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:31,  3.38s/it]Training Epoch71:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:27,  3.38s/it]Training Epoch71:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:24,  3.36s/it]Training Epoch71:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:20,  3.36s/it]Training Epoch71:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:18,  3.40s/it]Training Epoch71:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:14,  3.39s/it]Training Epoch71:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:11,  3.39s/it]Training Epoch71:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:07,  3.38s/it]Training Epoch71:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:03,  3.36s/it]Training Epoch71:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<01:00,  3.35s/it]Training Epoch71:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.34s/it]Training Epoch71:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.30s/it]Training Epoch71:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.29s/it]Training Epoch71:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.30s/it]Training Epoch71:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:43,  3.33s/it]Training Epoch71:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:40,  3.36s/it]Training Epoch71:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.35s/it]Training Epoch71:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.33s/it]Training Epoch71:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:30,  3.34s/it]Training Epoch71:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.36s/it]Training Epoch71:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.33s/it]Training Epoch71:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.31s/it]Training Epoch71:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.32s/it]Training Epoch71:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.32s/it]Training Epoch71:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.31s/it]Training Epoch71:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.31s/it]Training Epoch71:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.30s/it]Training Epoch71: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.33s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch71: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 9.959116869140416e-05

 step 1 is completed and loss is 0.00017873529577627778

 step 2 is completed and loss is 3.868264320772141e-05

 step 3 is completed and loss is 0.00011889968300238252

 step 4 is completed and loss is 7.575277413707227e-05

 step 5 is completed and loss is 4.708653432317078e-05

 step 6 is completed and loss is 0.0005567916086874902

 step 7 is completed and loss is 6.282052345341071e-05

 step 8 is completed and loss is 9.97728348011151e-05

 step 9 is completed and loss is 3.9755399484420195e-05

 step 10 is completed and loss is 0.000605796289164573

 step 11 is completed and loss is 0.001000615768134594

 step 12 is completed and loss is 0.00029354129219427705

 step 13 is completed and loss is 5.382154631661251e-05

 step 14 is completed and loss is 4.494077438721433e-05

 step 15 is completed and loss is 3.302042750874534e-05

 step 16 is completed and loss is 0.0002225808857474476

 step 17 is completed and loss is 0.00015173833526205271

 step 18 is completed and loss is 5.292752030072734e-05

 step 19 is completed and loss is 0.00013981694064568728

 step 20 is completed and loss is 4.2676016164477915e-05

 step 21 is completed and loss is 7.879352779127657e-05

 step 22 is completed and loss is 0.00035067275166511536

 step 23 is completed and loss is 0.00010442105121910572

 step 24 is completed and loss is 6.961576582398266e-05

 step 25 is completed and loss is 0.00021370704052969813

 step 26 is completed and loss is 7.569454464828596e-05

 step 27 is completed and loss is 0.00024684768868610263

 step 28 is completed and loss is 0.00013195216888561845

 step 29 is completed and loss is 9.887909982353449e-05

 step 30 is completed and loss is 0.00013833027333021164

 step 31 is completed and loss is 1.8775243006530218e-05

 step 32 is completed and loss is 0.0001131202225224115

 step 33 is completed and loss is 7.623137935297564e-05

 step 34 is completed and loss is 6.568209937540814e-05

 step 35 is completed and loss is 0.00016950079589150846

 step 36 is completed and loss is 1.478182639402803e-05

 step 37 is completed and loss is 6.180809577926993e-05

 step 38 is completed and loss is 7.611199544044212e-05

 step 39 is completed and loss is 5.841058737132698e-05

 step 40 is completed and loss is 0.00011687786900438368

 step 41 is completed and loss is 3.105340147158131e-05

 step 42 is completed and loss is 7.06289429217577e-05

 step 43 is completed and loss is 5.6562654208391905e-05

 step 44 is completed and loss is 2.7059946660301648e-05

 step 45 is completed and loss is 0.0002158003771910444

 step 46 is completed and loss is 2.8192474928800948e-05

 step 47 is completed and loss is 7.480103522539139e-05

 step 48 is completed and loss is 0.0003921540337614715

 step 49 is completed and loss is 7.766182534396648e-05

 step 50 is completed and loss is 7.331093365792185e-05

 step 51 is completed and loss is 5.9841200709342957e-05

 step 52 is completed and loss is 0.0017334220465272665

 step 53 is completed and loss is 0.00026460509980097413

 step 54 is completed and loss is 3.9338163333013654e-05

 step 55 is completed and loss is 0.0013848752714693546

 step 56 is completed and loss is 4.482155054574832e-05

 step 57 is completed and loss is 0.00015906574844848365

 step 58 is completed and loss is 6.043621397111565e-05

 step 59 is completed and loss is 0.0003113595303148031

 step 60 is completed and loss is 0.00010048806143458933

 step 61 is completed and loss is 8.755314775044098e-05

 step 62 is completed and loss is 8.189201616914943e-05

 step 63 is completed and loss is 0.00036713146255351603

 step 64 is completed and loss is 0.00031515545560978353

 step 65 is completed and loss is 8.046302536968142e-05

 step 66 is completed and loss is 0.0004084535175934434

 step 67 is completed and loss is 5.429793964140117e-05

 step 68 is completed and loss is 0.00019679497927427292

 step 69 is completed and loss is 0.00012909532233607024

 step 70 is completed and loss is 0.00016258431423921138

 step 71 is completed and loss is 0.00019458189490251243

 step 72 is completed and loss is 0.0004203568969387561

 step 73 is completed and loss is 8.386021363548934e-05

 step 74 is completed and loss is 0.00011193082173122093

 step 75 is completed and loss is 0.000251735036727041

 step 76 is completed and loss is 0.00011955969966948032

 step 77 is completed and loss is 6.651636795140803e-05

 step 78 is completed and loss is 0.00017349363770335913

 step 79 is completed and loss is 0.0007092523737810552

 step 80 is completed and loss is 0.00024011541972868145

 step 81 is completed and loss is 8.666103531140834e-05

 step 82 is completed and loss is 9.923611651174724e-05

 step 83 is completed and loss is 0.00016318270354531705

 step 84 is completed and loss is 9.786494774743915e-05

 step 85 is completed and loss is 0.00013159839727450162

 step 86 is completed and loss is 0.00013374387344811112

 step 87 is completed and loss is 0.00014214542170520872

 step 88 is completed and loss is 0.00017706258222460747

 step 89 is completed and loss is 6.425130413845181e-05

 step 90 is completed and loss is 0.0008844963158480823

 step 91 is completed and loss is 0.00014315392763819546
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.45it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.47it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.55it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.48it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.46it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.43it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.45it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.47it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.46it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.45it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.47it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.51it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.57it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:22,  1.60it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.60it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.57it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.55it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.53it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.56it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.55it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.51it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.50it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.50it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.47it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.47it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.48it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.47it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.47it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.46it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.52it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.55it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.56it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.58it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.61it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:07,  1.64it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.67it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.67it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.66it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.69it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:04,  1.71it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.72it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.74it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:02,  1.73it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.73it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.73it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.68it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.68it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.71it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.57it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 72: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.6353210220004s
Training Epoch72:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch72:   1%|[34m          [0m| 1/92 [00:03<04:50,  3.19s/it]Training Epoch72:   2%|[34mâ–         [0m| 2/92 [00:06<04:50,  3.22s/it]Training Epoch72:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:50,  3.26s/it]Training Epoch72:   4%|[34mâ–         [0m| 4/92 [00:12<04:45,  3.24s/it]Training Epoch72:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:43,  3.26s/it]Training Epoch72:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:38,  3.24s/it]Training Epoch72:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:36,  3.25s/it]Training Epoch72:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.28s/it]Training Epoch72:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.29s/it]Training Epoch72:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:29,  3.28s/it]Training Epoch72:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:26,  3.29s/it]Training Epoch72:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.28s/it]Training Epoch72:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.30s/it]Training Epoch72:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.31s/it]Training Epoch72:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.30s/it]Training Epoch72:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.28s/it]Training Epoch72:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:06,  3.29s/it]Training Epoch72:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:03,  3.30s/it]Training Epoch72:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:01,  3.30s/it]Training Epoch72:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.29s/it]Training Epoch72:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:54,  3.30s/it]Training Epoch72:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.30s/it]Training Epoch72:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.30s/it]Training Epoch72:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:45,  3.32s/it]Training Epoch72:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:41,  3.31s/it]Training Epoch72:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:37,  3.29s/it]Training Epoch72:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:31,  3.25s/it]Training Epoch72:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:26,  3.22s/it]Training Epoch72:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:24,  3.25s/it]Training Epoch72:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:20,  3.24s/it]Training Epoch72:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:18,  3.26s/it]Training Epoch72:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:44<03:16,  3.27s/it]Training Epoch72:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:10,  3.23s/it]Training Epoch72:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:07,  3.23s/it]Training Epoch72:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:03,  3.22s/it]Training Epoch72:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:57<03:02,  3.26s/it]Training Epoch72:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:59,  3.26s/it]Training Epoch72:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:54,  3.23s/it]Training Epoch72:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:07<02:51,  3.24s/it]Training Epoch72:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:10<02:50,  3.27s/it]Training Epoch72:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:46,  3.27s/it]Training Epoch72:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:44,  3.29s/it]Training Epoch72:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:41,  3.30s/it]Training Epoch72:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:38,  3.31s/it]Training Epoch72:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:34,  3.29s/it]Training Epoch72:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:31,  3.29s/it]Training Epoch72:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:33<02:26,  3.26s/it]Training Epoch72:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:36<02:22,  3.25s/it]Training Epoch72:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:19,  3.24s/it]Training Epoch72:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:43<02:16,  3.26s/it]Training Epoch72:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:46<02:14,  3.29s/it]Training Epoch72:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:11,  3.30s/it]Training Epoch72:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:07,  3.27s/it]Training Epoch72:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:56<02:03,  3.26s/it]Training Epoch72:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:02,  3.30s/it]Training Epoch72:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:58,  3.29s/it]Training Epoch72:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:06<01:55,  3.29s/it]Training Epoch72:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:09<01:51,  3.29s/it]Training Epoch72:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:49,  3.31s/it]Training Epoch72:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:16<01:45,  3.31s/it]Training Epoch72:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:19<01:43,  3.34s/it]Training Epoch72:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:39,  3.32s/it]Training Epoch72:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:36,  3.32s/it]Training Epoch72:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:29<01:32,  3.31s/it]Training Epoch72:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:28,  3.29s/it]Training Epoch72:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.27s/it]Training Epoch72:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:21,  3.27s/it]Training Epoch72:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:42<01:18,  3.28s/it]Training Epoch72:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:14,  3.25s/it]Training Epoch72:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:11,  3.25s/it]Training Epoch72:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:52<01:08,  3.27s/it]Training Epoch72:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:55<01:05,  3.28s/it]Training Epoch72:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.30s/it]Training Epoch72:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:59,  3.31s/it]Training Epoch72:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:05<00:56,  3.31s/it]Training Epoch72:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:52,  3.29s/it]Training Epoch72:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.31s/it]Training Epoch72:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:15<00:46,  3.32s/it]Training Epoch72:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:43,  3.32s/it]Training Epoch72:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:40,  3.34s/it]Training Epoch72:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.33s/it]Training Epoch72:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:32,  3.30s/it]Training Epoch72:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.31s/it]Training Epoch72:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.30s/it]Training Epoch72:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.30s/it]Training Epoch72:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.29s/it]Training Epoch72:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.28s/it]Training Epoch72:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:48<00:13,  3.27s/it]Training Epoch72:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.29s/it]Training Epoch72:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.28s/it]Training Epoch72:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:58<00:03,  3.29s/it]Training Epoch72: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:01<00:00,  3.30s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch72: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.28s/it]

 step 0 is completed and loss is 9.285694250138476e-05

 step 1 is completed and loss is 0.00017039477825164795

 step 2 is completed and loss is 5.352352309273556e-05

 step 3 is completed and loss is 7.998447836143896e-05

 step 4 is completed and loss is 6.872035737615079e-05

 step 5 is completed and loss is 4.21395743614994e-05

 step 6 is completed and loss is 0.0008911272161640227

 step 7 is completed and loss is 5.5311178584815934e-05

 step 8 is completed and loss is 7.015212759142742e-05

 step 9 is completed and loss is 3.874220055877231e-05

 step 10 is completed and loss is 0.0008660907624289393

 step 11 is completed and loss is 0.0009216599864885211

 step 12 is completed and loss is 0.0001965438132174313

 step 13 is completed and loss is 6.270210724323988e-05

 step 14 is completed and loss is 5.233150295680389e-05

 step 15 is completed and loss is 3.969590397900902e-05

 step 16 is completed and loss is 0.00021638761973008513

 step 17 is completed and loss is 0.00012980852625332773

 step 18 is completed and loss is 5.006649735150859e-05

 step 19 is completed and loss is 0.0001951740705408156

 step 20 is completed and loss is 4.607332812156528e-05

 step 21 is completed and loss is 4.809979145647958e-05

 step 22 is completed and loss is 0.0010093537857756019

 step 23 is completed and loss is 8.511149644618854e-05

 step 24 is completed and loss is 6.216565816430375e-05

 step 25 is completed and loss is 0.00014154876407701522

 step 26 is completed and loss is 6.07944093644619e-05

 step 27 is completed and loss is 0.0001388691016472876

 step 28 is completed and loss is 0.00015876688121352345

 step 29 is completed and loss is 8.153582894010469e-05

 step 30 is completed and loss is 0.00012045277981087565

 step 31 is completed and loss is 1.7285154171986505e-05

 step 32 is completed and loss is 0.00010847163503058255

 step 33 is completed and loss is 8.308538235723972e-05

 step 34 is completed and loss is 7.04499107087031e-05

 step 35 is completed and loss is 0.0001725986658129841

 step 36 is completed and loss is 1.5675894246669486e-05

 step 37 is completed and loss is 6.198678602231666e-05

 step 38 is completed and loss is 0.00010465907689649612

 step 39 is completed and loss is 4.768257349496707e-05

 step 40 is completed and loss is 0.00011097735114162788

 step 41 is completed and loss is 4.076835830346681e-05

 step 42 is completed and loss is 6.240410584723577e-05

 step 43 is completed and loss is 6.419153942260891e-05

 step 44 is completed and loss is 2.8550022761919536e-05

 step 45 is completed and loss is 0.00017808095435611904

 step 46 is completed and loss is 2.4675980967003852e-05

 step 47 is completed and loss is 6.359611870720983e-05

 step 48 is completed and loss is 0.00041055568726733327

 step 49 is completed and loss is 8.415817865170538e-05

 step 50 is completed and loss is 7.593338523292914e-05

 step 51 is completed and loss is 5.161628359928727e-05

 step 52 is completed and loss is 0.0010859450558200479

 step 53 is completed and loss is 0.00030375251662917435

 step 54 is completed and loss is 4.1960611270042136e-05

 step 55 is completed and loss is 0.0018943734467029572

 step 56 is completed and loss is 3.7192530726315454e-05

 step 57 is completed and loss is 0.0001743209722917527

 step 58 is completed and loss is 6.204540113685653e-05

 step 59 is completed and loss is 0.000309215160086751

 step 60 is completed and loss is 0.00013058504555374384

 step 61 is completed and loss is 9.518110891804099e-05

 step 62 is completed and loss is 7.491904398193583e-05

 step 63 is completed and loss is 0.0010749234352260828

 step 64 is completed and loss is 0.00028340413700789213

 step 65 is completed and loss is 7.885370723670349e-05

 step 66 is completed and loss is 0.0006099046440795064

 step 67 is completed and loss is 5.453627454699017e-05

 step 68 is completed and loss is 0.00018225438543595374

 step 69 is completed and loss is 0.00015972625988069922

 step 70 is completed and loss is 0.00017480301903560758

 step 71 is completed and loss is 0.00012837801477871835

 step 72 is completed and loss is 0.00044334502308629453

 step 73 is completed and loss is 9.691229206509888e-05

 step 74 is completed and loss is 0.0001175332727143541

 step 75 is completed and loss is 0.0002224160125479102

 step 76 is completed and loss is 0.00012861849972978234

 step 77 is completed and loss is 6.437081901822239e-05

 step 78 is completed and loss is 0.00017980969278141856

 step 79 is completed and loss is 0.0007353938417509198

 step 80 is completed and loss is 0.00022671016631647944

 step 81 is completed and loss is 8.46347538754344e-05

 step 82 is completed and loss is 0.000131835084175691

 step 83 is completed and loss is 0.00014238391304388642

 step 84 is completed and loss is 0.00010769804066512734

 step 85 is completed and loss is 0.00014220656885299832

 step 86 is completed and loss is 9.97731985989958e-05

 step 87 is completed and loss is 0.00015501855523325503

 step 88 is completed and loss is 0.00023342750500887632

 step 89 is completed and loss is 7.974715845193714e-05

 step 90 is completed and loss is 0.0008952023345045745

 step 91 is completed and loss is 0.00010006871889345348
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.42it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.50it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.54it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:28,  1.62it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:27,  1.66it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:27,  1.62it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.59it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.58it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.56it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.58it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:06<00:24,  1.59it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.58it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.57it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.57it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.55it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.51it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:22,  1.49it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.52it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.55it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.54it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.55it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.54it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.54it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.54it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.52it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.53it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.50it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.51it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.54it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.52it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.53it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.53it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.52it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.50it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.51it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.53it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.55it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.55it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.55it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.56it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.56it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.56it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.55it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.51it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.52it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.54it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 73: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 302.25506348499766s
Training Epoch73:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch73:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.26s/it]Training Epoch73:   2%|[34mâ–         [0m| 2/92 [00:06<04:51,  3.24s/it]Training Epoch73:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.26s/it]Training Epoch73:   4%|[34mâ–         [0m| 4/92 [00:12<04:45,  3.24s/it]Training Epoch73:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:41,  3.24s/it]Training Epoch73:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:36,  3.21s/it]Training Epoch73:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:33,  3.22s/it]Training Epoch73:   9%|[34mâ–Š         [0m| 8/92 [00:25<04:34,  3.26s/it]Training Epoch73:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:32,  3.29s/it]Training Epoch73:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:26,  3.25s/it]Training Epoch73:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:24,  3.27s/it]Training Epoch73:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.28s/it]Training Epoch73:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.30s/it]Training Epoch73:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:15,  3.28s/it]Training Epoch73:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:48<04:13,  3.29s/it]Training Epoch73:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:08,  3.27s/it]Training Epoch73:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:05,  3.27s/it]Training Epoch73:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:04,  3.31s/it]Training Epoch73:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.32s/it]Training Epoch73:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:57,  3.30s/it]Training Epoch73:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:52,  3.28s/it]Training Epoch73:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:49,  3.27s/it]Training Epoch73:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.30s/it]Training Epoch73:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:45,  3.32s/it]Training Epoch73:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.34s/it]Training Epoch73:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:40,  3.34s/it]Training Epoch73:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:37,  3.34s/it]Training Epoch73:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:33,  3.33s/it]Training Epoch73:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:29,  3.33s/it]Training Epoch73:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:25,  3.32s/it]Training Epoch73:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:21,  3.31s/it]Training Epoch73:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:18,  3.31s/it]Training Epoch73:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:15,  3.31s/it]Training Epoch73:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:09,  3.27s/it]Training Epoch73:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:06,  3.27s/it]Training Epoch73:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:04,  3.29s/it]Training Epoch73:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:02,  3.31s/it]Training Epoch73:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<03:00,  3.34s/it]Training Epoch73:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.30s/it]Training Epoch73:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:50,  3.28s/it]Training Epoch73:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:45,  3.25s/it]Training Epoch73:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:42,  3.26s/it]Training Epoch73:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:41,  3.30s/it]Training Epoch73:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:39,  3.32s/it]Training Epoch73:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:36,  3.33s/it]Training Epoch73:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:33,  3.33s/it]Training Epoch73:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:30,  3.34s/it]Training Epoch73:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:26,  3.32s/it]Training Epoch73:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:23,  3.33s/it]Training Epoch73:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:20,  3.34s/it]Training Epoch73:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:16,  3.33s/it]Training Epoch73:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.29s/it]Training Epoch73:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.29s/it]Training Epoch73:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:05,  3.29s/it]Training Epoch73:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.31s/it]Training Epoch73:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:58,  3.30s/it]Training Epoch73:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:56,  3.33s/it]Training Epoch73:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.31s/it]Training Epoch73:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:48,  3.30s/it]Training Epoch73:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:46,  3.32s/it]Training Epoch73:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.31s/it]Training Epoch73:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.31s/it]Training Epoch73:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:36,  3.31s/it]Training Epoch73:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:33,  3.33s/it]Training Epoch73:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:30,  3.34s/it]Training Epoch73:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.30s/it]Training Epoch73:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.30s/it]Training Epoch73:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:20,  3.34s/it]Training Epoch73:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.33s/it]Training Epoch73:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:13,  3.33s/it]Training Epoch73:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:10,  3.34s/it]Training Epoch73:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.35s/it]Training Epoch73:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:03,  3.33s/it]Training Epoch73:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.32s/it]Training Epoch73:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.33s/it]Training Epoch73:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:53,  3.32s/it]Training Epoch73:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.30s/it]Training Epoch73:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.29s/it]Training Epoch73:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.30s/it]Training Epoch73:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.28s/it]Training Epoch73:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.30s/it]Training Epoch73:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.30s/it]Training Epoch73:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.32s/it]Training Epoch73:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.30s/it]Training Epoch73:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.32s/it]Training Epoch73:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.31s/it]Training Epoch73:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.33s/it]Training Epoch73:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.35s/it]Training Epoch73:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:10,  3.35s/it]Training Epoch73:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.35s/it]Training Epoch73:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.36s/it]Training Epoch73: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.34s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch73: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.0001051337894750759

 step 1 is completed and loss is 0.0001649123732931912

 step 2 is completed and loss is 4.5596480049425736e-05

 step 3 is completed and loss is 0.0001405307702952996

 step 4 is completed and loss is 0.00011031777103198692

 step 5 is completed and loss is 4.1841565689537674e-05

 step 6 is completed and loss is 0.0006697152275592089

 step 7 is completed and loss is 5.280794721329585e-05

 step 8 is completed and loss is 7.939008355606347e-05

 step 9 is completed and loss is 4.7682457079645246e-05

 step 10 is completed and loss is 0.0006997305317781866

 step 11 is completed and loss is 0.0014362492365762591

 step 12 is completed and loss is 0.00025141690275631845

 step 13 is completed and loss is 6.329809548333287e-05

 step 14 is completed and loss is 4.535802872851491e-05

 step 15 is completed and loss is 4.649054244509898e-05

 step 16 is completed and loss is 0.00015441729919984937

 step 17 is completed and loss is 0.0001290933578275144

 step 18 is completed and loss is 5.3761898016091436e-05

 step 19 is completed and loss is 0.00011276258737780154

 step 20 is completed and loss is 3.999390537501313e-05

 step 21 is completed and loss is 7.652927888557315e-05

 step 22 is completed and loss is 0.000638829602394253

 step 23 is completed and loss is 8.982001600088552e-05

 step 24 is completed and loss is 7.128457946237177e-05

 step 25 is completed and loss is 0.00016806565690785646

 step 26 is completed and loss is 5.841066740686074e-05

 step 27 is completed and loss is 0.00012969126692041755

 step 28 is completed and loss is 0.00019970210269093513

 step 29 is completed and loss is 7.903261575847864e-05

 step 30 is completed and loss is 0.0001161620020866394

 step 31 is completed and loss is 2.1278567146509886e-05

 step 32 is completed and loss is 9.399090777151287e-05

 step 33 is completed and loss is 9.34556737774983e-05

 step 34 is completed and loss is 7.337050919886678e-05

 step 35 is completed and loss is 0.00020590847998391837

 step 36 is completed and loss is 1.4185784493747633e-05

 step 37 is completed and loss is 7.152301259338856e-05

 step 38 is completed and loss is 6.097368896007538e-05

 step 39 is completed and loss is 5.8649246057029814e-05

 step 40 is completed and loss is 0.00012194346345495433

 step 41 is completed and loss is 4.851642734138295e-05

 step 42 is completed and loss is 7.408582314383239e-05

 step 43 is completed and loss is 5.87081813137047e-05

 step 44 is completed and loss is 2.4258661142084748e-05

 step 45 is completed and loss is 0.00019744827295653522

 step 46 is completed and loss is 1.788121517165564e-05

 step 47 is completed and loss is 0.0001169961760751903

 step 48 is completed and loss is 0.00044058432104066014

 step 49 is completed and loss is 8.928363968152553e-05

 step 50 is completed and loss is 9.45879946812056e-05

 step 51 is completed and loss is 6.5801345044747e-05

 step 52 is completed and loss is 0.0017090319888666272

 step 53 is completed and loss is 0.00024220185878220946

 step 54 is completed and loss is 3.594082227209583e-05

 step 55 is completed and loss is 0.0011805201647803187

 step 56 is completed and loss is 4.2973992094630376e-05

 step 57 is completed and loss is 0.0003100451431237161

 step 58 is completed and loss is 5.227122164797038e-05

 step 59 is completed and loss is 0.0003516259603202343

 step 60 is completed and loss is 9.601835336070508e-05

 step 61 is completed and loss is 8.475175854982808e-05

 step 62 is completed and loss is 7.623015699209645e-05

 step 63 is completed and loss is 0.0004289006465114653

 step 64 is completed and loss is 0.0002895396901294589

 step 65 is completed and loss is 9.595884330337867e-05

 step 66 is completed and loss is 0.000652539893053472

 step 67 is completed and loss is 5.2569565013982356e-05

 step 68 is completed and loss is 0.0001926236436702311

 step 69 is completed and loss is 0.00013600819511339068

 step 70 is completed and loss is 0.00019053375581279397

 step 71 is completed and loss is 0.00021466337784659117

 step 72 is completed and loss is 0.00034262664848938584

 step 73 is completed and loss is 7.36089568817988e-05

 step 74 is completed and loss is 0.00011455289495643228

 step 75 is completed and loss is 0.00020954791398253292

 step 76 is completed and loss is 0.0001388092787237838

 step 77 is completed and loss is 7.784001354593784e-05

 step 78 is completed and loss is 0.00019971057190559804

 step 79 is completed and loss is 0.000583652057684958

 step 80 is completed and loss is 0.00030095811234787107

 step 81 is completed and loss is 8.850887388689443e-05

 step 82 is completed and loss is 0.0001428593968739733

 step 83 is completed and loss is 0.0001805829961085692

 step 84 is completed and loss is 0.00010436119919177145

 step 85 is completed and loss is 0.0001679517881711945

 step 86 is completed and loss is 0.00011729506513802335

 step 87 is completed and loss is 0.00015930998779367656

 step 88 is completed and loss is 0.00020626136392820626

 step 89 is completed and loss is 7.980698865139857e-05

 step 90 is completed and loss is 0.0007121399394236505

 step 91 is completed and loss is 0.0001715175312710926
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:37,  1.31it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.42it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.47it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.51it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.50it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.49it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.51it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.52it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.51it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.50it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.47it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.52it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.50it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.46it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.49it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.52it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:20,  1.58it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:19,  1.61it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.51it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.50it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.49it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.50it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.48it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.47it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.47it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:15,  1.45it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.46it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.48it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.51it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.51it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.50it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.48it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.47it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.43it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.45it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.46it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.47it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.49it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.47it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.47it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.47it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.48it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.52it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.53it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.50it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.50it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.46it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.45it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 74: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.5348858860016s
Training Epoch74:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch74:   1%|[34m          [0m| 1/92 [00:03<05:06,  3.37s/it]Training Epoch74:   2%|[34mâ–         [0m| 2/92 [00:06<04:59,  3.33s/it]Training Epoch74:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:56,  3.33s/it]Training Epoch74:   4%|[34mâ–         [0m| 4/92 [00:13<04:50,  3.30s/it]Training Epoch74:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch74:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:45,  3.31s/it]Training Epoch74:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.34s/it]Training Epoch74:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:40,  3.34s/it]Training Epoch74:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:38,  3.35s/it]Training Epoch74:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:36,  3.37s/it]Training Epoch74:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:32,  3.36s/it]Training Epoch74:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:27,  3.35s/it]Training Epoch74:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:21,  3.31s/it]Training Epoch74:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.30s/it]Training Epoch74:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.31s/it]Training Epoch74:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:09,  3.29s/it]Training Epoch74:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.31s/it]Training Epoch74:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.32s/it]Training Epoch74:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:00,  3.29s/it]Training Epoch74:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:56,  3.29s/it]Training Epoch74:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.31s/it]Training Epoch74:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:53,  3.33s/it]Training Epoch74:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:49,  3.33s/it]Training Epoch74:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:49,  3.37s/it]Training Epoch74:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:44,  3.35s/it]Training Epoch74:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:41,  3.36s/it]Training Epoch74:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:40,  3.39s/it]Training Epoch74:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:36,  3.38s/it]Training Epoch74:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:33,  3.39s/it]Training Epoch74:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:40<03:29,  3.37s/it]Training Epoch74:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:26,  3.38s/it]Training Epoch74:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:22,  3.38s/it]Training Epoch74:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:50<03:20,  3.39s/it]Training Epoch74:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:15,  3.38s/it]Training Epoch74:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:10,  3.35s/it]Training Epoch74:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [02:00<03:06,  3.32s/it]Training Epoch74:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:03,  3.33s/it]Training Epoch74:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<03:00,  3.34s/it]Training Epoch74:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:10<02:58,  3.36s/it]Training Epoch74:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:54,  3.36s/it]Training Epoch74:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:17<02:52,  3.38s/it]Training Epoch74:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:20<02:48,  3.36s/it]Training Epoch74:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:43,  3.35s/it]Training Epoch74:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:27<02:40,  3.35s/it]Training Epoch74:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:30<02:38,  3.36s/it]Training Epoch74:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:36,  3.40s/it]Training Epoch74:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:37<02:32,  3.39s/it]Training Epoch74:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:40<02:29,  3.39s/it]Training Epoch74:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:44<02:24,  3.37s/it]Training Epoch74:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:47<02:21,  3.37s/it]Training Epoch74:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:50<02:17,  3.35s/it]Training Epoch74:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:54<02:14,  3.37s/it]Training Epoch74:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:57<02:11,  3.38s/it]Training Epoch74:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [03:00<02:08,  3.38s/it]Training Epoch74:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:04<02:04,  3.36s/it]Training Epoch74:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:07<02:00,  3.34s/it]Training Epoch74:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:10<01:58,  3.37s/it]Training Epoch74:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:14<01:54,  3.38s/it]Training Epoch74:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:17<01:51,  3.38s/it]Training Epoch74:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:21<01:47,  3.36s/it]Training Epoch74:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:24<01:43,  3.35s/it]Training Epoch74:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:27<01:41,  3.37s/it]Training Epoch74:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:31<01:36,  3.34s/it]Training Epoch74:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:34<01:33,  3.32s/it]Training Epoch74:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:37<01:30,  3.34s/it]Training Epoch74:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:41<01:27,  3.36s/it]Training Epoch74:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:44<01:23,  3.35s/it]Training Epoch74:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:47<01:20,  3.34s/it]Training Epoch74:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:51<01:17,  3.36s/it]Training Epoch74:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:54<01:14,  3.37s/it]Training Epoch74:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:57<01:10,  3.34s/it]Training Epoch74:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [04:01<01:07,  3.36s/it]Training Epoch74:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:04<01:04,  3.38s/it]Training Epoch74:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:08<01:00,  3.38s/it]Training Epoch74:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:11<00:56,  3.34s/it]Training Epoch74:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:14<00:53,  3.34s/it]Training Epoch74:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:18<00:50,  3.35s/it]Training Epoch74:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:21<00:47,  3.37s/it]Training Epoch74:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:24<00:43,  3.36s/it]Training Epoch74:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:28<00:40,  3.35s/it]Training Epoch74:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:31<00:36,  3.34s/it]Training Epoch74:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:34<00:33,  3.36s/it]Training Epoch74:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:38<00:30,  3.34s/it]Training Epoch74:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:41<00:26,  3.35s/it]Training Epoch74:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:44<00:23,  3.35s/it]Training Epoch74:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:48<00:20,  3.34s/it]Training Epoch74:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:51<00:16,  3.36s/it]Training Epoch74:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:54<00:13,  3.36s/it]Training Epoch74:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:58<00:10,  3.35s/it]Training Epoch74:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [05:01<00:06,  3.38s/it]Training Epoch74:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:05<00:03,  3.39s/it]Training Epoch74: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:08<00:00,  3.36s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch74: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:08<00:00,  3.35s/it]

 step 0 is completed and loss is 0.00010626581206452101

 step 1 is completed and loss is 0.00018630501290317625

 step 2 is completed and loss is 3.236478369217366e-05

 step 3 is completed and loss is 0.00011180802539456636

 step 4 is completed and loss is 8.630123193142936e-05

 step 5 is completed and loss is 5.549023990170099e-05

 step 6 is completed and loss is 0.0005617312854155898

 step 7 is completed and loss is 6.305905117187649e-05

 step 8 is completed and loss is 7.59929753257893e-05

 step 9 is completed and loss is 4.708628330263309e-05

 step 10 is completed and loss is 0.0010521196527406573

 step 11 is completed and loss is 0.0014303048374131322

 step 12 is completed and loss is 0.00029103615088388324

 step 13 is completed and loss is 5.8589612308423966e-05

 step 14 is completed and loss is 5.411942402133718e-05

 step 15 is completed and loss is 4.494089080253616e-05

 step 16 is completed and loss is 0.00017574988305568695

 step 17 is completed and loss is 0.0001419638138031587

 step 18 is completed and loss is 5.2689112635562196e-05

 step 19 is completed and loss is 0.00017568838666193187

 step 20 is completed and loss is 6.156949530122802e-05

 step 21 is completed and loss is 6.133122951723635e-05

 step 22 is completed and loss is 0.0004886136739514768

 step 23 is completed and loss is 9.095245331991464e-05

 step 24 is completed and loss is 7.390702376142144e-05

 step 25 is completed and loss is 0.00031492445850744843

 step 26 is completed and loss is 7.080752402544022e-05

 step 27 is completed and loss is 0.0002438087685732171

 step 28 is completed and loss is 0.00020583957666531205

 step 29 is completed and loss is 9.381321433465928e-05

 step 30 is completed and loss is 0.00011908159649465233

 step 31 is completed and loss is 1.7046748325810768e-05

 step 32 is completed and loss is 8.707728557055816e-05

 step 33 is completed and loss is 9.822320134844631e-05

 step 34 is completed and loss is 7.00329037499614e-05

 step 35 is completed and loss is 0.00013541252701543272

 step 36 is completed and loss is 1.7046766515704803e-05

 step 37 is completed and loss is 7.331096276175231e-05

 step 38 is completed and loss is 7.736381667200476e-05

 step 39 is completed and loss is 7.110580918379128e-05

 step 40 is completed and loss is 8.314481237903237e-05

 step 41 is completed and loss is 3.3795033232308924e-05

 step 42 is completed and loss is 6.979460158618167e-05

 step 43 is completed and loss is 5.858939402969554e-05

 step 44 is completed and loss is 2.396068157395348e-05

 step 45 is completed and loss is 0.00017778138862922788

 step 46 is completed and loss is 2.1576572180492803e-05

 step 47 is completed and loss is 9.500497253611684e-05

 step 48 is completed and loss is 0.00047071618610061705

 step 49 is completed and loss is 9.756801591720432e-05

 step 50 is completed and loss is 8.296619489556178e-05

 step 51 is completed and loss is 6.210606079548597e-05

 step 52 is completed and loss is 0.0015497360145673156

 step 53 is completed and loss is 0.00035320036113262177

 step 54 is completed and loss is 4.434465881786309e-05

 step 55 is completed and loss is 0.0012153692077845335

 step 56 is completed and loss is 3.886138438247144e-05

 step 57 is completed and loss is 0.00015024715685285628

 step 58 is completed and loss is 7.164067210396752e-05

 step 59 is completed and loss is 0.0003431688528507948

 step 60 is completed and loss is 8.964103471953422e-05

 step 61 is completed and loss is 7.444182847393677e-05

 step 62 is completed and loss is 9.90554690361023e-05

 step 63 is completed and loss is 0.0005245552747510374

 step 64 is completed and loss is 0.00022293647634796798

 step 65 is completed and loss is 8.350255666300654e-05

 step 66 is completed and loss is 0.0008875863277353346

 step 67 is completed and loss is 5.751621210947633e-05

 step 68 is completed and loss is 0.00017838063649833202

 step 69 is completed and loss is 0.0001587124279467389

 step 70 is completed and loss is 0.00015054881805554032

 step 71 is completed and loss is 0.00016175024211406708

 step 72 is completed and loss is 0.00046466870117001235

 step 73 is completed and loss is 7.927101978566498e-05

 step 74 is completed and loss is 0.00010889143595704809

 step 75 is completed and loss is 0.0002497122040949762

 step 76 is completed and loss is 0.0001199769030790776

 step 77 is completed and loss is 7.867474050726742e-05

 step 78 is completed and loss is 0.00016222908743657172

 step 79 is completed and loss is 0.0007488833507522941

 step 80 is completed and loss is 0.00025161902885884047

 step 81 is completed and loss is 0.00010036873572971672

 step 82 is completed and loss is 0.00013356460840441287

 step 83 is completed and loss is 0.0001705138711258769

 step 84 is completed and loss is 0.0001359450543532148

 step 85 is completed and loss is 0.0001445904199499637

 step 86 is completed and loss is 9.178694017464295e-05

 step 87 is completed and loss is 0.00016431446420028806

 step 88 is completed and loss is 0.00017539382679387927

 step 89 is completed and loss is 5.388093995861709e-05

 step 90 is completed and loss is 0.0008089077891781926

 step 91 is completed and loss is 0.0001693733356660232
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.37it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.38it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:34,  1.36it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:33,  1.36it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:32,  1.38it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:31,  1.39it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:05<00:30,  1.40it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.44it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:29,  1.41it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:27,  1.43it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:27,  1.43it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.44it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:25,  1.47it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.47it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.48it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.46it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.46it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.47it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:20,  1.48it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.47it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.48it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:18,  1.51it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.49it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.49it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.47it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.50it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.53it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:14,  1.57it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.55it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.51it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:12,  1.53it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.55it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:10,  1.56it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.56it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.56it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.55it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.55it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.53it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.53it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.53it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.50it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.50it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.46it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.46it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.42it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.41it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.42it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.42it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.46it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.47it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 75: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 308.74903267699847s
Training Epoch75:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch75:   1%|[34m          [0m| 1/92 [00:03<04:58,  3.28s/it]Training Epoch75:   2%|[34mâ–         [0m| 2/92 [00:06<05:00,  3.34s/it]Training Epoch75:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:57,  3.34s/it]Training Epoch75:   4%|[34mâ–         [0m| 4/92 [00:13<04:54,  3.35s/it]Training Epoch75:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:52,  3.36s/it]Training Epoch75:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:48,  3.35s/it]Training Epoch75:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:46,  3.37s/it]Training Epoch75:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:40,  3.35s/it]Training Epoch75:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:38,  3.35s/it]Training Epoch75:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:36,  3.37s/it]Training Epoch75:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:32,  3.36s/it]Training Epoch75:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:29,  3.37s/it]Training Epoch75:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:24,  3.35s/it]Training Epoch75:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:19,  3.33s/it]Training Epoch75:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:50<04:14,  3.30s/it]Training Epoch75:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:10,  3.30s/it]Training Epoch75:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:05,  3.27s/it]Training Epoch75:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.30s/it]Training Epoch75:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:01,  3.31s/it]Training Epoch75:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:00,  3.34s/it]Training Epoch75:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:10<03:57,  3.35s/it]Training Epoch75:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:54,  3.35s/it]Training Epoch75:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:47,  3.30s/it]Training Epoch75:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.31s/it]Training Epoch75:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:43,  3.33s/it]Training Epoch75:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:40,  3.35s/it]Training Epoch75:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:36,  3.34s/it]Training Epoch75:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:35,  3.36s/it]Training Epoch75:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:30,  3.35s/it]Training Epoch75:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:40<03:26,  3.33s/it]Training Epoch75:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:25,  3.37s/it]Training Epoch75:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:22,  3.38s/it]Training Epoch75:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:50<03:16,  3.34s/it]Training Epoch75:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:12,  3.31s/it]Training Epoch75:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:08,  3.31s/it]Training Epoch75:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [02:00<03:04,  3.30s/it]Training Epoch75:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:02,  3.32s/it]Training Epoch75:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:59,  3.33s/it]Training Epoch75:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:54,  3.28s/it]Training Epoch75:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:50,  3.28s/it]Training Epoch75:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:48,  3.31s/it]Training Epoch75:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.30s/it]Training Epoch75:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:41,  3.31s/it]Training Epoch75:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:38,  3.30s/it]Training Epoch75:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:34,  3.28s/it]Training Epoch75:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:31,  3.29s/it]Training Epoch75:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:29,  3.33s/it]Training Epoch75:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:25,  3.31s/it]Training Epoch75:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:21,  3.30s/it]Training Epoch75:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:18,  3.29s/it]Training Epoch75:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:14,  3.28s/it]Training Epoch75:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:11,  3.29s/it]Training Epoch75:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:08,  3.28s/it]Training Epoch75:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:04,  3.29s/it]Training Epoch75:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:02,  3.31s/it]Training Epoch75:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<01:59,  3.32s/it]Training Epoch75:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:57,  3.34s/it]Training Epoch75:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:53,  3.35s/it]Training Epoch75:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:50,  3.36s/it]Training Epoch75:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:46,  3.33s/it]Training Epoch75:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:43,  3.33s/it]Training Epoch75:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:40,  3.34s/it]Training Epoch75:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:36,  3.31s/it]Training Epoch75:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:31,  3.28s/it]Training Epoch75:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:28,  3.29s/it]Training Epoch75:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:26,  3.31s/it]Training Epoch75:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:21,  3.27s/it]Training Epoch75:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.30s/it]Training Epoch75:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:16,  3.32s/it]Training Epoch75:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:12,  3.31s/it]Training Epoch75:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.31s/it]Training Epoch75:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.33s/it]Training Epoch75:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:02,  3.31s/it]Training Epoch75:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.32s/it]Training Epoch75:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:57,  3.36s/it]Training Epoch75:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:53,  3.36s/it]Training Epoch75:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:50,  3.37s/it]Training Epoch75:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:46,  3.33s/it]Training Epoch75:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:43,  3.34s/it]Training Epoch75:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:40,  3.34s/it]Training Epoch75:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:29<00:36,  3.35s/it]Training Epoch75:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.38s/it]Training Epoch75:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:36<00:30,  3.37s/it]Training Epoch75:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:26,  3.36s/it]Training Epoch75:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.37s/it]Training Epoch75:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:46<00:20,  3.36s/it]Training Epoch75:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.35s/it]Training Epoch75:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:52<00:13,  3.36s/it]Training Epoch75:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:56<00:10,  3.35s/it]Training Epoch75:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.37s/it]Training Epoch75:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.37s/it]Training Epoch75: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.35s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch75: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.33s/it]

 step 0 is completed and loss is 0.00013338089047465473

 step 1 is completed and loss is 0.000184337972314097

 step 2 is completed and loss is 4.196076042717323e-05

 step 3 is completed and loss is 8.719569450477138e-05

 step 4 is completed and loss is 7.634870416950434e-05

 step 5 is completed and loss is 5.4715499572921544e-05

 step 6 is completed and loss is 0.0010790021624416113

 step 7 is completed and loss is 5.20332068845164e-05

 step 8 is completed and loss is 7.307260239031166e-05

 step 9 is completed and loss is 4.696715041063726e-05

 step 10 is completed and loss is 0.0005726859671995044

 step 11 is completed and loss is 0.0011845482513308525

 step 12 is completed and loss is 0.0002672678674571216

 step 13 is completed and loss is 7.027140236459672e-05

 step 14 is completed and loss is 4.285474642529152e-05

 step 15 is completed and loss is 4.351044481154531e-05

 step 16 is completed and loss is 0.00015441783762071282

 step 17 is completed and loss is 0.00010084416135214269

 step 18 is completed and loss is 6.0318070609355345e-05

 step 19 is completed and loss is 0.0002524883602745831

 step 20 is completed and loss is 5.739758489653468e-05

 step 21 is completed and loss is 6.359611143125221e-05

 step 22 is completed and loss is 0.00042024694266729057

 step 23 is completed and loss is 9.726897405926138e-05

 step 24 is completed and loss is 6.693370232824236e-05

 step 25 is completed and loss is 0.0001408323587384075

 step 26 is completed and loss is 8.141619036905468e-05

 step 27 is completed and loss is 0.00020489977032411844

 step 28 is completed and loss is 0.00013433540880214423

 step 29 is completed and loss is 9.959432645700872e-05

 step 30 is completed and loss is 0.00011777107283705845

 step 31 is completed and loss is 2.0086506992811337e-05

 step 32 is completed and loss is 8.522993448423222e-05

 step 33 is completed and loss is 7.83174327807501e-05

 step 34 is completed and loss is 8.254849672084674e-05

 step 35 is completed and loss is 0.00018707782146520913

 step 36 is completed and loss is 1.64507218869403e-05

 step 37 is completed and loss is 7.259581616381183e-05

 step 38 is completed and loss is 7.402614573948085e-05

 step 39 is completed and loss is 6.431122892536223e-05

 step 40 is completed and loss is 9.518400474917144e-05

 step 41 is completed and loss is 2.9205766622908413e-05

 step 42 is completed and loss is 7.313219248317182e-05

 step 43 is completed and loss is 7.241631101351231e-05

 step 44 is completed and loss is 2.2589789296034724e-05

 step 45 is completed and loss is 0.00017998763360083103

 step 46 is completed and loss is 2.4497145204804838e-05

 step 47 is completed and loss is 6.830456550233066e-05

 step 48 is completed and loss is 0.0005364037351682782

 step 49 is completed and loss is 8.469446038361639e-05

 step 50 is completed and loss is 9.279992082156241e-05

 step 51 is completed and loss is 6.365565059240907e-05

 step 52 is completed and loss is 0.001899658003821969

 step 53 is completed and loss is 0.0003817895194515586

 step 54 is completed and loss is 4.2020143155241385e-05

 step 55 is completed and loss is 0.0010054624872282147

 step 56 is completed and loss is 3.3378018997609615e-05

 step 57 is completed and loss is 0.0002276486629853025

 step 58 is completed and loss is 5.876765135326423e-05

 step 59 is completed and loss is 0.000293424935080111

 step 60 is completed and loss is 0.00010841478069778532

 step 61 is completed and loss is 0.00010525307880016044

 step 62 is completed and loss is 9.506235073786229e-05

 step 63 is completed and loss is 0.0007925380486994982

 step 64 is completed and loss is 0.00028191559249535203

 step 65 is completed and loss is 0.00010001134796766564

 step 66 is completed and loss is 0.0005204745102673769

 step 67 is completed and loss is 7.617071241838858e-05

 step 68 is completed and loss is 0.00016532914014533162

 step 69 is completed and loss is 0.00016717585094738752

 step 70 is completed and loss is 0.00017486237629782408

 step 71 is completed and loss is 0.00016073556616902351

 step 72 is completed and loss is 0.00035340673639439046

 step 73 is completed and loss is 8.469459135085344e-05

 step 74 is completed and loss is 0.00010656686208676547

 step 75 is completed and loss is 0.00020770033006556332

 step 76 is completed and loss is 0.0001289761275984347

 step 77 is completed and loss is 7.021150668151677e-05

 step 78 is completed and loss is 0.00019947212422266603

 step 79 is completed and loss is 0.0009115535649470985

 step 80 is completed and loss is 0.00024273684539366513

 step 81 is completed and loss is 0.00011348001862643287

 step 82 is completed and loss is 0.00015579175669699907

 step 83 is completed and loss is 0.0001693205558694899

 step 84 is completed and loss is 0.00016317875997629017

 step 85 is completed and loss is 0.00015317220822907984

 step 86 is completed and loss is 0.00010871296399272978

 step 87 is completed and loss is 0.00014202714373823255

 step 88 is completed and loss is 0.0002277704479638487

 step 89 is completed and loss is 8.374053868465126e-05

 step 90 is completed and loss is 0.0007546345004811883

 step 91 is completed and loss is 0.0001602557604201138
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.42it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:30,  1.56it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.53it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.56it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.54it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.56it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.58it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:25,  1.63it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:24,  1.66it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:24,  1.65it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:06<00:24,  1.60it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.53it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.53it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:23,  1.50it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.52it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.52it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.52it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.54it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:20,  1.49it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.46it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:19,  1.41it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:19,  1.37it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:19,  1.36it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:18,  1.37it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:17,  1.37it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:16,  1.37it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:16,  1.37it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.40it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:14,  1.39it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.42it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.42it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.42it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:11,  1.44it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.47it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.47it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.49it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.52it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.53it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.53it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.53it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.55it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.60it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.63it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.55it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.54it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.50it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.51it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.50it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 76: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 306.59632995799984s
Training Epoch76:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch76:   1%|[34m          [0m| 1/92 [00:03<05:02,  3.32s/it]Training Epoch76:   2%|[34mâ–         [0m| 2/92 [00:06<05:01,  3.35s/it]Training Epoch76:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:56,  3.34s/it]Training Epoch76:   4%|[34mâ–         [0m| 4/92 [00:13<04:55,  3.35s/it]Training Epoch76:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:49,  3.33s/it]Training Epoch76:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:48,  3.35s/it]Training Epoch76:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.33s/it]Training Epoch76:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:40,  3.34s/it]Training Epoch76:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:38,  3.35s/it]Training Epoch76:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:36,  3.38s/it]Training Epoch76:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:32,  3.36s/it]Training Epoch76:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:27,  3.35s/it]Training Epoch76:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.33s/it]Training Epoch76:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:21,  3.35s/it]Training Epoch76:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:50<04:17,  3.35s/it]Training Epoch76:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:09,  3.29s/it]Training Epoch76:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.32s/it]Training Epoch76:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [01:00<04:06,  3.33s/it]Training Epoch76:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:03,  3.34s/it]Training Epoch76:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:01,  3.35s/it]Training Epoch76:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:10<03:57,  3.35s/it]Training Epoch76:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:50,  3.30s/it]Training Epoch76:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:48,  3.32s/it]Training Epoch76:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:20<03:45,  3.31s/it]Training Epoch76:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:40,  3.29s/it]Training Epoch76:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:37,  3.30s/it]Training Epoch76:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:35,  3.31s/it]Training Epoch76:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:31,  3.30s/it]Training Epoch76:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:28,  3.30s/it]Training Epoch76:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:22,  3.27s/it]Training Epoch76:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:19,  3.28s/it]Training Epoch76:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:17,  3.29s/it]Training Epoch76:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:14,  3.29s/it]Training Epoch76:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.31s/it]Training Epoch76:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:09,  3.32s/it]Training Epoch76:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:06,  3.33s/it]Training Epoch76:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.32s/it]Training Epoch76:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<03:00,  3.34s/it]Training Epoch76:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:57,  3.35s/it]Training Epoch76:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:53,  3.34s/it]Training Epoch76:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:49,  3.32s/it]Training Epoch76:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:44,  3.29s/it]Training Epoch76:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:41,  3.30s/it]Training Epoch76:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:38,  3.31s/it]Training Epoch76:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.33s/it]Training Epoch76:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:34,  3.35s/it]Training Epoch76:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:30,  3.35s/it]Training Epoch76:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:27,  3.34s/it]Training Epoch76:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:24,  3.36s/it]Training Epoch76:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:20,  3.36s/it]Training Epoch76:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:17,  3.35s/it]Training Epoch76:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:13,  3.34s/it]Training Epoch76:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:11,  3.36s/it]Training Epoch76:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:07,  3.37s/it]Training Epoch76:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:03<02:04,  3.37s/it]Training Epoch76:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<02:02,  3.39s/it]Training Epoch76:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:57,  3.37s/it]Training Epoch76:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:13<01:54,  3.35s/it]Training Epoch76:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:50,  3.34s/it]Training Epoch76:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:45,  3.30s/it]Training Epoch76:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:41,  3.28s/it]Training Epoch76:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:38,  3.29s/it]Training Epoch76:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:35,  3.29s/it]Training Epoch76:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:31,  3.28s/it]Training Epoch76:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:29,  3.30s/it]Training Epoch76:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:26,  3.31s/it]Training Epoch76:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:22,  3.31s/it]Training Epoch76:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:19,  3.32s/it]Training Epoch76:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:15,  3.27s/it]Training Epoch76:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:12,  3.28s/it]Training Epoch76:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:08,  3.28s/it]Training Epoch76:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:05,  3.27s/it]Training Epoch76:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:02,  3.29s/it]Training Epoch76:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:58,  3.26s/it]Training Epoch76:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:55,  3.26s/it]Training Epoch76:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:52,  3.27s/it]Training Epoch76:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.28s/it]Training Epoch76:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:45,  3.28s/it]Training Epoch76:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:42,  3.29s/it]Training Epoch76:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.30s/it]Training Epoch76:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.32s/it]Training Epoch76:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.31s/it]Training Epoch76:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:29,  3.30s/it]Training Epoch76:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.28s/it]Training Epoch76:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.30s/it]Training Epoch76:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:19,  3.26s/it]Training Epoch76:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.26s/it]Training Epoch76:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.29s/it]Training Epoch76:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:09,  3.28s/it]Training Epoch76:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.29s/it]Training Epoch76:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.30s/it]Training Epoch76: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch76: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 9.2857371782884e-05

 step 1 is completed and loss is 0.00015191976854112

 step 2 is completed and loss is 3.3735614124452695e-05

 step 3 is completed and loss is 0.00019928239635191858

 step 4 is completed and loss is 7.080630166456103e-05

 step 5 is completed and loss is 5.513247742783278e-05

 step 6 is completed and loss is 0.0005732261342927814

 step 7 is completed and loss is 5.423836046247743e-05

 step 8 is completed and loss is 8.517133392160758e-05

 step 9 is completed and loss is 4.1901068470906466e-05

 step 10 is completed and loss is 0.0006086430512368679

 step 11 is completed and loss is 0.0009469919023104012

 step 12 is completed and loss is 0.00021948572248220444

 step 13 is completed and loss is 4.54176843049936e-05

 step 14 is completed and loss is 4.607317896443419e-05

 step 15 is completed and loss is 3.838465272565372e-05

 step 16 is completed and loss is 0.00017855002079159021

 step 17 is completed and loss is 0.00018236757023259997

 step 18 is completed and loss is 4.9172595026902854e-05

 step 19 is completed and loss is 0.00017848893185146153

 step 20 is completed and loss is 6.0198686696821824e-05

 step 21 is completed and loss is 6.81257079122588e-05

 step 22 is completed and loss is 0.0007950197323225439

 step 23 is completed and loss is 0.00013189353921916336

 step 24 is completed and loss is 6.603954534512013e-05

 step 25 is completed and loss is 0.0004974184557795525

 step 26 is completed and loss is 8.588535274611786e-05

 step 27 is completed and loss is 0.0001979258086066693

 step 28 is completed and loss is 0.00012176136078778654

 step 29 is completed and loss is 8.469454769510776e-05

 step 30 is completed and loss is 0.00010412369738332927

 step 31 is completed and loss is 1.8179212929680943e-05

 step 32 is completed and loss is 8.904461719794199e-05

 step 33 is completed and loss is 7.790023664711043e-05

 step 34 is completed and loss is 6.603960355278105e-05

 step 35 is completed and loss is 0.00015931043890304863

 step 36 is completed and loss is 1.7285163266933523e-05

 step 37 is completed and loss is 6.121206388343126e-05

 step 38 is completed and loss is 0.00011318090400891379

 step 39 is completed and loss is 5.966243043076247e-05

 step 40 is completed and loss is 0.00011556627578102052

 step 41 is completed and loss is 4.32715896749869e-05

 step 42 is completed and loss is 8.05226227384992e-05

 step 43 is completed and loss is 6.0436519561335444e-05

 step 44 is completed and loss is 1.8298402210348286e-05

 step 45 is completed and loss is 0.0002567395567893982

 step 46 is completed and loss is 2.1278596250340343e-05

 step 47 is completed and loss is 6.198689516168088e-05

 step 48 is completed and loss is 0.0005344967357814312

 step 49 is completed and loss is 6.437088450184092e-05

 step 50 is completed and loss is 9.840221900958568e-05

 step 51 is completed and loss is 5.8112782426178455e-05

 step 52 is completed and loss is 0.0021631454583257437

 step 53 is completed and loss is 0.0003474835539236665

 step 54 is completed and loss is 4.5000128011452034e-05

 step 55 is completed and loss is 0.0013042101636528969

 step 56 is completed and loss is 3.367598765180446e-05

 step 57 is completed and loss is 0.0002804913674481213

 step 58 is completed and loss is 6.067470530979335e-05

 step 59 is completed and loss is 0.0004576464416459203

 step 60 is completed and loss is 9.995191066991538e-05

 step 61 is completed and loss is 5.298653195495717e-05

 step 62 is completed and loss is 7.491891301469877e-05

 step 63 is completed and loss is 0.000336152472300455

 step 64 is completed and loss is 0.0002361016522627324

 step 65 is completed and loss is 0.00011193028331035748

 step 66 is completed and loss is 0.0009400327689945698

 step 67 is completed and loss is 7.533634197898209e-05

 step 68 is completed and loss is 0.00017426848353352398

 step 69 is completed and loss is 0.00013588900037575513

 step 70 is completed and loss is 0.0001631806808291003

 step 71 is completed and loss is 0.00015692149463575333

 step 72 is completed and loss is 0.000307958252960816

 step 73 is completed and loss is 8.731693378649652e-05

 step 74 is completed and loss is 0.00011419540533097461

 step 75 is completed and loss is 0.0002733681467361748

 step 76 is completed and loss is 0.00013624670100398362

 step 77 is completed and loss is 7.78401008574292e-05

 step 78 is completed and loss is 0.00020120356930419803

 step 79 is completed and loss is 0.0008483781130053103

 step 80 is completed and loss is 0.0003007749910466373

 step 81 is completed and loss is 9.601821511751041e-05

 step 82 is completed and loss is 0.00013797335850540549

 step 83 is completed and loss is 0.00017682892212178558

 step 84 is completed and loss is 0.00010918803309323266

 step 85 is completed and loss is 0.00012265883560758084

 step 86 is completed and loss is 9.381330892210826e-05

 step 87 is completed and loss is 0.00014119267871137708

 step 88 is completed and loss is 0.0002462966076564044

 step 89 is completed and loss is 8.427695865975693e-05

 step 90 is completed and loss is 0.0006980254547670484

 step 91 is completed and loss is 0.00011246454232605174
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.38it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.44it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.48it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.50it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.44it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.45it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.48it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.50it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.50it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.49it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.48it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.49it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.49it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.51it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.55it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.54it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.52it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.55it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.54it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.54it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.52it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.56it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.55it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.57it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.57it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.56it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.57it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.60it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:11,  1.59it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.58it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.60it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:09,  1.60it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.59it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.54it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.53it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.54it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.53it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.53it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.50it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.53it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.54it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.55it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.57it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.52it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.52it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.63it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 77: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.3335262740002s
Training Epoch77:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch77:   1%|[34m          [0m| 1/92 [00:03<04:58,  3.28s/it]Training Epoch77:   2%|[34mâ–         [0m| 2/92 [00:06<04:52,  3.25s/it]Training Epoch77:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.25s/it]Training Epoch77:   4%|[34mâ–         [0m| 4/92 [00:12<04:45,  3.24s/it]Training Epoch77:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch77:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.31s/it]Training Epoch77:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:40,  3.30s/it]Training Epoch77:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.32s/it]Training Epoch77:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.32s/it]Training Epoch77:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:31,  3.31s/it]Training Epoch77:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.31s/it]Training Epoch77:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.31s/it]Training Epoch77:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:23,  3.33s/it]Training Epoch77:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.34s/it]Training Epoch77:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch77:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.30s/it]Training Epoch77:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.30s/it]Training Epoch77:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.31s/it]Training Epoch77:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:00,  3.30s/it]Training Epoch77:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:57,  3.30s/it]Training Epoch77:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:53,  3.28s/it]Training Epoch77:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.29s/it]Training Epoch77:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:46,  3.28s/it]Training Epoch77:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:42,  3.27s/it]Training Epoch77:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:39,  3.27s/it]Training Epoch77:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.28s/it]Training Epoch77:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:30,  3.24s/it]Training Epoch77:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:28,  3.26s/it]Training Epoch77:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:26,  3.28s/it]Training Epoch77:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:23,  3.29s/it]Training Epoch77:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.30s/it]Training Epoch77:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:18,  3.31s/it]Training Epoch77:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:16,  3.33s/it]Training Epoch77:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.31s/it]Training Epoch77:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:09,  3.32s/it]Training Epoch77:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:05,  3.32s/it]Training Epoch77:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:00,  3.29s/it]Training Epoch77:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.30s/it]Training Epoch77:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:56,  3.32s/it]Training Epoch77:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:53,  3.34s/it]Training Epoch77:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.32s/it]Training Epoch77:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:45,  3.31s/it]Training Epoch77:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:40,  3.28s/it]Training Epoch77:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:36,  3.26s/it]Training Epoch77:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:31,  3.23s/it]Training Epoch77:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:29,  3.24s/it]Training Epoch77:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:27,  3.27s/it]Training Epoch77:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:24,  3.28s/it]Training Epoch77:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:20,  3.28s/it]Training Epoch77:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:17,  3.28s/it]Training Epoch77:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.31s/it]Training Epoch77:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.29s/it]Training Epoch77:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.30s/it]Training Epoch77:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:05,  3.30s/it]Training Epoch77:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.30s/it]Training Epoch77:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:59,  3.31s/it]Training Epoch77:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:56,  3.33s/it]Training Epoch77:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.31s/it]Training Epoch77:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:50,  3.34s/it]Training Epoch77:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:46,  3.32s/it]Training Epoch77:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:41,  3.29s/it]Training Epoch77:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:38,  3.30s/it]Training Epoch77:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:35,  3.31s/it]Training Epoch77:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:32,  3.29s/it]Training Epoch77:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.29s/it]Training Epoch77:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.27s/it]Training Epoch77:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:21,  3.28s/it]Training Epoch77:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.31s/it]Training Epoch77:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.31s/it]Training Epoch77:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.30s/it]Training Epoch77:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:09,  3.29s/it]Training Epoch77:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.31s/it]Training Epoch77:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:03,  3.34s/it]Training Epoch77:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.33s/it]Training Epoch77:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.33s/it]Training Epoch77:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:53,  3.33s/it]Training Epoch77:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:50,  3.34s/it]Training Epoch77:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.34s/it]Training Epoch77:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:43,  3.36s/it]Training Epoch77:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:40,  3.34s/it]Training Epoch77:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.33s/it]Training Epoch77:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.33s/it]Training Epoch77:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:30,  3.34s/it]Training Epoch77:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.33s/it]Training Epoch77:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.34s/it]Training Epoch77:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.30s/it]Training Epoch77:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.31s/it]Training Epoch77:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.31s/it]Training Epoch77:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.32s/it]Training Epoch77:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.32s/it]Training Epoch77:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.29s/it]Training Epoch77: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch77: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 9.768415475264192e-05

 step 1 is completed and loss is 0.00015513820108026266

 step 2 is completed and loss is 3.510649548843503e-05

 step 3 is completed and loss is 0.0001036437606671825

 step 4 is completed and loss is 8.057997183641419e-05

 step 5 is completed and loss is 4.237797111272812e-05

 step 6 is completed and loss is 0.000363360857591033

 step 7 is completed and loss is 4.780156086781062e-05

 step 8 is completed and loss is 6.037764615030028e-05

 step 9 is completed and loss is 3.9755424950271845e-05

 step 10 is completed and loss is 0.001395990839228034

 step 11 is completed and loss is 0.0008520260453224182

 step 12 is completed and loss is 0.00023223573225550354

 step 13 is completed and loss is 6.991372356424108e-05

 step 14 is completed and loss is 4.798044392373413e-05

 step 15 is completed and loss is 3.4450891689630225e-05

 step 16 is completed and loss is 0.00017771606508176774

 step 17 is completed and loss is 0.0001489961869083345

 step 18 is completed and loss is 5.4894364438951015e-05

 step 19 is completed and loss is 0.00019696017261594534

 step 20 is completed and loss is 7.676754466956481e-05

 step 21 is completed and loss is 5.8291574532631785e-05

 step 22 is completed and loss is 0.00028126887627877295

 step 23 is completed and loss is 0.00011133427324239165

 step 24 is completed and loss is 6.174847658257931e-05

 step 25 is completed and loss is 0.00018188846297562122

 step 26 is completed and loss is 7.778025610605255e-05

 step 27 is completed and loss is 0.00014393479796126485

 step 28 is completed and loss is 0.00011788758274633437

 step 29 is completed and loss is 8.767459075897932e-05

 step 30 is completed and loss is 8.225088095059618e-05

 step 31 is completed and loss is 1.8298407667316496e-05

 step 32 is completed and loss is 7.074756285874173e-05

 step 33 is completed and loss is 9.178663458442315e-05

 step 34 is completed and loss is 0.0001002498174784705

 step 35 is completed and loss is 0.00015138310845941305

 step 36 is completed and loss is 2.0444153051357716e-05

 step 37 is completed and loss is 7.086737605277449e-05

 step 38 is completed and loss is 0.00010269264021189883

 step 39 is completed and loss is 5.674195199389942e-05

 step 40 is completed and loss is 0.00011389775318093598

 step 41 is completed and loss is 2.8073245630366728e-05

 step 42 is completed and loss is 7.062892836984247e-05

 step 43 is completed and loss is 5.4357627959689125e-05

 step 44 is completed and loss is 2.741758362390101e-05

 step 45 is completed and loss is 0.00020948518067598343

 step 46 is completed and loss is 2.396070158283692e-05

 step 47 is completed and loss is 8.254902786575258e-05

 step 48 is completed and loss is 0.00048727027024142444

 step 49 is completed and loss is 0.00010382587788626552

 step 50 is completed and loss is 8.469444583170116e-05

 step 51 is completed and loss is 6.627810944337398e-05

 step 52 is completed and loss is 0.0013867433881387115

 step 53 is completed and loss is 0.00026972588966600597

 step 54 is completed and loss is 3.927856596419588e-05

 step 55 is completed and loss is 0.001641270937398076

 step 56 is completed and loss is 3.909982478944585e-05

 step 57 is completed and loss is 0.00029133260250091553

 step 58 is completed and loss is 5.5668409913778305e-05

 step 59 is completed and loss is 0.000341445324011147

 step 60 is completed and loss is 8.999888086691499e-05

 step 61 is completed and loss is 9.160528861684725e-05

 step 62 is completed and loss is 8.856708882376552e-05

 step 63 is completed and loss is 0.00035092831240035594

 step 64 is completed and loss is 0.00025105703389272094

 step 65 is completed and loss is 7.384740456473082e-05

 step 66 is completed and loss is 0.0006239523063413799

 step 67 is completed and loss is 4.8457179218530655e-05

 step 68 is completed and loss is 0.00018934602849185467

 step 69 is completed and loss is 0.00015662740042898804

 step 70 is completed and loss is 0.00020411747391335666

 step 71 is completed and loss is 0.00022401459864340723

 step 72 is completed and loss is 0.000477409950690344

 step 73 is completed and loss is 8.284697105409577e-05

 step 74 is completed and loss is 0.00013511249562725425

 step 75 is completed and loss is 0.00018392287893220782

 step 76 is completed and loss is 0.0001425641094101593

 step 77 is completed and loss is 7.70653787185438e-05

 step 78 is completed and loss is 0.00015084740880411118

 step 79 is completed and loss is 0.0005182070308364928

 step 80 is completed and loss is 0.0002085348533000797

 step 81 is completed and loss is 8.04034061729908e-05

 step 82 is completed and loss is 0.00018105731578543782

 step 83 is completed and loss is 0.00016568537103012204

 step 84 is completed and loss is 0.00011228638322791085

 step 85 is completed and loss is 0.00014780859055463225

 step 86 is completed and loss is 0.00011062010162277147

 step 87 is completed and loss is 0.00012104913184884936

 step 88 is completed and loss is 0.0002410530869383365

 step 89 is completed and loss is 6.639676576014608e-05

 step 90 is completed and loss is 0.0004514584725257009

 step 91 is completed and loss is 0.00021769436716567725
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.48it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.53it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.48it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.50it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.52it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.53it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.53it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:27,  1.50it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.54it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.56it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:23,  1.59it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.58it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:22,  1.60it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.60it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.60it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.52it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.53it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.54it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.52it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.52it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.50it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.49it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.50it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.51it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.51it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.52it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.51it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.48it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.51it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.51it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.49it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.48it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.45it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.43it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.45it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.47it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.46it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.46it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.48it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.54it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.54it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.55it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.58it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.60it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.58it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.55it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.50it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.50it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.52it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 78: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.1500674589988s
Training Epoch78:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch78:   1%|[34m          [0m| 1/92 [00:03<05:02,  3.33s/it]Training Epoch78:   2%|[34mâ–         [0m| 2/92 [00:06<04:51,  3.23s/it]Training Epoch78:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:46,  3.22s/it]Training Epoch78:   4%|[34mâ–         [0m| 4/92 [00:12<04:42,  3.21s/it]Training Epoch78:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:42,  3.25s/it]Training Epoch78:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.27s/it]Training Epoch78:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:39,  3.29s/it]Training Epoch78:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch78:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.30s/it]Training Epoch78:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:30,  3.30s/it]Training Epoch78:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.33s/it]Training Epoch78:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:31,  3.39s/it]Training Epoch78:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:26,  3.38s/it]Training Epoch78:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:23,  3.38s/it]Training Epoch78:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:22,  3.41s/it]Training Epoch78:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:19,  3.42s/it]Training Epoch78:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:14,  3.39s/it]Training Epoch78:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [01:00<04:09,  3.37s/it]Training Epoch78:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:06,  3.38s/it]Training Epoch78:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:02,  3.37s/it]Training Epoch78:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:10<04:00,  3.38s/it]Training Epoch78:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:55,  3.36s/it]Training Epoch78:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:51,  3.35s/it]Training Epoch78:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:20<03:47,  3.35s/it]Training Epoch78:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:42,  3.31s/it]Training Epoch78:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:39,  3.32s/it]Training Epoch78:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:35,  3.32s/it]Training Epoch78:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:31,  3.31s/it]Training Epoch78:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:28,  3.31s/it]Training Epoch78:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:24,  3.30s/it]Training Epoch78:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:22,  3.32s/it]Training Epoch78:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:17,  3.29s/it]Training Epoch78:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:14,  3.30s/it]Training Epoch78:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:12,  3.31s/it]Training Epoch78:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:08,  3.30s/it]Training Epoch78:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:05,  3.31s/it]Training Epoch78:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:01,  3.30s/it]Training Epoch78:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:58,  3.30s/it]Training Epoch78:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:55,  3.32s/it]Training Epoch78:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:53,  3.33s/it]Training Epoch78:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:50,  3.33s/it]Training Epoch78:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:46,  3.33s/it]Training Epoch78:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:43,  3.33s/it]Training Epoch78:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:39,  3.33s/it]Training Epoch78:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:35,  3.30s/it]Training Epoch78:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:31,  3.30s/it]Training Epoch78:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:27,  3.28s/it]Training Epoch78:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:24,  3.28s/it]Training Epoch78:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:21,  3.29s/it]Training Epoch78:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:18,  3.29s/it]Training Epoch78:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:14,  3.28s/it]Training Epoch78:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:11,  3.29s/it]Training Epoch78:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:08,  3.29s/it]Training Epoch78:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:04,  3.28s/it]Training Epoch78:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:01,  3.28s/it]Training Epoch78:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:58,  3.29s/it]Training Epoch78:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:55,  3.29s/it]Training Epoch78:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:51,  3.29s/it]Training Epoch78:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.30s/it]Training Epoch78:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.29s/it]Training Epoch78:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:42,  3.30s/it]Training Epoch78:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:38,  3.29s/it]Training Epoch78:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:35,  3.30s/it]Training Epoch78:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:32,  3.29s/it]Training Epoch78:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:28,  3.29s/it]Training Epoch78:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:25,  3.30s/it]Training Epoch78:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.29s/it]Training Epoch78:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:18,  3.29s/it]Training Epoch78:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:15,  3.29s/it]Training Epoch78:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.29s/it]Training Epoch78:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.29s/it]Training Epoch78:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.30s/it]Training Epoch78:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.27s/it]Training Epoch78:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:58,  3.27s/it]Training Epoch78:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.30s/it]Training Epoch78:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.31s/it]Training Epoch78:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.31s/it]Training Epoch78:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.31s/it]Training Epoch78:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:42,  3.30s/it]Training Epoch78:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.31s/it]Training Epoch78:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.28s/it]Training Epoch78:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:32,  3.29s/it]Training Epoch78:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.30s/it]Training Epoch78:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.34s/it]Training Epoch78:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.39s/it]Training Epoch78:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:20,  3.34s/it]Training Epoch78:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.32s/it]Training Epoch78:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.32s/it]Training Epoch78:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.32s/it]Training Epoch78:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.33s/it]Training Epoch78:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.34s/it]Training Epoch78: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.32s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch78: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.00011091368651250377

 step 1 is completed and loss is 0.00016759283607825637

 step 2 is completed and loss is 3.9457409002352506e-05

 step 3 is completed and loss is 0.00010126014240086079

 step 4 is completed and loss is 9.106875950237736e-05

 step 5 is completed and loss is 4.6132841816870496e-05

 step 6 is completed and loss is 0.0004473963053897023

 step 7 is completed and loss is 4.60135233879555e-05

 step 8 is completed and loss is 6.16888573858887e-05

 step 9 is completed and loss is 4.845727380597964e-05

 step 10 is completed and loss is 0.0004359658050816506

 step 11 is completed and loss is 0.001275683636777103

 step 12 is completed and loss is 0.00024957043933682144

 step 13 is completed and loss is 6.496678543044254e-05

 step 14 is completed and loss is 5.668232552125119e-05

 step 15 is completed and loss is 3.969590397900902e-05

 step 16 is completed and loss is 0.00018534238915890455

 step 17 is completed and loss is 9.488507930655032e-05

 step 18 is completed and loss is 4.60732844658196e-05

 step 19 is completed and loss is 0.00024379134993068874

 step 20 is completed and loss is 4.053033626405522e-05

 step 21 is completed and loss is 6.294042395893484e-05

 step 22 is completed and loss is 0.00045745886745862663

 step 23 is completed and loss is 0.00010078625928144902

 step 24 is completed and loss is 6.40725193079561e-05

 step 25 is completed and loss is 0.00016758896526880562

 step 26 is completed and loss is 8.046256698435172e-05

 step 27 is completed and loss is 0.0001262941223103553

 step 28 is completed and loss is 0.00015894611715339124

 step 29 is completed and loss is 0.00010048834519693628

 step 30 is completed and loss is 0.00010722239676397294

 step 31 is completed and loss is 2.1040148567408323e-05

 step 32 is completed and loss is 9.071279782801867e-05

 step 33 is completed and loss is 8.761456410866231e-05

 step 34 is completed and loss is 6.454972753999755e-05

 step 35 is completed and loss is 0.00017366957035847008

 step 36 is completed and loss is 1.6450718248961493e-05

 step 37 is completed and loss is 7.02117831679061e-05

 step 38 is completed and loss is 0.0001048385602189228

 step 39 is completed and loss is 6.246357224881649e-05

 step 40 is completed and loss is 0.00011258682934567332

 step 41 is completed and loss is 4.416560841491446e-05

 step 42 is completed and loss is 7.158257358241826e-05

 step 43 is completed and loss is 5.7814519095700234e-05

 step 44 is completed and loss is 2.2232183255255222e-05

 step 45 is completed and loss is 0.0001621101691853255

 step 46 is completed and loss is 2.6702426112024114e-05

 step 47 is completed and loss is 6.353652861434966e-05

 step 48 is completed and loss is 0.0004010785196442157

 step 49 is completed and loss is 0.00011014327174052596

 step 50 is completed and loss is 7.676779932808131e-05

 step 51 is completed and loss is 5.87087961321231e-05

 step 52 is completed and loss is 0.0013680810807272792

 step 53 is completed and loss is 0.0003439076244831085

 step 54 is completed and loss is 4.2973879317287356e-05

 step 55 is completed and loss is 0.0012445526663213968

 step 56 is completed and loss is 3.689449658850208e-05

 step 57 is completed and loss is 0.00033744447864592075

 step 58 is completed and loss is 5.304614023771137e-05

 step 59 is completed and loss is 0.0004319135914556682

 step 60 is completed and loss is 9.178677282761782e-05

 step 61 is completed and loss is 7.557425851700827e-05

 step 62 is completed and loss is 8.129602065309882e-05

 step 63 is completed and loss is 0.0006753214402124286

 step 64 is completed and loss is 0.0002536172978579998

 step 65 is completed and loss is 9.285962005378678e-05

 step 66 is completed and loss is 0.000583894841838628

 step 67 is completed and loss is 5.8112305850954726e-05

 step 68 is completed and loss is 0.00017140810086857527

 step 69 is completed and loss is 0.00012969040835741907

 step 70 is completed and loss is 0.00015763842384330928

 step 71 is completed and loss is 0.00024219063925556839

 step 72 is completed and loss is 0.00039760128129273653

 step 73 is completed and loss is 8.189342770492658e-05

 step 74 is completed and loss is 0.00012224059901200235

 step 75 is completed and loss is 0.00020042891264893115

 step 76 is completed and loss is 0.00013350544031709433

 step 77 is completed and loss is 6.913893594173715e-05

 step 78 is completed and loss is 0.00020322873024269938

 step 79 is completed and loss is 0.0008269023383036256

 step 80 is completed and loss is 0.0002731295535340905

 step 81 is completed and loss is 0.00010626904258970171

 step 82 is completed and loss is 0.00013278893311508

 step 83 is completed and loss is 0.000154481953359209

 step 84 is completed and loss is 9.816288365982473e-05

 step 85 is completed and loss is 0.00012420836719684303

 step 86 is completed and loss is 9.07141511561349e-05

 step 87 is completed and loss is 0.00014208679203875363

 step 88 is completed and loss is 0.0001755121920723468

 step 89 is completed and loss is 6.329789175651968e-05

 step 90 is completed and loss is 0.0006422459264285862

 step 91 is completed and loss is 9.375170338898897e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.37it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.45it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.46it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.46it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.45it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.43it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:30,  1.42it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.43it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.44it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.49it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.55it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:24,  1.58it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:22,  1.61it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.55it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:22,  1.54it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.54it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.53it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.52it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.60it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.57it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.51it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.48it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:15,  1.45it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.44it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.44it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.44it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.48it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.46it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.46it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.45it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.44it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.45it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.43it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.45it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.47it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.45it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.47it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.45it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.49it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.50it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.51it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.50it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.52it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.53it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6000)
Epoch 79: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.0926227300006s
Training Epoch79:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch79:   1%|[34m          [0m| 1/92 [00:03<05:05,  3.36s/it]Training Epoch79:   2%|[34mâ–         [0m| 2/92 [00:06<04:59,  3.33s/it]Training Epoch79:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:55,  3.32s/it]Training Epoch79:   4%|[34mâ–         [0m| 4/92 [00:13<04:50,  3.30s/it]Training Epoch79:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:49,  3.32s/it]Training Epoch79:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:46,  3.33s/it]Training Epoch79:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch79:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch79:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:37,  3.34s/it]Training Epoch79:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:34,  3.34s/it]Training Epoch79:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:30,  3.34s/it]Training Epoch79:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:26,  3.33s/it]Training Epoch79:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.33s/it]Training Epoch79:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:21,  3.35s/it]Training Epoch79:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:16,  3.33s/it]Training Epoch79:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:11,  3.31s/it]Training Epoch79:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:09,  3.32s/it]Training Epoch79:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:07,  3.34s/it]Training Epoch79:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:05,  3.36s/it]Training Epoch79:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:03,  3.38s/it]Training Epoch79:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:10<04:00,  3.38s/it]Training Epoch79:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:57,  3.39s/it]Training Epoch79:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:51,  3.36s/it]Training Epoch79:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:20<03:50,  3.39s/it]Training Epoch79:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:45,  3.37s/it]Training Epoch79:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:27<03:42,  3.38s/it]Training Epoch79:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:38,  3.36s/it]Training Epoch79:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:33,  3.34s/it]Training Epoch79:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.32s/it]Training Epoch79:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:40<03:24,  3.30s/it]Training Epoch79:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:22,  3.32s/it]Training Epoch79:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:17,  3.30s/it]Training Epoch79:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:50<03:14,  3.29s/it]Training Epoch79:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:10,  3.28s/it]Training Epoch79:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:07,  3.29s/it]Training Epoch79:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:01,  3.25s/it]Training Epoch79:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:00,  3.28s/it]Training Epoch79:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:57,  3.28s/it]Training Epoch79:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:54,  3.29s/it]Training Epoch79:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:49,  3.27s/it]Training Epoch79:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:46,  3.26s/it]Training Epoch79:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:43,  3.26s/it]Training Epoch79:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:39,  3.26s/it]Training Epoch79:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:36,  3.27s/it]Training Epoch79:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:34,  3.28s/it]Training Epoch79:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:32,  3.31s/it]Training Epoch79:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:30,  3.33s/it]Training Epoch79:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:25,  3.31s/it]Training Epoch79:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:21,  3.30s/it]Training Epoch79:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.29s/it]Training Epoch79:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:15,  3.30s/it]Training Epoch79:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:11,  3.28s/it]Training Epoch79:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:08,  3.30s/it]Training Epoch79:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:05,  3.29s/it]Training Epoch79:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:01,  3.28s/it]Training Epoch79:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:58,  3.29s/it]Training Epoch79:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:56,  3.32s/it]Training Epoch79:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.32s/it]Training Epoch79:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.32s/it]Training Epoch79:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:46,  3.33s/it]Training Epoch79:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:42,  3.29s/it]Training Epoch79:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:38,  3.27s/it]Training Epoch79:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:34,  3.27s/it]Training Epoch79:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:32,  3.31s/it]Training Epoch79:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.32s/it]Training Epoch79:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.34s/it]Training Epoch79:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:22,  3.31s/it]Training Epoch79:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.33s/it]Training Epoch79:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:15,  3.27s/it]Training Epoch79:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:13,  3.32s/it]Training Epoch79:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.33s/it]Training Epoch79:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.31s/it]Training Epoch79:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:03,  3.32s/it]Training Epoch79:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.32s/it]Training Epoch79:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.32s/it]Training Epoch79:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:53,  3.31s/it]Training Epoch79:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.32s/it]Training Epoch79:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.30s/it]Training Epoch79:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.34s/it]Training Epoch79:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:40,  3.34s/it]Training Epoch79:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.35s/it]Training Epoch79:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.35s/it]Training Epoch79:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:30,  3.35s/it]Training Epoch79:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.33s/it]Training Epoch79:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.33s/it]Training Epoch79:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:20,  3.34s/it]Training Epoch79:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.33s/it]Training Epoch79:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.32s/it]Training Epoch79:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:10,  3.34s/it]Training Epoch79:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.35s/it]Training Epoch79:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.34s/it]Training Epoch79: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.35s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch79: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 8.808976417640224e-05

 step 1 is completed and loss is 0.0001746841735439375

 step 2 is completed and loss is 3.0934323149267584e-05

 step 3 is completed and loss is 9.190342098008841e-05

 step 4 is completed and loss is 7.062742952257395e-05

 step 5 is completed and loss is 4.9828016926767305e-05

 step 6 is completed and loss is 0.0008812493178993464

 step 7 is completed and loss is 5.525155575014651e-05

 step 8 is completed and loss is 9.303842671215534e-05

 step 9 is completed and loss is 4.446389357326552e-05

 step 10 is completed and loss is 0.0005604088655672967

 step 11 is completed and loss is 0.0019486263627186418

 step 12 is completed and loss is 0.00023551465710625052

 step 13 is completed and loss is 5.98412734689191e-05

 step 14 is completed and loss is 4.6490524255204946e-05

 step 15 is completed and loss is 4.410646579344757e-05

 step 16 is completed and loss is 0.0001749751972965896

 step 17 is completed and loss is 0.0001000699630822055

 step 18 is completed and loss is 4.708653432317078e-05

 step 19 is completed and loss is 0.000190467486390844

 step 20 is completed and loss is 4.982819518772885e-05

 step 21 is completed and loss is 7.217813981696963e-05

 step 22 is completed and loss is 0.0005182019667699933

 step 23 is completed and loss is 0.00010263293370371684

 step 24 is completed and loss is 6.329806637950242e-05

 step 25 is completed and loss is 0.00017372443107888103

 step 26 is completed and loss is 4.964927938999608e-05

 step 27 is completed and loss is 0.00015615177107974887

 step 28 is completed and loss is 0.0001390425895806402

 step 29 is completed and loss is 9.947518992703408e-05

 step 30 is completed and loss is 0.0001025141536956653

 step 31 is completed and loss is 1.4960626685933676e-05

 step 32 is completed and loss is 8.558713307138532e-05

 step 33 is completed and loss is 7.325132173718885e-05

 step 34 is completed and loss is 9.369351027999073e-05

 step 35 is completed and loss is 0.00016985725960694253

 step 36 is completed and loss is 1.6987132767098956e-05

 step 37 is completed and loss is 6.097368896007538e-05

 step 38 is completed and loss is 8.213176624849439e-05

 step 39 is completed and loss is 5.4894288041396067e-05

 step 40 is completed and loss is 0.00013243270223028958

 step 41 is completed and loss is 4.386766522657126e-05

 step 42 is completed and loss is 6.544376083184034e-05

 step 43 is completed and loss is 6.818502151872963e-05

 step 44 is completed and loss is 2.461627263983246e-05

 step 45 is completed and loss is 0.00017092905181925744

 step 46 is completed and loss is 2.247067095595412e-05

 step 47 is completed and loss is 6.991379632381722e-05

 step 48 is completed and loss is 0.0005496761295944452

 step 49 is completed and loss is 8.803216041997075e-05

 step 50 is completed and loss is 8.588650962337852e-05

 step 51 is completed and loss is 6.276171188801527e-05

 step 52 is completed and loss is 0.0021235779859125614

 step 53 is completed and loss is 0.0003664259274955839

 step 54 is completed and loss is 4.3689105950761586e-05

 step 55 is completed and loss is 0.0012912736274302006

 step 56 is completed and loss is 4.261640788172372e-05

 step 57 is completed and loss is 0.0002645272179506719

 step 58 is completed and loss is 6.353540811687708e-05

 step 59 is completed and loss is 0.00023074797354638577

 step 60 is completed and loss is 9.500522719463333e-05

 step 61 is completed and loss is 6.156869494589046e-05

 step 62 is completed and loss is 0.00010865053627640009

 step 63 is completed and loss is 0.00037356693064793944

 step 64 is completed and loss is 0.0003500633465591818

 step 65 is completed and loss is 9.232302545569837e-05

 step 66 is completed and loss is 0.0004320422885939479

 step 67 is completed and loss is 5.793351010652259e-05

 step 68 is completed and loss is 0.00016294470697175711

 step 69 is completed and loss is 0.00015233705926220864

 step 70 is completed and loss is 0.0001947633281815797

 step 71 is completed and loss is 0.00020256696734577417

 step 72 is completed and loss is 0.0004077885241713375

 step 73 is completed and loss is 8.827040437608957e-05

 step 74 is completed and loss is 9.959392627933994e-05

 step 75 is completed and loss is 0.00022539921337738633

 step 76 is completed and loss is 0.0001527549175079912

 step 77 is completed and loss is 7.313210517168045e-05

 step 78 is completed and loss is 0.00024201811174862087

 step 79 is completed and loss is 0.0008445957209914923

 step 80 is completed and loss is 0.0002060913247987628

 step 81 is completed and loss is 9.762728586792946e-05

 step 82 is completed and loss is 0.00021204169024713337

 step 83 is completed and loss is 0.00018982026085723191

 step 84 is completed and loss is 7.867453678045422e-05

 step 85 is completed and loss is 0.00013422065239865333

 step 86 is completed and loss is 9.464769391342998e-05

 step 87 is completed and loss is 0.00015644889208488166

 step 88 is completed and loss is 0.0002303303626831621

 step 89 is completed and loss is 6.937696889508516e-05

 step 90 is completed and loss is 0.0006143965292721987

 step 91 is completed and loss is 0.00012289332516957074
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:33,  1.45it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.47it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:30,  1.54it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:29,  1.56it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.54it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.55it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.55it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:26,  1.59it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.58it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.58it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:24,  1.57it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.56it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.56it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:23,  1.56it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.56it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.55it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.59it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.62it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:18,  1.62it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.58it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.56it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:17,  1.51it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.50it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.50it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:14,  1.49it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.52it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.50it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.50it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.51it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.53it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.60it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.59it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.58it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.56it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.49it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:06,  1.46it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.40it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.41it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:04,  1.40it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.42it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.46it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:02,  1.46it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.46it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.52it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.57it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 80: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.67742129999897s
Training Epoch80:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch80:   1%|[34m          [0m| 1/92 [00:03<04:56,  3.26s/it]Training Epoch80:   2%|[34mâ–         [0m| 2/92 [00:06<04:58,  3.31s/it]Training Epoch80:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:57,  3.34s/it]Training Epoch80:   4%|[34mâ–         [0m| 4/92 [00:13<04:53,  3.34s/it]Training Epoch80:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:50,  3.34s/it]Training Epoch80:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:45,  3.32s/it]Training Epoch80:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:42,  3.33s/it]Training Epoch80:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.28s/it]Training Epoch80:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.31s/it]Training Epoch80:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:30,  3.30s/it]Training Epoch80:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:27,  3.30s/it]Training Epoch80:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.30s/it]Training Epoch80:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:20,  3.30s/it]Training Epoch80:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.30s/it]Training Epoch80:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:17,  3.34s/it]Training Epoch80:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.30s/it]Training Epoch80:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.30s/it]Training Epoch80:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:03,  3.29s/it]Training Epoch80:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:01,  3.31s/it]Training Epoch80:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.31s/it]Training Epoch80:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.30s/it]Training Epoch80:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:52,  3.31s/it]Training Epoch80:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:48,  3.32s/it]Training Epoch80:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.31s/it]Training Epoch80:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.29s/it]Training Epoch80:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:38,  3.32s/it]Training Epoch80:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.30s/it]Training Epoch80:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:32,  3.32s/it]Training Epoch80:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.33s/it]Training Epoch80:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.31s/it]Training Epoch80:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:22,  3.32s/it]Training Epoch80:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:19,  3.32s/it]Training Epoch80:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:15,  3.32s/it]Training Epoch80:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.31s/it]Training Epoch80:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:06,  3.27s/it]Training Epoch80:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:01,  3.24s/it]Training Epoch80:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<02:58,  3.25s/it]Training Epoch80:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:56,  3.27s/it]Training Epoch80:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.28s/it]Training Epoch80:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:49,  3.26s/it]Training Epoch80:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:47,  3.29s/it]Training Epoch80:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:43,  3.27s/it]Training Epoch80:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:41,  3.30s/it]Training Epoch80:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:39,  3.32s/it]Training Epoch80:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:35,  3.31s/it]Training Epoch80:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:32,  3.31s/it]Training Epoch80:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.32s/it]Training Epoch80:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.30s/it]Training Epoch80:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:21,  3.30s/it]Training Epoch80:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.29s/it]Training Epoch80:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.31s/it]Training Epoch80:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:13,  3.35s/it]Training Epoch80:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:10,  3.35s/it]Training Epoch80:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:08,  3.38s/it]Training Epoch80:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:04,  3.37s/it]Training Epoch80:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.33s/it]Training Epoch80:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:57,  3.37s/it]Training Epoch80:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:55,  3.41s/it]Training Epoch80:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:51,  3.38s/it]Training Epoch80:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:47,  3.36s/it]Training Epoch80:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:43,  3.35s/it]Training Epoch80:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:40,  3.36s/it]Training Epoch80:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.33s/it]Training Epoch80:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:33,  3.35s/it]Training Epoch80:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:30,  3.34s/it]Training Epoch80:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:27,  3.37s/it]Training Epoch80:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:25,  3.43s/it]Training Epoch80:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:21,  3.41s/it]Training Epoch80:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:17,  3.38s/it]Training Epoch80:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:14,  3.37s/it]Training Epoch80:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:10,  3.36s/it]Training Epoch80:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.33s/it]Training Epoch80:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:03,  3.34s/it]Training Epoch80:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.29s/it]Training Epoch80:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:55,  3.29s/it]Training Epoch80:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:53,  3.33s/it]Training Epoch80:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.32s/it]Training Epoch80:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:46,  3.31s/it]Training Epoch80:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:43,  3.31s/it]Training Epoch80:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.33s/it]Training Epoch80:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:29<00:36,  3.33s/it]Training Epoch80:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.30s/it]Training Epoch80:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:30,  3.34s/it]Training Epoch80:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:27,  3.39s/it]Training Epoch80:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.39s/it]Training Epoch80:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:20,  3.36s/it]Training Epoch80:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.36s/it]Training Epoch80:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:52<00:13,  3.35s/it]Training Epoch80:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:09,  3.33s/it]Training Epoch80:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.29s/it]Training Epoch80:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.31s/it]Training Epoch80: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.34s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch80: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 9.988927195081487e-05

 step 1 is completed and loss is 0.0002377310738665983

 step 2 is completed and loss is 4.017270839540288e-05

 step 3 is completed and loss is 8.403684478253126e-05

 step 4 is completed and loss is 9.392954234499484e-05

 step 5 is completed and loss is 5.0245304009877145e-05

 step 6 is completed and loss is 0.0004015985468868166

 step 7 is completed and loss is 6.633700104430318e-05

 step 8 is completed and loss is 7.533741882070899e-05

 step 9 is completed and loss is 4.76824861834757e-05

 step 10 is completed and loss is 0.0006351399933919311

 step 11 is completed and loss is 0.0012836349196732044

 step 12 is completed and loss is 0.00023604869784321636

 step 13 is completed and loss is 5.1139359129592776e-05

 step 14 is completed and loss is 5.4834672482684255e-05

 step 15 is completed and loss is 4.8993817472364753e-05

 step 16 is completed and loss is 0.00018760799139272422

 step 17 is completed and loss is 0.00012963138578925282

 step 18 is completed and loss is 5.304655496729538e-05

 step 19 is completed and loss is 0.00013189157471060753

 step 20 is completed and loss is 4.225879820296541e-05

 step 21 is completed and loss is 6.603943620575592e-05

 step 22 is completed and loss is 0.00023575926024932414

 step 23 is completed and loss is 8.856807107804343e-05

 step 24 is completed and loss is 5.864910053787753e-05

 step 25 is completed and loss is 0.00022097528562881052

 step 26 is completed and loss is 8.189296931959689e-05

 step 27 is completed and loss is 0.00023117964155972004

 step 28 is completed and loss is 0.00021960270532872528

 step 29 is completed and loss is 8.415812044404447e-05

 step 30 is completed and loss is 9.339554526377469e-05

 step 31 is completed and loss is 1.7642774764681235e-05

 step 32 is completed and loss is 7.855481089791283e-05

 step 33 is completed and loss is 6.186756945680827e-05

 step 34 is completed and loss is 7.289375207619742e-05

 step 35 is completed and loss is 0.00018046429613605142

 step 36 is completed and loss is 1.5258661733241752e-05

 step 37 is completed and loss is 7.533741882070899e-05

 step 38 is completed and loss is 6.9138863182161e-05

 step 39 is completed and loss is 5.3165771532803774e-05

 step 40 is completed and loss is 0.00011157349945278838

 step 41 is completed and loss is 3.1172618037089705e-05

 step 42 is completed and loss is 6.7887369368691e-05

 step 43 is completed and loss is 5.6920212955446914e-05

 step 44 is completed and loss is 2.1934178221272305e-05

 step 45 is completed and loss is 0.0001603823620826006

 step 46 is completed and loss is 2.7000474801752716e-05

 step 47 is completed and loss is 9.983203199226409e-05

 step 48 is completed and loss is 0.00038749922532588243

 step 49 is completed and loss is 8.886655268725008e-05

 step 50 is completed and loss is 8.874715422280133e-05

 step 51 is completed and loss is 6.192730506882071e-05

 step 52 is completed and loss is 0.0015457312110811472

 step 53 is completed and loss is 0.0003593919682316482

 step 54 is completed and loss is 3.713291516760364e-05

 step 55 is completed and loss is 0.0018289261497557163

 step 56 is completed and loss is 5.346387479221448e-05

 step 57 is completed and loss is 0.000295862031634897

 step 58 is completed and loss is 6.556225707754493e-05

 step 59 is completed and loss is 0.00021365232532843947

 step 60 is completed and loss is 0.00010567311255726963

 step 61 is completed and loss is 6.0615071561187506e-05

 step 62 is completed and loss is 8.117710240185261e-05

 step 63 is completed and loss is 0.0003101796028204262

 step 64 is completed and loss is 0.00027017976390197873

 step 65 is completed and loss is 8.457514923065901e-05

 step 66 is completed and loss is 0.0005917015369050205

 step 67 is completed and loss is 6.270134326769039e-05

 step 68 is completed and loss is 0.0001753399264998734

 step 69 is completed and loss is 0.00016383756883442402

 step 70 is completed and loss is 0.00015042960876598954

 step 71 is completed and loss is 0.00014363280206453055

 step 72 is completed and loss is 0.0003624001983553171

 step 73 is completed and loss is 9.202528599416837e-05

 step 74 is completed and loss is 0.00011526855814736336

 step 75 is completed and loss is 0.00017891704919748008

 step 76 is completed and loss is 0.00013874984870199114

 step 77 is completed and loss is 8.761428762227297e-05

 step 78 is completed and loss is 0.00021109342924319208

 step 79 is completed and loss is 0.0008235815912485123

 step 80 is completed and loss is 0.0002948773908428848

 step 81 is completed and loss is 0.0001051364597515203

 step 82 is completed and loss is 0.00021788074809592217

 step 83 is completed and loss is 0.00016979753854684532

 step 84 is completed and loss is 9.238214261131361e-05

 step 85 is completed and loss is 0.0001662831346038729

 step 86 is completed and loss is 9.142934868577868e-05

 step 87 is completed and loss is 0.00016133469762280583

 step 88 is completed and loss is 0.00017956519150175154

 step 89 is completed and loss is 5.262917329673655e-05

 step 90 is completed and loss is 0.0005592403467744589

 step 91 is completed and loss is 0.00012944848276674747
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.37it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.41it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.44it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.40it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.41it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:31,  1.41it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:30,  1.42it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.42it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:29,  1.41it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:29,  1.36it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:29,  1.33it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:27,  1.36it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:26,  1.41it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:25,  1.44it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.45it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.47it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.46it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.46it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:21,  1.46it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:14<00:20,  1.48it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.48it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:19,  1.43it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:16<00:18,  1.44it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:18,  1.42it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.42it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:18<00:16,  1.42it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:16,  1.43it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:15,  1.43it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:20<00:15,  1.40it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:21<00:14,  1.42it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:13,  1.44it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:12,  1.45it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:23<00:11,  1.43it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.47it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:09,  1.53it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:08,  1.57it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.54it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.57it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.60it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:05,  1.58it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.60it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.57it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:03,  1.54it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.48it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.48it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:32<00:01,  1.55it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.55it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.52it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.47it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.46it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 81: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 306.12852526999995s
Training Epoch81:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch81:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.29s/it]Training Epoch81:   2%|[34mâ–         [0m| 2/92 [00:06<04:49,  3.22s/it]Training Epoch81:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:47,  3.23s/it]Training Epoch81:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.27s/it]Training Epoch81:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:47,  3.31s/it]Training Epoch81:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:46,  3.33s/it]Training Epoch81:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:42,  3.32s/it]Training Epoch81:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.32s/it]Training Epoch81:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:39,  3.36s/it]Training Epoch81:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:35,  3.36s/it]Training Epoch81:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:31,  3.36s/it]Training Epoch81:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:31,  3.39s/it]Training Epoch81:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:25,  3.36s/it]Training Epoch81:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:23,  3.37s/it]Training Epoch81:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:50<04:18,  3.36s/it]Training Epoch81:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:15,  3.36s/it]Training Epoch81:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:11,  3.35s/it]Training Epoch81:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [01:00<04:08,  3.36s/it]Training Epoch81:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:02,  3.33s/it]Training Epoch81:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:59,  3.33s/it]Training Epoch81:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:10<03:55,  3.32s/it]Training Epoch81:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:51,  3.31s/it]Training Epoch81:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:47,  3.30s/it]Training Epoch81:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.31s/it]Training Epoch81:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:44,  3.35s/it]Training Epoch81:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:43,  3.39s/it]Training Epoch81:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:39,  3.38s/it]Training Epoch81:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:36,  3.38s/it]Training Epoch81:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:30,  3.35s/it]Training Epoch81:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:40<03:25,  3.31s/it]Training Epoch81:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:22,  3.32s/it]Training Epoch81:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:18,  3.31s/it]Training Epoch81:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:50<03:17,  3.34s/it]Training Epoch81:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:13,  3.34s/it]Training Epoch81:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:08,  3.31s/it]Training Epoch81:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:04,  3.29s/it]Training Epoch81:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:01,  3.30s/it]Training Epoch81:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:58,  3.31s/it]Training Epoch81:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:55,  3.31s/it]Training Epoch81:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:52,  3.33s/it]Training Epoch81:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:50,  3.34s/it]Training Epoch81:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:20<02:48,  3.36s/it]Training Epoch81:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:44,  3.36s/it]Training Epoch81:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:40,  3.35s/it]Training Epoch81:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:30<02:37,  3.36s/it]Training Epoch81:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:34,  3.37s/it]Training Epoch81:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:32,  3.39s/it]Training Epoch81:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:40<02:27,  3.36s/it]Training Epoch81:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:23,  3.33s/it]Training Epoch81:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:20,  3.34s/it]Training Epoch81:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:50<02:17,  3.35s/it]Training Epoch81:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:13,  3.35s/it]Training Epoch81:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:10,  3.35s/it]Training Epoch81:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [03:00<02:07,  3.36s/it]Training Epoch81:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:03<02:04,  3.36s/it]Training Epoch81:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:07<02:01,  3.37s/it]Training Epoch81:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:10<01:56,  3.34s/it]Training Epoch81:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:13<01:53,  3.35s/it]Training Epoch81:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:17<01:51,  3.38s/it]Training Epoch81:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:20<01:47,  3.36s/it]Training Epoch81:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:43,  3.34s/it]Training Epoch81:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:27<01:40,  3.34s/it]Training Epoch81:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:30<01:36,  3.34s/it]Training Epoch81:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:33<01:33,  3.34s/it]Training Epoch81:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:37<01:30,  3.35s/it]Training Epoch81:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:40<01:26,  3.34s/it]Training Epoch81:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:43<01:24,  3.36s/it]Training Epoch81:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:47<01:20,  3.37s/it]Training Epoch81:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:50<01:17,  3.38s/it]Training Epoch81:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:54<01:14,  3.37s/it]Training Epoch81:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:57<01:10,  3.36s/it]Training Epoch81:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [04:00<01:07,  3.36s/it]Training Epoch81:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:04<01:04,  3.37s/it]Training Epoch81:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:07<01:00,  3.37s/it]Training Epoch81:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:10<00:56,  3.35s/it]Training Epoch81:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:14<00:53,  3.37s/it]Training Epoch81:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:17<00:50,  3.38s/it]Training Epoch81:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:21<00:47,  3.39s/it]Training Epoch81:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:24<00:43,  3.38s/it]Training Epoch81:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:27<00:40,  3.36s/it]Training Epoch81:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:31<00:36,  3.35s/it]Training Epoch81:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:34<00:33,  3.35s/it]Training Epoch81:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:37<00:30,  3.34s/it]Training Epoch81:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:40<00:26,  3.33s/it]Training Epoch81:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:44<00:23,  3.33s/it]Training Epoch81:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:47<00:19,  3.32s/it]Training Epoch81:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:50<00:16,  3.33s/it]Training Epoch81:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:54<00:13,  3.35s/it]Training Epoch81:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:57<00:10,  3.38s/it]Training Epoch81:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [05:01<00:06,  3.39s/it]Training Epoch81:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:04<00:03,  3.39s/it]Training Epoch81: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:07<00:00,  3.36s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch81: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:07<00:00,  3.35s/it]

 step 0 is completed and loss is 0.00012205772509332746

 step 1 is completed and loss is 0.00014143130101729184

 step 2 is completed and loss is 3.790783375734463e-05

 step 3 is completed and loss is 9.959117596736178e-05

 step 4 is completed and loss is 9.017498814500868e-05

 step 5 is completed and loss is 4.851692938245833e-05

 step 6 is completed and loss is 0.0005941224517300725

 step 7 is completed and loss is 5.775488534709439e-05

 step 8 is completed and loss is 0.00010316933185094967

 step 9 is completed and loss is 3.8146201404742897e-05

 step 10 is completed and loss is 0.0005900724790990353

 step 11 is completed and loss is 0.002364311832934618

 step 12 is completed and loss is 0.00021573204139713198

 step 13 is completed and loss is 6.800657865824178e-05

 step 14 is completed and loss is 4.535807966021821e-05

 step 15 is completed and loss is 3.6000557884108275e-05

 step 16 is completed and loss is 0.0001939834182849154

 step 17 is completed and loss is 9.583967039361596e-05

 step 18 is completed and loss is 4.523881943896413e-05

 step 19 is completed and loss is 0.00011711296247085556

 step 20 is completed and loss is 4.8278550821123645e-05

 step 21 is completed and loss is 7.766166527289897e-05

 step 22 is completed and loss is 0.00042810593731701374

 step 23 is completed and loss is 0.00011228775838389993

 step 24 is completed and loss is 6.925811612745747e-05

 step 25 is completed and loss is 0.00021102737809997052

 step 26 is completed and loss is 7.515837933169678e-05

 step 27 is completed and loss is 0.00017343423678539693

 step 28 is completed and loss is 0.0001236679236171767

 step 29 is completed and loss is 9.393250365974382e-05

 step 30 is completed and loss is 0.000120810407679528

 step 31 is completed and loss is 2.104014129145071e-05

 step 32 is completed and loss is 0.00010692249634303153

 step 33 is completed and loss is 8.082044951152056e-05

 step 34 is completed and loss is 7.921108044683933e-05

 step 35 is completed and loss is 0.0001721212174743414

 step 36 is completed and loss is 1.502024315414019e-05

 step 37 is completed and loss is 7.235732482513413e-05

 step 38 is completed and loss is 6.973494600970298e-05

 step 39 is completed and loss is 5.0245431339135394e-05

 step 40 is completed and loss is 0.000104600636404939

 step 41 is completed and loss is 3.701346577145159e-05

 step 42 is completed and loss is 6.87813590047881e-05

 step 43 is completed and loss is 6.0853755712741986e-05

 step 44 is completed and loss is 2.5927492970367894e-05

 step 45 is completed and loss is 0.00016425654757767916

 step 46 is completed and loss is 2.2530237401952036e-05

 step 47 is completed and loss is 8.719778270460665e-05

 step 48 is completed and loss is 0.00046069108066149056

 step 49 is completed and loss is 6.913898687344044e-05

 step 50 is completed and loss is 8.576731488574296e-05

 step 51 is completed and loss is 5.370233702706173e-05

 step 52 is completed and loss is 0.0014723737258464098

 step 53 is completed and loss is 0.00025858439039438963

 step 54 is completed and loss is 4.053016164107248e-05

 step 55 is completed and loss is 0.0011848947033286095

 step 56 is completed and loss is 3.778861355385743e-05

 step 57 is completed and loss is 0.00019994146714452654

 step 58 is completed and loss is 6.359505641739815e-05

 step 59 is completed and loss is 0.00016258393588941544

 step 60 is completed and loss is 9.04159969650209e-05

 step 61 is completed and loss is 6.276058411458507e-05

 step 62 is completed and loss is 8.648113725939766e-05

 step 63 is completed and loss is 0.00024881347781047225

 step 64 is completed and loss is 0.00025266417651437223

 step 65 is completed and loss is 9.816398960538208e-05

 step 66 is completed and loss is 0.0004921345389448106

 step 67 is completed and loss is 5.292701825965196e-05

 step 68 is completed and loss is 0.0002087732427753508

 step 69 is completed and loss is 0.0001551378663862124

 step 70 is completed and loss is 0.00016473194409627467

 step 71 is completed and loss is 0.00021567591466009617

 step 72 is completed and loss is 0.0004972924361936748

 step 73 is completed and loss is 8.30853678053245e-05

 step 74 is completed and loss is 0.0001035871246131137

 step 75 is completed and loss is 0.00020537612726911902

 step 76 is completed and loss is 0.00012259918730705976

 step 77 is completed and loss is 9.035622497322038e-05

 step 78 is completed and loss is 0.00018976051069330424

 step 79 is completed and loss is 0.0005960132111795247

 step 80 is completed and loss is 0.0002850469318218529

 step 81 is completed and loss is 0.00012057210551574826

 step 82 is completed and loss is 0.00020786830282304436

 step 83 is completed and loss is 0.00018332454783376306

 step 84 is completed and loss is 0.00015233253361657262

 step 85 is completed and loss is 0.00013958434283267707

 step 86 is completed and loss is 8.797258487902582e-05

 step 87 is completed and loss is 0.00014417227066587657

 step 88 is completed and loss is 0.0002335465542273596

 step 89 is completed and loss is 5.8351142797619104e-05

 step 90 is completed and loss is 0.0006387388566508889

 step 91 is completed and loss is 9.512293036095798e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.39it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.40it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.39it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:33,  1.39it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.43it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.45it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.43it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.43it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.42it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:27,  1.45it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:27,  1.44it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.43it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.51it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:22,  1.57it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:22,  1.58it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.48it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.46it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:21,  1.45it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.43it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:20,  1.39it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:19,  1.45it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.48it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:16,  1.54it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:16,  1.50it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.48it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.45it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:15,  1.41it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:15,  1.38it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:14,  1.37it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:13,  1.39it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:12,  1.48it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.50it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.50it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.50it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.54it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.53it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.50it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.52it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.50it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.49it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.50it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.52it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.51it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.48it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.50it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.47it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.47it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.47it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 82: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 308.18012094200094s
Training Epoch82:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch82:   1%|[34m          [0m| 1/92 [00:03<05:05,  3.36s/it]Training Epoch82:   2%|[34mâ–         [0m| 2/92 [00:06<05:02,  3.36s/it]Training Epoch82:   3%|[34mâ–Ž         [0m| 3/92 [00:10<05:02,  3.40s/it]Training Epoch82:   4%|[34mâ–         [0m| 4/92 [00:13<04:53,  3.34s/it]Training Epoch82:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:50,  3.34s/it]Training Epoch82:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:44,  3.31s/it]Training Epoch82:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.34s/it]Training Epoch82:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:40,  3.33s/it]Training Epoch82:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:35,  3.32s/it]Training Epoch82:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:32,  3.32s/it]Training Epoch82:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.29s/it]Training Epoch82:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.30s/it]Training Epoch82:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:20,  3.30s/it]Training Epoch82:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:19,  3.33s/it]Training Epoch82:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:50<04:18,  3.36s/it]Training Epoch82:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:14,  3.35s/it]Training Epoch82:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:12,  3.36s/it]Training Epoch82:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [01:00<04:06,  3.33s/it]Training Epoch82:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:04,  3.34s/it]Training Epoch82:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.31s/it]Training Epoch82:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:56,  3.33s/it]Training Epoch82:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:54,  3.35s/it]Training Epoch82:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:50,  3.34s/it]Training Epoch82:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:20<03:47,  3.34s/it]Training Epoch82:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:43,  3.34s/it]Training Epoch82:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:38,  3.31s/it]Training Epoch82:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:35,  3.31s/it]Training Epoch82:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:31,  3.31s/it]Training Epoch82:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:28,  3.31s/it]Training Epoch82:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:24,  3.30s/it]Training Epoch82:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:20,  3.29s/it]Training Epoch82:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:17,  3.29s/it]Training Epoch82:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:14,  3.30s/it]Training Epoch82:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:11,  3.30s/it]Training Epoch82:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:07,  3.30s/it]Training Epoch82:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:04,  3.30s/it]Training Epoch82:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:00,  3.29s/it]Training Epoch82:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:57,  3.28s/it]Training Epoch82:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:54,  3.30s/it]Training Epoch82:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:50,  3.28s/it]Training Epoch82:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:49,  3.32s/it]Training Epoch82:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.32s/it]Training Epoch82:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:43,  3.33s/it]Training Epoch82:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:40,  3.35s/it]Training Epoch82:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.32s/it]Training Epoch82:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.33s/it]Training Epoch82:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:28,  3.31s/it]Training Epoch82:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:25,  3.30s/it]Training Epoch82:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:21,  3.29s/it]Training Epoch82:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.29s/it]Training Epoch82:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:15,  3.31s/it]Training Epoch82:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:12,  3.31s/it]Training Epoch82:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:10,  3.34s/it]Training Epoch82:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:06,  3.33s/it]Training Epoch82:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:03,  3.35s/it]Training Epoch82:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<02:00,  3.36s/it]Training Epoch82:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:57,  3.37s/it]Training Epoch82:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:54,  3.37s/it]Training Epoch82:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:50,  3.36s/it]Training Epoch82:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:47,  3.35s/it]Training Epoch82:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:44,  3.37s/it]Training Epoch82:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:39,  3.33s/it]Training Epoch82:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:35,  3.30s/it]Training Epoch82:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:32,  3.30s/it]Training Epoch82:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.31s/it]Training Epoch82:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:26,  3.33s/it]Training Epoch82:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:23,  3.32s/it]Training Epoch82:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:19,  3.31s/it]Training Epoch82:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:15,  3.29s/it]Training Epoch82:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:12,  3.28s/it]Training Epoch82:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.31s/it]Training Epoch82:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.31s/it]Training Epoch82:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:02,  3.30s/it]Training Epoch82:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.30s/it]Training Epoch82:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:55,  3.29s/it]Training Epoch82:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:52,  3.29s/it]Training Epoch82:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:48,  3.26s/it]Training Epoch82:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:45,  3.28s/it]Training Epoch82:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:42,  3.30s/it]Training Epoch82:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.31s/it]Training Epoch82:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.34s/it]Training Epoch82:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.33s/it]Training Epoch82:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:29,  3.33s/it]Training Epoch82:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.36s/it]Training Epoch82:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.38s/it]Training Epoch82:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:20,  3.36s/it]Training Epoch82:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.34s/it]Training Epoch82:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:52<00:13,  3.34s/it]Training Epoch82:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:10,  3.34s/it]Training Epoch82:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.34s/it]Training Epoch82:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.30s/it]Training Epoch82: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch82: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 9.285723353968933e-05

 step 1 is completed and loss is 0.00022688682656735182

 step 2 is completed and loss is 4.118595097679645e-05

 step 3 is completed and loss is 0.00010155771451536566

 step 4 is completed and loss is 8.928108582040295e-05

 step 5 is completed and loss is 4.374883428681642e-05

 step 6 is completed and loss is 0.0004867602256126702

 step 7 is completed and loss is 4.7086341510294005e-05

 step 8 is completed and loss is 6.997322634560987e-05

 step 9 is completed and loss is 5.0602749979589134e-05

 step 10 is completed and loss is 0.0002492764906492084

 step 11 is completed and loss is 0.0006689397851005197

 step 12 is completed and loss is 0.00023020854860078543

 step 13 is completed and loss is 6.592055433429778e-05

 step 14 is completed and loss is 4.821897891815752e-05

 step 15 is completed and loss is 4.0411134250462055e-05

 step 16 is completed and loss is 0.00016162813699338585

 step 17 is completed and loss is 0.00016169068112503737

 step 18 is completed and loss is 4.684810119215399e-05

 step 19 is completed and loss is 0.0002244878705823794

 step 20 is completed and loss is 5.4000269301468506e-05

 step 21 is completed and loss is 7.640965486643836e-05

 step 22 is completed and loss is 0.00031969670089893043

 step 23 is completed and loss is 9.279953519580886e-05

 step 24 is completed and loss is 6.884079630253837e-05

 step 25 is completed and loss is 0.00011455201456556097

 step 26 is completed and loss is 7.104602991603315e-05

 step 27 is completed and loss is 9.959431190509349e-05

 step 28 is completed and loss is 0.00014523923164233565

 step 29 is completed and loss is 8.260861795861274e-05

 step 30 is completed and loss is 9.810403571464121e-05

 step 31 is completed and loss is 1.5973893823684193e-05

 step 32 is completed and loss is 8.117700053844601e-05

 step 33 is completed and loss is 8.576710388297215e-05

 step 34 is completed and loss is 8.499217801727355e-05

 step 35 is completed and loss is 0.00014977325918152928

 step 36 is completed and loss is 1.686795258137863e-05

 step 37 is completed and loss is 6.90195884089917e-05

 step 38 is completed and loss is 0.00011812741286121309

 step 39 is completed and loss is 5.0424219807609916e-05

 step 40 is completed and loss is 0.00010275312524754554

 step 41 is completed and loss is 4.088753485120833e-05

 step 42 is completed and loss is 6.627810216741636e-05

 step 43 is completed and loss is 8.630228694528341e-05

 step 44 is completed and loss is 2.1814990759594366e-05

 step 45 is completed and loss is 0.00022175790218170732

 step 46 is completed and loss is 1.9848108422593214e-05

 step 47 is completed and loss is 6.031808152329177e-05

 step 48 is completed and loss is 0.0006330402684397995

 step 49 is completed and loss is 8.815131877781823e-05

 step 50 is completed and loss is 9.131009574048221e-05

 step 51 is completed and loss is 7.045017991913483e-05

 step 52 is completed and loss is 0.001122695510275662

 step 53 is completed and loss is 0.0002741975476965308

 step 54 is completed and loss is 3.993415884906426e-05

 step 55 is completed and loss is 0.0010973288444802165

 step 56 is completed and loss is 3.886139893438667e-05

 step 57 is completed and loss is 0.00031361254514195025

 step 58 is completed and loss is 7.092563464539126e-05

 step 59 is completed and loss is 0.00025058817118406296

 step 60 is completed and loss is 8.397931378567591e-05

 step 61 is completed and loss is 7.617002847837284e-05

 step 62 is completed and loss is 8.111730858217925e-05

 step 63 is completed and loss is 0.0004996046191081405

 step 64 is completed and loss is 0.00033249001717194915

 step 65 is completed and loss is 0.00010311057849321514

 step 66 is completed and loss is 0.0002083480212604627

 step 67 is completed and loss is 8.33816739032045e-05

 step 68 is completed and loss is 0.000183684634976089

 step 69 is completed and loss is 0.00011574485688470304

 step 70 is completed and loss is 0.00014858126814942807

 step 71 is completed and loss is 0.00024052074877545238

 step 72 is completed and loss is 0.00039689033292233944

 step 73 is completed and loss is 8.34430247778073e-05

 step 74 is completed and loss is 0.00011455284402472898

 step 75 is completed and loss is 0.000165806311997585

 step 76 is completed and loss is 0.00013314773968886584

 step 77 is completed and loss is 8.177377458196133e-05

 step 78 is completed and loss is 0.0001664614537730813

 step 79 is completed and loss is 0.0007810890092514455

 step 80 is completed and loss is 0.00036435259971767664

 step 81 is completed and loss is 9.518399747321382e-05

 step 82 is completed and loss is 0.00012998745660297573

 step 83 is completed and loss is 0.0001359472080366686

 step 84 is completed and loss is 0.00018921642913483083

 step 85 is completed and loss is 0.00013636612857226282

 step 86 is completed and loss is 0.00011717586312443018

 step 87 is completed and loss is 0.0001404773211106658

 step 88 is completed and loss is 0.00019058919860981405

 step 89 is completed and loss is 6.019845750415698e-05

 step 90 is completed and loss is 0.0005097517278045416

 step 91 is completed and loss is 8.314383012475446e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.37it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.44it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.49it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.47it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.47it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.49it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.48it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.48it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.51it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.53it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:24,  1.53it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.51it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.52it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.53it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.53it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.51it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.48it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.54it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.56it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.54it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.55it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.53it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.52it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.49it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.50it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:15,  1.47it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.49it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.52it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.50it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.50it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.50it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.50it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.56it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.54it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.52it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.51it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.50it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.48it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.50it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.49it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.48it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.48it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.49it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.49it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.50it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.53it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.54it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.53it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 83: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.75041596200026s
Training Epoch83:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch83:   1%|[34m          [0m| 1/92 [00:03<05:02,  3.33s/it]Training Epoch83:   2%|[34mâ–         [0m| 2/92 [00:06<04:54,  3.28s/it]Training Epoch83:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:48,  3.25s/it]Training Epoch83:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.28s/it]Training Epoch83:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.29s/it]Training Epoch83:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.31s/it]Training Epoch83:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:42,  3.32s/it]Training Epoch83:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:35,  3.28s/it]Training Epoch83:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:32,  3.28s/it]Training Epoch83:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:31,  3.31s/it]Training Epoch83:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch83:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch83:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.29s/it]Training Epoch83:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.31s/it]Training Epoch83:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.30s/it]Training Epoch83:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:08,  3.26s/it]Training Epoch83:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:05,  3.27s/it]Training Epoch83:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:02,  3.28s/it]Training Epoch83:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:58,  3.26s/it]Training Epoch83:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:53,  3.24s/it]Training Epoch83:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:50,  3.25s/it]Training Epoch83:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch83:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:46,  3.28s/it]Training Epoch83:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:46,  3.33s/it]Training Epoch83:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.33s/it]Training Epoch83:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:39,  3.32s/it]Training Epoch83:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:35,  3.31s/it]Training Epoch83:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.28s/it]Training Epoch83:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:28,  3.31s/it]Training Epoch83:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:27,  3.34s/it]Training Epoch83:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:24,  3.36s/it]Training Epoch83:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:22,  3.37s/it]Training Epoch83:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:18,  3.36s/it]Training Epoch83:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:14,  3.35s/it]Training Epoch83:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.31s/it]Training Epoch83:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:04,  3.30s/it]Training Epoch83:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.31s/it]Training Epoch83:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.30s/it]Training Epoch83:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.30s/it]Training Epoch83:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.31s/it]Training Epoch83:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:47,  3.29s/it]Training Epoch83:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:44,  3.28s/it]Training Epoch83:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:42,  3.31s/it]Training Epoch83:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.30s/it]Training Epoch83:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:34,  3.29s/it]Training Epoch83:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:31,  3.30s/it]Training Epoch83:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:28,  3.31s/it]Training Epoch83:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.30s/it]Training Epoch83:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.31s/it]Training Epoch83:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.29s/it]Training Epoch83:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.30s/it]Training Epoch83:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:12,  3.31s/it]Training Epoch83:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:09,  3.31s/it]Training Epoch83:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.31s/it]Training Epoch83:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.29s/it]Training Epoch83:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:58,  3.30s/it]Training Epoch83:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:55,  3.31s/it]Training Epoch83:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.30s/it]Training Epoch83:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:48,  3.29s/it]Training Epoch83:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:44,  3.27s/it]Training Epoch83:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.29s/it]Training Epoch83:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:38,  3.30s/it]Training Epoch83:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.32s/it]Training Epoch83:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.29s/it]Training Epoch83:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.30s/it]Training Epoch83:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:26,  3.32s/it]Training Epoch83:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:23,  3.32s/it]Training Epoch83:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.33s/it]Training Epoch83:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:15,  3.30s/it]Training Epoch83:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:11,  3.26s/it]Training Epoch83:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:08,  3.28s/it]Training Epoch83:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.30s/it]Training Epoch83:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.31s/it]Training Epoch83:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.32s/it]Training Epoch83:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.32s/it]Training Epoch83:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:53,  3.33s/it]Training Epoch83:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.33s/it]Training Epoch83:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.33s/it]Training Epoch83:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.35s/it]Training Epoch83:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:40,  3.34s/it]Training Epoch83:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.34s/it]Training Epoch83:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.32s/it]Training Epoch83:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.31s/it]Training Epoch83:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.33s/it]Training Epoch83:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.33s/it]Training Epoch83:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.33s/it]Training Epoch83:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.30s/it]Training Epoch83:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.29s/it]Training Epoch83:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.31s/it]Training Epoch83:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.34s/it]Training Epoch83:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.35s/it]Training Epoch83: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch83: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 7.873270806157961e-05

 step 1 is completed and loss is 0.00021019794803578407

 step 2 is completed and loss is 4.410645487951115e-05

 step 3 is completed and loss is 9.595614392310381e-05

 step 4 is completed and loss is 6.711117748636752e-05

 step 5 is completed and loss is 4.5358072384260595e-05

 step 6 is completed and loss is 0.000627518689725548

 step 7 is completed and loss is 5.769509880337864e-05

 step 8 is completed and loss is 8.242944022640586e-05

 step 9 is completed and loss is 4.112629176233895e-05

 step 10 is completed and loss is 0.0003819387638941407

 step 11 is completed and loss is 0.0011837136698886752

 step 12 is completed and loss is 0.0002129867352778092

 step 13 is completed and loss is 5.745721864514053e-05

 step 14 is completed and loss is 5.000697274226695e-05

 step 15 is completed and loss is 3.8980677345534787e-05

 step 16 is completed and loss is 0.0002010141615755856

 step 17 is completed and loss is 0.0001378550659865141

 step 18 is completed and loss is 3.844415186904371e-05

 step 19 is completed and loss is 0.0001740810985211283

 step 20 is completed and loss is 5.6682350987102836e-05

 step 21 is completed and loss is 5.3404277423396707e-05

 step 22 is completed and loss is 0.000417620234657079

 step 23 is completed and loss is 0.00011008320143446326

 step 24 is completed and loss is 6.538406887557358e-05

 step 25 is completed and loss is 0.0002890127943828702

 step 26 is completed and loss is 4.941094812238589e-05

 step 27 is completed and loss is 0.00017504315474070609

 step 28 is completed and loss is 0.00015787222946528345

 step 29 is completed and loss is 9.107174992095679e-05

 step 30 is completed and loss is 0.00016031823179218918

 step 31 is completed and loss is 1.6569927538512275e-05

 step 32 is completed and loss is 0.00014976915554143488

 step 33 is completed and loss is 0.00012015538231935352

 step 34 is completed and loss is 7.223805005196482e-05

 step 35 is completed and loss is 0.00022491345589514822

 step 36 is completed and loss is 2.0980605768272653e-05

 step 37 is completed and loss is 5.3583069529850036e-05

 step 38 is completed and loss is 0.00010185800783801824

 step 39 is completed and loss is 6.752973422408104e-05

 step 40 is completed and loss is 0.00011675865243887529

 step 41 is completed and loss is 3.9337886846624315e-05

 step 42 is completed and loss is 6.550335820065811e-05

 step 43 is completed and loss is 6.448925705626607e-05

 step 44 is completed and loss is 2.6165937015321106e-05

 step 45 is completed and loss is 0.00025399093283340335

 step 46 is completed and loss is 1.9669294488267042e-05

 step 47 is completed and loss is 8.517138485331088e-05

 step 48 is completed and loss is 0.0003215013712178916

 step 49 is completed and loss is 6.514573760796338e-05

 step 50 is completed and loss is 8.147602784447372e-05

 step 51 is completed and loss is 5.793396121589467e-05

 step 52 is completed and loss is 0.0014473256887868047

 step 53 is completed and loss is 0.00023612368386238813

 step 54 is completed and loss is 4.362941035651602e-05

 step 55 is completed and loss is 0.0016564379911869764

 step 56 is completed and loss is 4.356996214482933e-05

 step 57 is completed and loss is 0.00020113372011110187

 step 58 is completed and loss is 6.562146882060915e-05

 step 59 is completed and loss is 0.0003950482059735805

 step 60 is completed and loss is 0.00011640106095001101

 step 61 is completed and loss is 5.537032848224044e-05

 step 62 is completed and loss is 8.117677498375997e-05

 step 63 is completed and loss is 0.0006622036453336477

 step 64 is completed and loss is 0.00015876405814196914

 step 65 is completed and loss is 8.332363358931616e-05

 step 66 is completed and loss is 0.0009172678110189736

 step 67 is completed and loss is 5.94233424635604e-05

 step 68 is completed and loss is 0.00019566266564652324

 step 69 is completed and loss is 0.00018034475215245038

 step 70 is completed and loss is 0.00016014250286389142

 step 71 is completed and loss is 0.0001879097690107301

 step 72 is completed and loss is 0.0004763348260894418

 step 73 is completed and loss is 8.725735824555159e-05

 step 74 is completed and loss is 0.00011008340516127646

 step 75 is completed and loss is 0.00016568717546761036

 step 76 is completed and loss is 0.00014166990877129138

 step 77 is completed and loss is 6.83044345350936e-05

 step 78 is completed and loss is 0.00017015665071085095

 step 79 is completed and loss is 0.00085177191067487

 step 80 is completed and loss is 0.0003178802435286343

 step 81 is completed and loss is 0.00010430214751977473

 step 82 is completed and loss is 0.00017920995014719665

 step 83 is completed and loss is 0.00016872581909410655

 step 84 is completed and loss is 0.00013302525621838868

 step 85 is completed and loss is 0.00011014331539627165

 step 86 is completed and loss is 0.00010525626566959545

 step 87 is completed and loss is 0.00014953536447137594

 step 88 is completed and loss is 0.00019750006322283298

 step 89 is completed and loss is 6.305950955720618e-05

 step 90 is completed and loss is 0.0008987078326754272

 step 91 is completed and loss is 0.00010287026088917628
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.32it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.42it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.46it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.47it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.48it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:27,  1.56it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.54it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:26,  1.53it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.53it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.56it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:25,  1.52it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.52it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.47it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.48it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.50it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.55it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.52it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.53it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.60it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.60it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.62it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:16,  1.60it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.58it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.52it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.49it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.49it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.45it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:14,  1.42it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.47it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.50it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.51it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.56it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.55it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.54it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.58it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.60it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:04,  1.64it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.60it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.61it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.55it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.53it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.53it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.53it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.51it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 84: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.5013973259993s
Training Epoch84:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch84:   1%|[34m          [0m| 1/92 [00:03<05:12,  3.44s/it]Training Epoch84:   2%|[34mâ–         [0m| 2/92 [00:06<05:01,  3.35s/it]Training Epoch84:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:53,  3.30s/it]Training Epoch84:   4%|[34mâ–         [0m| 4/92 [00:13<04:51,  3.31s/it]Training Epoch84:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:48,  3.31s/it]Training Epoch84:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.27s/it]Training Epoch84:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:39,  3.29s/it]Training Epoch84:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.31s/it]Training Epoch84:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.31s/it]Training Epoch84:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:34,  3.34s/it]Training Epoch84:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:27,  3.30s/it]Training Epoch84:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.30s/it]Training Epoch84:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.34s/it]Training Epoch84:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:16,  3.28s/it]Training Epoch84:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.30s/it]Training Epoch84:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:14,  3.35s/it]Training Epoch84:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:09,  3.33s/it]Training Epoch84:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:10,  3.38s/it]Training Epoch84:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:06,  3.38s/it]Training Epoch84:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:02,  3.37s/it]Training Epoch84:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.32s/it]Training Epoch84:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:53,  3.33s/it]Training Epoch84:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:51,  3.36s/it]Training Epoch84:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:48,  3.36s/it]Training Epoch84:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:43,  3.34s/it]Training Epoch84:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:42,  3.36s/it]Training Epoch84:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:42,  3.42s/it]Training Epoch84:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:35,  3.37s/it]Training Epoch84:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:34,  3.41s/it]Training Epoch84:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:40<03:30,  3.39s/it]Training Epoch84:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:23,  3.33s/it]Training Epoch84:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:21,  3.36s/it]Training Epoch84:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:50<03:18,  3.36s/it]Training Epoch84:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:12,  3.32s/it]Training Epoch84:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:08,  3.30s/it]Training Epoch84:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [02:00<03:08,  3.36s/it]Training Epoch84:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:06,  3.38s/it]Training Epoch84:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:07<03:01,  3.36s/it]Training Epoch84:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:10<02:56,  3.34s/it]Training Epoch84:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:54,  3.36s/it]Training Epoch84:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:17<02:51,  3.35s/it]Training Epoch84:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:20<02:46,  3.32s/it]Training Epoch84:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:41,  3.30s/it]Training Epoch84:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:38,  3.31s/it]Training Epoch84:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:30<02:34,  3.28s/it]Training Epoch84:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:29,  3.24s/it]Training Epoch84:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:26,  3.26s/it]Training Epoch84:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:25,  3.30s/it]Training Epoch84:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:21,  3.29s/it]Training Epoch84:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:19,  3.33s/it]Training Epoch84:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:50<02:17,  3.35s/it]Training Epoch84:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:15,  3.38s/it]Training Epoch84:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:11,  3.38s/it]Training Epoch84:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [03:00<02:07,  3.37s/it]Training Epoch84:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:03<02:04,  3.38s/it]Training Epoch84:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:07<02:01,  3.39s/it]Training Epoch84:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:10<01:58,  3.39s/it]Training Epoch84:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:13<01:54,  3.36s/it]Training Epoch84:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:17<01:51,  3.37s/it]Training Epoch84:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:20<01:48,  3.38s/it]Training Epoch84:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:43,  3.34s/it]Training Epoch84:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:27<01:41,  3.37s/it]Training Epoch84:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:30<01:38,  3.39s/it]Training Epoch84:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:34<01:35,  3.41s/it]Training Epoch84:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:37<01:31,  3.39s/it]Training Epoch84:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:40<01:27,  3.38s/it]Training Epoch84:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:44<01:24,  3.39s/it]Training Epoch84:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:47<01:21,  3.39s/it]Training Epoch84:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:50<01:17,  3.38s/it]Training Epoch84:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:54<01:14,  3.36s/it]Training Epoch84:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:57<01:10,  3.36s/it]Training Epoch84:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [04:00<01:07,  3.36s/it]Training Epoch84:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:04<01:03,  3.32s/it]Training Epoch84:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:07<01:00,  3.34s/it]Training Epoch84:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:11<00:57,  3.37s/it]Training Epoch84:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:14<00:53,  3.33s/it]Training Epoch84:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:17<00:50,  3.35s/it]Training Epoch84:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:21<00:46,  3.34s/it]Training Epoch84:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:24<00:43,  3.34s/it]Training Epoch84:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:27<00:40,  3.38s/it]Training Epoch84:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:31<00:36,  3.34s/it]Training Epoch84:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:34<00:33,  3.34s/it]Training Epoch84:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:37<00:30,  3.36s/it]Training Epoch84:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:41<00:27,  3.42s/it]Training Epoch84:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:44<00:23,  3.42s/it]Training Epoch84:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:48<00:20,  3.40s/it]Training Epoch84:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:51<00:16,  3.39s/it]Training Epoch84:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:54<00:13,  3.38s/it]Training Epoch84:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:58<00:10,  3.36s/it]Training Epoch84:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [05:01<00:06,  3.40s/it]Training Epoch84:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:05<00:03,  3.39s/it]Training Epoch84: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:08<00:00,  3.37s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch84: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:08<00:00,  3.35s/it]

 step 0 is completed and loss is 0.00013475051673594862

 step 1 is completed and loss is 0.00019458775932434946

 step 2 is completed and loss is 4.273557715350762e-05

 step 3 is completed and loss is 0.00010835201101144776

 step 4 is completed and loss is 7.086570985848084e-05

 step 5 is completed and loss is 6.693341856589541e-05

 step 6 is completed and loss is 0.0005987034528516233

 step 7 is completed and loss is 4.9708782171364874e-05

 step 8 is completed and loss is 8.821030496619642e-05

 step 9 is completed and loss is 4.6430719521595165e-05

 step 10 is completed and loss is 0.0008729120600037277

 step 11 is completed and loss is 0.0007550865993835032

 step 12 is completed and loss is 0.0002126914623659104

 step 13 is completed and loss is 6.204650708241388e-05

 step 14 is completed and loss is 4.905333844362758e-05

 step 15 is completed and loss is 3.9219088648678735e-05

 step 16 is completed and loss is 0.0002850787132047117

 step 17 is completed and loss is 0.00012939116277266294

 step 18 is completed and loss is 4.780162635142915e-05

 step 19 is completed and loss is 0.0001531057059764862

 step 20 is completed and loss is 5.656314897350967e-05

 step 21 is completed and loss is 6.371521158143878e-05

 step 22 is completed and loss is 0.000488197518279776

 step 23 is completed and loss is 0.00011550626368261874

 step 24 is completed and loss is 6.4311214373447e-05

 step 25 is completed and loss is 0.00017086499428842217

 step 26 is completed and loss is 7.462167559424415e-05

 step 27 is completed and loss is 0.00020328880054876208

 step 28 is completed and loss is 0.00010334717080695555

 step 29 is completed and loss is 8.856852218741551e-05

 step 30 is completed and loss is 0.00010251440107822418

 step 31 is completed and loss is 1.8298391296411864e-05

 step 32 is completed and loss is 0.00011425274715293199

 step 33 is completed and loss is 8.010542660485953e-05

 step 34 is completed and loss is 8.97601421456784e-05

 step 35 is completed and loss is 0.00015883168089203537

 step 36 is completed and loss is 1.7165941244456917e-05

 step 37 is completed and loss is 6.294044578680769e-05

 step 38 is completed and loss is 7.897292380221188e-05

 step 39 is completed and loss is 5.227183646638878e-05

 step 40 is completed and loss is 0.00011497070227051154

 step 41 is completed and loss is 3.844395178020932e-05

 step 42 is completed and loss is 6.562256021425128e-05

 step 43 is completed and loss is 5.4774893214926124e-05

 step 44 is completed and loss is 2.1636171368299983e-05

 step 45 is completed and loss is 0.0001677116670180112

 step 46 is completed and loss is 2.068256253551226e-05

 step 47 is completed and loss is 6.562250200659037e-05

 step 48 is completed and loss is 0.00040007801726460457

 step 49 is completed and loss is 7.49798200558871e-05

 step 50 is completed and loss is 7.575460767839104e-05

 step 51 is completed and loss is 5.203348700888455e-05

 step 52 is completed and loss is 0.0013150387676432729

 step 53 is completed and loss is 0.0003067829820793122

 step 54 is completed and loss is 3.898048453265801e-05

 step 55 is completed and loss is 0.001019646180793643

 step 56 is completed and loss is 4.4881191570311785e-05

 step 57 is completed and loss is 0.00019475643057376146

 step 58 is completed and loss is 6.0376736655598506e-05

 step 59 is completed and loss is 0.00027055080863647163

 step 60 is completed and loss is 0.00011121587886009365

 step 61 is completed and loss is 0.00012241523654665798

 step 62 is completed and loss is 8.308426913572475e-05

 step 63 is completed and loss is 0.0005667755613103509

 step 64 is completed and loss is 0.0005276523879729211

 step 65 is completed and loss is 8.326410170411691e-05

 step 66 is completed and loss is 0.00055447913473472

 step 67 is completed and loss is 5.787377813248895e-05

 step 68 is completed and loss is 0.0002576372353360057

 step 69 is completed and loss is 0.00012700910156127065

 step 70 is completed and loss is 0.0001653851941227913

 step 71 is completed and loss is 0.00015728057769592851

 step 72 is completed and loss is 0.0004621608240995556

 step 73 is completed and loss is 7.581421232316643e-05

 step 74 is completed and loss is 0.00011437389184720814

 step 75 is completed and loss is 0.0002225983771495521

 step 76 is completed and loss is 0.0001302869786741212

 step 77 is completed and loss is 6.419180135708302e-05

 step 78 is completed and loss is 0.0002445868158247322

 step 79 is completed and loss is 0.0007503234664909542

 step 80 is completed and loss is 0.0003254465409554541

 step 81 is completed and loss is 8.344277739524841e-05

 step 82 is completed and loss is 0.00016431213589385152

 step 83 is completed and loss is 0.00017045240383595228

 step 84 is completed and loss is 0.00010299018322257325

 step 85 is completed and loss is 0.00014232576359063387

 step 86 is completed and loss is 0.00011276562872808427

 step 87 is completed and loss is 0.00014071584155317396

 step 88 is completed and loss is 0.00022967453696765006

 step 89 is completed and loss is 6.842352013336495e-05

 step 90 is completed and loss is 0.0013372334651648998

 step 91 is completed and loss is 0.0001284941245103255
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.40it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.42it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.51it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.51it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:29,  1.51it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.49it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.50it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.50it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.46it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:27,  1.42it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.42it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:26,  1.42it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:25,  1.40it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.40it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:24,  1.39it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:23,  1.40it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.39it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:21,  1.45it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.46it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:20,  1.44it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:19,  1.45it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.45it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.46it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:16,  1.54it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.56it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.51it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:14,  1.49it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.48it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.44it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:13,  1.43it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:12,  1.44it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.46it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:11,  1.42it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:10,  1.42it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.45it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:09,  1.44it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:08,  1.42it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:27<00:08,  1.37it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:07,  1.39it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:06,  1.35it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:29<00:05,  1.38it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:05,  1.37it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:04,  1.39it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:31<00:03,  1.39it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:32<00:02,  1.39it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:32<00:02,  1.36it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:33<00:01,  1.33it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:34<00:00,  1.37it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.40it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.43it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 85: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 308.7126678179993s
Training Epoch85:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch85:   1%|[34m          [0m| 1/92 [00:03<05:12,  3.43s/it]Training Epoch85:   2%|[34mâ–         [0m| 2/92 [00:06<05:09,  3.44s/it]Training Epoch85:   3%|[34mâ–Ž         [0m| 3/92 [00:10<05:00,  3.37s/it]Training Epoch85:   4%|[34mâ–         [0m| 4/92 [00:13<04:57,  3.38s/it]Training Epoch85:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:53,  3.37s/it]Training Epoch85:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:50,  3.38s/it]Training Epoch85:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:48,  3.39s/it]Training Epoch85:   9%|[34mâ–Š         [0m| 8/92 [00:27<04:44,  3.38s/it]Training Epoch85:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:40,  3.38s/it]Training Epoch85:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.34s/it]Training Epoch85:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:37<04:30,  3.33s/it]Training Epoch85:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:26,  3.33s/it]Training Epoch85:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:24,  3.35s/it]Training Epoch85:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:47<04:21,  3.35s/it]Training Epoch85:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:50<04:16,  3.33s/it]Training Epoch85:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:11,  3.30s/it]Training Epoch85:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.30s/it]Training Epoch85:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [01:00<04:05,  3.32s/it]Training Epoch85:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:04,  3.35s/it]Training Epoch85:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:59,  3.33s/it]Training Epoch85:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:10<03:55,  3.32s/it]Training Epoch85:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:52,  3.31s/it]Training Epoch85:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:48,  3.32s/it]Training Epoch85:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:20<03:46,  3.33s/it]Training Epoch85:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:44,  3.34s/it]Training Epoch85:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:37,  3.30s/it]Training Epoch85:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:33,  3.28s/it]Training Epoch85:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:30,  3.29s/it]Training Epoch85:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:28,  3.30s/it]Training Epoch85:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:40<03:25,  3.32s/it]Training Epoch85:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:21,  3.30s/it]Training Epoch85:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:18,  3.31s/it]Training Epoch85:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:14,  3.30s/it]Training Epoch85:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:11,  3.30s/it]Training Epoch85:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:09,  3.32s/it]Training Epoch85:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:05,  3.32s/it]Training Epoch85:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:04,  3.35s/it]Training Epoch85:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<03:01,  3.35s/it]Training Epoch85:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:10<02:57,  3.34s/it]Training Epoch85:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:52,  3.32s/it]Training Epoch85:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:50,  3.35s/it]Training Epoch85:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:20<02:46,  3.33s/it]Training Epoch85:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:42,  3.31s/it]Training Epoch85:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:38,  3.30s/it]Training Epoch85:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.32s/it]Training Epoch85:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:32,  3.32s/it]Training Epoch85:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:30,  3.34s/it]Training Epoch85:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:27,  3.34s/it]Training Epoch85:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:24,  3.36s/it]Training Epoch85:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:20,  3.35s/it]Training Epoch85:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:50<02:17,  3.35s/it]Training Epoch85:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:14,  3.36s/it]Training Epoch85:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:12,  3.39s/it]Training Epoch85:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [03:00<02:07,  3.37s/it]Training Epoch85:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:03<02:04,  3.36s/it]Training Epoch85:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<02:00,  3.35s/it]Training Epoch85:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:10<01:57,  3.36s/it]Training Epoch85:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:13<01:53,  3.35s/it]Training Epoch85:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:17<01:51,  3.37s/it]Training Epoch85:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:20<01:46,  3.32s/it]Training Epoch85:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:43,  3.35s/it]Training Epoch85:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:39,  3.33s/it]Training Epoch85:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:30<01:35,  3.28s/it]Training Epoch85:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:33<01:32,  3.30s/it]Training Epoch85:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:28,  3.29s/it]Training Epoch85:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:25,  3.29s/it]Training Epoch85:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:43<01:22,  3.32s/it]Training Epoch85:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:19,  3.33s/it]Training Epoch85:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:50<01:16,  3.34s/it]Training Epoch85:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:53<01:13,  3.34s/it]Training Epoch85:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:56<01:10,  3.34s/it]Training Epoch85:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [04:00<01:06,  3.35s/it]Training Epoch85:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:03<01:03,  3.36s/it]Training Epoch85:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:06<01:00,  3.37s/it]Training Epoch85:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:10<00:57,  3.37s/it]Training Epoch85:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:13<00:53,  3.35s/it]Training Epoch85:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:17<00:50,  3.37s/it]Training Epoch85:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:20<00:46,  3.35s/it]Training Epoch85:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:23<00:43,  3.35s/it]Training Epoch85:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:27<00:40,  3.36s/it]Training Epoch85:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:30<00:36,  3.34s/it]Training Epoch85:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:33<00:33,  3.34s/it]Training Epoch85:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:37<00:30,  3.36s/it]Training Epoch85:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:40<00:27,  3.39s/it]Training Epoch85:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:43<00:23,  3.39s/it]Training Epoch85:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:47<00:20,  3.39s/it]Training Epoch85:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:50<00:16,  3.34s/it]Training Epoch85:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:53<00:13,  3.34s/it]Training Epoch85:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:57<00:10,  3.38s/it]Training Epoch85:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [05:00<00:06,  3.37s/it]Training Epoch85:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:04<00:03,  3.38s/it]Training Epoch85: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:07<00:00,  3.38s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch85: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:07<00:00,  3.34s/it]

 step 0 is completed and loss is 7.634920621057972e-05

 step 1 is completed and loss is 0.0002480403345543891

 step 2 is completed and loss is 4.172237095190212e-05

 step 3 is completed and loss is 0.00013290347123984247

 step 4 is completed and loss is 7.152141188271344e-05

 step 5 is completed and loss is 4.5477307139663026e-05

 step 6 is completed and loss is 0.0008364333771169186

 step 7 is completed and loss is 6.341648258967325e-05

 step 8 is completed and loss is 6.70527369948104e-05

 step 9 is completed and loss is 3.2543568522669375e-05

 step 10 is completed and loss is 0.0008407813147641718

 step 11 is completed and loss is 0.0014224917395040393

 step 12 is completed and loss is 0.00027036151732318103

 step 13 is completed and loss is 5.137787957210094e-05

 step 14 is completed and loss is 4.66096680611372e-05

 step 15 is completed and loss is 3.957670196541585e-05

 step 16 is completed and loss is 0.0003252879250794649

 step 17 is completed and loss is 0.00011306191299809143

 step 18 is completed and loss is 4.666933818953112e-05

 step 19 is completed and loss is 0.00020339631009846926

 step 20 is completed and loss is 4.8993802920449525e-05

 step 21 is completed and loss is 6.347680755425245e-05

 step 22 is completed and loss is 0.000367590255336836

 step 23 is completed and loss is 9.72697016550228e-05

 step 24 is completed and loss is 6.520534225273877e-05

 step 25 is completed and loss is 0.00019285273447167128

 step 26 is completed and loss is 6.842336733825505e-05

 step 27 is completed and loss is 0.0001976867497432977

 step 28 is completed and loss is 0.00015548896044492722

 step 29 is completed and loss is 7.223821012303233e-05

 step 30 is completed and loss is 9.703087562229484e-05

 step 31 is completed and loss is 1.889444683911279e-05

 step 32 is completed and loss is 0.00012039086868753657

 step 33 is completed and loss is 8.004576375242323e-05

 step 34 is completed and loss is 6.729130836902186e-05

 step 35 is completed and loss is 0.00019166793208569288

 step 36 is completed and loss is 1.4185792679199949e-05

 step 37 is completed and loss is 5.3702329751104116e-05

 step 38 is completed and loss is 9.142904309555888e-05

 step 39 is completed and loss is 5.203338514547795e-05

 step 40 is completed and loss is 0.0001230760244652629

 step 41 is completed and loss is 4.726479892269708e-05

 step 42 is completed and loss is 6.443054007831961e-05

 step 43 is completed and loss is 5.012592373532243e-05

 step 44 is completed and loss is 2.2470590920420364e-05

 step 45 is completed and loss is 0.00024595073773525655

 step 46 is completed and loss is 2.3424307073582895e-05

 step 47 is completed and loss is 7.31321852072142e-05

 step 48 is completed and loss is 0.0005137640982866287

 step 49 is completed and loss is 7.849617395550013e-05

 step 50 is completed and loss is 9.125038923230022e-05

 step 51 is completed and loss is 5.155659164302051e-05

 step 52 is completed and loss is 0.0018040459835901856

 step 53 is completed and loss is 0.00037023553159087896

 step 54 is completed and loss is 3.832478978438303e-05

 step 55 is completed and loss is 0.0007117440109141171

 step 56 is completed and loss is 4.8397760110674426e-05

 step 57 is completed and loss is 0.0002107260952470824

 step 58 is completed and loss is 6.615780876018107e-05

 step 59 is completed and loss is 0.000250290147960186

 step 60 is completed and loss is 9.476662671659142e-05

 step 61 is completed and loss is 6.311829201877117e-05

 step 62 is completed and loss is 9.136804874287918e-05

 step 63 is completed and loss is 0.00021347793517634273

 step 64 is completed and loss is 0.0001641887065488845

 step 65 is completed and loss is 9.60177494562231e-05

 step 66 is completed and loss is 0.0003759314713533968

 step 67 is completed and loss is 6.156902963994071e-05

 step 68 is completed and loss is 0.00017015502089634538

 step 69 is completed and loss is 0.00013779595610685647

 step 70 is completed and loss is 0.00016234724898822606

 step 71 is completed and loss is 0.00022098037879914045

 step 72 is completed and loss is 0.0005631521344184875

 step 73 is completed and loss is 9.160812624031678e-05

 step 74 is completed and loss is 0.00010090509022120386

 step 75 is completed and loss is 0.00022468381212092936

 step 76 is completed and loss is 0.00014524560538120568

 step 77 is completed and loss is 9.095214772969484e-05

 step 78 is completed and loss is 0.00015728414291515946

 step 79 is completed and loss is 0.001138028921559453

 step 80 is completed and loss is 0.00034742202842608094

 step 81 is completed and loss is 0.00011359898780938238

 step 82 is completed and loss is 0.00017045089043676853

 step 83 is completed and loss is 0.00018761424871627241

 step 84 is completed and loss is 0.00010936630133073777

 step 85 is completed and loss is 0.0001380348257953301

 step 86 is completed and loss is 0.00012015574611723423

 step 87 is completed and loss is 0.00016634026542305946

 step 88 is completed and loss is 0.00020119312102906406

 step 89 is completed and loss is 5.775490717496723e-05

 step 90 is completed and loss is 0.0006071887910366058

 step 91 is completed and loss is 0.00011520591942826286
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.36it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.40it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.40it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.42it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.42it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.45it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:30,  1.42it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:30,  1.39it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:30,  1.33it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:29,  1.34it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:28,  1.38it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:27,  1.40it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:26,  1.37it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:10<00:26,  1.34it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:26,  1.33it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:25,  1.36it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:12<00:23,  1.43it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.41it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:21,  1.41it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:14<00:21,  1.38it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:15<00:21,  1.36it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:20,  1.37it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:16<00:19,  1.39it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:17<00:18,  1.40it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:18<00:17,  1.40it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:18<00:17,  1.40it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:19<00:16,  1.39it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:20<00:15,  1.40it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:20<00:14,  1.41it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:21<00:14,  1.40it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:22<00:13,  1.41it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:23<00:13,  1.37it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:23<00:12,  1.39it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:24<00:11,  1.40it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:25<00:10,  1.41it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:25<00:09,  1.44it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:26<00:08,  1.46it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:27<00:08,  1.46it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:27<00:07,  1.39it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:28<00:07,  1.41it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:29<00:06,  1.40it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:30<00:05,  1.35it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:30<00:05,  1.39it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:31<00:04,  1.43it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:32<00:03,  1.45it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:32<00:02,  1.42it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:33<00:02,  1.44it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:34<00:01,  1.43it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:34<00:00,  1.49it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:35<00:00,  1.48it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:35<00:00,  1.40it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 86: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 307.78543624699887s
Training Epoch86:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch86:   1%|[34m          [0m| 1/92 [00:03<05:08,  3.40s/it]Training Epoch86:   2%|[34mâ–         [0m| 2/92 [00:06<05:03,  3.37s/it]Training Epoch86:   3%|[34mâ–Ž         [0m| 3/92 [00:10<05:00,  3.37s/it]Training Epoch86:   4%|[34mâ–         [0m| 4/92 [00:13<04:56,  3.36s/it]Training Epoch86:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:50,  3.34s/it]Training Epoch86:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:45,  3.32s/it]Training Epoch86:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.31s/it]Training Epoch86:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.32s/it]Training Epoch86:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.31s/it]Training Epoch86:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:31,  3.31s/it]Training Epoch86:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch86:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.32s/it]Training Epoch86:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:21,  3.31s/it]Training Epoch86:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.31s/it]Training Epoch86:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch86:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:12,  3.33s/it]Training Epoch86:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:09,  3.32s/it]Training Epoch86:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:06,  3.33s/it]Training Epoch86:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:02,  3.33s/it]Training Epoch86:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:57,  3.30s/it]Training Epoch86:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.30s/it]Training Epoch86:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.29s/it]Training Epoch86:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:47,  3.30s/it]Training Epoch86:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.32s/it]Training Epoch86:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.29s/it]Training Epoch86:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:36,  3.28s/it]Training Epoch86:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:33,  3.28s/it]Training Epoch86:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.30s/it]Training Epoch86:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:27,  3.30s/it]Training Epoch86:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:21,  3.25s/it]Training Epoch86:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:18,  3.25s/it]Training Epoch86:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:15,  3.26s/it]Training Epoch86:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:12,  3.26s/it]Training Epoch86:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:09,  3.27s/it]Training Epoch86:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.30s/it]Training Epoch86:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:05,  3.30s/it]Training Epoch86:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:01,  3.30s/it]Training Epoch86:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:57,  3.28s/it]Training Epoch86:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.29s/it]Training Epoch86:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.29s/it]Training Epoch86:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:48,  3.30s/it]Training Epoch86:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:45,  3.31s/it]Training Epoch86:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:41,  3.30s/it]Training Epoch86:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:39,  3.33s/it]Training Epoch86:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:36,  3.33s/it]Training Epoch86:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.34s/it]Training Epoch86:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:30,  3.34s/it]Training Epoch86:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.32s/it]Training Epoch86:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:23,  3.33s/it]Training Epoch86:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.32s/it]Training Epoch86:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:16,  3.33s/it]Training Epoch86:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:14,  3.36s/it]Training Epoch86:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:10,  3.34s/it]Training Epoch86:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:07,  3.35s/it]Training Epoch86:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:02,  3.32s/it]Training Epoch86:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:58,  3.29s/it]Training Epoch86:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:55,  3.31s/it]Training Epoch86:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.30s/it]Training Epoch86:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.30s/it]Training Epoch86:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.30s/it]Training Epoch86:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.32s/it]Training Epoch86:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:39,  3.33s/it]Training Epoch86:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.34s/it]Training Epoch86:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:33,  3.34s/it]Training Epoch86:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.33s/it]Training Epoch86:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.34s/it]Training Epoch86:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:23,  3.34s/it]Training Epoch86:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:20,  3.35s/it]Training Epoch86:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:16,  3.32s/it]Training Epoch86:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.32s/it]Training Epoch86:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:09,  3.33s/it]Training Epoch86:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:07,  3.35s/it]Training Epoch86:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:03,  3.34s/it]Training Epoch86:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.33s/it]Training Epoch86:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.31s/it]Training Epoch86:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:52,  3.31s/it]Training Epoch86:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.32s/it]Training Epoch86:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.30s/it]Training Epoch86:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.32s/it]Training Epoch86:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.31s/it]Training Epoch86:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.29s/it]Training Epoch86:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:32,  3.27s/it]Training Epoch86:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.28s/it]Training Epoch86:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.29s/it]Training Epoch86:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.32s/it]Training Epoch86:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.31s/it]Training Epoch86:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.33s/it]Training Epoch86:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.35s/it]Training Epoch86:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:55<00:10,  3.36s/it]Training Epoch86:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.34s/it]Training Epoch86:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.34s/it]Training Epoch86: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.33s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch86: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:05<00:00,  3.32s/it]

 step 0 is completed and loss is 0.00010936471517197788

 step 1 is completed and loss is 0.0002065076114377007

 step 2 is completed and loss is 4.017267929157242e-05

 step 3 is completed and loss is 0.00011872023605974391

 step 4 is completed and loss is 6.478697468992323e-05

 step 5 is completed and loss is 4.7742090828251094e-05

 step 6 is completed and loss is 0.0008034047787077725

 step 7 is completed and loss is 6.0317594034131616e-05

 step 8 is completed and loss is 7.080780051182956e-05

 step 9 is completed and loss is 4.6907462092349306e-05

 step 10 is completed and loss is 0.0011205580085515976

 step 11 is completed and loss is 0.0013685901649296284

 step 12 is completed and loss is 0.00022162812820170075

 step 13 is completed and loss is 5.590759246842936e-05

 step 14 is completed and loss is 4.684803570853546e-05

 step 15 is completed and loss is 4.327203714638017e-05

 step 16 is completed and loss is 0.00022633712796960026

 step 17 is completed and loss is 0.00014422884851228446

 step 18 is completed and loss is 6.055636185919866e-05

 step 19 is completed and loss is 0.00019725895253941417

 step 20 is completed and loss is 6.00200000917539e-05

 step 21 is completed and loss is 5.435794446384534e-05

 step 22 is completed and loss is 0.0008165608160197735

 step 23 is completed and loss is 9.18464211281389e-05

 step 24 is completed and loss is 6.216569454409182e-05

 step 25 is completed and loss is 0.0003942069015465677

 step 26 is completed and loss is 7.390671817120165e-05

 step 27 is completed and loss is 0.00022116501349955797

 step 28 is completed and loss is 0.00017253070836886764

 step 29 is completed and loss is 0.00010024990478996187

 step 30 is completed and loss is 9.613699512556195e-05

 step 31 is completed and loss is 1.7583164662937634e-05

 step 32 is completed and loss is 9.720848902361467e-05

 step 33 is completed and loss is 8.082034037215635e-05

 step 34 is completed and loss is 6.842369475634769e-05

 step 35 is completed and loss is 0.0001622285635676235

 step 36 is completed and loss is 1.8000409909291193e-05

 step 37 is completed and loss is 6.830459460616112e-05

 step 38 is completed and loss is 0.00011282419291092083

 step 39 is completed and loss is 5.4000334785087034e-05

 step 40 is completed and loss is 0.0001063288509612903

 step 41 is completed and loss is 3.838434713543393e-05

 step 42 is completed and loss is 8.034382335608825e-05

 step 43 is completed and loss is 5.531132046598941e-05

 step 44 is completed and loss is 2.413944821455516e-05

 step 45 is completed and loss is 0.00017736600420903414

 step 46 is completed and loss is 2.3603100999025628e-05

 step 47 is completed and loss is 7.539702346548438e-05

 step 48 is completed and loss is 0.0006223808159120381

 step 49 is completed and loss is 9.393240907229483e-05

 step 50 is completed and loss is 9.542248153593391e-05

 step 51 is completed and loss is 5.590754153672606e-05

 step 52 is completed and loss is 0.0010845426004379988

 step 53 is completed and loss is 0.0003626703401096165

 step 54 is completed and loss is 4.690747300628573e-05

 step 55 is completed and loss is 0.0015606759116053581

 step 56 is completed and loss is 4.1543564293533564e-05

 step 57 is completed and loss is 0.00024254265008494258

 step 58 is completed and loss is 5.74563309783116e-05

 step 59 is completed and loss is 0.0003122528432868421

 step 60 is completed and loss is 9.613765723770484e-05

 step 61 is completed and loss is 9.732648322824389e-05

 step 62 is completed and loss is 9.035474067786708e-05

 step 63 is completed and loss is 0.0004082399536855519

 step 64 is completed and loss is 0.0002743489749263972

 step 65 is completed and loss is 9.232318552676588e-05

 step 66 is completed and loss is 0.0005302408244460821

 step 67 is completed and loss is 4.851663106819615e-05

 step 68 is completed and loss is 0.00019321957370266318

 step 69 is completed and loss is 0.00010698453115765005

 step 70 is completed and loss is 0.00015585237997584045

 step 71 is completed and loss is 0.00017491949256509542

 step 72 is completed and loss is 0.00044131564209237695

 step 73 is completed and loss is 8.588646596763283e-05

 step 74 is completed and loss is 0.00011526866001076996

 step 75 is completed and loss is 0.00017790377023629844

 step 76 is completed and loss is 0.00014441140228882432

 step 77 is completed and loss is 9.577876335242763e-05

 step 78 is completed and loss is 0.00022027075465302914

 step 79 is completed and loss is 0.0007839150493964553

 step 80 is completed and loss is 0.0003387914621271193

 step 81 is completed and loss is 0.00010710342030506581

 step 82 is completed and loss is 0.0002070945774903521

 step 83 is completed and loss is 0.00015311158495023847

 step 84 is completed and loss is 0.00013475390733219683

 step 85 is completed and loss is 0.00010013079008786008

 step 86 is completed and loss is 0.00010561384988250211

 step 87 is completed and loss is 0.0001388082018820569

 step 88 is completed and loss is 0.00015328651352319866

 step 89 is completed and loss is 6.83641410432756e-05

 step 90 is completed and loss is 0.0006166441016830504

 step 91 is completed and loss is 0.00015840795822441578
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.39it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.44it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.43it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.46it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.45it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.44it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.43it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.47it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.45it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.51it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.50it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.51it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.48it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.48it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.48it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.47it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.47it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:21,  1.46it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.46it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.46it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.48it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.47it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.48it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:16,  1.48it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.48it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.50it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.50it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.49it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.47it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:12,  1.47it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.46it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.45it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:11,  1.44it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.45it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.47it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.49it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.47it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.48it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.46it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:06,  1.47it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.46it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.46it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.47it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.47it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.49it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.48it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.49it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.54it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.56it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.48it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 87: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.32935515299687s
Training Epoch87:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch87:   1%|[34m          [0m| 1/92 [00:03<05:00,  3.30s/it]Training Epoch87:   2%|[34mâ–         [0m| 2/92 [00:06<04:57,  3.31s/it]Training Epoch87:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:57,  3.35s/it]Training Epoch87:   4%|[34mâ–         [0m| 4/92 [00:13<04:51,  3.32s/it]Training Epoch87:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:48,  3.32s/it]Training Epoch87:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:42,  3.29s/it]Training Epoch87:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch87:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.31s/it]Training Epoch87:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.30s/it]Training Epoch87:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:31,  3.31s/it]Training Epoch87:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.32s/it]Training Epoch87:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch87:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.29s/it]Training Epoch87:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:15,  3.28s/it]Training Epoch87:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.31s/it]Training Epoch87:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.31s/it]Training Epoch87:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.30s/it]Training Epoch87:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.31s/it]Training Epoch87:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:03,  3.34s/it]Training Epoch87:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.31s/it]Training Epoch87:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.31s/it]Training Epoch87:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.31s/it]Training Epoch87:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:49,  3.33s/it]Training Epoch87:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.32s/it]Training Epoch87:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:43,  3.34s/it]Training Epoch87:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:39,  3.32s/it]Training Epoch87:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.30s/it]Training Epoch87:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:29,  3.28s/it]Training Epoch87:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:25,  3.27s/it]Training Epoch87:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:23,  3.28s/it]Training Epoch87:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:20,  3.28s/it]Training Epoch87:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:17,  3.29s/it]Training Epoch87:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:14,  3.30s/it]Training Epoch87:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.30s/it]Training Epoch87:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:08,  3.30s/it]Training Epoch87:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:05,  3.31s/it]Training Epoch87:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:01,  3.31s/it]Training Epoch87:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:58,  3.30s/it]Training Epoch87:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.30s/it]Training Epoch87:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.32s/it]Training Epoch87:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:47,  3.29s/it]Training Epoch87:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:47,  3.34s/it]Training Epoch87:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:43,  3.34s/it]Training Epoch87:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:41,  3.36s/it]Training Epoch87:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:36,  3.33s/it]Training Epoch87:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:33,  3.34s/it]Training Epoch87:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.33s/it]Training Epoch87:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.31s/it]Training Epoch87:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:23,  3.33s/it]Training Epoch87:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.32s/it]Training Epoch87:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:14,  3.29s/it]Training Epoch87:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:10,  3.27s/it]Training Epoch87:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:07,  3.26s/it]Training Epoch87:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:04,  3.28s/it]Training Epoch87:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:00,  3.27s/it]Training Epoch87:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.31s/it]Training Epoch87:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:57,  3.35s/it]Training Epoch87:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:55,  3.38s/it]Training Epoch87:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:50,  3.36s/it]Training Epoch87:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:47,  3.37s/it]Training Epoch87:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:44,  3.38s/it]Training Epoch87:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:41,  3.37s/it]Training Epoch87:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:37,  3.38s/it]Training Epoch87:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:34,  3.37s/it]Training Epoch87:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:30,  3.35s/it]Training Epoch87:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:26,  3.34s/it]Training Epoch87:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:24,  3.36s/it]Training Epoch87:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:20,  3.37s/it]Training Epoch87:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:17,  3.38s/it]Training Epoch87:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:52<01:13,  3.34s/it]Training Epoch87:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:10,  3.35s/it]Training Epoch87:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:07,  3.35s/it]Training Epoch87:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:02<01:03,  3.36s/it]Training Epoch87:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<01:00,  3.36s/it]Training Epoch87:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:57,  3.36s/it]Training Epoch87:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:12<00:53,  3.33s/it]Training Epoch87:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:49,  3.32s/it]Training Epoch87:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:46,  3.33s/it]Training Epoch87:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:22<00:42,  3.30s/it]Training Epoch87:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:40,  3.34s/it]Training Epoch87:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:29<00:36,  3.35s/it]Training Epoch87:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:33,  3.35s/it]Training Epoch87:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:35<00:30,  3.34s/it]Training Epoch87:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:26,  3.32s/it]Training Epoch87:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.34s/it]Training Epoch87:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:45<00:20,  3.34s/it]Training Epoch87:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.36s/it]Training Epoch87:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:52<00:13,  3.39s/it]Training Epoch87:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:56<00:10,  3.40s/it]Training Epoch87:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.39s/it]Training Epoch87:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:02<00:03,  3.40s/it]Training Epoch87: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.39s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch87: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.33s/it]

 step 0 is completed and loss is 8.040177635848522e-05

 step 1 is completed and loss is 0.00014381547225639224

 step 2 is completed and loss is 3.5642864531837404e-05

 step 3 is completed and loss is 0.00014047129661776125

 step 4 is completed and loss is 7.009124237811193e-05

 step 5 is completed and loss is 4.678840559790842e-05

 step 6 is completed and loss is 0.00029217274277471006

 step 7 is completed and loss is 4.255671956343576e-05

 step 8 is completed and loss is 8.767444523982704e-05

 step 9 is completed and loss is 4.768230428453535e-05

 step 10 is completed and loss is 0.00033672942663542926

 step 11 is completed and loss is 0.0012482013553380966

 step 12 is completed and loss is 0.0002647037908900529

 step 13 is completed and loss is 6.139085598988459e-05

 step 14 is completed and loss is 4.047065522172488e-05

 step 15 is completed and loss is 4.255681051290594e-05

 step 16 is completed and loss is 0.0001890977582661435

 step 17 is completed and loss is 0.00015722177340649068

 step 18 is completed and loss is 6.013927486492321e-05

 step 19 is completed and loss is 0.0001470276474719867

 step 20 is completed and loss is 5.0424121582182124e-05

 step 21 is completed and loss is 5.4298310715239495e-05

 step 22 is completed and loss is 0.00042351873707957566

 step 23 is completed and loss is 7.938998169265687e-05

 step 24 is completed and loss is 7.718486449448392e-05

 step 25 is completed and loss is 0.0005148103227838874

 step 26 is completed and loss is 5.358307680580765e-05

 step 27 is completed and loss is 0.00020388446864672005

 step 28 is completed and loss is 0.00017783252405934036

 step 29 is completed and loss is 8.934337529353797e-05

 step 30 is completed and loss is 0.00010132226452697068

 step 31 is completed and loss is 1.6808335203677416e-05

 step 32 is completed and loss is 6.82445679558441e-05

 step 33 is completed and loss is 8.58866042108275e-05

 step 34 is completed and loss is 8.01649148343131e-05

 step 35 is completed and loss is 0.00017164333257824183

 step 36 is completed and loss is 1.931169390445575e-05

 step 37 is completed and loss is 5.119907291373238e-05

 step 38 is completed and loss is 6.997320451773703e-05

 step 39 is completed and loss is 5.525174492504448e-05

 step 40 is completed and loss is 0.00011234832345508039

 step 41 is completed and loss is 5.149639036972076e-05

 step 42 is completed and loss is 7.295334944501519e-05

 step 43 is completed and loss is 5.674159183399752e-05

 step 44 is completed and loss is 2.5689103495096788e-05

 step 45 is completed and loss is 0.00022974409512244165

 step 46 is completed and loss is 2.181503441534005e-05

 step 47 is completed and loss is 6.574176222784445e-05

 step 48 is completed and loss is 0.0006187487742863595

 step 49 is completed and loss is 8.970096678240225e-05

 step 50 is completed and loss is 9.059488365892321e-05

 step 51 is completed and loss is 6.586094241356477e-05

 step 52 is completed and loss is 0.001970497891306877

 step 53 is completed and loss is 0.0003412801306694746

 step 54 is completed and loss is 4.184134741080925e-05

 step 55 is completed and loss is 0.002005987334996462

 step 56 is completed and loss is 4.1066683479584754e-05

 step 57 is completed and loss is 0.0001271853834623471

 step 58 is completed and loss is 5.9304089518263936e-05

 step 59 is completed and loss is 0.0004765272024087608

 step 60 is completed and loss is 9.232327283825725e-05

 step 61 is completed and loss is 4.762248499901034e-05

 step 62 is completed and loss is 8.677902224007994e-05

 step 63 is completed and loss is 0.0005117991240695119

 step 64 is completed and loss is 0.00017336274322587997

 step 65 is completed and loss is 8.147614425979555e-05

 step 66 is completed and loss is 0.00048749512643553317

 step 67 is completed and loss is 5.0066300900653005e-05

 step 68 is completed and loss is 0.00014488838496617973

 step 69 is completed and loss is 0.00018809130415320396

 step 70 is completed and loss is 0.00015805722796358168

 step 71 is completed and loss is 0.00019053270807489753

 step 72 is completed and loss is 0.00042113085510209203

 step 73 is completed and loss is 8.135699317790568e-05

 step 74 is completed and loss is 9.774672071216628e-05

 step 75 is completed and loss is 0.00024571793619543314

 step 76 is completed and loss is 0.00011908270244020969

 step 77 is completed and loss is 8.296561281895265e-05

 step 78 is completed and loss is 0.00023618021805305034

 step 79 is completed and loss is 0.000666072650346905

 step 80 is completed and loss is 0.00030714907916262746

 step 81 is completed and loss is 0.00012373042409308255

 step 82 is completed and loss is 0.00031654100166633725

 step 83 is completed and loss is 0.0001946456904988736

 step 84 is completed and loss is 0.00015799328684806824

 step 85 is completed and loss is 0.00016378014697693288

 step 86 is completed and loss is 8.987976616481319e-05

 step 87 is completed and loss is 0.00014828465646132827

 step 88 is completed and loss is 0.00015900717698968947

 step 89 is completed and loss is 5.715915176551789e-05

 step 90 is completed and loss is 0.0006109320092946291

 step 91 is completed and loss is 0.00012152272392995656
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:37,  1.31it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.46it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.41it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:33,  1.37it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:33,  1.36it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:31,  1.39it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.45it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.44it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.45it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:27,  1.43it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:27,  1.42it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:27,  1.38it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:27,  1.34it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:10<00:26,  1.37it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:25,  1.40it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.42it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:12<00:23,  1.40it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.41it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:22,  1.40it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:14<00:21,  1.38it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:20,  1.41it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:19,  1.43it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:16<00:18,  1.46it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:16,  1.53it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.47it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:18<00:17,  1.39it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:19<00:16,  1.39it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:15,  1.40it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:20<00:14,  1.41it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:21<00:14,  1.38it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:22<00:14,  1.35it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:13,  1.36it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:23<00:12,  1.36it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:24<00:11,  1.40it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:10,  1.44it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:25<00:10,  1.39it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:26<00:09,  1.38it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:27<00:09,  1.32it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:27<00:08,  1.34it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:28<00:07,  1.36it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:29<00:06,  1.41it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:29<00:05,  1.44it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:30<00:05,  1.39it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:31<00:04,  1.42it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:32<00:03,  1.37it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:33<00:03,  1.31it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:33<00:02,  1.31it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:34<00:01,  1.30it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:35<00:00,  1.38it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:35<00:00,  1.37it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:35<00:00,  1.39it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 88: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 306.5910693850019s
Training Epoch88:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch88:   1%|[34m          [0m| 1/92 [00:03<05:01,  3.31s/it]Training Epoch88:   2%|[34mâ–         [0m| 2/92 [00:06<05:01,  3.35s/it]Training Epoch88:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:58,  3.35s/it]Training Epoch88:   4%|[34mâ–         [0m| 4/92 [00:13<04:56,  3.37s/it]Training Epoch88:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:50,  3.34s/it]Training Epoch88:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:48,  3.35s/it]Training Epoch88:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.33s/it]Training Epoch88:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.32s/it]Training Epoch88:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:36,  3.33s/it]Training Epoch88:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:31,  3.31s/it]Training Epoch88:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.33s/it]Training Epoch88:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.30s/it]Training Epoch88:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.33s/it]Training Epoch88:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:18,  3.31s/it]Training Epoch88:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch88:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:09,  3.28s/it]Training Epoch88:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:06,  3.29s/it]Training Epoch88:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.31s/it]Training Epoch88:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:02,  3.32s/it]Training Epoch88:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:56,  3.28s/it]Training Epoch88:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:52,  3.28s/it]Training Epoch88:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:48,  3.27s/it]Training Epoch88:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:43,  3.24s/it]Training Epoch88:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:43,  3.28s/it]Training Epoch88:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:41,  3.31s/it]Training Epoch88:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:37,  3.29s/it]Training Epoch88:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.31s/it]Training Epoch88:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.30s/it]Training Epoch88:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.33s/it]Training Epoch88:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:25,  3.31s/it]Training Epoch88:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:20,  3.29s/it]Training Epoch88:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:16,  3.27s/it]Training Epoch88:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:12,  3.27s/it]Training Epoch88:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.29s/it]Training Epoch88:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:07,  3.29s/it]Training Epoch88:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:03,  3.29s/it]Training Epoch88:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<02:59,  3.26s/it]Training Epoch88:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:57,  3.28s/it]Training Epoch88:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:53,  3.28s/it]Training Epoch88:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.30s/it]Training Epoch88:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:48,  3.30s/it]Training Epoch88:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:44,  3.30s/it]Training Epoch88:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:41,  3.30s/it]Training Epoch88:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.30s/it]Training Epoch88:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:34,  3.29s/it]Training Epoch88:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:30,  3.28s/it]Training Epoch88:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:27,  3.28s/it]Training Epoch88:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:23,  3.26s/it]Training Epoch88:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.31s/it]Training Epoch88:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.32s/it]Training Epoch88:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:16,  3.33s/it]Training Epoch88:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:14,  3.36s/it]Training Epoch88:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:10,  3.34s/it]Training Epoch88:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.31s/it]Training Epoch88:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.29s/it]Training Epoch88:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:58,  3.29s/it]Training Epoch88:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:55,  3.30s/it]Training Epoch88:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:51,  3.29s/it]Training Epoch88:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.32s/it]Training Epoch88:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:46,  3.34s/it]Training Epoch88:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.32s/it]Training Epoch88:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:38,  3.30s/it]Training Epoch88:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:35,  3.28s/it]Training Epoch88:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:31,  3.27s/it]Training Epoch88:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.26s/it]Training Epoch88:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.28s/it]Training Epoch88:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.30s/it]Training Epoch88:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.32s/it]Training Epoch88:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:15,  3.30s/it]Training Epoch88:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.31s/it]Training Epoch88:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.30s/it]Training Epoch88:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:06,  3.32s/it]Training Epoch88:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.30s/it]Training Epoch88:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:58,  3.27s/it]Training Epoch88:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:55,  3.28s/it]Training Epoch88:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.30s/it]Training Epoch88:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:50,  3.34s/it]Training Epoch88:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.31s/it]Training Epoch88:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:43,  3.34s/it]Training Epoch88:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:40,  3.37s/it]Training Epoch88:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:37,  3.37s/it]Training Epoch88:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.37s/it]Training Epoch88:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:30,  3.37s/it]Training Epoch88:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:27,  3.38s/it]Training Epoch88:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.34s/it]Training Epoch88:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.32s/it]Training Epoch88:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.34s/it]Training Epoch88:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.35s/it]Training Epoch88:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:10,  3.36s/it]Training Epoch88:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.35s/it]Training Epoch88:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.36s/it]Training Epoch88: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.36s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch88: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 0.0001299834984820336

 step 1 is completed and loss is 0.00018249207641929388

 step 2 is completed and loss is 2.9921075110905804e-05

 step 3 is completed and loss is 7.605108112329617e-05

 step 4 is completed and loss is 7.867295062169433e-05

 step 5 is completed and loss is 4.386797081679106e-05

 step 6 is completed and loss is 0.0004039204213768244

 step 7 is completed and loss is 7.158167863963172e-05

 step 8 is completed and loss is 6.824498996138573e-05

 step 9 is completed and loss is 3.7013702240074053e-05

 step 10 is completed and loss is 0.0010932731674984097

 step 11 is completed and loss is 0.001049302751198411

 step 12 is completed and loss is 0.0002633326512295753

 step 13 is completed and loss is 6.288089934969321e-05

 step 14 is completed and loss is 5.0006896344712004e-05

 step 15 is completed and loss is 3.6238969187252223e-05

 step 16 is completed and loss is 0.00019851038814522326

 step 17 is completed and loss is 0.00013070313434582204

 step 18 is completed and loss is 4.6430868678726256e-05

 step 19 is completed and loss is 0.00012068798241671175

 step 20 is completed and loss is 5.858951772097498e-05

 step 21 is completed and loss is 6.568215030711144e-05

 step 22 is completed and loss is 0.000337450037477538

 step 23 is completed and loss is 8.272739069070667e-05

 step 24 is completed and loss is 6.049681542208418e-05

 step 25 is completed and loss is 0.0002408154250588268

 step 26 is completed and loss is 7.456232560798526e-05

 step 27 is completed and loss is 0.00020108447642996907

 step 28 is completed and loss is 0.00011902009282493964

 step 29 is completed and loss is 9.315769420936704e-05

 step 30 is completed and loss is 9.54222705331631e-05

 step 31 is completed and loss is 1.9728886400116608e-05

 step 32 is completed and loss is 7.193977216957137e-05

 step 33 is completed and loss is 8.225096098612994e-05

 step 34 is completed and loss is 6.752961780875921e-05

 step 35 is completed and loss is 0.00015734267071820796

 step 36 is completed and loss is 1.7940796169568785e-05

 step 37 is completed and loss is 7.033100700937212e-05

 step 38 is completed and loss is 0.0001017980684991926

 step 39 is completed and loss is 5.721882189391181e-05

 step 40 is completed and loss is 0.00011377879127394408

 step 41 is completed and loss is 6.127078086137772e-05

 step 42 is completed and loss is 7.009260298218578e-05

 step 43 is completed and loss is 6.448959902627394e-05

 step 44 is completed and loss is 2.6821557185030542e-05

 step 45 is completed and loss is 0.0002876514627132565

 step 46 is completed and loss is 2.074215626635123e-05

 step 47 is completed and loss is 7.694660598644987e-05

 step 48 is completed and loss is 0.0005518278339877725

 step 49 is completed and loss is 0.0001072826053132303

 step 50 is completed and loss is 7.986689161043614e-05

 step 51 is completed and loss is 6.0496837249957025e-05

 step 52 is completed and loss is 0.0018363433191552758

 step 53 is completed and loss is 0.0003022632736247033

 step 54 is completed and loss is 3.7728928873548284e-05

 step 55 is completed and loss is 0.0010373778641223907

 step 56 is completed and loss is 3.653696694527753e-05

 step 57 is completed and loss is 0.0002811492304317653

 step 58 is completed and loss is 5.429761949926615e-05

 step 59 is completed and loss is 0.0005673326086252928

 step 60 is completed and loss is 0.00011598334822338074

 step 61 is completed and loss is 6.806488090660423e-05

 step 62 is completed and loss is 7.670713966945186e-05

 step 63 is completed and loss is 0.00042522253352217376

 step 64 is completed and loss is 0.0003479771548882127

 step 65 is completed and loss is 7.438371540047228e-05

 step 66 is completed and loss is 0.0005299500771798193

 step 67 is completed and loss is 4.5477019739337265e-05

 step 68 is completed and loss is 0.00019298007828183472

 step 69 is completed and loss is 0.00016532742301933467

 step 70 is completed and loss is 0.00016002345364540815

 step 71 is completed and loss is 0.0001910065475385636

 step 72 is completed and loss is 0.0004717515839729458

 step 73 is completed and loss is 8.141662692651153e-05

 step 74 is completed and loss is 0.00011342077050358057

 step 75 is completed and loss is 0.00017677167488727719

 step 76 is completed and loss is 0.00012694913311861455

 step 77 is completed and loss is 8.248852100223303e-05

 step 78 is completed and loss is 0.00017241851310245693

 step 79 is completed and loss is 0.0005589412176050246

 step 80 is completed and loss is 0.0002683038474060595

 step 81 is completed and loss is 9.768686140887439e-05

 step 82 is completed and loss is 0.00020209106151014566

 step 83 is completed and loss is 0.00013004732318222523

 step 84 is completed and loss is 0.0001725333568174392

 step 85 is completed and loss is 0.00015841660206206143

 step 86 is completed and loss is 0.00012289722508285195

 step 87 is completed and loss is 0.0001380933535983786

 step 88 is completed and loss is 0.00021090723748784512

 step 89 is completed and loss is 5.954289372311905e-05

 step 90 is completed and loss is 0.0005148942000232637

 step 91 is completed and loss is 0.00011794755118899047
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:39,  1.25it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:36,  1.30it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.46it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.47it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.46it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.43it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:30,  1.42it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:30,  1.39it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.42it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:27,  1.43it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:27,  1.43it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.49it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:25,  1.46it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.50it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:22,  1.56it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.52it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.52it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.52it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.45it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:20,  1.42it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:20,  1.40it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.44it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:18,  1.43it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.47it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.47it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.51it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:14,  1.52it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:13,  1.50it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.44it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:13,  1.40it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:12,  1.40it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.42it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:11,  1.41it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:10,  1.41it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.43it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.46it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:08,  1.49it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.51it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.52it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:06,  1.50it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.49it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.45it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:04,  1.42it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:31<00:03,  1.38it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.37it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:32<00:02,  1.37it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:33<00:01,  1.40it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.38it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.40it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.44it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 89: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.9620830040003s
Training Epoch89:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch89:   1%|[34m          [0m| 1/92 [00:03<05:06,  3.36s/it]Training Epoch89:   2%|[34mâ–         [0m| 2/92 [00:06<05:02,  3.36s/it]Training Epoch89:   3%|[34mâ–Ž         [0m| 3/92 [00:10<04:55,  3.33s/it]Training Epoch89:   4%|[34mâ–         [0m| 4/92 [00:13<04:53,  3.33s/it]Training Epoch89:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:49,  3.32s/it]Training Epoch89:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:47,  3.34s/it]Training Epoch89:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:46,  3.37s/it]Training Epoch89:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:41,  3.35s/it]Training Epoch89:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:35,  3.32s/it]Training Epoch89:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.33s/it]Training Epoch89:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch89:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:26,  3.33s/it]Training Epoch89:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.34s/it]Training Epoch89:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.34s/it]Training Epoch89:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:50<04:17,  3.34s/it]Training Epoch89:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:11,  3.32s/it]Training Epoch89:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.32s/it]Training Epoch89:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [01:00<04:07,  3.34s/it]Training Epoch89:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:04,  3.35s/it]Training Epoch89:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<04:00,  3.34s/it]Training Epoch89:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:10<03:58,  3.36s/it]Training Epoch89:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:54,  3.35s/it]Training Epoch89:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:49,  3.33s/it]Training Epoch89:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:20<03:45,  3.32s/it]Training Epoch89:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:23<03:42,  3.33s/it]Training Epoch89:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:40,  3.35s/it]Training Epoch89:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:36,  3.33s/it]Training Epoch89:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:33<03:33,  3.33s/it]Training Epoch89:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:31,  3.35s/it]Training Epoch89:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:40<03:25,  3.32s/it]Training Epoch89:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:24,  3.35s/it]Training Epoch89:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:20,  3.35s/it]Training Epoch89:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:50<03:17,  3.34s/it]Training Epoch89:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:13,  3.34s/it]Training Epoch89:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:10,  3.35s/it]Training Epoch89:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [02:00<03:06,  3.33s/it]Training Epoch89:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:03<03:00,  3.29s/it]Training Epoch89:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:57,  3.29s/it]Training Epoch89:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:53,  3.28s/it]Training Epoch89:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:13<02:51,  3.29s/it]Training Epoch89:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:48,  3.31s/it]Training Epoch89:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:46,  3.32s/it]Training Epoch89:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:23<02:43,  3.33s/it]Training Epoch89:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:39,  3.33s/it]Training Epoch89:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:36,  3.34s/it]Training Epoch89:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:33<02:33,  3.33s/it]Training Epoch89:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:29,  3.33s/it]Training Epoch89:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:26,  3.33s/it]Training Epoch89:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:22,  3.30s/it]Training Epoch89:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:18,  3.31s/it]Training Epoch89:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:15,  3.31s/it]Training Epoch89:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:12,  3.32s/it]Training Epoch89:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:09,  3.31s/it]Training Epoch89:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:05,  3.30s/it]Training Epoch89:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:03<02:02,  3.31s/it]Training Epoch89:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<01:59,  3.32s/it]Training Epoch89:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:55,  3.30s/it]Training Epoch89:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.31s/it]Training Epoch89:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:49,  3.33s/it]Training Epoch89:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:46,  3.33s/it]Training Epoch89:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:43,  3.34s/it]Training Epoch89:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:41,  3.37s/it]Training Epoch89:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:29<01:37,  3.36s/it]Training Epoch89:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:33<01:33,  3.35s/it]Training Epoch89:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:30,  3.34s/it]Training Epoch89:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:26,  3.34s/it]Training Epoch89:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:43<01:23,  3.34s/it]Training Epoch89:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:19,  3.33s/it]Training Epoch89:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:16,  3.34s/it]Training Epoch89:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:53<01:13,  3.34s/it]Training Epoch89:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:56<01:09,  3.33s/it]Training Epoch89:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.31s/it]Training Epoch89:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:03<01:03,  3.32s/it]Training Epoch89:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:06<00:59,  3.32s/it]Training Epoch89:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:09<00:56,  3.33s/it]Training Epoch89:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:13<00:53,  3.37s/it]Training Epoch89:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:16<00:50,  3.37s/it]Training Epoch89:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:19<00:46,  3.34s/it]Training Epoch89:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:23<00:42,  3.30s/it]Training Epoch89:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:26<00:39,  3.27s/it]Training Epoch89:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:29<00:36,  3.29s/it]Training Epoch89:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:32<00:32,  3.28s/it]Training Epoch89:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:36<00:29,  3.31s/it]Training Epoch89:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:39<00:26,  3.32s/it]Training Epoch89:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:42<00:23,  3.35s/it]Training Epoch89:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:46<00:20,  3.33s/it]Training Epoch89:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.34s/it]Training Epoch89:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:52<00:13,  3.32s/it]Training Epoch89:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:56<00:10,  3.36s/it]Training Epoch89:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.36s/it]Training Epoch89:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:03<00:03,  3.37s/it]Training Epoch89: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.36s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch89: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.33s/it]

 step 0 is completed and loss is 8.516972593497485e-05

 step 1 is completed and loss is 0.0001603813434485346

 step 2 is completed and loss is 3.9397866203216836e-05

 step 3 is completed and loss is 0.00014249722880776972

 step 4 is completed and loss is 6.854152888990939e-05

 step 5 is completed and loss is 4.792086110683158e-05

 step 6 is completed and loss is 0.00045794027391821146

 step 7 is completed and loss is 4.261633876012638e-05

 step 8 is completed and loss is 7.617183291586116e-05

 step 9 is completed and loss is 4.5953976950841025e-05

 step 10 is completed and loss is 0.0006544237257912755

 step 11 is completed and loss is 0.0008277533343061805

 step 12 is completed and loss is 0.00023032799072097987

 step 13 is completed and loss is 6.747014413122088e-05

 step 14 is completed and loss is 4.833815182792023e-05

 step 15 is completed and loss is 3.564294092939235e-05

 step 16 is completed and loss is 0.00011705387441907078

 step 17 is completed and loss is 9.190554555971175e-05

 step 18 is completed and loss is 4.422566416906193e-05

 step 19 is completed and loss is 0.0002296109450981021

 step 20 is completed and loss is 3.683499380713329e-05

 step 21 is completed and loss is 7.182066474342719e-05

 step 22 is completed and loss is 0.0005273892311379313

 step 23 is completed and loss is 0.00010495765309315175

 step 24 is completed and loss is 6.913889956194907e-05

 step 25 is completed and loss is 0.0003583523503039032

 step 26 is completed and loss is 5.614597466774285e-05

 step 27 is completed and loss is 0.00013177692017052323

 step 28 is completed and loss is 0.00014869535516481847

 step 29 is completed and loss is 8.022461406653747e-05

 step 30 is completed and loss is 8.004557457752526e-05

 step 31 is completed and loss is 1.907324440253433e-05

 step 32 is completed and loss is 8.58260173117742e-05

 step 33 is completed and loss is 7.509902934543788e-05

 step 34 is completed and loss is 5.668238736689091e-05

 step 35 is completed and loss is 0.00023683591280132532

 step 36 is completed and loss is 1.43645956995897e-05

 step 37 is completed and loss is 6.764897261746228e-05

 step 38 is completed and loss is 9.035626135300845e-05

 step 39 is completed and loss is 4.535800690064207e-05

 step 40 is completed and loss is 9.572039562044665e-05

 step 41 is completed and loss is 3.182822183589451e-05

 step 42 is completed and loss is 7.402613118756562e-05

 step 43 is completed and loss is 5.823173705721274e-05

 step 44 is completed and loss is 2.6285160856787115e-05

 step 45 is completed and loss is 0.00018159550381824374

 step 46 is completed and loss is 2.2709065888193436e-05

 step 47 is completed and loss is 6.323852721834555e-05

 step 48 is completed and loss is 0.00046594871673732996

 step 49 is completed and loss is 7.742337766103446e-05

 step 50 is completed and loss is 9.530285024084151e-05

 step 51 is completed and loss is 5.125865573063493e-05

 step 52 is completed and loss is 0.001699940301477909

 step 53 is completed and loss is 0.00037643639370799065

 step 54 is completed and loss is 4.2914150981232524e-05

 step 55 is completed and loss is 0.002004215493798256

 step 56 is completed and loss is 3.8444166420958936e-05

 step 57 is completed and loss is 0.00011627922503976151

 step 58 is completed and loss is 5.739665721193887e-05

 step 59 is completed and loss is 0.00023933238117024302

 step 60 is completed and loss is 0.00010960678628180176

 step 61 is completed and loss is 8.522874122718349e-05

 step 62 is completed and loss is 7.986550190253183e-05

 step 63 is completed and loss is 0.0006868633790872991

 step 64 is completed and loss is 0.00020643298921640962

 step 65 is completed and loss is 8.010523742996156e-05

 step 66 is completed and loss is 0.0006476430571638048

 step 67 is completed and loss is 5.5728363804519176e-05

 step 68 is completed and loss is 0.00021592379198409617

 step 69 is completed and loss is 0.00013565068366006017

 step 70 is completed and loss is 0.00017992715584114194

 step 71 is completed and loss is 0.000174322456587106

 step 72 is completed and loss is 0.0004381045582704246

 step 73 is completed and loss is 7.670822378713638e-05

 step 74 is completed and loss is 0.0001045406679622829

 step 75 is completed and loss is 0.00019065692322328687

 step 76 is completed and loss is 0.00013761695299763232

 step 77 is completed and loss is 8.082022395683452e-05

 step 78 is completed and loss is 0.0001749822695273906

 step 79 is completed and loss is 0.00042570935329422355

 step 80 is completed and loss is 0.0002501283888705075

 step 81 is completed and loss is 0.00010591093450784683

 step 82 is completed and loss is 0.00013737731205765158

 step 83 is completed and loss is 0.00015895074466243386

 step 84 is completed and loss is 0.0001550150045659393

 step 85 is completed and loss is 0.00010764019680209458

 step 86 is completed and loss is 8.916457591112703e-05

 step 87 is completed and loss is 0.00017867726273834705

 step 88 is completed and loss is 0.00025707803433761

 step 89 is completed and loss is 6.705286796204746e-05

 step 90 is completed and loss is 0.0007204575231298804

 step 91 is completed and loss is 9.708914149086922e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.33it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.38it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.42it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.42it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.43it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.44it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.45it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.46it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.46it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.45it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.46it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.49it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:25,  1.48it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.46it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.50it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.50it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.50it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.50it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.50it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:20,  1.44it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:19,  1.46it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.48it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.48it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.47it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.46it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.44it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:15,  1.47it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.48it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.47it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:12,  1.50it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.54it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.54it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.55it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.53it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.47it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.48it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.47it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.48it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.52it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.54it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.53it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.50it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.48it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.47it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.46it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.48it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.48it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.48it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.48it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6400)
Epoch 90: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 306.78555533300096s
Training Epoch90:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch90:   1%|[34m          [0m| 1/92 [00:03<05:07,  3.38s/it]Training Epoch90:   2%|[34mâ–         [0m| 2/92 [00:06<04:58,  3.32s/it]Training Epoch90:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:55,  3.32s/it]Training Epoch90:   4%|[34mâ–         [0m| 4/92 [00:13<04:54,  3.35s/it]Training Epoch90:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:53,  3.37s/it]Training Epoch90:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:48,  3.36s/it]Training Epoch90:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.34s/it]Training Epoch90:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:41,  3.35s/it]Training Epoch90:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:36,  3.33s/it]Training Epoch90:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:32,  3.33s/it]Training Epoch90:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.33s/it]Training Epoch90:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:27,  3.34s/it]Training Epoch90:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:23,  3.33s/it]Training Epoch90:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.34s/it]Training Epoch90:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:50<04:17,  3.35s/it]Training Epoch90:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:12,  3.32s/it]Training Epoch90:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.29s/it]Training Epoch90:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:02,  3.28s/it]Training Epoch90:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:00,  3.29s/it]Training Epoch90:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:56,  3.29s/it]Training Epoch90:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:55,  3.31s/it]Training Epoch90:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:49,  3.28s/it]Training Epoch90:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:47,  3.30s/it]Training Epoch90:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.32s/it]Training Epoch90:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.30s/it]Training Epoch90:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:39,  3.32s/it]Training Epoch90:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:35,  3.31s/it]Training Epoch90:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.31s/it]Training Epoch90:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.32s/it]Training Epoch90:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:26,  3.33s/it]Training Epoch90:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:43<03:23,  3.34s/it]Training Epoch90:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:46<03:19,  3.32s/it]Training Epoch90:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:17,  3.34s/it]Training Epoch90:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:53<03:13,  3.33s/it]Training Epoch90:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:56<03:10,  3.33s/it]Training Epoch90:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:59<03:06,  3.33s/it]Training Epoch90:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:02,  3.31s/it]Training Epoch90:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:06<02:59,  3.32s/it]Training Epoch90:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<02:55,  3.31s/it]Training Epoch90:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:52,  3.31s/it]Training Epoch90:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:16<02:49,  3.32s/it]Training Epoch90:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:45,  3.30s/it]Training Epoch90:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:42,  3.32s/it]Training Epoch90:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:39,  3.32s/it]Training Epoch90:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:34,  3.29s/it]Training Epoch90:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:31,  3.29s/it]Training Epoch90:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:27,  3.28s/it]Training Epoch90:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:23,  3.27s/it]Training Epoch90:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:42<02:20,  3.27s/it]Training Epoch90:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:18,  3.29s/it]Training Epoch90:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:14,  3.29s/it]Training Epoch90:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:52<02:11,  3.29s/it]Training Epoch90:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:07,  3.28s/it]Training Epoch90:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:04,  3.27s/it]Training Epoch90:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:01,  3.29s/it]Training Epoch90:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:05<01:59,  3.31s/it]Training Epoch90:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:55,  3.30s/it]Training Epoch90:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:52,  3.32s/it]Training Epoch90:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:15<01:49,  3.31s/it]Training Epoch90:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:45,  3.31s/it]Training Epoch90:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:22<01:43,  3.34s/it]Training Epoch90:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:25<01:40,  3.34s/it]Training Epoch90:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.33s/it]Training Epoch90:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:32<01:32,  3.32s/it]Training Epoch90:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:35<01:29,  3.32s/it]Training Epoch90:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:25,  3.30s/it]Training Epoch90:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:42<01:22,  3.30s/it]Training Epoch90:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:45<01:18,  3.28s/it]Training Epoch90:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:48<01:15,  3.30s/it]Training Epoch90:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:12,  3.29s/it]Training Epoch90:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:55<01:08,  3.27s/it]Training Epoch90:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:58<01:06,  3.31s/it]Training Epoch90:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.28s/it]Training Epoch90:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:05<00:59,  3.31s/it]Training Epoch90:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:08<00:56,  3.31s/it]Training Epoch90:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:53,  3.34s/it]Training Epoch90:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:15<00:50,  3.35s/it]Training Epoch90:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:18<00:46,  3.33s/it]Training Epoch90:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.31s/it]Training Epoch90:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:25<00:39,  3.30s/it]Training Epoch90:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:28<00:36,  3.30s/it]Training Epoch90:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:33,  3.31s/it]Training Epoch90:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.32s/it]Training Epoch90:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:38<00:26,  3.32s/it]Training Epoch90:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:41<00:23,  3.32s/it]Training Epoch90:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.31s/it]Training Epoch90:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:48<00:16,  3.30s/it]Training Epoch90:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.31s/it]Training Epoch90:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.31s/it]Training Epoch90:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:58<00:06,  3.32s/it]Training Epoch90:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:01<00:03,  3.32s/it]Training Epoch90: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.33s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch90: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 7.599147647852078e-05

 step 1 is completed and loss is 0.00019756790425162762

 step 2 is completed and loss is 3.909984661731869e-05

 step 3 is completed and loss is 8.898343367036432e-05

 step 4 is completed and loss is 7.938812632346526e-05

 step 5 is completed and loss is 6.091361501603387e-05

 step 6 is completed and loss is 0.0005338683840818703

 step 7 is completed and loss is 5.715866063837893e-05

 step 8 is completed and loss is 7.13441550033167e-05

 step 9 is completed and loss is 4.023225847049616e-05

 step 10 is completed and loss is 0.0005636526038870215

 step 11 is completed and loss is 0.0006520831375382841

 step 12 is completed and loss is 0.00024557937285862863

 step 13 is completed and loss is 8.695939322933555e-05

 step 14 is completed and loss is 4.941093720844947e-05

 step 15 is completed and loss is 3.71926071238704e-05

 step 16 is completed and loss is 0.00016871887783054262

 step 17 is completed and loss is 0.00015281117521226406

 step 18 is completed and loss is 4.136471761739813e-05

 step 19 is completed and loss is 0.00013534842582885176

 step 20 is completed and loss is 4.4344866182655096e-05

 step 21 is completed and loss is 5.93045842833817e-05

 step 22 is completed and loss is 0.0002912796044256538

 step 23 is completed and loss is 0.0001141350221587345

 step 24 is completed and loss is 6.90793531248346e-05

 step 25 is completed and loss is 0.00034041961771436036

 step 26 is completed and loss is 5.334464367479086e-05

 step 27 is completed and loss is 0.0003064995107706636

 step 28 is completed and loss is 0.0001413667923770845

 step 29 is completed and loss is 7.438381726387888e-05

 step 30 is completed and loss is 8.934332436183468e-05

 step 31 is completed and loss is 1.591429281688761e-05

 step 32 is completed and loss is 5.990048521198332e-05

 step 33 is completed and loss is 9.035596303874627e-05

 step 34 is completed and loss is 5.94240591453854e-05

 step 35 is completed and loss is 0.00015758065273985267

 step 36 is completed and loss is 1.8656019165064208e-05

 step 37 is completed and loss is 6.693371688015759e-05

 step 38 is completed and loss is 8.082018757704645e-05

 step 39 is completed and loss is 5.6086399126797915e-05

 step 40 is completed and loss is 0.00010108371498063207

 step 41 is completed and loss is 4.321189771872014e-05

 step 42 is completed and loss is 6.413252413040027e-05

 step 43 is completed and loss is 6.413170194718987e-05

 step 44 is completed and loss is 2.616596975713037e-05

 step 45 is completed and loss is 0.0003175636229570955

 step 46 is completed and loss is 2.5927596652763896e-05

 step 47 is completed and loss is 8.487341256113723e-05

 step 48 is completed and loss is 0.0005543850129470229

 step 49 is completed and loss is 9.619722550269216e-05

 step 50 is completed and loss is 7.861531048547477e-05

 step 51 is completed and loss is 6.425173341995105e-05

 step 52 is completed and loss is 0.001409314339980483

 step 53 is completed and loss is 0.00036994245601817966

 step 54 is completed and loss is 5.167545168660581e-05

 step 55 is completed and loss is 0.0015414028894156218

 step 56 is completed and loss is 3.5762135667027906e-05

 step 57 is completed and loss is 0.00040498757152818143

 step 58 is completed and loss is 6.663461681455374e-05

 step 59 is completed and loss is 0.00023450290609616786

 step 60 is completed and loss is 9.768705058377236e-05

 step 61 is completed and loss is 8.058012463152409e-05

 step 62 is completed and loss is 8.862667164066806e-05

 step 63 is completed and loss is 0.00024916636175476015

 step 64 is completed and loss is 0.0002299079205840826

 step 65 is completed and loss is 8.099942351691425e-05

 step 66 is completed and loss is 0.0005479824030771852

 step 67 is completed and loss is 5.376153058023192e-05

 step 68 is completed and loss is 0.00016509034321643412

 step 69 is completed and loss is 0.00014947704039514065

 step 70 is completed and loss is 0.00021484628086909652

 step 71 is completed and loss is 0.0001423237263225019

 step 72 is completed and loss is 0.0004048132977914065

 step 73 is completed and loss is 8.332364086527377e-05

 step 74 is completed and loss is 0.00010287182522006333

 step 75 is completed and loss is 0.0002352289156988263

 step 76 is completed and loss is 0.00013773670070804656

 step 77 is completed and loss is 7.170141179813072e-05

 step 78 is completed and loss is 0.0001817147567635402

 step 79 is completed and loss is 0.0005054319044575095

 step 80 is completed and loss is 0.0002603782631922513

 step 81 is completed and loss is 8.499248360749334e-05

 step 82 is completed and loss is 0.00022395813721232116

 step 83 is completed and loss is 0.00015209868433885276

 step 84 is completed and loss is 8.445573621429503e-05

 step 85 is completed and loss is 0.0001481661747675389

 step 86 is completed and loss is 0.0001003691868390888

 step 87 is completed and loss is 0.00014667467621620744

 step 88 is completed and loss is 0.00013952053268440068

 step 89 is completed and loss is 5.733789294026792e-05

 step 90 is completed and loss is 0.0007334260153584182

 step 91 is completed and loss is 0.00017777361790649593
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.34it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:35,  1.34it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:35,  1.32it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:33,  1.39it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.44it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.49it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.48it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.48it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.48it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.50it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.49it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.51it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.51it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:22,  1.53it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.54it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.55it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:20,  1.55it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.55it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.55it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.51it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.49it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.50it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.49it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.47it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.47it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:16,  1.43it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:15,  1.46it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.48it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.46it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.43it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.44it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.42it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:11,  1.43it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.45it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.44it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.46it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.46it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.47it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.50it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.51it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.50it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.57it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.58it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.58it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.57it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.56it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.54it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.52it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.49it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 91: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 305.1253415079991s
Training Epoch91:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch91:   1%|[34m          [0m| 1/92 [00:03<05:01,  3.31s/it]Training Epoch91:   2%|[34mâ–         [0m| 2/92 [00:06<04:55,  3.29s/it]Training Epoch91:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.28s/it]Training Epoch91:   4%|[34mâ–         [0m| 4/92 [00:13<04:48,  3.27s/it]Training Epoch91:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:45,  3.28s/it]Training Epoch91:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:41,  3.27s/it]Training Epoch91:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:41,  3.31s/it]Training Epoch91:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:40,  3.33s/it]Training Epoch91:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:37,  3.34s/it]Training Epoch91:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.33s/it]Training Epoch91:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:30,  3.34s/it]Training Epoch91:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:27,  3.35s/it]Training Epoch91:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:24,  3.35s/it]Training Epoch91:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.33s/it]Training Epoch91:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.30s/it]Training Epoch91:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.29s/it]Training Epoch91:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.31s/it]Training Epoch91:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.32s/it]Training Epoch91:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:00,  3.30s/it]Training Epoch91:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:57,  3.30s/it]Training Epoch91:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:54,  3.30s/it]Training Epoch91:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.30s/it]Training Epoch91:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:48,  3.31s/it]Training Epoch91:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:44,  3.30s/it]Training Epoch91:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.30s/it]Training Epoch91:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:37,  3.30s/it]Training Epoch91:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:35,  3.31s/it]Training Epoch91:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:30,  3.29s/it]Training Epoch91:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:26,  3.28s/it]Training Epoch91:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:23,  3.29s/it]Training Epoch91:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.30s/it]Training Epoch91:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:18,  3.31s/it]Training Epoch91:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:14,  3.30s/it]Training Epoch91:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:10,  3.28s/it]Training Epoch91:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:07,  3.29s/it]Training Epoch91:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:04,  3.30s/it]Training Epoch91:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:00,  3.28s/it]Training Epoch91:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:56,  3.26s/it]Training Epoch91:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.29s/it]Training Epoch91:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:51,  3.31s/it]Training Epoch91:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:48,  3.31s/it]Training Epoch91:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:46,  3.33s/it]Training Epoch91:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:42,  3.33s/it]Training Epoch91:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.31s/it]Training Epoch91:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:35,  3.30s/it]Training Epoch91:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:32,  3.31s/it]Training Epoch91:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.31s/it]Training Epoch91:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.31s/it]Training Epoch91:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.32s/it]Training Epoch91:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:45<02:19,  3.33s/it]Training Epoch91:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:16,  3.32s/it]Training Epoch91:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.29s/it]Training Epoch91:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:55<02:08,  3.30s/it]Training Epoch91:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.30s/it]Training Epoch91:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.29s/it]Training Epoch91:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:57,  3.28s/it]Training Epoch91:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:54,  3.27s/it]Training Epoch91:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:51,  3.27s/it]Training Epoch91:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:48,  3.28s/it]Training Epoch91:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:43,  3.25s/it]Training Epoch91:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:39,  3.22s/it]Training Epoch91:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:37,  3.25s/it]Training Epoch91:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:34,  3.24s/it]Training Epoch91:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:31,  3.26s/it]Training Epoch91:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.27s/it]Training Epoch91:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.27s/it]Training Epoch91:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:21,  3.27s/it]Training Epoch91:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.30s/it]Training Epoch91:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:15,  3.27s/it]Training Epoch91:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:11,  3.26s/it]Training Epoch91:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.25s/it]Training Epoch91:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.27s/it]Training Epoch91:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:01,  3.23s/it]Training Epoch91:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:58,  3.26s/it]Training Epoch91:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:55,  3.28s/it]Training Epoch91:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.30s/it]Training Epoch91:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:49,  3.32s/it]Training Epoch91:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.31s/it]Training Epoch91:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.31s/it]Training Epoch91:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:39,  3.29s/it]Training Epoch91:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:36,  3.32s/it]Training Epoch91:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.31s/it]Training Epoch91:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.30s/it]Training Epoch91:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.30s/it]Training Epoch91:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.31s/it]Training Epoch91:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.29s/it]Training Epoch91:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.29s/it]Training Epoch91:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.31s/it]Training Epoch91:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.32s/it]Training Epoch91:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.30s/it]Training Epoch91:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.30s/it]Training Epoch91: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch91: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 0.00011115231609437615

 step 1 is completed and loss is 0.00016544756363146007

 step 2 is completed and loss is 3.510649548843503e-05

 step 3 is completed and loss is 0.0001072191953426227

 step 4 is completed and loss is 8.546685421606526e-05

 step 5 is completed and loss is 4.6252065658336505e-05

 step 6 is completed and loss is 0.0009441356523893774

 step 7 is completed and loss is 6.2105456891004e-05

 step 8 is completed and loss is 5.8470403018873185e-05

 step 9 is completed and loss is 4.315258775022812e-05

 step 10 is completed and loss is 0.0003890866646543145

 step 11 is completed and loss is 0.001358419074676931

 step 12 is completed and loss is 0.00020655567641369998

 step 13 is completed and loss is 6.323847628664225e-05

 step 14 is completed and loss is 4.511947190621868e-05

 step 15 is completed and loss is 4.124556289752945e-05

 step 16 is completed and loss is 0.00018438957340549678

 step 17 is completed and loss is 0.00014780684432480484

 step 18 is completed and loss is 5.346390753402375e-05

 step 19 is completed and loss is 0.00014672971155960113

 step 20 is completed and loss is 5.7874312915373594e-05

 step 21 is completed and loss is 6.0973667132202536e-05

 step 22 is completed and loss is 0.00025387058849446476

 step 23 is completed and loss is 8.326407987624407e-05

 step 24 is completed and loss is 5.9245197917334735e-05

 step 25 is completed and loss is 0.00020268201478756964

 step 26 is completed and loss is 5.322525248629972e-05

 step 27 is completed and loss is 0.00023064110428094864

 step 28 is completed and loss is 0.00013087884872220457

 step 29 is completed and loss is 9.017769480124116e-05

 step 30 is completed and loss is 0.00013773530372418463

 step 31 is completed and loss is 1.6629506717436016e-05

 step 32 is completed and loss is 6.019855209160596e-05

 step 33 is completed and loss is 8.505211008014157e-05

 step 34 is completed and loss is 7.045008533168584e-05

 step 35 is completed and loss is 0.00018499477300792933

 step 36 is completed and loss is 1.5377861927845515e-05

 step 37 is completed and loss is 6.919850420672446e-05

 step 38 is completed and loss is 7.676774839637801e-05

 step 39 is completed and loss is 5.21526817465201e-05

 step 40 is completed and loss is 8.266817167168483e-05

 step 41 is completed and loss is 5.6264165323227644e-05

 step 42 is completed and loss is 7.080780778778717e-05

 step 43 is completed and loss is 6.341654079733416e-05

 step 44 is completed and loss is 2.4497063350281678e-05

 step 45 is completed and loss is 0.00019107021216768771

 step 46 is completed and loss is 2.092097929562442e-05

 step 47 is completed and loss is 8.761485514696687e-05

 step 48 is completed and loss is 0.0007013202412053943

 step 49 is completed and loss is 7.301299774553627e-05

 step 50 is completed and loss is 8.952213102020323e-05

 step 51 is completed and loss is 5.322552897268906e-05

 step 52 is completed and loss is 0.0023795836605131626

 step 53 is completed and loss is 0.000274081714451313

 step 54 is completed and loss is 4.303331661503762e-05

 step 55 is completed and loss is 0.0011804295936599374

 step 56 is completed and loss is 3.90402419725433e-05

 step 57 is completed and loss is 0.0003184399101883173

 step 58 is completed and loss is 6.299900996964425e-05

 step 59 is completed and loss is 0.00023289694217965007

 step 60 is completed and loss is 7.897282193880528e-05

 step 61 is completed and loss is 6.836283864686266e-05

 step 62 is completed and loss is 8.344132220372558e-05

 step 63 is completed and loss is 0.00026752398116514087

 step 64 is completed and loss is 0.00040658543002791703

 step 65 is completed and loss is 9.095252607949078e-05

 step 66 is completed and loss is 0.0005553081864491105

 step 67 is completed and loss is 6.240357470232993e-05

 step 68 is completed and loss is 0.00018028760678134859

 step 69 is completed and loss is 0.00014983335859142244

 step 70 is completed and loss is 0.00015841361891943961

 step 71 is completed and loss is 0.0002202621108153835

 step 72 is completed and loss is 0.0003933163534384221

 step 73 is completed and loss is 8.272782724816352e-05

 step 74 is completed and loss is 0.00011777141480706632

 step 75 is completed and loss is 0.00017915548232849687

 step 76 is completed and loss is 0.0001303466851823032

 step 77 is completed and loss is 8.159506251104176e-05

 step 78 is completed and loss is 0.00017408969870302826

 step 79 is completed and loss is 0.0010934098390862346

 step 80 is completed and loss is 0.0003428464406169951

 step 81 is completed and loss is 0.00010036886669695377

 step 82 is completed and loss is 0.00014005920093040913

 step 83 is completed and loss is 0.00019279951811768115

 step 84 is completed and loss is 8.725643419893458e-05

 step 85 is completed and loss is 0.00014506718434859067

 step 86 is completed and loss is 8.689979586051777e-05

 step 87 is completed and loss is 0.00015919029829092324

 step 88 is completed and loss is 0.00021674297749996185

 step 89 is completed and loss is 6.782697164453566e-05

 step 90 is completed and loss is 0.000656584685202688

 step 91 is completed and loss is 6.276133353821933e-05
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:37,  1.30it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:36,  1.32it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.41it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.48it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.50it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.52it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.46it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:28,  1.46it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.48it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.49it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.49it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.53it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.51it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:22,  1.53it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.54it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:21,  1.57it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:19,  1.62it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.60it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.60it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.59it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.60it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:16,  1.62it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.61it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.59it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.55it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.52it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.54it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.58it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.61it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:11,  1.62it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.57it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.56it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.55it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.58it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.58it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.59it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.59it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:06,  1.61it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.60it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.60it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.59it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.57it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.58it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.54it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.50it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.52it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.53it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.55it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.53it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 92: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 303.5402306429969s
Training Epoch92:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch92:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.29s/it]Training Epoch92:   2%|[34mâ–         [0m| 2/92 [00:06<04:53,  3.27s/it]Training Epoch92:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:49,  3.25s/it]Training Epoch92:   4%|[34mâ–         [0m| 4/92 [00:12<04:43,  3.23s/it]Training Epoch92:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:41,  3.23s/it]Training Epoch92:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:39,  3.25s/it]Training Epoch92:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:38,  3.27s/it]Training Epoch92:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.30s/it]Training Epoch92:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:34,  3.31s/it]Training Epoch92:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:30,  3.30s/it]Training Epoch92:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:26,  3.29s/it]Training Epoch92:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:23,  3.30s/it]Training Epoch92:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.29s/it]Training Epoch92:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.30s/it]Training Epoch92:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:14,  3.30s/it]Training Epoch92:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:10,  3.29s/it]Training Epoch92:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:06,  3.29s/it]Training Epoch92:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:02,  3.28s/it]Training Epoch92:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:58,  3.27s/it]Training Epoch92:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:55,  3.28s/it]Training Epoch92:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:52,  3.28s/it]Training Epoch92:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:51,  3.30s/it]Training Epoch92:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.30s/it]Training Epoch92:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:43,  3.28s/it]Training Epoch92:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:37,  3.25s/it]Training Epoch92:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:36,  3.27s/it]Training Epoch92:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:33,  3.28s/it]Training Epoch92:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:31,  3.30s/it]Training Epoch92:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:27,  3.30s/it]Training Epoch92:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:22,  3.27s/it]Training Epoch92:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:20,  3.29s/it]Training Epoch92:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:16,  3.28s/it]Training Epoch92:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:14,  3.29s/it]Training Epoch92:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:51<03:10,  3.29s/it]Training Epoch92:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:54<03:06,  3.27s/it]Training Epoch92:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:03,  3.27s/it]Training Epoch92:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:01,  3.29s/it]Training Epoch92:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:04<02:56,  3.27s/it]Training Epoch92:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:54,  3.28s/it]Training Epoch92:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:50,  3.27s/it]Training Epoch92:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:46,  3.26s/it]Training Epoch92:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:17<02:41,  3.23s/it]Training Epoch92:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:20<02:39,  3.25s/it]Training Epoch92:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:37,  3.28s/it]Training Epoch92:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:34,  3.28s/it]Training Epoch92:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:30<02:31,  3.29s/it]Training Epoch92:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.30s/it]Training Epoch92:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:24,  3.30s/it]Training Epoch92:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:21,  3.30s/it]Training Epoch92:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:18,  3.30s/it]Training Epoch92:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:15,  3.30s/it]Training Epoch92:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:11,  3.30s/it]Training Epoch92:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.30s/it]Training Epoch92:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:04,  3.28s/it]Training Epoch92:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<02:00,  3.27s/it]Training Epoch92:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:57,  3.27s/it]Training Epoch92:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:54,  3.28s/it]Training Epoch92:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:52,  3.29s/it]Training Epoch92:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:49,  3.32s/it]Training Epoch92:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:45,  3.31s/it]Training Epoch92:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:42,  3.30s/it]Training Epoch92:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:38,  3.30s/it]Training Epoch92:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:35,  3.31s/it]Training Epoch92:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:32,  3.29s/it]Training Epoch92:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:27,  3.26s/it]Training Epoch92:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:25,  3.28s/it]Training Epoch92:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:40<01:22,  3.28s/it]Training Epoch92:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:18,  3.29s/it]Training Epoch92:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:15,  3.28s/it]Training Epoch92:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:12,  3.29s/it]Training Epoch92:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.27s/it]Training Epoch92:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:05,  3.27s/it]Training Epoch92:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.29s/it]Training Epoch92:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:58,  3.26s/it]Training Epoch92:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:54,  3.23s/it]Training Epoch92:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:52,  3.27s/it]Training Epoch92:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.29s/it]Training Epoch92:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:46,  3.29s/it]Training Epoch92:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.30s/it]Training Epoch92:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.30s/it]Training Epoch92:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.30s/it]Training Epoch92:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:33,  3.32s/it]Training Epoch92:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.33s/it]Training Epoch92:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.35s/it]Training Epoch92:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.36s/it]Training Epoch92:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:20,  3.35s/it]Training Epoch92:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.34s/it]Training Epoch92:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.34s/it]Training Epoch92:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:10,  3.36s/it]Training Epoch92:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.36s/it]Training Epoch92:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.35s/it]Training Epoch92: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.35s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch92: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 9.536008292343467e-05

 step 1 is completed and loss is 0.0001663415168877691

 step 2 is completed and loss is 3.260318408138119e-05

 step 3 is completed and loss is 7.366717181866989e-05

 step 4 is completed and loss is 8.576479740440845e-05

 step 5 is completed and loss is 4.52388048870489e-05

 step 6 is completed and loss is 0.0006681204540655017

 step 7 is completed and loss is 7.956742047099397e-05

 step 8 is completed and loss is 7.092700980138034e-05

 step 9 is completed and loss is 3.5940829548053443e-05

 step 10 is completed and loss is 0.00029396163881756365

 step 11 is completed and loss is 0.0023507638834416866

 step 12 is completed and loss is 0.00035674156970344484

 step 13 is completed and loss is 6.216570909600705e-05

 step 14 is completed and loss is 4.410641486174427e-05

 step 15 is completed and loss is 4.136476854910143e-05

 step 16 is completed and loss is 0.00024188656243495643

 step 17 is completed and loss is 0.00011514801008161157

 step 18 is completed and loss is 4.8636145947966725e-05

 step 19 is completed and loss is 0.0001494708121754229

 step 20 is completed and loss is 4.3450825614854693e-05

 step 21 is completed and loss is 5.6503573432564735e-05

 step 22 is completed and loss is 0.00041071797022596

 step 23 is completed and loss is 0.00011240674939472228

 step 24 is completed and loss is 6.496693822555244e-05

 step 25 is completed and loss is 0.00019648556190077215

 step 26 is completed and loss is 6.299979577306658e-05

 step 27 is completed and loss is 0.00015728373546153307

 step 28 is completed and loss is 0.00010245305020362139

 step 29 is completed and loss is 8.415822230745107e-05

 step 30 is completed and loss is 0.00010013057180913165

 step 31 is completed and loss is 1.651031016081106e-05

 step 32 is completed and loss is 8.016385982045904e-05

 step 33 is completed and loss is 9.51838301261887e-05

 step 34 is completed and loss is 8.338298357557505e-05

 step 35 is completed and loss is 0.00017527976888231933

 step 36 is completed and loss is 1.7463971744291484e-05

 step 37 is completed and loss is 5.79936386202462e-05

 step 38 is completed and loss is 7.968761201482266e-05

 step 39 is completed and loss is 5.1556660764617845e-05

 step 40 is completed and loss is 9.762762783793733e-05

 step 41 is completed and loss is 3.129177275695838e-05

 step 42 is completed and loss is 5.7516826927894726e-05

 step 43 is completed and loss is 5.858924123458564e-05

 step 44 is completed and loss is 2.5271932827308774e-05

 step 45 is completed and loss is 0.00024362458498217165

 step 46 is completed and loss is 1.94308868231019e-05

 step 47 is completed and loss is 7.17018119757995e-05

 step 48 is completed and loss is 0.000384223967557773

 step 49 is completed and loss is 6.413254595827311e-05

 step 50 is completed and loss is 7.533734606113285e-05

 step 51 is completed and loss is 6.19272468611598e-05

 step 52 is completed and loss is 0.0022996345069259405

 step 53 is completed and loss is 0.00036589076626114547

 step 54 is completed and loss is 4.041098145535216e-05

 step 55 is completed and loss is 0.0019641390535980463

 step 56 is completed and loss is 4.4106382119935006e-05

 step 57 is completed and loss is 0.0004943747771903872

 step 58 is completed and loss is 7.193872443167493e-05

 step 59 is completed and loss is 0.00023492149193771183

 step 60 is completed and loss is 9.834237425820902e-05

 step 61 is completed and loss is 7.450138946296647e-05

 step 62 is completed and loss is 9.720817615743726e-05

 step 63 is completed and loss is 0.0007821485633030534

 step 64 is completed and loss is 0.0002129253844032064

 step 65 is completed and loss is 9.518384467810392e-05

 step 66 is completed and loss is 0.0005423252005130053

 step 67 is completed and loss is 6.824395677540451e-05

 step 68 is completed and loss is 0.00018910759536083788

 step 69 is completed and loss is 0.00013892867718823254

 step 70 is completed and loss is 0.00019136897753924131

 step 71 is completed and loss is 0.0002284256333950907

 step 72 is completed and loss is 0.0005793453310616314

 step 73 is completed and loss is 8.165502367774025e-05

 step 74 is completed and loss is 0.00013243187277112156

 step 75 is completed and loss is 0.00023314410645980388

 step 76 is completed and loss is 0.00015323134721256793

 step 77 is completed and loss is 6.93772963131778e-05

 step 78 is completed and loss is 0.00018934407853521407

 step 79 is completed and loss is 0.0007195801590569317

 step 80 is completed and loss is 0.00029553574859164655

 step 81 is completed and loss is 9.667374251876026e-05

 step 82 is completed and loss is 0.00020572675566654652

 step 83 is completed and loss is 0.0001649716286920011

 step 84 is completed and loss is 0.0002210939273936674

 step 85 is completed and loss is 0.00015615197480656207

 step 86 is completed and loss is 9.142934868577868e-05

 step 87 is completed and loss is 0.00014893879415467381

 step 88 is completed and loss is 0.0001240855490323156

 step 89 is completed and loss is 7.283373270183802e-05

 step 90 is completed and loss is 0.0009094894048757851

 step 91 is completed and loss is 0.0001926113764056936
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.39it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:31,  1.52it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.47it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.51it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.48it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.47it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.46it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.47it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:27,  1.48it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.51it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.49it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.53it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.52it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.55it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.56it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:20,  1.58it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.59it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.60it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.59it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.58it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.50it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.56it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.57it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:16,  1.54it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:15,  1.54it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.58it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.51it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.46it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.45it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.46it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:11,  1.50it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.49it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:11,  1.45it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.47it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.48it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.49it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.49it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.50it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.50it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.54it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.50it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.50it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.51it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.49it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.48it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:02,  1.48it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.48it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.48it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.47it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.50it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 93: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 303.2051284179979s
Training Epoch93:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch93:   1%|[34m          [0m| 1/92 [00:03<05:01,  3.31s/it]Training Epoch93:   2%|[34mâ–         [0m| 2/92 [00:06<04:53,  3.26s/it]Training Epoch93:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:53,  3.29s/it]Training Epoch93:   4%|[34mâ–         [0m| 4/92 [00:13<04:51,  3.31s/it]Training Epoch93:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:48,  3.31s/it]Training Epoch93:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:44,  3.31s/it]Training Epoch93:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:42,  3.32s/it]Training Epoch93:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch93:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.32s/it]Training Epoch93:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.34s/it]Training Epoch93:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.31s/it]Training Epoch93:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:24,  3.31s/it]Training Epoch93:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:20,  3.29s/it]Training Epoch93:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:15,  3.28s/it]Training Epoch93:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:13,  3.29s/it]Training Epoch93:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.31s/it]Training Epoch93:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:08,  3.31s/it]Training Epoch93:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:06,  3.32s/it]Training Epoch93:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.32s/it]Training Epoch93:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:58,  3.31s/it]Training Epoch93:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:53,  3.28s/it]Training Epoch93:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch93:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.27s/it]Training Epoch93:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:43,  3.29s/it]Training Epoch93:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.30s/it]Training Epoch93:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:37,  3.30s/it]Training Epoch93:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:32,  3.27s/it]Training Epoch93:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:29,  3.27s/it]Training Epoch93:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:25,  3.26s/it]Training Epoch93:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:21,  3.26s/it]Training Epoch93:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:19,  3.27s/it]Training Epoch93:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:16,  3.28s/it]Training Epoch93:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:13,  3.28s/it]Training Epoch93:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.30s/it]Training Epoch93:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:07,  3.29s/it]Training Epoch93:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:04,  3.29s/it]Training Epoch93:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:02,  3.31s/it]Training Epoch93:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:59,  3.32s/it]Training Epoch93:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:55,  3.30s/it]Training Epoch93:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:51,  3.29s/it]Training Epoch93:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:48,  3.30s/it]Training Epoch93:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:46,  3.32s/it]Training Epoch93:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:42,  3.32s/it]Training Epoch93:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:39,  3.33s/it]Training Epoch93:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:36,  3.33s/it]Training Epoch93:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:32,  3.31s/it]Training Epoch93:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.32s/it]Training Epoch93:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.31s/it]Training Epoch93:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:21,  3.30s/it]Training Epoch93:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:18,  3.29s/it]Training Epoch93:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.30s/it]Training Epoch93:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:11,  3.28s/it]Training Epoch93:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:07,  3.27s/it]Training Epoch93:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:04,  3.27s/it]Training Epoch93:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:01,  3.29s/it]Training Epoch93:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:59,  3.31s/it]Training Epoch93:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:56,  3.33s/it]Training Epoch93:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.31s/it]Training Epoch93:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.30s/it]Training Epoch93:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:45,  3.29s/it]Training Epoch93:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.30s/it]Training Epoch93:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.31s/it]Training Epoch93:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:35,  3.29s/it]Training Epoch93:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.30s/it]Training Epoch93:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:28,  3.29s/it]Training Epoch93:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.27s/it]Training Epoch93:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.30s/it]Training Epoch93:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.31s/it]Training Epoch93:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.31s/it]Training Epoch93:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.30s/it]Training Epoch93:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:08,  3.28s/it]Training Epoch93:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.27s/it]Training Epoch93:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:02,  3.27s/it]Training Epoch93:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:59,  3.28s/it]Training Epoch93:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:55,  3.28s/it]Training Epoch93:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.27s/it]Training Epoch93:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:49,  3.27s/it]Training Epoch93:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:45,  3.24s/it]Training Epoch93:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.24s/it]Training Epoch93:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:39,  3.26s/it]Training Epoch93:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:36,  3.29s/it]Training Epoch93:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:33,  3.31s/it]Training Epoch93:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.32s/it]Training Epoch93:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.29s/it]Training Epoch93:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:22,  3.27s/it]Training Epoch93:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.26s/it]Training Epoch93:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.25s/it]Training Epoch93:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:49<00:13,  3.26s/it]Training Epoch93:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.26s/it]Training Epoch93:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.27s/it]Training Epoch93:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:59<00:03,  3.29s/it]Training Epoch93: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch93: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.29s/it]

 step 0 is completed and loss is 8.326232637045905e-05

 step 1 is completed and loss is 0.0001490002468926832

 step 2 is completed and loss is 3.707338328240439e-05

 step 3 is completed and loss is 8.582496229792014e-05

 step 4 is completed and loss is 9.094963752431795e-05

 step 5 is completed and loss is 4.9768597818911076e-05

 step 6 is completed and loss is 0.00039295945316553116

 step 7 is completed and loss is 6.1032886151224375e-05

 step 8 is completed and loss is 7.611192995682359e-05

 step 9 is completed and loss is 4.172231274424121e-05

 step 10 is completed and loss is 0.0009367095190100372

 step 11 is completed and loss is 0.0013037155149504542

 step 12 is completed and loss is 0.0002602924651000649

 step 13 is completed and loss is 5.286791565595195e-05

 step 14 is completed and loss is 5.602677265414968e-05

 step 15 is completed and loss is 3.3854863431770355e-05

 step 16 is completed and loss is 0.0003610278363339603

 step 17 is completed and loss is 0.00010430208931211382

 step 18 is completed and loss is 5.143743328517303e-05

 step 19 is completed and loss is 0.00026238072314299643

 step 20 is completed and loss is 5.185465852264315e-05

 step 21 is completed and loss is 5.6324719480471686e-05

 step 22 is completed and loss is 0.0004982600803487003

 step 23 is completed and loss is 0.00010275293607264757

 step 24 is completed and loss is 7.045008533168584e-05

 step 25 is completed and loss is 0.00018075620755553246

 step 26 is completed and loss is 5.6086173572111875e-05

 step 27 is completed and loss is 0.00022307244944386184

 step 28 is completed and loss is 0.00013922160724177957

 step 29 is completed and loss is 7.658903632545844e-05

 step 30 is completed and loss is 7.742343586869538e-05

 step 31 is completed and loss is 2.0801726350327954e-05

 step 32 is completed and loss is 5.6443866924382746e-05

 step 33 is completed and loss is 0.00010287188342772424

 step 34 is completed and loss is 8.761404023971409e-05

 step 35 is completed and loss is 0.00018040392023976892

 step 36 is completed and loss is 1.9550083379726857e-05

 step 37 is completed and loss is 6.741056859027594e-05

 step 38 is completed and loss is 8.916386286728084e-05

 step 39 is completed and loss is 5.858964868821204e-05

 step 40 is completed and loss is 9.595885057933629e-05

 step 41 is completed and loss is 5.191361560719088e-05

 step 42 is completed and loss is 7.790015661157668e-05

 step 43 is completed and loss is 5.80527848796919e-05

 step 44 is completed and loss is 1.9132832676405087e-05

 step 45 is completed and loss is 0.0001809414679883048

 step 46 is completed and loss is 2.6464025722816586e-05

 step 47 is completed and loss is 7.080778595991433e-05

 step 48 is completed and loss is 0.0006000608555041254

 step 49 is completed and loss is 8.67805938469246e-05

 step 50 is completed and loss is 7.253618241520599e-05

 step 51 is completed and loss is 5.924521974520758e-05

 step 52 is completed and loss is 0.0018650841666385531

 step 53 is completed and loss is 0.0003176872560288757

 step 54 is completed and loss is 4.732469824375585e-05

 step 55 is completed and loss is 0.0015859933337196708

 step 56 is completed and loss is 3.826539250439964e-05

 step 57 is completed and loss is 0.00017205665062647313

 step 58 is completed and loss is 6.31779184914194e-05

 step 59 is completed and loss is 0.00023027320276014507

 step 60 is completed and loss is 0.00011389790597604588

 step 61 is completed and loss is 9.470462100580335e-05

 step 62 is completed and loss is 9.142732596956193e-05

 step 63 is completed and loss is 0.0004707193293143064

 step 64 is completed and loss is 0.0002352671726839617

 step 65 is completed and loss is 8.767399413045496e-05

 step 66 is completed and loss is 0.0005399464862421155

 step 67 is completed and loss is 6.693291652482003e-05

 step 68 is completed and loss is 0.00021270575234666467

 step 69 is completed and loss is 0.0001484630338381976

 step 70 is completed and loss is 0.00018719644867815077

 step 71 is completed and loss is 0.00027590914396569133

 step 72 is completed and loss is 0.0004195201036054641

 step 73 is completed and loss is 7.968823774717748e-05

 step 74 is completed and loss is 0.00011097712558694184

 step 75 is completed and loss is 0.00022748447372578084

 step 76 is completed and loss is 0.00013791548553854227

 step 77 is completed and loss is 8.749531116336584e-05

 step 78 is completed and loss is 0.00019440962933003902

 step 79 is completed and loss is 0.0007191500044427812

 step 80 is completed and loss is 0.0003128137905150652

 step 81 is completed and loss is 8.540966518921778e-05

 step 82 is completed and loss is 0.00014858045324217528

 step 83 is completed and loss is 0.00018242988153360784

 step 84 is completed and loss is 0.00010096350160893053

 step 85 is completed and loss is 0.00015567521040793508

 step 86 is completed and loss is 8.415821503149346e-05

 step 87 is completed and loss is 0.00015364712453447282

 step 88 is completed and loss is 0.00019964379316661507

 step 89 is completed and loss is 8.141600847011432e-05

 step 90 is completed and loss is 0.0012957665603607893

 step 91 is completed and loss is 0.00011025919229723513
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:34,  1.42it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.40it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:32,  1.43it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.44it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.46it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.48it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.51it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.50it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.47it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.53it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.55it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.55it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.56it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:23,  1.56it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:21,  1.59it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.60it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:20,  1.60it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:19,  1.63it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.62it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:18,  1.61it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.59it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.60it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:16,  1.60it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.54it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.57it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.56it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.57it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:13,  1.57it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.59it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:12,  1.57it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:12,  1.58it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:11,  1.60it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:10,  1.64it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:09,  1.63it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.62it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:08,  1.61it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.61it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.63it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:24<00:06,  1.62it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.62it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.63it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:26<00:04,  1.62it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.61it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.57it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:28<00:03,  1.58it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.59it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:29<00:01,  1.60it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.60it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.60it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.59it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:31<00:00,  1.57it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 94: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 303.29606589800096s
Training Epoch94:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch94:   1%|[34m          [0m| 1/92 [00:03<04:54,  3.24s/it]Training Epoch94:   2%|[34mâ–         [0m| 2/92 [00:06<04:48,  3.21s/it]Training Epoch94:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:45,  3.21s/it]Training Epoch94:   4%|[34mâ–         [0m| 4/92 [00:12<04:44,  3.23s/it]Training Epoch94:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:39,  3.22s/it]Training Epoch94:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:38,  3.24s/it]Training Epoch94:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:36,  3.25s/it]Training Epoch94:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:36,  3.29s/it]Training Epoch94:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:31,  3.27s/it]Training Epoch94:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:28,  3.27s/it]Training Epoch94:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:35<04:25,  3.28s/it]Training Epoch94:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:22,  3.28s/it]Training Epoch94:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.29s/it]Training Epoch94:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:17,  3.30s/it]Training Epoch94:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:48<04:12,  3.28s/it]Training Epoch94:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.29s/it]Training Epoch94:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:03,  3.25s/it]Training Epoch94:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:58<04:00,  3.25s/it]Training Epoch94:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<03:58,  3.27s/it]Training Epoch94:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:57,  3.29s/it]Training Epoch94:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:54,  3.30s/it]Training Epoch94:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:11<03:51,  3.30s/it]Training Epoch94:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:47,  3.30s/it]Training Epoch94:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:44,  3.29s/it]Training Epoch94:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:21<03:39,  3.27s/it]Training Epoch94:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:37,  3.30s/it]Training Epoch94:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.30s/it]Training Epoch94:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:31<03:32,  3.32s/it]Training Epoch94:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:30,  3.34s/it]Training Epoch94:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:26,  3.33s/it]Training Epoch94:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:41<03:24,  3.35s/it]Training Epoch94:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:24,  3.41s/it]Training Epoch94:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:21,  3.42s/it]Training Epoch94:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:18,  3.42s/it]Training Epoch94:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:11,  3.36s/it]Training Epoch94:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:09,  3.38s/it]Training Epoch94:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<03:06,  3.39s/it]Training Epoch94:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<03:03,  3.41s/it]Training Epoch94:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:09<03:00,  3.41s/it]Training Epoch94:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:12<02:56,  3.40s/it]Training Epoch94:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:51,  3.37s/it]Training Epoch94:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:19<02:47,  3.36s/it]Training Epoch94:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:22<02:44,  3.36s/it]Training Epoch94:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:26<02:42,  3.38s/it]Training Epoch94:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:29<02:39,  3.40s/it]Training Epoch94:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:32<02:36,  3.41s/it]Training Epoch94:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:36<02:34,  3.44s/it]Training Epoch94:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:39<02:30,  3.43s/it]Training Epoch94:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:43<02:25,  3.39s/it]Training Epoch94:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:46<02:20,  3.34s/it]Training Epoch94:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:49<02:16,  3.33s/it]Training Epoch94:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:53<02:13,  3.34s/it]Training Epoch94:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:56<02:08,  3.30s/it]Training Epoch94:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:59<02:04,  3.28s/it]Training Epoch94:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:02<02:02,  3.31s/it]Training Epoch94:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:06<01:59,  3.32s/it]Training Epoch94:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:09<01:56,  3.34s/it]Training Epoch94:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:12<01:54,  3.36s/it]Training Epoch94:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:16<01:51,  3.38s/it]Training Epoch94:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:19<01:47,  3.37s/it]Training Epoch94:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:23<01:45,  3.41s/it]Training Epoch94:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:26<01:41,  3.39s/it]Training Epoch94:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:30<01:38,  3.41s/it]Training Epoch94:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:33<01:35,  3.40s/it]Training Epoch94:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:36<01:30,  3.34s/it]Training Epoch94:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:39<01:26,  3.32s/it]Training Epoch94:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:43<01:22,  3.31s/it]Training Epoch94:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:46<01:19,  3.33s/it]Training Epoch94:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:49<01:16,  3.32s/it]Training Epoch94:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:53<01:13,  3.32s/it]Training Epoch94:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:56<01:10,  3.35s/it]Training Epoch94:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:59<01:06,  3.33s/it]Training Epoch94:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:03<01:03,  3.35s/it]Training Epoch94:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:06<01:00,  3.37s/it]Training Epoch94:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:10<00:57,  3.38s/it]Training Epoch94:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:13<00:54,  3.38s/it]Training Epoch94:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:16<00:50,  3.37s/it]Training Epoch94:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:20<00:47,  3.38s/it]Training Epoch94:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:23<00:43,  3.35s/it]Training Epoch94:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:26<00:39,  3.32s/it]Training Epoch94:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:30<00:36,  3.32s/it]Training Epoch94:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:33<00:33,  3.34s/it]Training Epoch94:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:36<00:30,  3.34s/it]Training Epoch94:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:40<00:26,  3.33s/it]Training Epoch94:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:43<00:23,  3.31s/it]Training Epoch94:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:46<00:19,  3.30s/it]Training Epoch94:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:49<00:16,  3.31s/it]Training Epoch94:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:53<00:13,  3.29s/it]Training Epoch94:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:56<00:09,  3.28s/it]Training Epoch94:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:59<00:06,  3.31s/it]Training Epoch94:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:03<00:03,  3.31s/it]Training Epoch94: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch94: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:06<00:00,  3.33s/it]

 step 0 is completed and loss is 0.00011639691365417093

 step 1 is completed and loss is 0.0002209274098277092

 step 2 is completed and loss is 3.6775389162357897e-05

 step 3 is completed and loss is 9.810127085074782e-05

 step 4 is completed and loss is 8.171228546416387e-05

 step 5 is completed and loss is 5.11988255311735e-05

 step 6 is completed and loss is 0.0009841988794505596

 step 7 is completed and loss is 5.358278940548189e-05

 step 8 is completed and loss is 8.260827598860487e-05

 step 9 is completed and loss is 4.351032112026587e-05

 step 10 is completed and loss is 0.0007029937696643174

 step 11 is completed and loss is 0.0013084628153592348

 step 12 is completed and loss is 0.0002871040487661958

 step 13 is completed and loss is 6.317891529761255e-05

 step 14 is completed and loss is 3.933827974833548e-05

 step 15 is completed and loss is 2.8729025871143676e-05

 step 16 is completed and loss is 0.00016949388373177499

 step 17 is completed and loss is 0.00012098863953724504

 step 18 is completed and loss is 5.167586277821101e-05

 step 19 is completed and loss is 0.00017741764895617962

 step 20 is completed and loss is 5.3225448937155306e-05

 step 21 is completed and loss is 8.362151856999844e-05

 step 22 is completed and loss is 0.00038325434434227645

 step 23 is completed and loss is 0.00013606814900413156

 step 24 is completed and loss is 6.645674875471741e-05

 step 25 is completed and loss is 0.0001713411184027791

 step 26 is completed and loss is 5.531142232939601e-05

 step 27 is completed and loss is 0.00019536411855369806

 step 28 is completed and loss is 0.00010149938316317275

 step 29 is completed and loss is 9.309808956459165e-05

 step 30 is completed and loss is 0.0001026331665343605

 step 31 is completed and loss is 1.6808344298624434e-05

 step 32 is completed and loss is 7.432351412717253e-05

 step 33 is completed and loss is 8.344290836248547e-05

 step 34 is completed and loss is 9.357403905596584e-05

 step 35 is completed and loss is 0.000208113735425286

 step 36 is completed and loss is 1.9848110241582617e-05

 step 37 is completed and loss is 5.972207145532593e-05

 step 38 is completed and loss is 8.356205944437534e-05

 step 39 is completed and loss is 5.096060340292752e-05

 step 40 is completed and loss is 0.00011073900532210246

 step 41 is completed and loss is 4.583421105053276e-05

 step 42 is completed and loss is 6.985419895499945e-05

 step 43 is completed and loss is 6.729061715304852e-05

 step 44 is completed and loss is 2.6404319214634597e-05

 step 45 is completed and loss is 0.0002656069991644472

 step 46 is completed and loss is 2.3662672901991755e-05

 step 47 is completed and loss is 7.503941742470488e-05

 step 48 is completed and loss is 0.0005237705772742629

 step 49 is completed and loss is 8.952216012403369e-05

 step 50 is completed and loss is 8.5528998170048e-05

 step 51 is completed and loss is 5.102020804770291e-05

 step 52 is completed and loss is 0.0018735366174951196

 step 53 is completed and loss is 0.00035718624712899327

 step 54 is completed and loss is 4.8338093620259315e-05

 step 55 is completed and loss is 0.0010365014895796776

 step 56 is completed and loss is 3.8801837945356965e-05

 step 57 is completed and loss is 0.0001321327144978568

 step 58 is completed and loss is 6.222425145097077e-05

 step 59 is completed and loss is 0.0002418912190478295

 step 60 is completed and loss is 9.130974649451673e-05

 step 61 is completed and loss is 8.85066983755678e-05

 step 62 is completed and loss is 8.797085320111364e-05

 step 63 is completed and loss is 0.00037445337511599064

 step 64 is completed and loss is 0.00023234802938532084

 step 65 is completed and loss is 7.825778448022902e-05

 step 66 is completed and loss is 0.0006052650860510767

 step 67 is completed and loss is 5.394022082327865e-05

 step 68 is completed and loss is 0.00017981011478696018

 step 69 is completed and loss is 0.00012653236626647413

 step 70 is completed and loss is 0.00019840065215248615

 step 71 is completed and loss is 0.000247850053710863

 step 72 is completed and loss is 0.0005279656616039574

 step 73 is completed and loss is 9.673361637396738e-05

 step 74 is completed and loss is 0.00010227569873677567

 step 75 is completed and loss is 0.00024810247123241425

 step 76 is completed and loss is 0.00014774897135794163

 step 77 is completed and loss is 8.59455976751633e-05

 step 78 is completed and loss is 0.00018439904670231044

 step 79 is completed and loss is 0.000416411436162889

 step 80 is completed and loss is 0.00025858954177238047

 step 81 is completed and loss is 9.15480122785084e-05

 step 82 is completed and loss is 0.0001292131346417591

 step 83 is completed and loss is 0.00014905986608937383

 step 84 is completed and loss is 9.983174095395952e-05

 step 85 is completed and loss is 0.00015293381875380874

 step 86 is completed and loss is 9.703165414975956e-05

 step 87 is completed and loss is 0.00012879625137429684

 step 88 is completed and loss is 0.00016871970728971064

 step 89 is completed and loss is 6.371489143930376e-05

 step 90 is completed and loss is 0.0006283096736297011

 step 91 is completed and loss is 0.00011979387636529282
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.36it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:36,  1.30it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:36,  1.29it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:33,  1.37it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.42it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:31,  1.39it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:29,  1.48it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:27,  1.51it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.51it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.49it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.48it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:26,  1.44it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:26,  1.42it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:25,  1.42it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.41it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.43it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:23,  1.40it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.40it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:21,  1.45it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:14<00:21,  1.42it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.45it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:19,  1.45it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:16<00:18,  1.49it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.49it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:16,  1.52it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:18<00:16,  1.49it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:15,  1.50it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:14,  1.53it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.50it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.45it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:12,  1.48it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:11,  1.50it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.51it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.54it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.53it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.53it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.52it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.48it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.45it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:07,  1.42it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:06,  1.39it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.41it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.40it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:04,  1.43it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.45it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.45it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:32<00:02,  1.46it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.47it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.45it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.40it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:34<00:00,  1.45it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 95: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 306.723521300999s
Training Epoch95:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch95:   1%|[34m          [0m| 1/92 [00:03<05:06,  3.37s/it]Training Epoch95:   2%|[34mâ–         [0m| 2/92 [00:06<04:58,  3.31s/it]Training Epoch95:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:52,  3.29s/it]Training Epoch95:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.27s/it]Training Epoch95:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.29s/it]Training Epoch95:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.26s/it]Training Epoch95:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch95:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:38,  3.31s/it]Training Epoch95:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:37,  3.34s/it]Training Epoch95:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:31,  3.31s/it]Training Epoch95:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:29,  3.33s/it]Training Epoch95:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:26,  3.33s/it]Training Epoch95:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:21,  3.31s/it]Training Epoch95:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:19,  3.33s/it]Training Epoch95:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:16,  3.34s/it]Training Epoch95:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:11,  3.30s/it]Training Epoch95:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:10,  3.34s/it]Training Epoch95:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:07,  3.34s/it]Training Epoch95:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:03,  3.34s/it]Training Epoch95:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:57,  3.30s/it]Training Epoch95:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:53,  3.29s/it]Training Epoch95:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch95:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:47,  3.29s/it]Training Epoch95:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:45,  3.32s/it]Training Epoch95:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:42,  3.32s/it]Training Epoch95:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:38,  3.30s/it]Training Epoch95:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.30s/it]Training Epoch95:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:32,  3.31s/it]Training Epoch95:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:36<03:29,  3.32s/it]Training Epoch95:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:24,  3.30s/it]Training Epoch95:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:20,  3.29s/it]Training Epoch95:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:18,  3.31s/it]Training Epoch95:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:49<03:15,  3.32s/it]Training Epoch95:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.30s/it]Training Epoch95:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:06,  3.27s/it]Training Epoch95:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:02,  3.26s/it]Training Epoch95:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:02<02:58,  3.25s/it]Training Epoch95:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:55,  3.26s/it]Training Epoch95:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:52,  3.25s/it]Training Epoch95:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:48,  3.25s/it]Training Epoch95:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:46,  3.27s/it]Training Epoch95:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:43,  3.27s/it]Training Epoch95:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:40,  3.27s/it]Training Epoch95:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:38,  3.31s/it]Training Epoch95:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:34,  3.30s/it]Training Epoch95:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:32,  3.31s/it]Training Epoch95:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:35<02:29,  3.32s/it]Training Epoch95:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:24,  3.29s/it]Training Epoch95:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:21,  3.29s/it]Training Epoch95:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:18,  3.29s/it]Training Epoch95:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:14,  3.28s/it]Training Epoch95:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:10,  3.27s/it]Training Epoch95:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.29s/it]Training Epoch95:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.31s/it]Training Epoch95:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.30s/it]Training Epoch95:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:58,  3.30s/it]Training Epoch95:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:54,  3.28s/it]Training Epoch95:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:51,  3.28s/it]Training Epoch95:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:48,  3.28s/it]Training Epoch95:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:45,  3.28s/it]Training Epoch95:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.30s/it]Training Epoch95:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.31s/it]Training Epoch95:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:36,  3.33s/it]Training Epoch95:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.32s/it]Training Epoch95:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.31s/it]Training Epoch95:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:25,  3.31s/it]Training Epoch95:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.30s/it]Training Epoch95:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:20,  3.34s/it]Training Epoch95:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.34s/it]Training Epoch95:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:13,  3.32s/it]Training Epoch95:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.30s/it]Training Epoch95:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.30s/it]Training Epoch95:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:02,  3.27s/it]Training Epoch95:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:58,  3.26s/it]Training Epoch95:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:55,  3.29s/it]Training Epoch95:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.29s/it]Training Epoch95:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:49,  3.29s/it]Training Epoch95:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.30s/it]Training Epoch95:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:43,  3.33s/it]Training Epoch95:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.32s/it]Training Epoch95:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.29s/it]Training Epoch95:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:32,  3.27s/it]Training Epoch95:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.28s/it]Training Epoch95:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.29s/it]Training Epoch95:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.32s/it]Training Epoch95:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.30s/it]Training Epoch95:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.30s/it]Training Epoch95:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.28s/it]Training Epoch95:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.27s/it]Training Epoch95:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.26s/it]Training Epoch95:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.29s/it]Training Epoch95: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.29s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch95: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 7.688537880312651e-05

 step 1 is completed and loss is 0.00016336234693881124

 step 2 is completed and loss is 3.5344899515621364e-05

 step 3 is completed and loss is 8.993697701953351e-05

 step 4 is completed and loss is 8.129516936605796e-05

 step 5 is completed and loss is 6.097342702560127e-05

 step 6 is completed and loss is 0.00039522291626781225

 step 7 is completed and loss is 5.566878826357424e-05

 step 8 is completed and loss is 8.070135663729161e-05

 step 9 is completed and loss is 3.820579877356067e-05

 step 10 is completed and loss is 0.0002960447163786739

 step 11 is completed and loss is 0.001267066108994186

 step 12 is completed and loss is 0.0003196893376298249

 step 13 is completed and loss is 6.836409738752991e-05

 step 14 is completed and loss is 4.023222209070809e-05

 step 15 is completed and loss is 3.93382906622719e-05

 step 16 is completed and loss is 0.00018367482698522508

 step 17 is completed and loss is 9.804414003156126e-05

 step 18 is completed and loss is 4.702695150626823e-05

 step 19 is completed and loss is 0.00011854225158458576

 step 20 is completed and loss is 4.5834916818421334e-05

 step 21 is completed and loss is 9.017698175739497e-05

 step 22 is completed and loss is 0.00027239721384830773

 step 23 is completed and loss is 0.00011103587894467637

 step 24 is completed and loss is 6.603974907193333e-05

 step 25 is completed and loss is 0.00014464632840827107

 step 26 is completed and loss is 6.907916394993663e-05

 step 27 is completed and loss is 0.00028075597947463393

 step 28 is completed and loss is 9.107039659284055e-05

 step 29 is completed and loss is 8.695934229763225e-05

 step 30 is completed and loss is 9.482633322477341e-05

 step 31 is completed and loss is 1.5079838703968562e-05

 step 32 is completed and loss is 0.00011878156510647386

 step 33 is completed and loss is 7.778056169627234e-05

 step 34 is completed and loss is 7.193997589638457e-05

 step 35 is completed and loss is 0.00017176417168229818

 step 36 is completed and loss is 1.5616269593010657e-05

 step 37 is completed and loss is 7.396660657832399e-05

 step 38 is completed and loss is 0.000133025212562643

 step 39 is completed and loss is 6.222514639375731e-05

 step 40 is completed and loss is 0.0001064481693902053

 step 41 is completed and loss is 4.7205165174091235e-05

 step 42 is completed and loss is 6.472854875028133e-05

 step 43 is completed and loss is 6.764845602447167e-05

 step 44 is completed and loss is 2.050372313533444e-05

 step 45 is completed and loss is 0.00021514479885809124

 step 46 is completed and loss is 2.39606924878899e-05

 step 47 is completed and loss is 8.302580681629479e-05

 step 48 is completed and loss is 0.0005262034828774631

 step 49 is completed and loss is 7.605259452247992e-05

 step 50 is completed and loss is 0.00010477883188286796

 step 51 is completed and loss is 5.7755227317102253e-05

 step 52 is completed and loss is 0.0011017204960808158

 step 53 is completed and loss is 0.00029969224124215543

 step 54 is completed and loss is 3.874211324728094e-05

 step 55 is completed and loss is 0.0009431387879885733

 step 56 is completed and loss is 4.416597221279517e-05

 step 57 is completed and loss is 0.0001841513585532084

 step 58 is completed and loss is 5.000644887331873e-05

 step 59 is completed and loss is 0.0007370027014985681

 step 60 is completed and loss is 0.00011050047032767907

 step 61 is completed and loss is 8.61224762047641e-05

 step 62 is completed and loss is 8.612385863671079e-05

 step 63 is completed and loss is 0.0005094330408610404

 step 64 is completed and loss is 0.00035351706901565194

 step 65 is completed and loss is 8.5588195361197e-05

 step 66 is completed and loss is 0.00030307748238556087

 step 67 is completed and loss is 5.7039585954044014e-05

 step 68 is completed and loss is 0.0001924447569763288

 step 69 is completed and loss is 0.00012891586811747402

 step 70 is completed and loss is 0.00019309614435769618

 step 71 is completed and loss is 0.0001567453145980835

 step 72 is completed and loss is 0.0004710402572527528

 step 73 is completed and loss is 9.357489761896431e-05

 step 74 is completed and loss is 0.00011258584709139541

 step 75 is completed and loss is 0.00019065706874243915

 step 76 is completed and loss is 0.00013743876479566097

 step 77 is completed and loss is 7.199966785265133e-05

 step 78 is completed and loss is 0.00015215802704915404

 step 79 is completed and loss is 0.0008924805442802608

 step 80 is completed and loss is 0.00028051817207597196

 step 81 is completed and loss is 9.208456322085112e-05

 step 82 is completed and loss is 0.0001028719125315547

 step 83 is completed and loss is 0.00016228857566602528

 step 84 is completed and loss is 0.0001275421236641705

 step 85 is completed and loss is 0.00014768941036891192

 step 86 is completed and loss is 8.320462075062096e-05

 step 87 is completed and loss is 0.00013177627988625318

 step 88 is completed and loss is 0.00023247516946867108

 step 89 is completed and loss is 6.025811308063567e-05

 step 90 is completed and loss is 0.00041614254587329924

 step 91 is completed and loss is 0.00016281870193779469
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:36,  1.35it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.39it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:33,  1.40it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.40it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.44it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:31,  1.41it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:30,  1.42it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:30,  1.37it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:30,  1.36it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:07<00:29,  1.36it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:28,  1.36it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:27,  1.37it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:09<00:26,  1.40it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:10<00:25,  1.43it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:24,  1.46it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:11<00:23,  1.43it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:12<00:23,  1.41it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:22,  1.42it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:13<00:20,  1.50it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:14<00:20,  1.47it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:19,  1.51it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:18,  1.48it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:16<00:18,  1.47it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:17,  1.45it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.43it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:18<00:16,  1.46it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:16,  1.42it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:15,  1.41it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:20<00:14,  1.43it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:21<00:13,  1.47it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:12,  1.46it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:22<00:12,  1.48it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:23<00:11,  1.47it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:10,  1.46it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:10,  1.48it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.55it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:08,  1.59it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:07,  1.59it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:06,  1.58it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.60it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:05,  1.55it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.50it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.50it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:03,  1.52it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.54it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.60it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.61it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.56it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.57it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.58it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.47it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 96: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 303.72659427799954s
Training Epoch96:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch96:   1%|[34m          [0m| 1/92 [00:03<05:05,  3.36s/it]Training Epoch96:   2%|[34mâ–         [0m| 2/92 [00:06<05:02,  3.37s/it]Training Epoch96:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:53,  3.30s/it]Training Epoch96:   4%|[34mâ–         [0m| 4/92 [00:13<04:52,  3.32s/it]Training Epoch96:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.29s/it]Training Epoch96:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.30s/it]Training Epoch96:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:44,  3.34s/it]Training Epoch96:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:39,  3.33s/it]Training Epoch96:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:37,  3.35s/it]Training Epoch96:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:33,  3.33s/it]Training Epoch96:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:31,  3.35s/it]Training Epoch96:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:30,  3.38s/it]Training Epoch96:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:24,  3.35s/it]Training Epoch96:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:20,  3.34s/it]Training Epoch96:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:15,  3.32s/it]Training Epoch96:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:10,  3.30s/it]Training Epoch96:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.30s/it]Training Epoch96:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:03,  3.29s/it]Training Epoch96:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:00,  3.29s/it]Training Epoch96:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:56,  3.29s/it]Training Epoch96:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:53,  3.28s/it]Training Epoch96:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:49,  3.28s/it]Training Epoch96:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:16<03:45,  3.27s/it]Training Epoch96:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:43,  3.28s/it]Training Epoch96:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:40,  3.29s/it]Training Epoch96:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:26<03:36,  3.28s/it]Training Epoch96:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:29<03:34,  3.30s/it]Training Epoch96:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:29,  3.28s/it]Training Epoch96:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:25,  3.27s/it]Training Epoch96:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:39<03:22,  3.26s/it]Training Epoch96:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:18,  3.25s/it]Training Epoch96:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:15,  3.26s/it]Training Epoch96:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:12,  3.26s/it]Training Epoch96:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:09,  3.26s/it]Training Epoch96:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:04,  3.24s/it]Training Epoch96:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:02,  3.25s/it]Training Epoch96:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:59,  3.26s/it]Training Epoch96:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:55,  3.26s/it]Training Epoch96:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:52,  3.26s/it]Training Epoch96:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:49,  3.26s/it]Training Epoch96:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:47,  3.28s/it]Training Epoch96:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:44,  3.29s/it]Training Epoch96:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:41,  3.30s/it]Training Epoch96:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:38,  3.30s/it]Training Epoch96:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:34,  3.29s/it]Training Epoch96:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:31,  3.30s/it]Training Epoch96:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:28,  3.30s/it]Training Epoch96:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:25,  3.31s/it]Training Epoch96:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.31s/it]Training Epoch96:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:18,  3.30s/it]Training Epoch96:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.31s/it]Training Epoch96:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:12,  3.30s/it]Training Epoch96:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:08,  3.30s/it]Training Epoch96:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:05,  3.31s/it]Training Epoch96:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.31s/it]Training Epoch96:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:59,  3.31s/it]Training Epoch96:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:56,  3.32s/it]Training Epoch96:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:52,  3.32s/it]Training Epoch96:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:49,  3.30s/it]Training Epoch96:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:45,  3.30s/it]Training Epoch96:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:42,  3.30s/it]Training Epoch96:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.31s/it]Training Epoch96:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:27<01:36,  3.31s/it]Training Epoch96:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.32s/it]Training Epoch96:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.32s/it]Training Epoch96:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:37<01:26,  3.31s/it]Training Epoch96:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.31s/it]Training Epoch96:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:19,  3.31s/it]Training Epoch96:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:16,  3.31s/it]Training Epoch96:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:50<01:12,  3.30s/it]Training Epoch96:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:08,  3.26s/it]Training Epoch96:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.28s/it]Training Epoch96:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:00<01:02,  3.28s/it]Training Epoch96:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:03<00:59,  3.28s/it]Training Epoch96:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:55,  3.28s/it]Training Epoch96:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:10<00:52,  3.29s/it]Training Epoch96:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:13<00:49,  3.28s/it]Training Epoch96:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:45,  3.27s/it]Training Epoch96:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:20<00:42,  3.27s/it]Training Epoch96:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:23<00:39,  3.28s/it]Training Epoch96:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:26<00:36,  3.28s/it]Training Epoch96:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:30<00:32,  3.29s/it]Training Epoch96:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:33<00:29,  3.30s/it]Training Epoch96:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:36<00:26,  3.30s/it]Training Epoch96:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:22,  3.29s/it]Training Epoch96:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:43<00:19,  3.29s/it]Training Epoch96:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:46<00:16,  3.29s/it]Training Epoch96:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:50<00:13,  3.30s/it]Training Epoch96:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:53<00:09,  3.31s/it]Training Epoch96:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:56<00:06,  3.32s/it]Training Epoch96:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.33s/it]Training Epoch96: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.32s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch96: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:03<00:00,  3.30s/it]

 step 0 is completed and loss is 7.181983528425917e-05

 step 1 is completed and loss is 0.00021550437668338418

 step 2 is completed and loss is 3.3080028515541926e-05

 step 3 is completed and loss is 9.303584374720231e-05

 step 4 is completed and loss is 7.861360063543543e-05

 step 5 is completed and loss is 5.692058402928524e-05

 step 6 is completed and loss is 0.0006470489897765219

 step 7 is completed and loss is 5.22120863024611e-05

 step 8 is completed and loss is 9.19657395570539e-05

 step 9 is completed and loss is 3.915937850251794e-05

 step 10 is completed and loss is 0.0003339974791742861

 step 11 is completed and loss is 0.001041825977154076

 step 12 is completed and loss is 0.00024438713444396853

 step 13 is completed and loss is 6.151010165922344e-05

 step 14 is completed and loss is 3.8026966649340466e-05

 step 15 is completed and loss is 3.659658250398934e-05

 step 16 is completed and loss is 0.0003513790143188089

 step 17 is completed and loss is 0.00011425474076531827

 step 18 is completed and loss is 5.626519487123005e-05

 step 19 is completed and loss is 0.00018659331544768065

 step 20 is completed and loss is 3.826544707408175e-05

 step 21 is completed and loss is 7.31917389202863e-05

 step 22 is completed and loss is 0.0003840321733150631

 step 23 is completed and loss is 0.0001248040935024619

 step 24 is completed and loss is 5.7099576224572957e-05

 step 25 is completed and loss is 0.0001599595125298947

 step 26 is completed and loss is 6.770842446712777e-05

 step 27 is completed and loss is 0.0001253404770977795

 step 28 is completed and loss is 0.0001445843663532287

 step 29 is completed and loss is 7.867503154557198e-05

 step 30 is completed and loss is 0.00010203756392002106

 step 31 is completed and loss is 1.609310129424557e-05

 step 32 is completed and loss is 0.0001093068640329875

 step 33 is completed and loss is 7.545662811025977e-05

 step 34 is completed and loss is 6.222531374078244e-05

 step 35 is completed and loss is 0.00025917653692886233

 step 36 is completed and loss is 1.6271909771603532e-05

 step 37 is completed and loss is 6.162913632579148e-05

 step 38 is completed and loss is 0.00012289518781471997

 step 39 is completed and loss is 5.0483664381317794e-05

 step 40 is completed and loss is 0.00010495790775166824

 step 41 is completed and loss is 3.063619078602642e-05

 step 42 is completed and loss is 6.836415559519082e-05

 step 43 is completed and loss is 6.937634316273034e-05

 step 44 is completed and loss is 2.5033510610228404e-05

 step 45 is completed and loss is 0.00033722553052939475

 step 46 is completed and loss is 2.0086536096641794e-05

 step 47 is completed and loss is 6.13313022768125e-05

 step 48 is completed and loss is 0.0010474695591256022

 step 49 is completed and loss is 8.481374243274331e-05

 step 50 is completed and loss is 7.539700163761154e-05

 step 51 is completed and loss is 5.8172365243081003e-05

 step 52 is completed and loss is 0.002440946875140071

 step 53 is completed and loss is 0.00047048693522810936

 step 54 is completed and loss is 4.345060733612627e-05

 step 55 is completed and loss is 0.001609015860594809

 step 56 is completed and loss is 4.058984632138163e-05

 step 57 is completed and loss is 0.00028043484780937433

 step 58 is completed and loss is 5.513194264494814e-05

 step 59 is completed and loss is 0.0004924855893477798

 step 60 is completed and loss is 9.566049266140908e-05

 step 61 is completed and loss is 7.545483094872907e-05

 step 62 is completed and loss is 6.985350046306849e-05

 step 63 is completed and loss is 0.00025006511714309454

 step 64 is completed and loss is 0.0001723498571664095

 step 65 is completed and loss is 0.00010036895400844514

 step 66 is completed and loss is 0.0005894278874620795

 step 67 is completed and loss is 4.8159163270611316e-05

 step 68 is completed and loss is 0.00017814230523072183

 step 69 is completed and loss is 0.0001600239920662716

 step 70 is completed and loss is 0.00016330031212419271

 step 71 is completed and loss is 0.00018129407544620335

 step 72 is completed and loss is 0.0005263516795821488

 step 73 is completed and loss is 9.256162593374029e-05

 step 74 is completed and loss is 9.810419578570873e-05

 step 75 is completed and loss is 0.0002634138218127191

 step 76 is completed and loss is 0.00015102647012099624

 step 77 is completed and loss is 6.097342338762246e-05

 step 78 is completed and loss is 0.00015662795340176672

 step 79 is completed and loss is 0.0005769799463450909

 step 80 is completed and loss is 0.0002659781603142619

 step 81 is completed and loss is 0.00012963058543391526

 step 82 is completed and loss is 0.00010829530947376043

 step 83 is completed and loss is 0.00014458918303716928

 step 84 is completed and loss is 0.00013397914881352335

 step 85 is completed and loss is 0.00011359999916749075

 step 86 is completed and loss is 0.00010251473577227443

 step 87 is completed and loss is 0.00016073936421889812

 step 88 is completed and loss is 0.00017271235992666334

 step 89 is completed and loss is 6.460897566284984e-05

 step 90 is completed and loss is 0.0009420850547030568

 step 91 is completed and loss is 0.00022252072812989354
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.38it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:33,  1.44it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.47it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:30,  1.52it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:28,  1.58it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:27,  1.60it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:26,  1.60it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:25,  1.62it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:25,  1.61it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:25,  1.57it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.55it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:24,  1.58it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.59it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:08<00:22,  1.58it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:22,  1.55it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.58it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:10<00:21,  1.55it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.54it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.60it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:12<00:19,  1.58it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:18,  1.58it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.58it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:14<00:17,  1.58it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:15<00:16,  1.55it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:15,  1.55it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.56it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:17<00:14,  1.56it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.52it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.50it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:19<00:12,  1.50it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:20<00:12,  1.48it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.50it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:21<00:10,  1.52it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:22<00:09,  1.51it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.50it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:23<00:08,  1.52it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:24<00:07,  1.54it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.52it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:25<00:06,  1.54it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:26<00:05,  1.56it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.57it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:27<00:04,  1.57it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:28<00:03,  1.55it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.55it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:29<00:02,  1.56it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.54it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:30<00:01,  1.55it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:31<00:00,  1.54it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.54it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.55it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 97: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 303.62538997999945s
Training Epoch97:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch97:   1%|[34m          [0m| 1/92 [00:03<05:01,  3.31s/it]Training Epoch97:   2%|[34mâ–         [0m| 2/92 [00:06<04:58,  3.32s/it]Training Epoch97:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.27s/it]Training Epoch97:   4%|[34mâ–         [0m| 4/92 [00:13<04:49,  3.29s/it]Training Epoch97:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:46,  3.29s/it]Training Epoch97:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:43,  3.30s/it]Training Epoch97:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:40,  3.30s/it]Training Epoch97:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch97:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:35,  3.32s/it]Training Epoch97:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:31,  3.32s/it]Training Epoch97:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch97:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.32s/it]Training Epoch97:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:19,  3.29s/it]Training Epoch97:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:46<04:17,  3.31s/it]Training Epoch97:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:12,  3.28s/it]Training Epoch97:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.28s/it]Training Epoch97:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:56<04:07,  3.30s/it]Training Epoch97:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:04,  3.31s/it]Training Epoch97:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:02,  3.32s/it]Training Epoch97:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:56,  3.29s/it]Training Epoch97:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:09<03:51,  3.27s/it]Training Epoch97:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:48,  3.26s/it]Training Epoch97:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:45,  3.26s/it]Training Epoch97:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:19<03:43,  3.28s/it]Training Epoch97:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:39,  3.28s/it]Training Epoch97:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:37,  3.30s/it]Training Epoch97:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.30s/it]Training Epoch97:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.30s/it]Training Epoch97:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:28,  3.30s/it]Training Epoch97:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:25,  3.32s/it]Training Epoch97:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:21,  3.31s/it]Training Epoch97:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:17,  3.30s/it]Training Epoch97:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:15,  3.31s/it]Training Epoch97:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:12,  3.32s/it]Training Epoch97:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:07,  3.29s/it]Training Epoch97:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:03,  3.27s/it]Training Epoch97:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<02:59,  3.27s/it]Training Epoch97:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:56,  3.27s/it]Training Epoch97:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:53,  3.27s/it]Training Epoch97:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:49,  3.25s/it]Training Epoch97:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:14<02:44,  3.23s/it]Training Epoch97:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:40,  3.22s/it]Training Epoch97:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:37,  3.22s/it]Training Epoch97:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:24<02:35,  3.24s/it]Training Epoch97:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:27<02:32,  3.24s/it]Training Epoch97:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:29,  3.25s/it]Training Epoch97:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:27,  3.27s/it]Training Epoch97:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:37<02:23,  3.27s/it]Training Epoch97:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:40<02:21,  3.29s/it]Training Epoch97:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:18,  3.30s/it]Training Epoch97:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:47<02:13,  3.26s/it]Training Epoch97:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:50<02:10,  3.25s/it]Training Epoch97:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:53<02:06,  3.25s/it]Training Epoch97:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:57<02:03,  3.25s/it]Training Epoch97:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:00<01:59,  3.24s/it]Training Epoch97:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:03<01:57,  3.27s/it]Training Epoch97:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:07<01:55,  3.30s/it]Training Epoch97:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:10<01:52,  3.32s/it]Training Epoch97:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:13<01:49,  3.33s/it]Training Epoch97:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:17<01:46,  3.31s/it]Training Epoch97:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:20<01:42,  3.30s/it]Training Epoch97:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:23<01:38,  3.28s/it]Training Epoch97:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:26<01:35,  3.29s/it]Training Epoch97:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:30<01:31,  3.27s/it]Training Epoch97:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:33<01:28,  3.27s/it]Training Epoch97:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:36<01:24,  3.24s/it]Training Epoch97:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:39<01:21,  3.25s/it]Training Epoch97:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:43<01:18,  3.27s/it]Training Epoch97:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:46<01:15,  3.28s/it]Training Epoch97:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:49<01:12,  3.28s/it]Training Epoch97:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:53<01:08,  3.27s/it]Training Epoch97:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:56<01:05,  3.27s/it]Training Epoch97:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [03:59<01:02,  3.29s/it]Training Epoch97:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:02<00:58,  3.28s/it]Training Epoch97:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:06<00:55,  3.28s/it]Training Epoch97:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:09<00:53,  3.32s/it]Training Epoch97:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:12<00:49,  3.32s/it]Training Epoch97:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:16<00:45,  3.28s/it]Training Epoch97:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:19<00:42,  3.28s/it]Training Epoch97:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:22<00:39,  3.27s/it]Training Epoch97:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:25<00:36,  3.28s/it]Training Epoch97:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:29<00:32,  3.27s/it]Training Epoch97:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:32<00:29,  3.26s/it]Training Epoch97:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:35<00:26,  3.27s/it]Training Epoch97:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:39<00:23,  3.29s/it]Training Epoch97:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:42<00:19,  3.28s/it]Training Epoch97:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:45<00:16,  3.29s/it]Training Epoch97:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:48<00:13,  3.31s/it]Training Epoch97:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:52<00:09,  3.31s/it]Training Epoch97:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:55<00:06,  3.27s/it]Training Epoch97:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [04:58<00:03,  3.30s/it]Training Epoch97: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.38s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch97: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:02<00:00,  3.29s/it]

 step 0 is completed and loss is 9.416762623004615e-05

 step 1 is completed and loss is 0.00015835552767384797

 step 2 is completed and loss is 3.87422478524968e-05

 step 3 is completed and loss is 0.00010835163993760943

 step 4 is completed and loss is 7.658704271307215e-05

 step 5 is completed and loss is 4.649051697924733e-05

 step 6 is completed and loss is 0.0002149017236661166

 step 7 is completed and loss is 4.8695626901462674e-05

 step 8 is completed and loss is 7.962863310240209e-05

 step 9 is completed and loss is 4.219910624669865e-05

 step 10 is completed and loss is 0.00048110229545272887

 step 11 is completed and loss is 0.0006561323534697294

 step 12 is completed and loss is 0.00021048961207270622

 step 13 is completed and loss is 6.311928882496431e-05

 step 14 is completed and loss is 5.4059939429862425e-05

 step 15 is completed and loss is 4.5536911784438416e-05

 step 16 is completed and loss is 0.00027500951546244323

 step 17 is completed and loss is 0.00015936676936689764

 step 18 is completed and loss is 6.44899409962818e-05

 step 19 is completed and loss is 0.00014541909331455827

 step 20 is completed and loss is 3.611975989770144e-05

 step 21 is completed and loss is 5.9781646996270865e-05

 step 22 is completed and loss is 0.0004158905940130353

 step 23 is completed and loss is 0.0001080565998563543

 step 24 is completed and loss is 6.800655683036894e-05

 step 25 is completed and loss is 0.00016621800023131073

 step 26 is completed and loss is 6.568193202838302e-05

 step 27 is completed and loss is 0.00023058374063111842

 step 28 is completed and loss is 0.00011455075582489371

 step 29 is completed and loss is 8.117811375996098e-05

 step 30 is completed and loss is 0.00010746094631031156

 step 31 is completed and loss is 1.9848090232699178e-05

 step 32 is completed and loss is 7.223785360110924e-05

 step 33 is completed and loss is 7.91517086327076e-05

 step 34 is completed and loss is 8.111825445666909e-05

 step 35 is completed and loss is 0.00020471644529607147

 step 36 is completed and loss is 1.770240669429768e-05

 step 37 is completed and loss is 6.764890713384375e-05

 step 38 is completed and loss is 8.588611672166735e-05

 step 39 is completed and loss is 6.800658593419939e-05

 step 40 is completed and loss is 0.0001016206806525588

 step 41 is completed and loss is 5.197317659622058e-05

 step 42 is completed and loss is 6.62185630062595e-05

 step 43 is completed and loss is 7.551525777671486e-05

 step 44 is completed and loss is 2.6463949325261638e-05

 step 45 is completed and loss is 0.00019953370792791247

 step 46 is completed and loss is 1.829844586609397e-05

 step 47 is completed and loss is 8.183369936887175e-05

 step 48 is completed and loss is 0.00042871604091487825

 step 49 is completed and loss is 7.980738882906735e-05

 step 50 is completed and loss is 8.284689101856202e-05

 step 51 is completed and loss is 6.05564855504781e-05

 step 52 is completed and loss is 0.002101734047755599

 step 53 is completed and loss is 0.0002925508306361735

 step 54 is completed and loss is 3.719246160471812e-05

 step 55 is completed and loss is 0.0015124118654057384

 step 56 is completed and loss is 3.8682563172187656e-05

 step 57 is completed and loss is 0.00021495950932148844

 step 58 is completed and loss is 5.1436887588351965e-05

 step 59 is completed and loss is 0.0002154387766495347

 step 60 is completed and loss is 0.00010305098840035498

 step 61 is completed and loss is 7.819644088158384e-05

 step 62 is completed and loss is 8.642141619930044e-05

 step 63 is completed and loss is 0.0004452793800737709

 step 64 is completed and loss is 0.0002420003293082118

 step 65 is completed and loss is 8.386019908357412e-05

 step 66 is completed and loss is 0.0005966397002339363

 step 67 is completed and loss is 6.293979822658002e-05

 step 68 is completed and loss is 0.00018910752260126173

 step 69 is completed and loss is 0.00013082355144433677

 step 70 is completed and loss is 0.00016133504686877131

 step 71 is completed and loss is 0.0002262789203086868

 step 72 is completed and loss is 0.0005914957728236914

 step 73 is completed and loss is 8.231059473473579e-05

 step 74 is completed and loss is 0.00010418331658001989

 step 75 is completed and loss is 0.0001811220427043736

 step 76 is completed and loss is 0.00013874971773475409

 step 77 is completed and loss is 7.754230318823829e-05

 step 78 is completed and loss is 0.00023933926422614604

 step 79 is completed and loss is 0.0005903562996536493

 step 80 is completed and loss is 0.00031102681532502174

 step 81 is completed and loss is 8.827012788970023e-05

 step 82 is completed and loss is 0.00020131526980549097

 step 83 is completed and loss is 0.00019995227921754122

 step 84 is completed and loss is 8.523054566467181e-05

 step 85 is completed and loss is 0.00013684290752280504

 step 86 is completed and loss is 8.761498611420393e-05

 step 87 is completed and loss is 0.00015507859643548727

 step 88 is completed and loss is 0.0002779306669253856

 step 89 is completed and loss is 6.54435862088576e-05

 step 90 is completed and loss is 0.0007371995016001165

 step 91 is completed and loss is 0.0001281973090954125
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:39,  1.23it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:34,  1.39it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:34,  1.37it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:32,  1.42it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:31,  1.42it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:30,  1.43it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:05<00:31,  1.38it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:29,  1.44it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.50it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.49it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:25,  1.52it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:24,  1.55it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:23,  1.57it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:22,  1.57it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:22,  1.56it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:21,  1.57it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:20,  1.60it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:20,  1.59it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:19,  1.61it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:18,  1.64it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:17,  1.62it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:17,  1.62it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:16,  1.63it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.62it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.60it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:16<00:14,  1.60it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:14,  1.62it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:13,  1.61it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:18<00:13,  1.52it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.44it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:13,  1.43it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.41it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.45it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.46it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:10,  1.45it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.45it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.45it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:08,  1.50it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.52it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.51it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.53it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.51it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:04,  1.46it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.49it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.51it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.53it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.49it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.51it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.50it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.51it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 98: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 302.62813972000004s
Training Epoch98:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch98:   1%|[34m          [0m| 1/92 [00:03<05:18,  3.50s/it]Training Epoch98:   2%|[34mâ–         [0m| 2/92 [00:06<05:07,  3.42s/it]Training Epoch98:   3%|[34mâ–Ž         [0m| 3/92 [00:10<05:03,  3.41s/it]Training Epoch98:   4%|[34mâ–         [0m| 4/92 [00:13<04:58,  3.39s/it]Training Epoch98:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:53,  3.37s/it]Training Epoch98:   7%|[34mâ–‹         [0m| 6/92 [00:20<04:48,  3.36s/it]Training Epoch98:   8%|[34mâ–Š         [0m| 7/92 [00:23<04:43,  3.33s/it]Training Epoch98:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:41,  3.35s/it]Training Epoch98:  10%|[34mâ–‰         [0m| 9/92 [00:30<04:37,  3.34s/it]Training Epoch98:  11%|[34mâ–ˆ         [0m| 10/92 [00:33<04:32,  3.32s/it]Training Epoch98:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:28,  3.32s/it]Training Epoch98:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:40<04:30,  3.38s/it]Training Epoch98:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:43<04:26,  3.37s/it]Training Epoch98:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:47<04:23,  3.38s/it]Training Epoch98:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:50<04:19,  3.37s/it]Training Epoch98:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:53<04:14,  3.35s/it]Training Epoch98:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:57<04:10,  3.34s/it]Training Epoch98:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [01:00<04:06,  3.33s/it]Training Epoch98:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:03<04:01,  3.31s/it]Training Epoch98:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:06<03:57,  3.30s/it]Training Epoch98:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:10<03:58,  3.36s/it]Training Epoch98:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:13<03:55,  3.37s/it]Training Epoch98:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:17<03:54,  3.39s/it]Training Epoch98:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:20<03:51,  3.40s/it]Training Epoch98:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:24<03:49,  3.42s/it]Training Epoch98:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:27<03:44,  3.41s/it]Training Epoch98:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:30<03:41,  3.40s/it]Training Epoch98:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:34<03:39,  3.43s/it]Training Epoch98:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:37<03:34,  3.41s/it]Training Epoch98:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:41<03:31,  3.41s/it]Training Epoch98:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:44<03:27,  3.40s/it]Training Epoch98:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:48<03:24,  3.41s/it]Training Epoch98:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:51<03:19,  3.38s/it]Training Epoch98:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:54<03:16,  3.39s/it]Training Epoch98:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:58<03:12,  3.38s/it]Training Epoch98:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [02:01<03:07,  3.36s/it]Training Epoch98:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:04<03:06,  3.39s/it]Training Epoch98:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:08<03:03,  3.40s/it]Training Epoch98:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:11<02:59,  3.38s/it]Training Epoch98:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:14<02:53,  3.34s/it]Training Epoch98:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:18<02:50,  3.34s/it]Training Epoch98:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:21<02:46,  3.33s/it]Training Epoch98:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:24<02:41,  3.29s/it]Training Epoch98:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:27<02:37,  3.28s/it]Training Epoch98:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:31<02:36,  3.34s/it]Training Epoch98:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:34<02:32,  3.31s/it]Training Epoch98:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:37<02:28,  3.29s/it]Training Epoch98:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:41<02:23,  3.27s/it]Training Epoch98:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:44<02:21,  3.28s/it]Training Epoch98:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:47<02:17,  3.28s/it]Training Epoch98:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:51<02:15,  3.30s/it]Training Epoch98:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:54<02:13,  3.34s/it]Training Epoch98:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:58<02:12,  3.41s/it]Training Epoch98:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [03:01<02:09,  3.41s/it]Training Epoch98:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:04<02:04,  3.38s/it]Training Epoch98:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:08<02:01,  3.37s/it]Training Epoch98:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:11<01:57,  3.37s/it]Training Epoch98:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:14<01:53,  3.34s/it]Training Epoch98:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:18<01:49,  3.32s/it]Training Epoch98:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:21<01:45,  3.29s/it]Training Epoch98:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:24<01:41,  3.28s/it]Training Epoch98:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:27<01:38,  3.28s/it]Training Epoch98:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:31<01:35,  3.30s/it]Training Epoch98:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:34<01:32,  3.29s/it]Training Epoch98:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:37<01:28,  3.28s/it]Training Epoch98:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:41<01:25,  3.30s/it]Training Epoch98:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:44<01:22,  3.29s/it]Training Epoch98:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:47<01:19,  3.29s/it]Training Epoch98:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:50<01:15,  3.30s/it]Training Epoch98:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:54<01:12,  3.28s/it]Training Epoch98:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:57<01:09,  3.29s/it]Training Epoch98:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [04:00<01:06,  3.32s/it]Training Epoch98:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:04<01:03,  3.33s/it]Training Epoch98:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:07<01:00,  3.36s/it]Training Epoch98:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:11<00:57,  3.38s/it]Training Epoch98:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:14<00:53,  3.37s/it]Training Epoch98:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:17<00:49,  3.33s/it]Training Epoch98:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:20<00:46,  3.32s/it]Training Epoch98:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:24<00:42,  3.28s/it]Training Epoch98:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:27<00:39,  3.32s/it]Training Epoch98:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:30<00:36,  3.31s/it]Training Epoch98:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:34<00:32,  3.29s/it]Training Epoch98:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:37<00:29,  3.31s/it]Training Epoch98:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:40<00:26,  3.29s/it]Training Epoch98:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:44<00:23,  3.31s/it]Training Epoch98:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:47<00:19,  3.32s/it]Training Epoch98:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:50<00:16,  3.34s/it]Training Epoch98:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:54<00:13,  3.35s/it]Training Epoch98:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:57<00:10,  3.34s/it]Training Epoch98:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [05:00<00:06,  3.32s/it]Training Epoch98:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:03<00:03,  3.28s/it]Training Epoch98: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:07<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch98: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:07<00:00,  3.34s/it]

 step 0 is completed and loss is 0.00011383412493159994

 step 1 is completed and loss is 0.00016741480794735253

 step 2 is completed and loss is 3.6954166716896e-05

 step 3 is completed and loss is 7.509745773859322e-05

 step 4 is completed and loss is 8.689744572620839e-05

 step 5 is completed and loss is 5.465583672048524e-05

 step 6 is completed and loss is 0.0007090690778568387

 step 7 is completed and loss is 5.745685484725982e-05

 step 8 is completed and loss is 6.198679329827428e-05

 step 9 is completed and loss is 4.261630238033831e-05

 step 10 is completed and loss is 0.0006168563268147409

 step 11 is completed and loss is 0.0007437015301547945

 step 12 is completed and loss is 0.0002998012350872159

 step 13 is completed and loss is 5.173547106096521e-05

 step 14 is completed and loss is 4.124552651774138e-05

 step 15 is completed and loss is 3.158996332786046e-05

 step 16 is completed and loss is 0.00024319771910086274

 step 17 is completed and loss is 0.00010942726657958701

 step 18 is completed and loss is 5.686121585313231e-05

 step 19 is completed and loss is 0.00012158257595729083

 step 20 is completed and loss is 4.839769098907709e-05

 step 21 is completed and loss is 5.447713192552328e-05

 step 22 is completed and loss is 0.00031433493131771684

 step 23 is completed and loss is 7.670812192372978e-05

 step 24 is completed and loss is 7.676780660403892e-05

 step 25 is completed and loss is 0.0002373013412579894

 step 26 is completed and loss is 6.639696948695928e-05

 step 27 is completed and loss is 0.00019149115541949868

 step 28 is completed and loss is 0.00013034211588092148

 step 29 is completed and loss is 9.446866170037538e-05

 step 30 is completed and loss is 8.064176654443145e-05

 step 31 is completed and loss is 1.5377851013909094e-05

 step 32 is completed and loss is 7.867399835959077e-05

 step 33 is completed and loss is 7.247614848893136e-05

 step 34 is completed and loss is 8.46347538754344e-05

 step 35 is completed and loss is 0.00014667591312900186

 step 36 is completed and loss is 2.062296334770508e-05

 step 37 is completed and loss is 8.153555245371535e-05

 step 38 is completed and loss is 7.247659959830344e-05

 step 39 is completed and loss is 5.173538374947384e-05

 step 40 is completed and loss is 0.00010209728498011827

 step 41 is completed and loss is 4.041075590066612e-05

 step 42 is completed and loss is 7.754259422654286e-05

 step 43 is completed and loss is 6.75291521474719e-05

 step 44 is completed and loss is 2.4377866793656722e-05

 step 45 is completed and loss is 0.00016371867968700826

 step 46 is completed and loss is 1.8715669284574687e-05

 step 47 is completed and loss is 8.248942322097719e-05

 step 48 is completed and loss is 0.0007397843291983008

 step 49 is completed and loss is 8.57673876453191e-05

 step 50 is completed and loss is 9.154835424851626e-05

 step 51 is completed and loss is 7.092699524946511e-05

 step 52 is completed and loss is 0.0016420424217358232

 step 53 is completed and loss is 0.00028516334714367986

 step 54 is completed and loss is 3.415274841245264e-05

 step 55 is completed and loss is 0.0010583278490230441

 step 56 is completed and loss is 4.136452480452135e-05

 step 57 is completed and loss is 0.00021024975285399705

 step 58 is completed and loss is 6.830335041740909e-05

 step 59 is completed and loss is 0.0003042095631826669

 step 60 is completed and loss is 0.00010662667045835406

 step 61 is completed and loss is 7.241555431392044e-05

 step 62 is completed and loss is 8.934121433412656e-05

 step 63 is completed and loss is 0.0005917809903621674

 step 64 is completed and loss is 0.000304016430163756

 step 65 is completed and loss is 8.850892481859773e-05

 step 66 is completed and loss is 0.00036014628130942583

 step 67 is completed and loss is 0.00011526451271492988

 step 68 is completed and loss is 0.0001646732707740739

 step 69 is completed and loss is 0.0001848743559094146

 step 70 is completed and loss is 0.00017086956358980387

 step 71 is completed and loss is 0.00014178805577103049

 step 72 is completed and loss is 0.0005707187810912728

 step 73 is completed and loss is 8.386021363548934e-05

 step 74 is completed and loss is 9.583952487446368e-05

 step 75 is completed and loss is 0.00021496962290257215

 step 76 is completed and loss is 0.00012456532567739487

 step 77 is completed and loss is 7.718459528405219e-05

 step 78 is completed and loss is 0.00018016708781942725

 step 79 is completed and loss is 0.0007489744457416236

 step 80 is completed and loss is 0.0002780759532470256

 step 81 is completed and loss is 8.743615762796253e-05

 step 82 is completed and loss is 0.00016228805179707706

 step 83 is completed and loss is 0.00017939247481990606

 step 84 is completed and loss is 8.719732431927696e-05

 step 85 is completed and loss is 0.00013910756388213485

 step 86 is completed and loss is 9.107174992095679e-05

 step 87 is completed and loss is 0.0001448276307201013

 step 88 is completed and loss is 0.00016240343393292278

 step 89 is completed and loss is 7.235676457639784e-05

 step 90 is completed and loss is 0.0004474713059607893

 step 91 is completed and loss is 0.00010030777775682509
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:35,  1.39it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:32,  1.47it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:02<00:31,  1.49it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:31,  1.48it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:30,  1.46it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:04<00:29,  1.49it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.49it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.47it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:06<00:27,  1.48it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.49it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.49it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:08<00:25,  1.46it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.52it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.48it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:10<00:23,  1.47it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.48it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.47it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:12<00:21,  1.48it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:21,  1.46it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:20,  1.45it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:14<00:20,  1.43it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:15<00:19,  1.42it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:18,  1.43it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:16<00:18,  1.42it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:17<00:17,  1.44it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:17,  1.41it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:18<00:16,  1.44it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:19<00:15,  1.43it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:20<00:15,  1.38it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:20<00:13,  1.43it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:21<00:13,  1.46it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.49it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:22<00:11,  1.46it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:23<00:11,  1.42it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:24<00:10,  1.43it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:24<00:09,  1.44it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:25<00:09,  1.43it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:26<00:08,  1.40it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:26<00:07,  1.42it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:27<00:06,  1.45it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:28<00:06,  1.47it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:28<00:05,  1.50it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:29<00:04,  1.56it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:30<00:03,  1.58it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:30<00:03,  1.62it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:31<00:02,  1.65it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:31<00:01,  1.65it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:32<00:01,  1.60it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:33<00:00,  1.58it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.56it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:33<00:00,  1.48it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 99: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 307.49102244200185s
Training Epoch99:   0%|[34m          [0m| 0/92 [00:00<?, ?it/s]Training Epoch99:   1%|[34m          [0m| 1/92 [00:03<04:59,  3.29s/it]Training Epoch99:   2%|[34mâ–         [0m| 2/92 [00:06<04:54,  3.27s/it]Training Epoch99:   3%|[34mâ–Ž         [0m| 3/92 [00:09<04:51,  3.27s/it]Training Epoch99:   4%|[34mâ–         [0m| 4/92 [00:13<04:47,  3.27s/it]Training Epoch99:   5%|[34mâ–Œ         [0m| 5/92 [00:16<04:42,  3.25s/it]Training Epoch99:   7%|[34mâ–‹         [0m| 6/92 [00:19<04:40,  3.27s/it]Training Epoch99:   8%|[34mâ–Š         [0m| 7/92 [00:22<04:40,  3.30s/it]Training Epoch99:   9%|[34mâ–Š         [0m| 8/92 [00:26<04:37,  3.30s/it]Training Epoch99:  10%|[34mâ–‰         [0m| 9/92 [00:29<04:33,  3.30s/it]Training Epoch99:  11%|[34mâ–ˆ         [0m| 10/92 [00:32<04:29,  3.29s/it]Training Epoch99:  12%|[34mâ–ˆâ–        [0m| 11/92 [00:36<04:27,  3.31s/it]Training Epoch99:  13%|[34mâ–ˆâ–Ž        [0m| 12/92 [00:39<04:25,  3.31s/it]Training Epoch99:  14%|[34mâ–ˆâ–        [0m| 13/92 [00:42<04:18,  3.27s/it]Training Epoch99:  15%|[34mâ–ˆâ–Œ        [0m| 14/92 [00:45<04:13,  3.25s/it]Training Epoch99:  16%|[34mâ–ˆâ–‹        [0m| 15/92 [00:49<04:08,  3.23s/it]Training Epoch99:  17%|[34mâ–ˆâ–‹        [0m| 16/92 [00:52<04:09,  3.29s/it]Training Epoch99:  18%|[34mâ–ˆâ–Š        [0m| 17/92 [00:55<04:04,  3.26s/it]Training Epoch99:  20%|[34mâ–ˆâ–‰        [0m| 18/92 [00:59<04:05,  3.32s/it]Training Epoch99:  21%|[34mâ–ˆâ–ˆ        [0m| 19/92 [01:02<04:01,  3.30s/it]Training Epoch99:  22%|[34mâ–ˆâ–ˆâ–       [0m| 20/92 [01:05<03:57,  3.30s/it]Training Epoch99:  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 21/92 [01:08<03:53,  3.28s/it]Training Epoch99:  24%|[34mâ–ˆâ–ˆâ–       [0m| 22/92 [01:12<03:50,  3.30s/it]Training Epoch99:  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 23/92 [01:15<03:50,  3.34s/it]Training Epoch99:  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 24/92 [01:18<03:45,  3.31s/it]Training Epoch99:  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 25/92 [01:22<03:42,  3.32s/it]Training Epoch99:  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 26/92 [01:25<03:38,  3.31s/it]Training Epoch99:  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 27/92 [01:28<03:34,  3.31s/it]Training Epoch99:  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 28/92 [01:32<03:31,  3.30s/it]Training Epoch99:  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 29/92 [01:35<03:29,  3.33s/it]Training Epoch99:  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 30/92 [01:38<03:25,  3.32s/it]Training Epoch99:  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 31/92 [01:42<03:23,  3.33s/it]Training Epoch99:  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/92 [01:45<03:20,  3.35s/it]Training Epoch99:  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 33/92 [01:48<03:16,  3.32s/it]Training Epoch99:  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 34/92 [01:52<03:11,  3.31s/it]Training Epoch99:  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 35/92 [01:55<03:07,  3.29s/it]Training Epoch99:  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 36/92 [01:58<03:03,  3.29s/it]Training Epoch99:  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 37/92 [02:01<03:00,  3.29s/it]Training Epoch99:  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 38/92 [02:05<02:57,  3.29s/it]Training Epoch99:  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 39/92 [02:08<02:55,  3.31s/it]Training Epoch99:  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 40/92 [02:11<02:52,  3.32s/it]Training Epoch99:  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 41/92 [02:15<02:49,  3.33s/it]Training Epoch99:  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 42/92 [02:18<02:46,  3.34s/it]Training Epoch99:  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 43/92 [02:21<02:42,  3.32s/it]Training Epoch99:  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 44/92 [02:25<02:37,  3.29s/it]Training Epoch99:  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 45/92 [02:28<02:33,  3.26s/it]Training Epoch99:  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 46/92 [02:31<02:30,  3.26s/it]Training Epoch99:  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 47/92 [02:34<02:27,  3.28s/it]Training Epoch99:  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 48/92 [02:38<02:24,  3.29s/it]Training Epoch99:  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 49/92 [02:41<02:22,  3.31s/it]Training Epoch99:  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 50/92 [02:44<02:19,  3.31s/it]Training Epoch99:  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 51/92 [02:48<02:15,  3.32s/it]Training Epoch99:  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 52/92 [02:51<02:13,  3.35s/it]Training Epoch99:  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 53/92 [02:54<02:09,  3.33s/it]Training Epoch99:  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 54/92 [02:58<02:06,  3.34s/it]Training Epoch99:  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 55/92 [03:01<02:02,  3.30s/it]Training Epoch99:  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 56/92 [03:04<01:59,  3.32s/it]Training Epoch99:  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 57/92 [03:08<01:57,  3.35s/it]Training Epoch99:  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 58/92 [03:11<01:53,  3.35s/it]Training Epoch99:  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 59/92 [03:14<01:50,  3.33s/it]Training Epoch99:  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 60/92 [03:18<01:47,  3.36s/it]Training Epoch99:  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 61/92 [03:21<01:43,  3.34s/it]Training Epoch99:  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 62/92 [03:24<01:39,  3.32s/it]Training Epoch99:  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 63/92 [03:28<01:36,  3.33s/it]Training Epoch99:  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 64/92 [03:31<01:32,  3.31s/it]Training Epoch99:  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 65/92 [03:34<01:29,  3.31s/it]Training Epoch99:  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 66/92 [03:38<01:25,  3.28s/it]Training Epoch99:  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 67/92 [03:41<01:22,  3.29s/it]Training Epoch99:  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 68/92 [03:44<01:18,  3.29s/it]Training Epoch99:  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 69/92 [03:47<01:15,  3.29s/it]Training Epoch99:  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 70/92 [03:51<01:13,  3.34s/it]Training Epoch99:  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 71/92 [03:54<01:09,  3.32s/it]Training Epoch99:  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 72/92 [03:57<01:05,  3.29s/it]Training Epoch99:  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 73/92 [04:01<01:02,  3.28s/it]Training Epoch99:  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 74/92 [04:04<00:59,  3.29s/it]Training Epoch99:  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 75/92 [04:07<00:56,  3.31s/it]Training Epoch99:  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 76/92 [04:11<00:53,  3.33s/it]Training Epoch99:  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 77/92 [04:14<00:49,  3.33s/it]Training Epoch99:  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 78/92 [04:17<00:46,  3.34s/it]Training Epoch99:  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 79/92 [04:21<00:43,  3.32s/it]Training Epoch99:  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 80/92 [04:24<00:39,  3.32s/it]Training Epoch99:  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 81/92 [04:27<00:36,  3.31s/it]Training Epoch99:  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 82/92 [04:31<00:32,  3.30s/it]Training Epoch99:  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 83/92 [04:34<00:29,  3.29s/it]Training Epoch99:  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 84/92 [04:37<00:26,  3.29s/it]Training Epoch99:  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 85/92 [04:40<00:23,  3.30s/it]Training Epoch99:  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 86/92 [04:44<00:19,  3.32s/it]Training Epoch99:  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 87/92 [04:47<00:16,  3.33s/it]Training Epoch99:  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 88/92 [04:51<00:13,  3.33s/it]Training Epoch99:  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 89/92 [04:54<00:09,  3.33s/it]Training Epoch99:  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 90/92 [04:57<00:06,  3.32s/it]Training Epoch99:  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 91/92 [05:00<00:03,  3.31s/it]Training Epoch99: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.28s/it]Number of tokens in the example:  217
Number of tokens in the example:  318
Number of tokens in the example:  310
Number of tokens in the example:  313
Number of tokens in the example:  313
Number of tokens in the example:  286
Number of tokens in the example:  276
Number of tokens in the example:  257
Number of tokens in the example:  284
Number of tokens in the example:  323
Number of tokens in the example:  273
Number of tokens in the example:  382
Number of tokens in the example:  485
Number of tokens in the example:  328
Number of tokens in the example:  371
Number of tokens in the example:  339
Number of tokens in the example:  313
Number of tokens in the example:  382
Number of tokens in the example:  242
Number of tokens in the example:  381
Number of tokens in the example:  324
Number of tokens in the example:  356
Number of tokens in the example:  363
Number of tokens in the example:  315
Number of tokens in the example:  240
Number of tokens in the example:  334
Number of tokens in the example:  363
Number of tokens in the example:  343
Number of tokens in the example:  262
Number of tokens in the example:  395
Number of tokens in the example:  533
Number of tokens in the example:  287
Number of tokens in the example:  388
Number of tokens in the example:  227
Number of tokens in the example:  397
Number of tokens in the example:  454
Number of tokens in the example:  314
Number of tokens in the example:  374
Number of tokens in the example:  222
Number of tokens in the example:  283
Number of tokens in the example:  309
Number of tokens in the example:  291
Number of tokens in the example:  383
Number of tokens in the example:  217
Number of tokens in the example:  289
Number of tokens in the example:  381
Number of tokens in the example:  464
Number of tokens in the example:  359
Number of tokens in the example:  214
Number of tokens in the example:  306
Number of tokens in the example:  403
Number of tokens in the example:  318
Number of tokens in the example:  290
Number of tokens in the example:  225
Number of tokens in the example:  258
Number of tokens in the example:  293
Number of tokens in the example:  294
Number of tokens in the example:  393
Number of tokens in the example:  234
Number of tokens in the example:  360
Number of tokens in the example:  319
Number of tokens in the example:  291
Number of tokens in the example:  281
Number of tokens in the example:  338
Number of tokens in the example:  217
Number of tokens in the example:  339
Number of tokens in the example:  262
Number of tokens in the example:  257
Number of tokens in the example:  315
Number of tokens in the example:  229
Number of tokens in the example:  334
Number of tokens in the example:  245
Number of tokens in the example:  368
Number of tokens in the example:  338
Number of tokens in the example:  249
Number of tokens in the example:  348
Number of tokens in the example:  327
Number of tokens in the example:  320
Number of tokens in the example:  289
Number of tokens in the example:  178
Number of tokens in the example:  481
Number of tokens in the example:  258
Number of tokens in the example:  351
Number of tokens in the example:  345
Number of tokens in the example:  183
Number of tokens in the example:  372
Number of tokens in the example:  341
Number of tokens in the example:  362
Number of tokens in the example:  347
Number of tokens in the example:  187
Number of tokens in the example:  360
Number of tokens in the example:  256
Number of tokens in the example:  352
Number of tokens in the example:  403
Number of tokens in the example:  220
Number of tokens in the example:  320
Number of tokens in the example:  238
Number of tokens in the example:  280
Number of tokens in the example:  272
Number of tokens in the example:  164
Number of tokens in the example:  444
Number of tokens in the example:  230
Number of tokens in the example:  345
Number of tokens in the example:  300
Number of tokens in the example:  361
Number of tokens in the example:  307
Number of tokens in the example:  205
Number of tokens in the example:  251
Number of tokens in the example:  255
Number of tokens in the example:  301
Number of tokens in the example:  491
Number of tokens in the example:  266
Number of tokens in the example:  367
Number of tokens in the example:  397
Number of tokens in the example:  329
Number of tokens in the example:  355
Number of tokens in the example:  450
Number of tokens in the example:  339
Number of tokens in the example:  320
Number of tokens in the example:  313
Number of tokens in the example:  322
Number of tokens in the example:  247
Number of tokens in the example:  357
Number of tokens in the example:  275
Number of tokens in the example:  403
Number of tokens in the example:  320
Number of tokens in the example:  297
Number of tokens in the example:  307
Number of tokens in the example:  288
Number of tokens in the example:  180
Number of tokens in the example:  287
Number of tokens in the example:  357
Number of tokens in the example:  223
Number of tokens in the example:  272
Number of tokens in the example:  365
Number of tokens in the example:  498
Number of tokens in the example:  309
Number of tokens in the example:  332
Number of tokens in the example:  221
Number of tokens in the example:  325
Number of tokens in the example:  344
Number of tokens in the example:  239
Number of tokens in the example:  341
Number of tokens in the example:  339
Number of tokens in the example:  256
Number of tokens in the example:  397
Number of tokens in the example:  319
Number of tokens in the example:  335
Number of tokens in the example:  309
Number of tokens in the example:  406
Number of tokens in the example:  369
Number of tokens in the example:  345
Number of tokens in the example:  378
Number of tokens in the example:  234
Number of tokens in the example:  290
Number of tokens in the example:  399
Number of tokens in the example:  363
Number of tokens in the example:  223
Number of tokens in the example:  497
Number of tokens in the example:  283
Number of tokens in the example:  434
Number of tokens in the example:  382
Number of tokens in the example:  342
Number of tokens in the example:  334
Number of tokens in the example:  463
Number of tokens in the example:  449
Number of tokens in the example:  358
Number of tokens in the example:  388
Number of tokens in the example:  357
Number of tokens in the example:  375
Number of tokens in the example:  722
Number of tokens in the example:  279
Number of tokens in the example:  422
Number of tokens in the example:  589
Number of tokens in the example:  331
Number of tokens in the example:  412
Number of tokens in the example:  427
Number of tokens in the example:  464
Number of tokens in the example:  255
Number of tokens in the example:  438
Number of tokens in the example:  349
Number of tokens in the example:  349
Number of tokens in the example:  390
Number of tokens in the example:  244
Training Epoch99: 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 92/92 [05:04<00:00,  3.31s/it]

 step 0 is completed and loss is 9.75059301708825e-05

 step 1 is completed and loss is 0.00019959500059485435

 step 2 is completed and loss is 3.7013778637629e-05

 step 3 is completed and loss is 8.129591878969222e-05

 step 4 is completed and loss is 7.032950088614598e-05

 step 5 is completed and loss is 4.112635360797867e-05

 step 6 is completed and loss is 0.0006252573803067207

 step 7 is completed and loss is 6.168839172460139e-05

 step 8 is completed and loss is 7.694663509028032e-05

 step 9 is completed and loss is 4.1424264054512605e-05

 step 10 is completed and loss is 0.00043614301830530167

 step 11 is completed and loss is 0.0004889897536486387

 step 12 is completed and loss is 0.00028174370527267456

 step 13 is completed and loss is 6.186767132021487e-05

 step 14 is completed and loss is 4.17819683207199e-05

 step 15 is completed and loss is 3.40932747349143e-05

 step 16 is completed and loss is 0.00015459595306310803

 step 17 is completed and loss is 0.00010901011410169303

 step 18 is completed and loss is 4.643078500521369e-05

 step 19 is completed and loss is 0.0003065814380533993

 step 20 is completed and loss is 4.577530489768833e-05

 step 21 is completed and loss is 6.311916513368487e-05

 step 22 is completed and loss is 0.0003805228916462511

 step 23 is completed and loss is 9.464697359362617e-05

 step 24 is completed and loss is 6.294048216659576e-05

 step 25 is completed and loss is 0.00027060278807766736

 step 26 is completed and loss is 5.805290493299253e-05

 step 27 is completed and loss is 0.0001862471690401435

 step 28 is completed and loss is 0.00017038673104252666

 step 29 is completed and loss is 8.362179505638778e-05

 step 30 is completed and loss is 9.607707033865154e-05

 step 31 is completed and loss is 1.734475517878309e-05

 step 32 is completed and loss is 9.37520744628273e-05

 step 33 is completed and loss is 8.165495819412172e-05

 step 34 is completed and loss is 6.222529918886721e-05

 step 35 is completed and loss is 0.00020012787717860192

 step 36 is completed and loss is 1.8298431314178742e-05

 step 37 is completed and loss is 8.064183202804998e-05

 step 38 is completed and loss is 0.00010334766557207331

 step 39 is completed and loss is 5.644393968395889e-05

 step 40 is completed and loss is 9.113088162848726e-05

 step 41 is completed and loss is 4.202000855002552e-05

 step 42 is completed and loss is 7.360900053754449e-05

 step 43 is completed and loss is 4.9947026127483696e-05

 step 44 is completed and loss is 2.6404344680486247e-05

 step 45 is completed and loss is 0.00023689219960942864

 step 46 is completed and loss is 2.3662714738748036e-05

 step 47 is completed and loss is 6.222531374078244e-05

 step 48 is completed and loss is 0.00044253579108044505

 step 49 is completed and loss is 0.00010632904013618827

 step 50 is completed and loss is 8.999884448712692e-05

 step 51 is completed and loss is 5.382150266086683e-05

 step 52 is completed and loss is 0.0023755610454827547

 step 53 is completed and loss is 0.0002918363898061216

 step 54 is completed and loss is 3.242438469897024e-05

 step 55 is completed and loss is 0.0012445546453818679

 step 56 is completed and loss is 3.892105451086536e-05

 step 57 is completed and loss is 0.00014869769802317023

 step 58 is completed and loss is 7.509734859922901e-05

 step 59 is completed and loss is 0.0004212561761960387

 step 60 is completed and loss is 0.00012206238170620054

 step 61 is completed and loss is 8.504992729285732e-05

 step 62 is completed and loss is 9.23810584936291e-05

 step 63 is completed and loss is 0.000650511123239994

 step 64 is completed and loss is 0.0002237089502159506

 step 65 is completed and loss is 7.53371641621925e-05

 step 66 is completed and loss is 0.0005512073985300958

 step 67 is completed and loss is 5.155630424269475e-05

 step 68 is completed and loss is 0.00017134810332208872

 step 69 is completed and loss is 0.00012069118383806199

 step 70 is completed and loss is 0.0001612165360711515

 step 71 is completed and loss is 0.00022794924734625965

 step 72 is completed and loss is 0.0005087280296720564

 step 73 is completed and loss is 9.387290629092604e-05

 step 74 is completed and loss is 0.00010591177851893008

 step 75 is completed and loss is 0.0003046432393603027

 step 76 is completed and loss is 0.0001363065093755722

 step 77 is completed and loss is 8.248903031926602e-05

 step 78 is completed and loss is 0.00015853525837883353

 step 79 is completed and loss is 0.0007341699674725533

 step 80 is completed and loss is 0.0002958325785584748

 step 81 is completed and loss is 9.482625318923965e-05

 step 82 is completed and loss is 0.00018528786313254386

 step 83 is completed and loss is 0.00018803235434461385

 step 84 is completed and loss is 0.00010465888772159815

 step 85 is completed and loss is 0.00013529339048545808

 step 86 is completed and loss is 0.00010513706365600228

 step 87 is completed and loss is 0.00016276539827231318

 step 88 is completed and loss is 0.00020107223826926202

 step 89 is completed and loss is 6.633755401708186e-05

 step 90 is completed and loss is 0.0005713969003409147

 step 91 is completed and loss is 0.00014905435091350228
Max CUDA memory allocated was 14 GB
Max CUDA memory reserved was 16 GB
Peak active CUDA memory was 14 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 0 GB
evaluating Epoch:   0%|[32m          [0m| 0/50 [00:00<?, ?it/s]evaluating Epoch:   2%|[32mâ–         [0m| 1/50 [00:00<00:30,  1.60it/s]evaluating Epoch:   4%|[32mâ–         [0m| 2/50 [00:01<00:29,  1.63it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 3/50 [00:01<00:29,  1.59it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 4/50 [00:02<00:28,  1.59it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 5/50 [00:03<00:27,  1.63it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 6/50 [00:03<00:28,  1.55it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 7/50 [00:04<00:28,  1.49it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 8/50 [00:05<00:28,  1.46it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 9/50 [00:05<00:27,  1.47it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 10/50 [00:06<00:26,  1.50it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 11/50 [00:07<00:26,  1.47it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 12/50 [00:07<00:25,  1.50it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 13/50 [00:08<00:24,  1.50it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 14/50 [00:09<00:24,  1.48it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 15/50 [00:09<00:23,  1.49it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 16/50 [00:10<00:22,  1.52it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 17/50 [00:11<00:22,  1.49it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 18/50 [00:11<00:21,  1.48it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 19/50 [00:12<00:20,  1.49it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 20/50 [00:13<00:19,  1.52it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 21/50 [00:13<00:19,  1.48it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 22/50 [00:14<00:18,  1.51it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 23/50 [00:15<00:17,  1.54it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 24/50 [00:15<00:16,  1.58it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 25/50 [00:16<00:15,  1.59it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 26/50 [00:17<00:16,  1.48it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 27/50 [00:17<00:15,  1.50it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 28/50 [00:18<00:14,  1.48it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 29/50 [00:19<00:14,  1.44it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 30/50 [00:19<00:13,  1.45it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 31/50 [00:20<00:12,  1.46it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 32/50 [00:21<00:12,  1.45it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 33/50 [00:21<00:11,  1.46it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 34/50 [00:22<00:10,  1.48it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 35/50 [00:23<00:09,  1.50it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 36/50 [00:23<00:09,  1.52it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 37/50 [00:24<00:08,  1.51it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 38/50 [00:25<00:07,  1.52it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 39/50 [00:25<00:07,  1.52it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 40/50 [00:26<00:06,  1.51it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 41/50 [00:27<00:05,  1.52it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 42/50 [00:27<00:05,  1.53it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 43/50 [00:28<00:04,  1.52it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 44/50 [00:29<00:03,  1.53it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 45/50 [00:29<00:03,  1.56it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 46/50 [00:30<00:02,  1.62it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 47/50 [00:30<00:01,  1.63it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 48/50 [00:31<00:01,  1.59it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 49/50 [00:32<00:00,  1.60it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.59it/s]Number of tokens in the example:  341
Number of tokens in the example:  366
Number of tokens in the example:  462
Number of tokens in the example:  431
Number of tokens in the example:  281
Number of tokens in the example:  327
Number of tokens in the example:  372
Number of tokens in the example:  364
Number of tokens in the example:  308
Number of tokens in the example:  291
Number of tokens in the example:  353
Number of tokens in the example:  328
Number of tokens in the example:  337
Number of tokens in the example:  343
Number of tokens in the example:  417
Number of tokens in the example:  271
Number of tokens in the example:  300
Number of tokens in the example:  244
Number of tokens in the example:  238
Number of tokens in the example:  270
Number of tokens in the example:  311
Number of tokens in the example:  261
Number of tokens in the example:  386
Number of tokens in the example:  204
Number of tokens in the example:  364
Number of tokens in the example:  202
Number of tokens in the example:  270
Number of tokens in the example:  349
Number of tokens in the example:  438
Number of tokens in the example:  351
Number of tokens in the example:  378
Number of tokens in the example:  315
Number of tokens in the example:  328
Number of tokens in the example:  229
Number of tokens in the example:  252
Number of tokens in the example:  200
Number of tokens in the example:  213
Number of tokens in the example:  571
Number of tokens in the example:  241
Number of tokens in the example:  256
Number of tokens in the example:  401
Number of tokens in the example:  346
Number of tokens in the example:  251
Number of tokens in the example:  411
Number of tokens in the example:  336
Number of tokens in the example:  427
Number of tokens in the example:  347
Number of tokens in the example:  295
Number of tokens in the example:  247
Number of tokens in the example:  341
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 50/50 [00:32<00:00,  1.52it/s]
 eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0') eval_acc=tensor(0.6200)
Epoch 100: train_perplexity=1.0002, train_epoch_loss=0.0002, epcoh time 304.43316480499925s
Key: avg_train_prep, Value: 1.0243010520935059
Key: avg_train_loss, Value: 0.019363243132829666
Key: avg_eval_prep, Value: nan
Key: avg_eval_loss, Value: 0.7773994207382202
Key: avg_epoch_time, Value: 304.1779570446898
Key: avg_checkpoint_time, Value: 0.022590207030061718
